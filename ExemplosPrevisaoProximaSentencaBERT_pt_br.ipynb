{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osmarbraz/exemplos_BERT/blob/main/ExemplosPrevisaoProximaSentencaBERT_pt_br.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78HE8FLsKN9Q"
      },
      "source": [
        "#Exemplo de Previsão Próxima Sentença usando BERT Transformers by HuggingFace\n",
        "\n",
        "## **A execução pode ser feita através do menu Ambiente de Execução opção Executar tudo.**\n",
        "\n",
        "Exemplos **Previsão Próxima Sentença** usando **BERT**.\n",
        "\n",
        "**Link biblioteca Huggingface:**\n",
        "https://github.com/huggingface/transformers\n",
        "\n",
        "\n",
        "**Artigo original BERT Jacob Devlin:**\n",
        "https://arxiv.org/pdf/1506.06724.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyxb5Px3p1-e"
      },
      "source": [
        "## 0 - Preparação do ambiente\n",
        "Preparação do ambiente para execução do exemplo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAPVtRXQqDim"
      },
      "source": [
        "###Tratamento de logs\n",
        "\n",
        "Método para tratamento dos logs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcopxbGZqDip"
      },
      "outputs": [],
      "source": [
        "#biblioteca de logging\n",
        "import logging\n",
        "\n",
        "#formatando a mensagem de logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GjYtXcMnSAe"
      },
      "source": [
        "### Identificando o ambiente Colab\n",
        "\n",
        "Cria uma variável para identificar que o notebook está sendo executado no Google Colaboratory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMiH0E3OnRa1"
      },
      "outputs": [],
      "source": [
        "#se estiver executando no Google Colaboratory\n",
        "import sys\n",
        "#retorna true ou false se estiver no Google Colaboratory\n",
        "IN_COLAB = 'google.colab' in sys.modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqa-7WXBAw8q"
      },
      "source": [
        "## 1 - Instalação BERT da Hugging Face"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCdqJCtQN52l"
      },
      "source": [
        "Instala a interface pytorch para o BERT by Hugging Face. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RfUN_KolV-f",
        "outputId": "c0c7ed04-215f-4197-95e4-d6a655123dfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.5.1\n",
            "  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 14.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.8.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.62.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 50.4 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 50.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (1.19.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.1) (3.0.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.1.0)\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.5.1\n"
          ]
        }
      ],
      "source": [
        "# Instala a última versão da biblioteca\n",
        "#!pip install transformers\n",
        "\n",
        "# Instala uma versão específica da biblioteca\n",
        "!pip install -U transformers==4.5.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQj2wmKDpkrH"
      },
      "source": [
        "## 2 - Download do arquivo do PyTorch Checkpoint\n",
        "\n",
        "Lista de modelos da comunidade:\n",
        "* https://huggingface.co/models\n",
        "\n",
        "Português(https://github.com/neuralmind-ai/portuguese-bert):  \n",
        "* **'neuralmind/bert-base-portuguese-cased'**\n",
        "* **'neuralmind/bert-large-portuguese-cased'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajrTjZzapkrK",
        "outputId": "f59e3232-f2ab-48e1-a6e0-7651b2ea710b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-10 20:26:30--  https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\n",
            "Resolving neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)... 52.219.104.176\n",
            "Connecting to neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)|52.219.104.176|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1244275810 (1.2G) [application/zip]\n",
            "Saving to: ‘bert-large-portuguese-cased_pytorch_checkpoint.zip’\n",
            "\n",
            "bert-large-portugue 100%[===================>]   1.16G  30.1MB/s    in 43s     \n",
            "\n",
            "2021-12-10 20:27:13 (27.6 MB/s) - ‘bert-large-portuguese-cased_pytorch_checkpoint.zip’ saved [1244275810/1244275810]\n",
            "\n",
            "Archive:  bert-large-portuguese-cased_pytorch_checkpoint.zip\n",
            "  inflating: /content/modelo/config.json  \n",
            "  inflating: /content/modelo/pytorch_model.bin  \n",
            "--2021-12-10 20:27:29--  https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/vocab.txt\n",
            "Resolving neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)... 52.219.101.106\n",
            "Connecting to neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)|52.219.101.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 209528 (205K) [text/plain]\n",
            "Saving to: ‘vocab.txt’\n",
            "\n",
            "vocab.txt           100%[===================>] 204.62K   711KB/s    in 0.3s    \n",
            "\n",
            "2021-12-10 20:27:29 (711 KB/s) - ‘vocab.txt’ saved [209528/209528]\n",
            "\n",
            "Pasta do /content/modelo pronta!\n",
            "total 2525908\n",
            "drwxr-xr-x 2 root root       4096 Dec 10 20:27 .\n",
            "drwxr-xr-x 1 root root       4096 Dec 10 20:27 ..\n",
            "-rw-r--r-- 1 root root 1244275810 Jan 22  2020 bert-large-portuguese-cased_pytorch_checkpoint.zip\n",
            "-rw-rw-r-- 1 root root        874 Jan 12  2020 config.json\n",
            "-rw-rw-r-- 1 root root 1342014951 Jan 12  2020 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root     209528 Jan 21  2020 vocab.txt\n"
          ]
        }
      ],
      "source": [
        "# Importando as bibliotecas\n",
        "import os\n",
        "\n",
        "# Variável para setar o arquivo\n",
        "URL_MODELO = None\n",
        "\n",
        "# Comente uma das urls para carregar modelos de tamanhos diferentes(base/large)\n",
        "# URL_MODELO do arquivo do modelo tensorflow\n",
        "# arquivo menor(base) 1.1 Gbytes\n",
        "#URL_MODELO = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "# arquivo grande(large) 3.5 Gbytes\n",
        "URL_MODELO = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "# Se a variável foi setada\n",
        "if URL_MODELO:\n",
        "\n",
        "    # Diretório descompactação\n",
        "    DIRETORIO_MODELO = '/content/modelo'\n",
        "\n",
        "    # Recupera o nome do arquivo do modelo da URL_MODELO\n",
        "    arquivo = URL_MODELO.split(\"/\")[-1]\n",
        "\n",
        "    # Nome do arquivo do vocabulário\n",
        "    arquivo_vocab = \"vocab.txt\"\n",
        "\n",
        "    # Caminho do arquivo na URL_MODELO\n",
        "    caminho = URL_MODELO[0:len(URL_MODELO)-len(arquivo)]\n",
        "\n",
        "    # Verifica se a pasta de descompactação existe na pasta corrente\n",
        "    if os.path.exists(DIRETORIO_MODELO):\n",
        "      print(\"Apagando diretório existente do modelo!\")\n",
        "      # Apaga a pasta e os arquivos existentes\n",
        "      !rm -rf $DIRETORIO_MODELO    \n",
        "\n",
        "    # Baixa o arquivo do modelo\n",
        "    !wget $URL_MODELO\n",
        "    \n",
        "    # Descompacta o arquivo na pasta de descompactação\n",
        "    !unzip -o $arquivo -d $DIRETORIO_MODELO\n",
        "\n",
        "    # Baixa o arquivo do vocabulário\n",
        "    # O vocabulário não está no arquivo compactado acima, mesma url mas arquivo diferente\n",
        "    URL_MODELO_VOCAB = caminho + arquivo_vocab\n",
        "    !wget $URL_MODELO_VOCAB\n",
        "    \n",
        "    # Coloca o arquivo do vocabulário no diretório de descompactação\n",
        "    !mv $arquivo_vocab $DIRETORIO_MODELO\n",
        "            \n",
        "    # Move o arquivo para pasta de descompactação\n",
        "    !mv $arquivo $DIRETORIO_MODELO\n",
        "       \n",
        "    print('Pasta do ' + DIRETORIO_MODELO + ' pronta!')\n",
        "    \n",
        "    # Lista a pasta corrente\n",
        "    !ls -la $DIRETORIO_MODELO\n",
        "else:\n",
        "    print('Variável URL_MODELO não setada!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcpd9t9PpkrX"
      },
      "source": [
        "## 3 - Carregando o Tokenizador BERT\n",
        "\n",
        "O tokenizador utiliza WordPiece, veja em [artigo original](https://arxiv.org/pdf/1609.08144.pdf).\n",
        "\n",
        "Carregando o tokenizador da pasta '/content/modelo/' do diretório padrão se variável `URL_MODELO` setada.\n",
        "\n",
        "**Caso contrário carrega da comunidade**\n",
        "\n",
        "Por default(`do_lower_case=True`) todas as letras são colocadas para minúsculas. Para ignorar a conversão para minúsculo use o parâmetro `do_lower_case=False`. Esta opção também considera as letras acentuadas(ãçéí...), que são necessárias a língua portuguesa.\n",
        "\n",
        "O parâmetro `do_lower_case` interfere na quantidade tokens a ser gerado apartir de um texto. Quando igual a `False` reduz a quantidade de tokens gerados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8cKVs4fpkrY",
        "outputId": "7ee25355-975c-402c-bd55-c50b68be76e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carrgando o tokenizador BERT do diretório /content/modelo...\n"
          ]
        }
      ],
      "source": [
        "# Importando as bibliotecas do tokenizador\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = None\n",
        "\n",
        "# Se a variável URL_MODELO foi setada\n",
        "if URL_MODELO:\n",
        "    # Carregando o Tokenizador\n",
        "    print('Carrgando o tokenizador BERT do diretório ' + DIRETORIO_MODELO + '...')\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(DIRETORIO_MODELO, \n",
        "                                              do_lower_case=False)    \n",
        "else:\n",
        "    # Carregando o Tokenizador da comunidade\n",
        "    print('Carregando o tokenizador da comunidade...')\n",
        "    \n",
        "    #tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=False)\n",
        "    tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-large-portuguese-cased', do_lower_case=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m__On2g1a--K"
      },
      "source": [
        "## 4 - Carregando o Modelo BERT(BertForNextSentencePrediction)\n",
        "\n",
        "Se a variável `URL_MODELO` estiver setada carrega o modelo do diretório `content/modelo`.\n",
        "\n",
        "Caso contrário carrega da comunidade.\n",
        "\n",
        "Carregando o modelo da pasta '/content/modelo/' do diretório padrão.\n",
        "\n",
        "A implementação do huggingface pytorch inclui um conjunto de interfaces projetadas para uma variedade de tarefas de PNL. Embora essas interfaces sejam todas construídas sobre um modelo treinado de BERT, cada uma possui diferentes camadas superiores e tipos de saída projetados para acomodar suas tarefas específicas de PNL.\n",
        "\n",
        "A documentação para estas pode ser encontrada em [aqui](https://huggingface.co/transformers/model_doc/bert.html#bertfornextsentenceprediction).\n",
        "\n",
        "Por default o modelo está em modo avaliação ou seja `model.eval()`.\n",
        "\n",
        "-----------------------\n",
        "\n",
        "Durante a avaliação do modelo, este retorna um número de diferentes objetos com base em como é configurado na chamada do método `from_pretrained`. \n",
        "\n",
        "Quando definimos `output_hidden_states = True` na chamada do método `from_pretrained`, retorno do modelo possui no terceiro item os estados ocultos(**hidden_states**) de todas as camadas.  Veja a documentação para mais detalhes: https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "\n",
        "Quando **`output_hidden_states = True`** model retorna:\n",
        "- outputs[0] = last_hidden_state;\n",
        "- outputs[1] = pooler_output; \n",
        "- outputs[2] = hidden_states.\n",
        "\n",
        "Quando **`output_hidden_states = False`** ou não especificado model retorna:\n",
        "- outputs[0] = last_hidden_state;\n",
        "- outputs[1] = pooler_output.\n",
        "\n",
        "\n",
        "**ATENÇÃO**: O parâmetro ´**output_hidden_states = True**´ habilita gerar as camadas ocultas do modelo. Caso contrário somente a última camada é mantida. Este parâmetro otimiza a memória mas não os resultados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRV6l_I-qg9s",
        "outputId": "aed74419-799d-4275-ec70-cb6526545b34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando o modelo BERT do diretório /content/modelo...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/modelo were not used when initializing BertForNextSentencePrediction: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# Importando as bibliotecas do Modelo\n",
        "from transformers import BertForNextSentencePrediction\n",
        "\n",
        "# Se a variável URL_MODELO1 foi setada\n",
        "if URL_MODELO:\n",
        "    # Carregando o modelo\n",
        "    print('Carregando o modelo BERT do diretório ' + DIRETORIO_MODELO + '...')\n",
        "\n",
        "    model = BertForNextSentencePrediction.from_pretrained(DIRETORIO_MODELO, \n",
        "                                      output_hidden_states = True)    \n",
        "else:\n",
        "    # Carregando o modelo da comunidade\n",
        "    print('Carregando o modelo BERT da comunidade ...')\n",
        "\n",
        "    model = BertForNextSentencePrediction.from_pretrained('neuralmind/bert-large-portuguese-cased', \n",
        "                                       output_hidden_states = True)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgnApndAsiGm",
        "outputId": "84efc15d-0d1c-4acf-cda4-d28fb1132a03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForNextSentencePrediction(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(29794, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyNSPHead(\n",
              "    (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIU-LMRnI8TZ"
      },
      "source": [
        "## 5 - Função de previsão da próxima sentença com probabilidades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcSx0uhoI8d1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def pontuacaoSentenca(entrada, candidato):\t\t\t\n",
        "  # Adiciona os tokens especiais ao texto\n",
        "  texto_marcado = \"[CLS] \" + entrada + \" [SEP] \" + candidato + \" [SEP]\"\n",
        "  #print(\"texto_marcado:\", texto_marcado)\n",
        "  \n",
        "  # Divide a sentenças em tokens\n",
        "  texto_tokenizado = tokenizer.tokenize(texto_marcado)    \n",
        "  #print(\"texto_tokenizado:\", texto_tokenizado\n",
        "\n",
        "  # Mapeia os tokens em seus índices do vocabulario\n",
        "  tokens_indexados = tokenizer.convert_tokens_to_ids(texto_tokenizado)\n",
        "  #print(\"tokens_indexados:\", tokens_indexados)\n",
        "\n",
        "  # Converte as entradas de lista para tensores do torch\n",
        "  tokens_tensores = torch.tensor([tokens_indexados])\n",
        "  \n",
        "  with torch.no_grad():\n",
        "\t  # Submete o texto ao modela\n",
        "    outputs = model(tokens_tensores)  \n",
        "\t# outputs é uma matriz com perdas como o primeiro valor e logits como o segundo\n",
        "  # outputs[0] = last_hidden_state\n",
        "  # outputs[0][0] é igual outputs.logits[0]. Logits retorna dois valores, referenciado pelo terceiro índice.      \n",
        "  # A função `.item()` retorna apenas o valor Python do tensor.       \n",
        "  print(\"Saída:\",outputs[0][0])\n",
        "  \n",
        "  # Calcula a média das probabildades\n",
        "  pontuacao = torch.mean(outputs.logits[0])   \n",
        "  #print(candidato, \":\", pontuacao)\n",
        "  return pontuacao"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj0JqtVxmlXm"
      },
      "source": [
        "## 6 - Exemplos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySIv8YYlmWid"
      },
      "source": [
        "### Comparando sentenças"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ron7ab4pKYiW",
        "outputId": "00eeb137-bd7e-4cee-f800-c84b031e3388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentença 1: Hoje está calor.\n",
            "Sentença 2: Vamos a praia.\n",
            "Saída: tensor([ 0.6251, -0.9251])\n",
            "Resultado da relação da sentença 2: tensor(-0.1500)\n",
            "\n",
            "Sentença 1: Hoje está calor.\n",
            "Sentença 3: O carro estragou.\n",
            "Saída: tensor([0.1169, 0.5731])\n",
            "Resultado da relação da sentença 3: tensor(0.3450)\n",
            "\n",
            "Sentença 3: O carro estragou.\n",
            "Sentença 4: Vou levar a oficina.\n",
            "Saída: tensor([ 0.9069, -1.0739])\n",
            "Resultado da relação da sentença 4: tensor(-0.0835)\n",
            "\n",
            "Sentença 3: O carro estragou.\n",
            "Sentença 1: Hoje está calor.\n",
            "Saída: tensor([ 0.2409, -0.0578])\n",
            "Resultado da relação da sentença 1: tensor(0.0916)\n"
          ]
        }
      ],
      "source": [
        "sentenca1 = \"Hoje está calor.\"\n",
        "sentenca2 = \"Vamos a praia.\"\n",
        "sentenca3 = \"O carro estragou.\"\n",
        "sentenca4 = \"Vou levar a oficina.\"\n",
        "\n",
        "print(\"Sentença 1:\", sentenca1)\n",
        "print(\"Sentença 2:\", sentenca2)\n",
        "resultado = pontuacaoSentenca(sentenca1, sentenca2)\n",
        "print(\"Resultado da relação da sentença 2:\", resultado)\n",
        "\n",
        "print(\"\\nSentença 1:\", sentenca1)\n",
        "print(\"Sentença 3:\", sentenca3)\n",
        "resultado = pontuacaoSentenca(sentenca1, sentenca3)\n",
        "print(\"Resultado da relação da sentença 3:\", resultado)\n",
        "\n",
        "print(\"\\nSentença 3:\", sentenca3)\n",
        "print(\"Sentença 4:\", sentenca4)\n",
        "resultado = pontuacaoSentenca(sentenca3, sentenca4)\n",
        "print(\"Resultado da relação da sentença 4:\", resultado)\n",
        "\n",
        "print(\"\\nSentença 3:\", sentenca3)\n",
        "print(\"Sentença 1:\", sentenca1)\n",
        "resultado = pontuacaoSentenca(sentenca3, sentenca1)\n",
        "print(\"Resultado da relação da sentença 1:\", resultado)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOj1d8N3ZKYy"
      },
      "source": [
        "### Comparando uma sequência de sentenças 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZAPmtizZKiI",
        "outputId": "7a5c0006-60c2-4b73-cf23-12cfe59864fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saída: tensor([ 0.8284, -0.1576])\n",
            "Fui de carro.  =>  O caminhão tombou. : tensor(0.3354)\n",
            "Saída: tensor([ 0.5830, -0.0621])\n",
            "O caminhão tombou.  =>  O ônibus atrasou. : tensor(0.2605)\n",
            "Total sentenças: 3\n",
            "Total: tensor(0.5959)\n",
            "Média: tensor(0.1986)\n"
          ]
        }
      ],
      "source": [
        "# Define um texto\n",
        "texto = ['Fui de carro.',\n",
        "         'O caminhão tombou.',              \n",
        "         'O ônibus atrasou.']\n",
        "\n",
        "total = 0\n",
        "for i in range(len(texto)-1):\n",
        "    pontuacao = pontuacaoSentenca(texto[i], texto[i+1])\n",
        "    total = total + abs(pontuacao)\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", pontuacao)\n",
        "\n",
        "print(\"Total sentenças:\", len(texto))\n",
        "print(\"Total:\",total)\n",
        "print(\"Média:\",total/len(texto))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7WZwQpwZkVy"
      },
      "source": [
        "### Comparando uma sequência de sentenças 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQVQC8aZjr5",
        "outputId": "29117323-b7d9-4e14-a90a-c96b414fbd61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saída: tensor([0.1706, 0.7546])\n",
            "O gato saiu correndo.  =>  O cachorro latiu. : tensor(0.4626)\n",
            "Saída: tensor([-0.0530, -0.1603])\n",
            "O cachorro latiu.  =>  O passáro está no ninho. : tensor(-0.1066)\n",
            "Total sentenças: 3\n",
            "Total: tensor(0.5692)\n",
            "Média: tensor(0.1897)\n"
          ]
        }
      ],
      "source": [
        "# Define um texto com a permutação das sentenças do texto original\n",
        "texto = ['O gato saiu correndo.',   \n",
        "             'O cachorro latiu.',             \n",
        "             'O passáro está no ninho.']    \n",
        "\n",
        "total = 0\n",
        "for i in range(len(texto)-1):\n",
        "    pontuacao = pontuacaoSentenca(texto[i], texto[i+1])\n",
        "    total = total + abs(pontuacao)\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", pontuacao)\n",
        "\n",
        "print(\"Total sentenças:\", len(texto))\n",
        "print(\"Total:\",total)\n",
        "print(\"Média:\",total/len(texto))           "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE4FTWikZRQH"
      },
      "source": [
        "### Comparando texto original com permutado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4n0fHITZRXo",
        "outputId": "98cabc00-42d4-406b-bce1-dcb8a99eea25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto Original\n",
            "Saída: tensor([ 1.5311, -0.2564])\n",
            "Bom Dia, professor.  =>  Qual o conteúdo da prova? : tensor(0.6373)\n",
            "Saída: tensor([0.8600, 0.5956])\n",
            "Qual o conteúdo da prova?  =>  Vai cair tudo na prova? : tensor(0.7278)\n",
            "Saída: tensor([ 1.4897, -1.0947])\n",
            "Vai cair tudo na prova?  =>  Aguardo uma resposta, João. : tensor(0.1975)\n",
            "Total sentenças: 4\n",
            "Total: tensor(1.5627)\n",
            "Média: tensor(0.3907)\n",
            "\n",
            "Texto permutado\n",
            "Saída: tensor([ 1.5511, -0.4897])\n",
            "Aguardo uma resposta, João.  =>  Qual o conteúdo da prova? : tensor(0.5307)\n",
            "Saída: tensor([ 1.0969, -0.0118])\n",
            "Qual o conteúdo da prova?  =>  Bom Dia, professor. : tensor(0.5425)\n",
            "Saída: tensor([1.2152, 0.1825])\n",
            "Bom Dia, professor.  =>  Vai cair tudo na prova? : tensor(0.6988)\n",
            "Total sentenças: 4\n",
            "Total: tensor(1.7721)\n",
            "Média: tensor(0.4430)\n"
          ]
        }
      ],
      "source": [
        "print(\"Texto Original\")\n",
        "\n",
        "# Define um texto com 4 sentenças\n",
        "texto_original = ['Bom Dia, professor.',\n",
        "             'Qual o conteúdo da prova?',              \n",
        "             'Vai cair tudo na prova?',\n",
        "             'Aguardo uma resposta, João.']\n",
        "\n",
        "texto = texto_original\n",
        "\n",
        "total = 0\n",
        "for i in range(len(texto)-1):    \n",
        "    pontuacao = pontuacaoSentenca(texto[i], texto[i+1])\n",
        "    total = total + pontuacao\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", pontuacao)\n",
        "\n",
        "print(\"Total sentenças:\", len(texto))\n",
        "print(\"Total:\",total)\n",
        "print(\"Média:\",total/len(texto))           \n",
        "\n",
        "print(\"\\nTexto permutado\")\n",
        "# Define um texto com a permutação das sentenças do texto original\n",
        "texto = [texto_original[3],   # 'Aguardo uma resposta, João.',\n",
        "             texto_original[1],             # 'Qual o conteúdo da prova?',              \n",
        "             texto_original[0],             # 'Vai cair tudo na prova?',\n",
        "             texto_original[2]]             # 'Bom Dia, professor.']                 \n",
        "\n",
        "total = 0\n",
        "for i in range(len(texto)-1):\n",
        "    pontuacao = pontuacaoSentenca(texto[i], texto[i+1])\n",
        "    total = total + abs(pontuacao)\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", pontuacao)\n",
        "\n",
        "print(\"Total sentenças:\", len(texto))\n",
        "print(\"Total:\",total)\n",
        "print(\"Média:\",total/len(texto))           "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIp96olKnI5e"
      },
      "source": [
        "### Comparando palavras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JQdYZdjnJBe",
        "outputId": "73c6b5fb-4fd9-4ca4-85c7-c4a6e8a3b8e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentença 1: cachorro\n",
            "Sentença 2: gato\n",
            "Saída: tensor([-0.9021,  0.8146])\n",
            "Resultado da relação da sentença 2: tensor(-0.0438)\n",
            "\n",
            "Sentença 1: cachorro\n",
            "Sentença 3: avião\n",
            "Saída: tensor([-0.3603,  0.9946])\n",
            "Resultado da relação da sentença 3: tensor(0.3172)\n",
            "\n",
            "Sentença 3: avião\n",
            "Sentença 4: ônibus\n",
            "Saída: tensor([0.3336, 0.0673])\n",
            "Resultado da relação da sentença 4: tensor(0.2005)\n",
            "\n",
            "Sentença 3: avião\n",
            "Sentença 1: cachorro\n",
            "Saída: tensor([-0.4827,  0.9095])\n",
            "Resultado da relação da sentença 1: tensor(0.2134)\n"
          ]
        }
      ],
      "source": [
        "sentenca1 = \"cachorro\"\n",
        "sentenca2 = \"gato\"\n",
        "sentenca3 = \"avião\"\n",
        "sentenca4 = \"ônibus\"\n",
        "\n",
        "print(\"Sentença 1:\", sentenca1)\n",
        "print(\"Sentença 2:\", sentenca2)\n",
        "resultado = pontuacaoSentenca(sentenca1, sentenca2)\n",
        "print(\"Resultado da relação da sentença 2:\", resultado)\n",
        "\n",
        "print(\"\\nSentença 1:\", sentenca1)\n",
        "print(\"Sentença 3:\", sentenca3)\n",
        "resultado = pontuacaoSentenca(sentenca1, sentenca3)\n",
        "print(\"Resultado da relação da sentença 3:\", resultado)\n",
        "\n",
        "print(\"\\nSentença 3:\", sentenca3)\n",
        "print(\"Sentença 4:\", sentenca4)\n",
        "resultado = pontuacaoSentenca(sentenca3, sentenca4)\n",
        "print(\"Resultado da relação da sentença 4:\", resultado)\n",
        "\n",
        "print(\"\\nSentença 3:\", sentenca3)\n",
        "print(\"Sentença 1:\", sentenca1)\n",
        "resultado = pontuacaoSentenca(sentenca3, sentenca1)\n",
        "print(\"Resultado da relação da sentença 1:\", resultado)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyS0d-ueoIre"
      },
      "source": [
        "### Grupo de palavras relacionadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0mbfQkuoI30",
        "outputId": "cf4a703a-022a-4aeb-a4d5-3e597919da78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grupo palavras\n",
            "Saída: tensor([-0.9021,  0.8146])\n",
            "cachorro  =>  gato : tensor(-0.0438)\n",
            "Saída: tensor([-0.0915,  1.0238])\n",
            "gato  =>  cavalo : tensor(0.4662)\n",
            "Saída: tensor([0.0490, 1.0001])\n",
            "cavalo  =>  zebra : tensor(0.5246)\n",
            "Total sentenças: 4\n",
            "Total: tensor(1.0345)\n",
            "Média: tensor(0.2586)\n"
          ]
        }
      ],
      "source": [
        "print(\"Grupo palavras\")\n",
        "\n",
        "# Define uma lista com 4 palavras\n",
        "texto = ['cachorro',\n",
        "         'gato',              \n",
        "         'cavalo',\n",
        "         'zebra']\n",
        "\n",
        "total = 0\n",
        "for i in range(len(texto)-1):    \n",
        "    pontuacao = pontuacaoSentenca(texto[i], texto[i+1])\n",
        "    total = total + abs(pontuacao)\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", pontuacao)\n",
        "\n",
        "print(\"Total sentenças:\", len(texto))\n",
        "print(\"Total:\",total)\n",
        "print(\"Média:\",total/len(texto))           "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOcKkMhTojIs"
      },
      "source": [
        "### Grupo de palavras relacionadas com ruído"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzccCUMXobm-",
        "outputId": "a9143fce-b6b7-48a5-91e6-87fad7683757"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grupo palavras\n",
            "Saída: tensor([-0.9021,  0.8146])\n",
            "cachorro  =>  gato : tensor(-0.0438)\n",
            "Saída: tensor([0.1469, 1.3691])\n",
            "gato  =>  avião : tensor(0.7580)\n",
            "Saída: tensor([0.2148, 0.8442])\n",
            "avião  =>  zebra : tensor(0.5295)\n",
            "Total sentenças: 4\n",
            "Total: tensor(1.3313)\n",
            "Média: tensor(0.3328)\n"
          ]
        }
      ],
      "source": [
        "print(\"Grupo palavras\")\n",
        "\n",
        "# Define uma lista com 4 palavras\n",
        "texto = ['cachorro',\n",
        "         'gato',              \n",
        "         'avião', #<= Ruído\n",
        "         'zebra']\n",
        "\n",
        "total = 0\n",
        "for i in range(len(texto)-1):    \n",
        "    pontuacao = pontuacaoSentenca(texto[i], texto[i+1])\n",
        "    total = total + abs(pontuacao)\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", pontuacao)\n",
        "\n",
        "print(\"Total sentenças:\", len(texto))\n",
        "print(\"Total:\",total)\n",
        "print(\"Média:\",total/len(texto))           "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0GfzZr3tz43"
      },
      "source": [
        "## 7 - Função de previsão da próxima sentença com softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIp0Sly-t0CF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def previsaoProximaSentenca(entrada, candidato):      \n",
        "  # Adiciona os tokens especiais ao texto\n",
        "  texto_marcado = \"[CLS] \" + entrada + \" [SEP] \" + candidato + \" [SEP]\"\n",
        "  #print(\"texto_marcado:\", texto_marcado)\n",
        "\n",
        "  # Divide a sentenças em tokens\n",
        "  texto_tokenizado = tokenizer.tokenize(texto_marcado)    \n",
        "  #print(\"texto_tokenizado:\", texto_tokenizado\n",
        "\n",
        "  # Mapeia os tokens em seus índices do vocabulario\n",
        "  tokens_indexados = tokenizer.convert_tokens_to_ids(texto_tokenizado)\n",
        "  #print(\"tokens_indexados:\", tokens_indexados)\n",
        "\n",
        "  # Converte as entradas de lista para tensores do torch\n",
        "  tokens_tensores = torch.tensor([tokens_indexados])\n",
        "\n",
        "  # Realiza a predição da sentença\n",
        "  with torch.no_grad():\n",
        "\t  # Submete o texto ao modela\n",
        "    outputs = model(tokens_tensores)  \n",
        "\t  # outputs é uma matriz com perdas como o primeiro valor e logits como o segundo\n",
        "    # outputs[0] = last_hidden_state\n",
        "    # outputs[0][0] é igual outputs.logits[0]. Logits retorna dois valores, referenciado pelo terceiro índice.      \n",
        "    #print(\"Saída:\",outputs[0][0])\n",
        "    \n",
        "  # Normaliza os pesos das predições nos embeddings e calcula sua probabilidade\n",
        "  probabilidades  = torch.nn.functional.softmax(outputs[0], dim=1)\n",
        "  print(\"Probabilidades:\", probabilidades)\n",
        "\n",
        "  # A função `.item()` retorna apenas o valor Python do tensor.\n",
        "  # Torch.argmax retorna o índice da posição do maior valor\n",
        "  previsao = torch.argmax(probabilidades).item()\n",
        "  #print(\"Previsão:\", previsao)\n",
        "\n",
        "  return probabilidades , previsao"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_PZcFRowhqc"
      },
      "source": [
        "### Comparando sentenças"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vGSkOl2ase4",
        "outputId": "448cd6f3-b91c-4025-c3ff-a57fda467ada"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentença 1: O que é uma fila?\n",
            "Sentença 2: Como inserir um elemento em uma fila?\n",
            "Probabilidades: tensor([[0.5512, 0.4488]])\n",
            "Resultado da relação da sentença 2: tensor(0.2134)\n",
            "Probabilidade: tensor([[0.5512, 0.4488]])\n",
            "Previsão     : 0\n"
          ]
        }
      ],
      "source": [
        "sentenca1 = \"O que é uma fila?\"\n",
        "sentenca2 = \"Como inserir um elemento em uma fila?\" \n",
        "\n",
        "print(\"Sentença 1:\", sentenca1)\n",
        "print(\"Sentença 2:\", sentenca2)\n",
        "probabilidade, previsao = previsaoProximaSentenca(sentenca1, sentenca2)\n",
        "print(\"Resultado da relação da sentença 2:\", resultado)\n",
        "print(\"Probabilidade:\", probabilidade)\n",
        "print(\"Previsão     :\", previsao)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH5K-o8sk9fu",
        "outputId": "4c83c671-b229-4fb5-ca93-6b955a41b460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentença 1: O que é uma fila?\n",
            "Sentença 2: Como esvaziar uma pilha?\n",
            "Probabilidades: tensor([[0.3691, 0.6309]])\n",
            "Resultado da relação da sentença 2: tensor(0.2134)\n",
            "Probabilidade: tensor([[0.3691, 0.6309]])\n",
            "Previsão     : 1\n"
          ]
        }
      ],
      "source": [
        "sentenca1 = \"O que é uma fila?\"\n",
        "sentenca2 = \"Como esvaziar uma pilha?\" \n",
        " \n",
        "print(\"Sentença 1:\", sentenca1)\n",
        "print(\"Sentença 2:\", sentenca2)\n",
        "probabilidade, previsao = previsaoProximaSentenca(sentenca1, sentenca2)\n",
        "print(\"Resultado da relação da sentença 2:\", resultado)\n",
        "print(\"Probabilidade:\", probabilidade)\n",
        "print(\"Previsão     :\", previsao)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9FabsFKwhqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10c91667-b8fc-4881-a64d-c9f1ca4cdbe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentença 1: Hoje está calor.\n",
            "Sentença 2: Vamos a praia.\n",
            "Probabilidades: tensor([[0.8249, 0.1751]])\n",
            "Resultado da relação da sentença 2: tensor(0.2134)\n",
            "Probabilidade: tensor([[0.8249, 0.1751]])\n",
            "Previsão     : 0\n",
            "\n",
            "Sentença 1: Hoje está calor.\n",
            "Sentença 3: O carro estragou.\n",
            "Probabilidades: tensor([[0.3879, 0.6121]])\n",
            "Resultado da relação da sentença 3: tensor(0.2134)\n",
            "Probabilidade: tensor([[0.3879, 0.6121]])\n",
            "Previsão     : 1\n",
            "\n",
            "Sentença 3: O carro estragou.\n",
            "Sentença 4: Vou levar a oficina.\n",
            "Probabilidades: tensor([[0.8788, 0.1212]])\n",
            "Resultado da relação da sentença 4: tensor(0.2134)\n",
            "Probabilidade: tensor([[0.8788, 0.1212]])\n",
            "Previsão     : 0\n",
            "\n",
            "Sentença 3: O carro estragou.\n",
            "Sentença 1: Hoje está calor.\n",
            "Probabilidades: tensor([[0.5741, 0.4259]])\n",
            "Resultado da relação da sentença 1: tensor(0.2134)\n",
            "Probabilidade: tensor([[0.5741, 0.4259]])\n",
            "Previsão     : 0\n"
          ]
        }
      ],
      "source": [
        "sentenca1 = \"Hoje está calor.\"\n",
        "sentenca2 = \"Vamos a praia.\"\n",
        "sentenca3 = \"O carro estragou.\"\n",
        "sentenca4 = \"Vou levar a oficina.\"\n",
        "\n",
        "print(\"Sentença 1:\", sentenca1)\n",
        "print(\"Sentença 2:\", sentenca2)\n",
        "probabilidade, previsao = previsaoProximaSentenca(sentenca1, sentenca2)\n",
        "print(\"Resultado da relação da sentença 2:\", resultado)\n",
        "print(\"Probabilidade:\", probabilidade)\n",
        "print(\"Previsão     :\", previsao)\n",
        "\n",
        "print(\"\\nSentença 1:\", sentenca1)\n",
        "print(\"Sentença 3:\", sentenca3)\n",
        "probabilidade, previsao = previsaoProximaSentenca(sentenca1, sentenca3)\n",
        "print(\"Resultado da relação da sentença 3:\", resultado)\n",
        "print(\"Probabilidade:\", probabilidade)\n",
        "print(\"Previsão     :\", previsao)\n",
        "\n",
        "print(\"\\nSentença 3:\", sentenca3)\n",
        "print(\"Sentença 4:\", sentenca4)\n",
        "probabilidade, previsao = previsaoProximaSentenca(sentenca3, sentenca4)\n",
        "print(\"Resultado da relação da sentença 4:\", resultado)\n",
        "print(\"Probabilidade:\", probabilidade)\n",
        "print(\"Previsão     :\", previsao)\n",
        "\n",
        "print(\"\\nSentença 3:\", sentenca3)\n",
        "print(\"Sentença 1:\", sentenca1)\n",
        "probabilidade, previsao = previsaoProximaSentenca(sentenca3, sentenca1)\n",
        "print(\"Resultado da relação da sentença 1:\", resultado)\n",
        "print(\"Probabilidade:\", probabilidade)\n",
        "print(\"Previsão     :\", previsao)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-stq4ZZwT3u"
      },
      "source": [
        "### Comparando uma sequência de sentenças 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrWn5ju2wT3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f5ef9a1-d89f-4e39-fee6-56fe797cac4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probabilidades: tensor([[0.7283, 0.2717]])\n",
            "Fui de carro.  =>  O caminhão tombou. : tensor([[0.7283, 0.2717]])\n",
            "    Probabilidade: tensor([[0.7283, 0.2717]])\n",
            "    Previsao     : 0\n",
            "Probabilidades: tensor([[0.6559, 0.3441]])\n",
            "O caminhão tombou.  =>  O ônibus atrasou. : tensor([[0.6559, 0.3441]])\n",
            "    Probabilidade: tensor([[0.6559, 0.3441]])\n",
            "    Previsao     : 0\n"
          ]
        }
      ],
      "source": [
        "# Define um texto\n",
        "texto = ['Fui de carro.',\n",
        "         'O caminhão tombou.',              \n",
        "         'O ônibus atrasou.']\n",
        "\n",
        "for i in range(len(texto)-1):\n",
        "    probabilidade, previsao = previsaoProximaSentenca(texto[i], texto[i+1])\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", probabilidade)\n",
        "    print(\"    Probabilidade:\", probabilidade)\n",
        "    print(\"    Previsao     :\", previsao)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7dp-bHawT3u"
      },
      "source": [
        "### Comparando uma sequência de sentenças 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwCJNCxDwT3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fef32d8-96c3-422c-f80d-969d8878daf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probabilidades: tensor([[0.3580, 0.6420]])\n",
            "O gato saiu correndo.  =>  O cachorro latiu. : tensor([[0.3580, 0.6420]])\n",
            "    Probabilidade: tensor([[0.3580, 0.6420]])\n",
            "    Previsao     : 1\n",
            "Probabilidades: tensor([[0.5268, 0.4732]])\n",
            "O cachorro latiu.  =>  O passáro está no ninho. : tensor([[0.5268, 0.4732]])\n",
            "    Probabilidade: tensor([[0.5268, 0.4732]])\n",
            "    Previsao     : 0\n"
          ]
        }
      ],
      "source": [
        "# Define um texto com a permutação das sentenças do texto original\n",
        "texto = ['O gato saiu correndo.',   \n",
        "             'O cachorro latiu.',             \n",
        "             'O passáro está no ninho.']    \n",
        "\n",
        "for i in range(len(texto)-1):\n",
        "    probabilidade, previsao = previsaoProximaSentenca(texto[i], texto[i+1])\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", probabilidade)\n",
        "    print(\"    Probabilidade:\", probabilidade)\n",
        "    print(\"    Previsao     :\", previsao)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BucZI8uNwT3v"
      },
      "source": [
        "### Comparando texto original com permutado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJHG6Y2JwT3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6f50a62-305d-47ac-8d2e-1d7b672611ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto Original\n",
            "Probabilidades: tensor([[0.8566, 0.1434]])\n",
            "Bom Dia, professor.  =>  Qual o conteúdo da prova? : tensor([[0.8566, 0.1434]])\n",
            "    Probabilidade: tensor([[0.8566, 0.1434]])\n",
            "    Previsao     : 0\n",
            "Probabilidades: tensor([[0.5657, 0.4343]])\n",
            "Qual o conteúdo da prova?  =>  Vai cair tudo na prova? : tensor([[0.5657, 0.4343]])\n",
            "    Probabilidade: tensor([[0.5657, 0.4343]])\n",
            "    Previsao     : 0\n",
            "Probabilidades: tensor([[0.9299, 0.0701]])\n",
            "Vai cair tudo na prova?  =>  Aguardo uma resposta, João. : tensor([[0.9299, 0.0701]])\n",
            "    Probabilidade: tensor([[0.9299, 0.0701]])\n",
            "    Previsao     : 0\n",
            "\n",
            "Texto permutado\n",
            "Probabilidades: tensor([[0.8850, 0.1150]])\n",
            "Aguardo uma resposta, João.  =>  Qual o conteúdo da prova? : tensor([[0.8850, 0.1150]])\n",
            "    Probabilidade: tensor([[0.8850, 0.1150]])\n",
            "    Previsao     : 0\n",
            "Probabilidades: tensor([[0.7519, 0.2481]])\n",
            "Qual o conteúdo da prova?  =>  Bom Dia, professor. : tensor([[0.7519, 0.2481]])\n",
            "    Probabilidade: tensor([[0.7519, 0.2481]])\n",
            "    Previsao     : 0\n",
            "Probabilidades: tensor([[0.7374, 0.2626]])\n",
            "Bom Dia, professor.  =>  Vai cair tudo na prova? : tensor([[0.7374, 0.2626]])\n",
            "    Probabilidade: tensor([[0.7374, 0.2626]])\n",
            "    Previsao     : 0\n"
          ]
        }
      ],
      "source": [
        "print(\"Texto Original\")\n",
        "\n",
        "# Define um texto com 4 sentenças\n",
        "texto_original = ['Bom Dia, professor.',\n",
        "             'Qual o conteúdo da prova?',              \n",
        "             'Vai cair tudo na prova?',\n",
        "             'Aguardo uma resposta, João.']\n",
        "\n",
        "texto = texto_original\n",
        "\n",
        "for i in range(len(texto)-1):\n",
        "    probabilidade, previsao = previsaoProximaSentenca(texto[i], texto[i+1])\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", probabilidade)\n",
        "    print(\"    Probabilidade:\", probabilidade)\n",
        "    print(\"    Previsao     :\", previsao)\n",
        "\n",
        "print(\"\\nTexto permutado\")\n",
        "# Define um texto com a permutação das sentenças do texto original\n",
        "texto = [texto_original[3],   # 'Aguardo uma resposta, João.',\n",
        "             texto_original[1],             # 'Qual o conteúdo da prova?',              \n",
        "             texto_original[0],             # 'Vai cair tudo na prova?',\n",
        "             texto_original[2]]             # 'Bom Dia, professor.']                 \n",
        "\n",
        "\n",
        "for i in range(len(texto)-1):\n",
        "    probabilidade, previsao = previsaoProximaSentenca(texto[i], texto[i+1])\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", probabilidade)\n",
        "    print(\"    Probabilidade:\", probabilidade)\n",
        "    print(\"    Previsao     :\", previsao)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFekj_F-wT3v"
      },
      "source": [
        "### Comparando palavras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6imhnfd_wT3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b7e33e8-e5ac-4d3e-a34a-da46e672cedf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentença 1: cachorro\n",
            "Sentença 2: gato\n",
            "Probabilidades: tensor([[0.1523, 0.8477]])\n",
            "Probabilidade: tensor([[0.1523, 0.8477]])\n",
            "Previsão     : 1\n",
            "\n",
            "Sentença 1: cachorro\n",
            "Sentença 3: avião\n",
            "Probabilidades: tensor([[0.2051, 0.7949]])\n",
            "Resultado da relação da sentença 3: tensor([[0.2051, 0.7949]])\n",
            "Previsão     : 1\n",
            "\n",
            "Sentença 3: avião\n",
            "Sentença 4: ônibus\n",
            "Probabilidades: tensor([[0.5662, 0.4338]])\n",
            "Resultado da relação da sentença 4: tensor([[0.5662, 0.4338]])\n",
            "Previsão     : 0\n",
            "\n",
            "Sentença 3: avião\n",
            "Sentença 1: cachorro\n",
            "Probabilidades: tensor([[0.1991, 0.8009]])\n",
            "Resultado da relação da sentença 1: tensor([[0.1991, 0.8009]])\n",
            "Previsão     : 1\n"
          ]
        }
      ],
      "source": [
        "sentenca1 = \"cachorro\"\n",
        "sentenca2 = \"gato\"\n",
        "sentenca3 = \"avião\"\n",
        "sentenca4 = \"ônibus\"\n",
        "\n",
        "print(\"Sentença 1:\", sentenca1)\n",
        "print(\"Sentença 2:\", sentenca2)\n",
        "probabilidade, previsao = previsaoProximaSentenca(sentenca1, sentenca2)\n",
        "print(\"Probabilidade:\", probabilidade)\n",
        "print(\"Previsão     :\", previsao)\n",
        "\n",
        "print(\"\\nSentença 1:\", sentenca1)\n",
        "print(\"Sentença 3:\", sentenca3)\n",
        "probabilidade, previsao = previsaoProximaSentenca(sentenca1, sentenca3)\n",
        "print(\"Resultado da relação da sentença 3:\", probabilidade)\n",
        "print(\"Previsão     :\", previsao)\n",
        "\n",
        "print(\"\\nSentença 3:\", sentenca3)\n",
        "print(\"Sentença 4:\", sentenca4)\n",
        "probabilidade, previsao = previsaoProximaSentenca(sentenca3, sentenca4)\n",
        "print(\"Resultado da relação da sentença 4:\", probabilidade)\n",
        "print(\"Previsão     :\", previsao)\n",
        "\n",
        "print(\"\\nSentença 3:\", sentenca3)\n",
        "print(\"Sentença 1:\", sentenca1)\n",
        "probabilidade, previsao = previsaoProximaSentenca(sentenca3, sentenca1)\n",
        "print(\"Resultado da relação da sentença 1:\", probabilidade)\n",
        "print(\"Previsão     :\", previsao)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccUrj-w7wT3v"
      },
      "source": [
        "### Grupo de palavras relacionadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEz3yTeOwT3w",
        "outputId": "c193402b-2531-493b-ce8f-5a30aef42e3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grupo palavras\n",
            "Probabilidades: tensor([[0.1523, 0.8477]])\n",
            "cachorro  =>  gato : tensor([[0.1523, 0.8477]])\n",
            "    Probabilidade: tensor([[0.1523, 0.8477]])\n",
            "    Previsao     : 1\n",
            "Probabilidades: tensor([[0.2469, 0.7531]])\n",
            "gato  =>  cavalo : tensor([[0.2469, 0.7531]])\n",
            "    Probabilidade: tensor([[0.2469, 0.7531]])\n",
            "    Previsao     : 1\n",
            "Probabilidades: tensor([[0.2787, 0.7213]])\n",
            "cavalo  =>  zebra : tensor([[0.2787, 0.7213]])\n",
            "    Probabilidade: tensor([[0.2787, 0.7213]])\n",
            "    Previsao     : 1\n"
          ]
        }
      ],
      "source": [
        "print(\"Grupo palavras\")\n",
        "\n",
        "# Define uma lista com 4 palavras\n",
        "texto = ['cachorro',\n",
        "         'gato',              \n",
        "         'cavalo',\n",
        "         'zebra']\n",
        "\n",
        "for i in range(len(texto)-1):    \n",
        "    probabilidade, previsao = previsaoProximaSentenca(texto[i], texto[i+1])\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", probabilidade)\n",
        "    print(\"    Probabilidade:\", probabilidade)\n",
        "    print(\"    Previsao     :\", previsao)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOPs-HB5wT3w"
      },
      "source": [
        "### Grupo de palavras relacionadas com ruído"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdHNWJG4wT3w",
        "outputId": "cfea0631-c4f6-45a1-8db8-b1270e9d91f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grupo palavras\n",
            "Probabilidades: tensor([[0.1523, 0.8477]])\n",
            "cachorro  =>  gato : tensor([[0.1523, 0.8477]])\n",
            "    Probabilidade: tensor([[0.1523, 0.8477]])\n",
            "    Previsao     : 1\n",
            "Probabilidades: tensor([[0.2276, 0.7724]])\n",
            "gato  =>  avião : tensor([[0.2276, 0.7724]])\n",
            "    Probabilidade: tensor([[0.2276, 0.7724]])\n",
            "    Previsao     : 1\n",
            "Probabilidades: tensor([[0.3476, 0.6524]])\n",
            "avião  =>  zebra : tensor([[0.3476, 0.6524]])\n",
            "    Probabilidade: tensor([[0.3476, 0.6524]])\n",
            "    Previsao     : 1\n"
          ]
        }
      ],
      "source": [
        "print(\"Grupo palavras\")\n",
        "\n",
        "# Define uma lista com 4 palavras\n",
        "texto = ['cachorro',\n",
        "         'gato',              \n",
        "         'avião', #<= Ruído\n",
        "         'zebra']\n",
        "\n",
        "for i in range(len(texto)-1):    \n",
        "    probabilidade, previsao = previsaoProximaSentenca(texto[i], texto[i+1])\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", probabilidade)\n",
        "    print(\"    Probabilidade:\", probabilidade)\n",
        "    print(\"    Previsao     :\", previsao)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ExemplosPrevisaoProximaSentencaBERT_pt_br.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}