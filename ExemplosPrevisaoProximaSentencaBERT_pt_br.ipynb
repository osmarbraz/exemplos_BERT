{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExemplosPrevisaoProximaSentencaBERT_pt_br.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osmarbraz/exemplos_BERT/blob/main/ExemplosPrevisaoProximaSentencaBERT_pt_br.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78HE8FLsKN9Q"
      },
      "source": [
        "#Exemplo de Previsão Próxima Sentença usando BERT Transformers by HuggingFace\n",
        "\n",
        "## **A execução pode ser feita através do menu Ambiente de Execução opção Executar tudo.**\n",
        "\n",
        "Exemplos de uso de **Word Embeddings Contextuais** para previsão da próxima sentença.\n",
        "\n",
        "\n",
        "**Link biblioteca Huggingface:**\n",
        "https://github.com/huggingface/transformers\n",
        "\n",
        "\n",
        "**Artigo original BERT Jacob Devlin:**\n",
        "https://arxiv.org/pdf/1506.06724.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyxb5Px3p1-e"
      },
      "source": [
        "## 0 - Preparação do ambiente\n",
        "Preparação do ambiente para execução do exemplo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAPVtRXQqDim"
      },
      "source": [
        "###Tratamento de logs\n",
        "\n",
        "Método para tratamento dos logs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcopxbGZqDip"
      },
      "source": [
        "#biblioteca de logging\n",
        "import logging\n",
        "\n",
        "#formatando a mensagem de logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GjYtXcMnSAe"
      },
      "source": [
        "### Identificando o ambiente Colab\n",
        "\n",
        "Cria uma variável para identificar que o notebook está sendo executado no Google Colaboratory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMiH0E3OnRa1"
      },
      "source": [
        "#se estiver executando no Google Colaboratory\n",
        "import sys\n",
        "#retorna true ou false se estiver no Google Colaboratory\n",
        "IN_COLAB = 'google.colab' in sys.modules"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqa-7WXBAw8q"
      },
      "source": [
        "## 1 - Instalação BERT da Hugging Face"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCdqJCtQN52l"
      },
      "source": [
        "Instala a interface pytorch para o BERT by Hugging Face. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RfUN_KolV-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c287defa-a677-40a0-a014-7458db18a668"
      },
      "source": [
        "# Instala a última versão da biblioteca\n",
        "#!pip install transformers\n",
        "\n",
        "# Instala uma versão específica da biblioteca\n",
        "!pip install -U transformers==4.5.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==4.5.1 in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (21.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (0.10.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.62.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (0.0.45)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.6.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.1) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2021.5.30)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQj2wmKDpkrH"
      },
      "source": [
        "## 2 - Download do arquivo do PyTorch Checkpoint\n",
        "\n",
        "Lista de modelos da comunidade:\n",
        "* https://huggingface.co/models\n",
        "\n",
        "Português(https://github.com/neuralmind-ai/portuguese-bert):  \n",
        "* **'neuralmind/bert-base-portuguese-cased'**\n",
        "* **'neuralmind/bert-large-portuguese-cased'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajrTjZzapkrK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99e7dc36-212f-4be6-dd2a-0419bbedb62d"
      },
      "source": [
        "# Importando as bibliotecas\n",
        "import os\n",
        "\n",
        "# Variável para setar o arquivo\n",
        "URL_MODELO = None\n",
        "\n",
        "# Comente uma das urls para carregar modelos de tamanhos diferentes(base/large)\n",
        "# URL_MODELO do arquivo do modelo tensorflow\n",
        "# arquivo menor(base) 1.1 Gbytes\n",
        "#URL_MODELO = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "# arquivo grande(large) 3.5 Gbytes\n",
        "URL_MODELO = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "# Se a variável foi setada\n",
        "if URL_MODELO:\n",
        "\n",
        "    # Diretório descompactação\n",
        "    DIRETORIO_MODELO = '/content/modelo'\n",
        "\n",
        "    # Recupera o nome do arquivo do modelo da URL_MODELO\n",
        "    arquivo = URL_MODELO.split(\"/\")[-1]\n",
        "\n",
        "    # Nome do arquivo do vocabulário\n",
        "    arquivo_vocab = \"vocab.txt\"\n",
        "\n",
        "    # Caminho do arquivo na URL_MODELO\n",
        "    caminho = URL_MODELO[0:len(URL_MODELO)-len(arquivo)]\n",
        "\n",
        "    # Verifica se a pasta de descompactação existe na pasta corrente\n",
        "    if os.path.exists(DIRETORIO_MODELO):\n",
        "      print(\"Apagando diretório existente do modelo!\")\n",
        "      # Apaga a pasta e os arquivos existentes\n",
        "      !rm -rf $DIRETORIO_MODELO    \n",
        "\n",
        "    # Baixa o arquivo do modelo\n",
        "    !wget $URL_MODELO\n",
        "    \n",
        "    # Descompacta o arquivo na pasta de descompactação\n",
        "    !unzip -o $arquivo -d $DIRETORIO_MODELO\n",
        "\n",
        "    # Baixa o arquivo do vocabulário\n",
        "    # O vocabulário não está no arquivo compactado acima, mesma url mas arquivo diferente\n",
        "    URL_MODELO_VOCAB = caminho + arquivo_vocab\n",
        "    !wget $URL_MODELO_VOCAB\n",
        "    \n",
        "    # Coloca o arquivo do vocabulário no diretório de descompactação\n",
        "    !mv $arquivo_vocab $DIRETORIO_MODELO\n",
        "            \n",
        "    # Move o arquivo para pasta de descompactação\n",
        "    !mv $arquivo $DIRETORIO_MODELO\n",
        "       \n",
        "    print('Pasta do ' + DIRETORIO_MODELO + ' pronta!')\n",
        "    \n",
        "    # Lista a pasta corrente\n",
        "    !ls -la $DIRETORIO_MODELO\n",
        "else:\n",
        "    print('Variável URL_MODELO não setada!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apagando diretório existente do modelo!\n",
            "--2021-08-16 12:02:53--  https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\n",
            "Resolving neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)... 52.219.105.178\n",
            "Connecting to neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)|52.219.105.178|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1244275810 (1.2G) [application/zip]\n",
            "Saving to: ‘bert-large-portuguese-cased_pytorch_checkpoint.zip’\n",
            "\n",
            "bert-large-portugue 100%[===================>]   1.16G  93.6MB/s    in 13s     \n",
            "\n",
            "2021-08-16 12:03:06 (92.3 MB/s) - ‘bert-large-portuguese-cased_pytorch_checkpoint.zip’ saved [1244275810/1244275810]\n",
            "\n",
            "Archive:  bert-large-portuguese-cased_pytorch_checkpoint.zip\n",
            "  inflating: /content/modelo/config.json  \n",
            "  inflating: /content/modelo/pytorch_model.bin  \n",
            "--2021-08-16 12:03:27--  https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/vocab.txt\n",
            "Resolving neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)... 52.219.141.74\n",
            "Connecting to neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)|52.219.141.74|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 209528 (205K) [text/plain]\n",
            "Saving to: ‘vocab.txt’\n",
            "\n",
            "vocab.txt           100%[===================>] 204.62K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-08-16 12:03:27 (1.64 MB/s) - ‘vocab.txt’ saved [209528/209528]\n",
            "\n",
            "Pasta do /content/modelo pronta!\n",
            "total 2525908\n",
            "drwxr-xr-x 2 root root       4096 Aug 16 12:03 .\n",
            "drwxr-xr-x 1 root root       4096 Aug 16 12:03 ..\n",
            "-rw-r--r-- 1 root root 1244275810 Jan 22  2020 bert-large-portuguese-cased_pytorch_checkpoint.zip\n",
            "-rw-rw-r-- 1 root root        874 Jan 12  2020 config.json\n",
            "-rw-rw-r-- 1 root root 1342014951 Jan 12  2020 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root     209528 Jan 21  2020 vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcpd9t9PpkrX"
      },
      "source": [
        "## 3 - Carregando o Tokenizador BERT\n",
        "\n",
        "O tokenizador utiliza WordPiece, veja em [artigo original](https://arxiv.org/pdf/1609.08144.pdf).\n",
        "\n",
        "Carregando o tokenizador da pasta '/content/modelo/' do diretório padrão se variável `URL_MODELO` setada.\n",
        "\n",
        "**Caso contrário carrega da comunidade**\n",
        "\n",
        "Por default(`do_lower_case=True`) todas as letras são colocadas para minúsculas. Para ignorar a conversão para minúsculo use o parâmetro `do_lower_case=False`. Esta opção também considera as letras acentuadas(ãçéí...), que são necessárias a língua portuguesa.\n",
        "\n",
        "O parâmetro `do_lower_case` interfere na quantidade tokens a ser gerado apartir de um texto. Quando igual a `False` reduz a quantidade de tokens gerados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8cKVs4fpkrY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebb2ec2e-0cfe-4059-eb08-699c7eea74d4"
      },
      "source": [
        "# Importando as bibliotecas do tokenizador\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = None\n",
        "\n",
        "# Se a variável URL_MODELO foi setada\n",
        "if URL_MODELO:\n",
        "    # Carregando o Tokenizador\n",
        "    print('Carrgando o tokenizador BERT do diretório ' + DIRETORIO_MODELO + '...')\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(DIRETORIO_MODELO, \n",
        "                                              do_lower_case=False)    \n",
        "else:\n",
        "    # Carregando o Tokenizador da comunidade\n",
        "    print('Carregando o tokenizador da comunidade...')\n",
        "    \n",
        "    #tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=False)\n",
        "    tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-large-portuguese-cased', do_lower_case=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carrgando o tokenizador BERT do diretório /content/modelo...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m__On2g1a--K"
      },
      "source": [
        "## 4 - Carregando o Modelo BERT(BertModel)\n",
        "\n",
        "Se a variável `URL_MODELO` estiver setada carrega o modelo do diretório `content/modelo`.\n",
        "\n",
        "Caso contrário carrega da comunidade.\n",
        "\n",
        "Carregando o modelo da pasta '/content/modelo/' do diretório padrão.\n",
        "\n",
        "A implementação do huggingface pytorch inclui um conjunto de interfaces projetadas para uma variedade de tarefas de PNL. Embora essas interfaces sejam todas construídas sobre um modelo treinado de BERT, cada uma possui diferentes camadas superiores e tipos de saída projetados para acomodar suas tarefas específicas de PNL.\n",
        "\n",
        "A documentação para estas pode ser encontrada em [aqui](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html).\n",
        "\n",
        "Por default o modelo está em modo avaliação ou seja `model.eval()`.\n",
        "\n",
        "-----------------------\n",
        "\n",
        "Durante a avaliação do modelo, este retorna um número de diferentes objetos com base em como é configurado na chamada do método `from_pretrained`. \n",
        "\n",
        "Quando definimos `output_hidden_states = True` na chamada do método `from_pretrained`, retorno do modelo possui no terceiro item os estados ocultos(**hidden_states**) de todas as camadas.  Veja a documentação para mais detalhes: https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "\n",
        "Quando **`output_hidden_states = True`** model retorna:\n",
        "- outputs[0] = last_hidden_state;\n",
        "- outputs[1] = pooler_output; \n",
        "- outputs[2] = hidden_states.\n",
        "\n",
        "Quando **`output_hidden_states = False`** ou não especificado model retorna:\n",
        "- outputs[0] = last_hidden_state;\n",
        "- outputs[1] = pooler_output.\n",
        "\n",
        "\n",
        "**ATENÇÃO**: O parâmetro ´**output_hidden_states = True**´ habilita gerar as camadas ocultas do modelo. Caso contrário somente a última camada é mantida. Este parâmetro otimiza a memória mas não os resultados.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRV6l_I-qg9s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd6c4a7b-5eda-4d40-afb3-c4b6ff39b150"
      },
      "source": [
        "# Importando as bibliotecas do Modelo\n",
        "from transformers import BertForNextSentencePrediction\n",
        "\n",
        "# Se a variável URL_MODELO1 foi setada\n",
        "if URL_MODELO:\n",
        "    # Carregando o Tokenizador\n",
        "    print('Carregando o modelo BERT do diretório ' + DIRETORIO_MODELO + '...')\n",
        "\n",
        "    model = BertForNextSentencePrediction.from_pretrained(DIRETORIO_MODELO, \n",
        "                                      output_hidden_states = True)    \n",
        "else:\n",
        "    # Carregando o Tokenizador da comunidade\n",
        "    print('Carregando o modelo BERT da comunidade ...')\n",
        "\n",
        "    model = BertForNextSentencePrediction.from_pretrained('neuralmind/bert-large-portuguese-cased', \n",
        "                                       output_hidden_states = True)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o modelo BERT do diretório /content/modelo...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/modelo were not used when initializing BertForNextSentencePrediction: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgnApndAsiGm",
        "outputId": "32bbbd1b-a3ad-4b8e-8805-4d72f219dced"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForNextSentencePrediction(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(29794, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyNSPHead(\n",
              "    (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIU-LMRnI8TZ"
      },
      "source": [
        "## 5 - Função de comparação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcSx0uhoI8d1"
      },
      "source": [
        "import torch\n",
        "\n",
        "def pontuacaoSentenca(entrada, candidato):\t\t\t\n",
        "  # pode ser melhor concatenar * após * a tokenização usando token especial [SEP]\n",
        "  combinado = entrada + ' [SEP] ' + candidato\n",
        "  entrada_tokenizada = tokenizer.encode(combinado, add_special_tokens=True)\n",
        "\t# Gera a entrada como tokenizada e o unsqueeze insere uma dimensão na posição 0\n",
        "  entrada_tokenizada_indexada = torch.tensor(entrada_tokenizada).unsqueeze(0)\n",
        "  #print(entrada_tokenizada_indexada)\n",
        "\t# Submete o texto ao modela\n",
        "  outputs = model(entrada_tokenizada_indexada)  \n",
        "\t# outputs é uma matriz com perdas como o primeiro valor e logits como o segundo\n",
        "  # outputs[0] = last_hidden_state\n",
        "  # outputs[0][0] é igual outputs.logits[0]. Logits retorna dois valores, referenciado pelo terceiro índice.      \n",
        "  # A função `.item()` retorna apenas o valor Python do tensor.       \n",
        "  print(\"Saída:\",outputs[0][0])\n",
        "  pontuacao = outputs.logits[0][0].item()   \n",
        "  #print(candidato, \":\", pontuacao)\n",
        "  return pontuacao"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj0JqtVxmlXm"
      },
      "source": [
        "## 6 - Exemplos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySIv8YYlmWid"
      },
      "source": [
        "### Comparando sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ron7ab4pKYiW",
        "outputId": "cc1d3e88-b301-4314-bc22-5176248eaa9b"
      },
      "source": [
        "sentenca1 = \"Hoje está calor.\"\n",
        "sentenca2 = \"Vamos a praia.\"\n",
        "sentenca3 = \"O carro estragou.\"\n",
        "sentenca4 = \"Vou levar a oficina.\"\n",
        "\n",
        "print(\"Sentença 1:\", sentenca1)\n",
        "print(\"Sentença 2:\", sentenca2)\n",
        "resultado = pontuacaoSentenca(sentenca1, sentenca2)\n",
        "print(\"Resultado da relação da sentença 2:\", resultado)\n",
        "\n",
        "print(\"\\nSentença 1:\", sentenca1)\n",
        "print(\"Sentença 3:\", sentenca3)\n",
        "resultado = pontuacaoSentenca(sentenca1, sentenca3)\n",
        "print(\"Resultado da relação da sentença 3:\", resultado)\n",
        "\n",
        "print(\"\\nSentença 3:\", sentenca3)\n",
        "print(\"Sentença 4:\", sentenca4)\n",
        "resultado = pontuacaoSentenca(sentenca3, sentenca4)\n",
        "print(\"Resultado da relação da sentença 4:\", resultado)\n",
        "\n",
        "print(\"\\nSentença 3:\", sentenca3)\n",
        "print(\"Sentença 1:\", sentenca1)\n",
        "resultado = pontuacaoSentenca(sentenca3, sentenca1)\n",
        "print(\"Resultado da relação da sentença 1:\", resultado)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentença 1: Hoje está calor.\n",
            "Sentença 2: Vamos a praia.\n",
            "Saída: tensor([ 0.6251, -0.9251], grad_fn=<SelectBackward>)\n",
            "Resultado da relação da sentença 2: 0.625061571598053\n",
            "\n",
            "Sentença 1: Hoje está calor.\n",
            "Sentença 3: O carro estragou.\n",
            "Saída: tensor([0.1169, 0.5731], grad_fn=<SelectBackward>)\n",
            "Resultado da relação da sentença 3: 0.11686892062425613\n",
            "\n",
            "Sentença 3: O carro estragou.\n",
            "Sentença 4: Vou levar a oficina.\n",
            "Saída: tensor([ 0.9069, -1.0739], grad_fn=<SelectBackward>)\n",
            "Resultado da relação da sentença 4: 0.9069446325302124\n",
            "\n",
            "Sentença 3: O carro estragou.\n",
            "Sentença 1: Hoje está calor.\n",
            "Saída: tensor([ 0.2409, -0.0578], grad_fn=<SelectBackward>)\n",
            "Resultado da relação da sentença 1: 0.240912064909935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOj1d8N3ZKYy"
      },
      "source": [
        "### Comparando uma sequência de sentenças 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZAPmtizZKiI",
        "outputId": "59ae1e56-d36b-4619-fec4-954b16a028c4"
      },
      "source": [
        "# Define um texto\n",
        "texto = ['Fui de carro.',\n",
        "         'O caminhão tombou.',              \n",
        "         'O ônibus atrasou.']\n",
        "\n",
        "total = 0\n",
        "for i in range(len(texto)-1):\n",
        "    pontuacao = pontuacaoSentenca(texto[i], texto[i+1])\n",
        "    total = total + abs(pontuacao)\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", pontuacao)\n",
        "\n",
        "print(\"Total sentenças:\", len(texto))\n",
        "print(\"Total:\",total)\n",
        "print(\"Média:\",total/len(texto))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saída: tensor([ 0.8284, -0.1576], grad_fn=<SelectBackward>)\n",
            "Fui de carro.  =>  O caminhão tombou. : 0.8284463286399841\n",
            "Saída: tensor([ 0.5831, -0.0621], grad_fn=<SelectBackward>)\n",
            "O caminhão tombou.  =>  O ônibus atrasou. : 0.5830506682395935\n",
            "Total sentenças: 3\n",
            "Total: 1.4114969968795776\n",
            "Média: 0.4704989989598592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7WZwQpwZkVy"
      },
      "source": [
        "### Comparando uma sequência de sentenças 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQVQC8aZjr5",
        "outputId": "e31855d2-f8e9-4a71-c49d-bf631d950696"
      },
      "source": [
        "# Define um texto com a permutação das sentenças do texto original\n",
        "texto = ['O gato saiu correndo.',   \n",
        "             'O cachorro latiu.',             \n",
        "             'O passáro está no ninho.']    \n",
        "\n",
        "total = 0\n",
        "for i in range(len(texto)-1):\n",
        "    pontuacao = pontuacaoSentenca(texto[i], texto[i+1])\n",
        "    total = total + abs(pontuacao)\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", pontuacao)\n",
        "\n",
        "print(\"Total sentenças:\", len(texto))\n",
        "print(\"Total:\",total)\n",
        "print(\"Média:\",total/len(texto))           "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saída: tensor([0.1706, 0.7546], grad_fn=<SelectBackward>)\n",
            "O gato saiu correndo.  =>  O cachorro latiu. : 0.1705625355243683\n",
            "Saída: tensor([-0.0530, -0.1603], grad_fn=<SelectBackward>)\n",
            "O cachorro latiu.  =>  O passáro está no ninho. : -0.05296250060200691\n",
            "Total sentenças: 3\n",
            "Total: 0.2235250361263752\n",
            "Média: 0.0745083453754584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE4FTWikZRQH"
      },
      "source": [
        "### Comparando texto original com permutado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4n0fHITZRXo",
        "outputId": "ec2acd39-fd17-41a9-c939-d53cf09fd3a4"
      },
      "source": [
        "print(\"Texto Original\")\n",
        "\n",
        "# Define um texto com 4 sentenças\n",
        "texto_original = ['Bom Dia, professor.',\n",
        "             'Qual o conteúdo da prova?',              \n",
        "             'Vai cair tudo na prova?',\n",
        "             'Aguardo uma resposta, João.']\n",
        "\n",
        "texto = texto_original\n",
        "\n",
        "total = 0\n",
        "for i in range(len(texto)-1):    \n",
        "    pontuacao = pontuacaoSentenca(texto[i], texto[i+1])\n",
        "    total = total + pontuacao\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", pontuacao)\n",
        "\n",
        "print(\"Total sentenças:\", len(texto))\n",
        "print(\"Total:\",total)\n",
        "print(\"Média:\",total/len(texto))           \n",
        "\n",
        "print(\"\\nTexto permutado\")\n",
        "# Define um texto com a permutação das sentenças do texto original\n",
        "texto = [texto_original[3],   # 'Aguardo uma resposta, João.',\n",
        "             texto_original[1],             # 'Qual o conteúdo da prova?',              \n",
        "             texto_original[0],             # 'Vai cair tudo na prova?',\n",
        "             texto_original[2]]             # 'Bom Dia, professor.']                 \n",
        "\n",
        "total = 0\n",
        "for i in range(len(texto)-1):\n",
        "    pontuacao = pontuacaoSentenca(texto[i], texto[i+1])\n",
        "    total = total + abs(pontuacao)\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", pontuacao)\n",
        "\n",
        "print(\"Total sentenças:\", len(texto))\n",
        "print(\"Total:\",total)\n",
        "print(\"Média:\",total/len(texto))           "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original\n",
            "Saída: tensor([ 1.5311, -0.2564], grad_fn=<SelectBackward>)\n",
            "Bom Dia, professor.  =>  Qual o conteúdo da prova? : 1.5311131477355957\n",
            "Saída: tensor([0.8600, 0.5956], grad_fn=<SelectBackward>)\n",
            "Qual o conteúdo da prova?  =>  Vai cair tudo na prova? : 0.860034167766571\n",
            "Saída: tensor([ 1.4897, -1.0947], grad_fn=<SelectBackward>)\n",
            "Vai cair tudo na prova?  =>  Aguardo uma resposta, João. : 1.4897127151489258\n",
            "Total sentenças: 4\n",
            "Total: 3.8808600306510925\n",
            "Média: 0.9702150076627731\n",
            "\n",
            "Texto permutado\n",
            "Saída: tensor([ 1.5511, -0.4897], grad_fn=<SelectBackward>)\n",
            "Aguardo uma resposta, João.  =>  Qual o conteúdo da prova? : 1.5511293411254883\n",
            "Saída: tensor([ 1.0969, -0.0119], grad_fn=<SelectBackward>)\n",
            "Qual o conteúdo da prova?  =>  Bom Dia, professor. : 1.0969069004058838\n",
            "Saída: tensor([1.2152, 0.1825], grad_fn=<SelectBackward>)\n",
            "Bom Dia, professor.  =>  Vai cair tudo na prova? : 1.2151997089385986\n",
            "Total sentenças: 4\n",
            "Total: 3.8632359504699707\n",
            "Média: 0.9658089876174927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIp96olKnI5e"
      },
      "source": [
        "### Comparando palavras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JQdYZdjnJBe",
        "outputId": "d35991f0-9215-4e33-8bdd-213fc9019860"
      },
      "source": [
        "sentenca1 = \"cachorro\"\n",
        "sentenca2 = \"gato\"\n",
        "sentenca3 = \"avião\"\n",
        "sentenca4 = \"ônibus\"\n",
        "\n",
        "print(\"Sentença 1:\", sentenca1)\n",
        "print(\"Sentença 2:\", sentenca2)\n",
        "resultado = pontuacaoSentenca(sentenca1, sentenca2)\n",
        "print(\"Resultado da relação da sentença 2:\", resultado)\n",
        "\n",
        "print(\"\\nSentença 1:\", sentenca1)\n",
        "print(\"Sentença 3:\", sentenca3)\n",
        "resultado = pontuacaoSentenca(sentenca1, sentenca3)\n",
        "print(\"Resultado da relação da sentença 3:\", resultado)\n",
        "\n",
        "print(\"\\nSentença 3:\", sentenca3)\n",
        "print(\"Sentença 4:\", sentenca4)\n",
        "resultado = pontuacaoSentenca(sentenca3, sentenca4)\n",
        "print(\"Resultado da relação da sentença 4:\", resultado)\n",
        "\n",
        "print(\"\\nSentença 3:\", sentenca3)\n",
        "print(\"Sentença 1:\", sentenca1)\n",
        "resultado = pontuacaoSentenca(sentenca3, sentenca1)\n",
        "print(\"Resultado da relação da sentença 1:\", resultado)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentença 1: cachorro\n",
            "Sentença 2: gato\n",
            "Saída: tensor([-0.9021,  0.8146], grad_fn=<SelectBackward>)\n",
            "Resultado da relação da sentença 2: -0.9021257758140564\n",
            "\n",
            "Sentença 1: cachorro\n",
            "Sentença 3: avião\n",
            "Saída: tensor([-0.3603,  0.9946], grad_fn=<SelectBackward>)\n",
            "Resultado da relação da sentença 3: -0.3602618873119354\n",
            "\n",
            "Sentença 3: avião\n",
            "Sentença 4: ônibus\n",
            "Saída: tensor([0.3336, 0.0673], grad_fn=<SelectBackward>)\n",
            "Resultado da relação da sentença 4: 0.3336144983768463\n",
            "\n",
            "Sentença 3: avião\n",
            "Sentença 1: cachorro\n",
            "Saída: tensor([-0.4827,  0.9095], grad_fn=<SelectBackward>)\n",
            "Resultado da relação da sentença 1: -0.48266738653182983\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyS0d-ueoIre"
      },
      "source": [
        "### Grupo de palavras relacionadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0mbfQkuoI30",
        "outputId": "6f2356a2-f238-4c8a-94a1-a4cbce2779e2"
      },
      "source": [
        "print(\"Grupo palavras\")\n",
        "\n",
        "# Define uma lista com 4 palavras\n",
        "texto = ['cachorro',\n",
        "         'gato',              \n",
        "         'cavalo',\n",
        "         'zebra']\n",
        "\n",
        "total = 0\n",
        "for i in range(len(texto)-1):    \n",
        "    pontuacao = pontuacaoSentenca(texto[i], texto[i+1])\n",
        "    total = total + abs(pontuacao)\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", pontuacao)\n",
        "\n",
        "print(\"Total sentenças:\", len(texto))\n",
        "print(\"Total:\",total)\n",
        "print(\"Média:\",total/len(texto))           "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Grupo palavras\n",
            "Saída: tensor([-0.9021,  0.8146], grad_fn=<SelectBackward>)\n",
            "cachorro  =>  gato : -0.9021257758140564\n",
            "Saída: tensor([-0.0915,  1.0238], grad_fn=<SelectBackward>)\n",
            "gato  =>  cavalo : -0.0914822444319725\n",
            "Saída: tensor([0.0490, 1.0001], grad_fn=<SelectBackward>)\n",
            "cavalo  =>  zebra : 0.04902910441160202\n",
            "Total sentenças: 4\n",
            "Total: 1.042637124657631\n",
            "Média: 0.26065928116440773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOcKkMhTojIs"
      },
      "source": [
        "### Grupo de palavras relacionadas com ruído"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzccCUMXobm-",
        "outputId": "9f595632-f621-43c7-9a67-db1316543700"
      },
      "source": [
        "print(\"Grupo palavras\")\n",
        "\n",
        "# Define uma lista com 4 palavras\n",
        "texto = ['cachorro',\n",
        "         'gato',              \n",
        "         'avião', #<= Ruído\n",
        "         'zebra']\n",
        "\n",
        "total = 0\n",
        "for i in range(len(texto)-1):    \n",
        "    pontuacao = pontuacaoSentenca(texto[i], texto[i+1])\n",
        "    total = total + abs(pontuacao)\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", pontuacao)\n",
        "\n",
        "print(\"Total sentenças:\", len(texto))\n",
        "print(\"Total:\",total)\n",
        "print(\"Média:\",total/len(texto))           "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Grupo palavras\n",
            "Saída: tensor([-0.9021,  0.8146], grad_fn=<SelectBackward>)\n",
            "cachorro  =>  gato : -0.9021257758140564\n",
            "Saída: tensor([0.1469, 1.3691], grad_fn=<SelectBackward>)\n",
            "gato  =>  avião : 0.14692886173725128\n",
            "Saída: tensor([0.2148, 0.8442], grad_fn=<SelectBackward>)\n",
            "avião  =>  zebra : 0.21484261751174927\n",
            "Total sentenças: 4\n",
            "Total: 1.263897255063057\n",
            "Média: 0.31597431376576424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0GfzZr3tz43"
      },
      "source": [
        "## 7 - Função de comparação com softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIp0Sly-t0CF"
      },
      "source": [
        "import torch\n",
        "from torch.nn.functional import softmax\n",
        "\n",
        "def pontuacaoSentenca2(entrada, candidato):\t\t\t  \n",
        "  entrada_tokenizada_indexada = tokenizer.encode_plus(entrada, text_pair=candidato, return_tensors='pt')\n",
        "\t# Submete o texto ao modelo\n",
        "  #outputs = model(entrada_tokenizada_indexada)  \n",
        "  outputs = model(**entrada_tokenizada_indexada)  \n",
        "\t# outputs é uma matriz com perdas como o primeiro valor e logits como o segundo\n",
        "  # outputs[0] = last_hidden_state\n",
        "  # outputs[0][0] é igual outputs.logits[0]. Logits retorna dois valores, referenciado pelo terceiro índice.      \n",
        "  # A função `.item()` retorna apenas o valor Python do tensor.       \n",
        "  #print(\"Saída:\",outputs[0][0])\n",
        "  #Recupera a probabilidade da sequência\n",
        "  probs = softmax(outputs[0], dim=1)\n",
        "  # valor muito alto para o índice 0: alta probabilidade de candidato ser uma continuação da entrada\n",
        "  #print(\"Probabilidade:\",probs)\n",
        "  pontuacao = outputs.logits[0][0].item()   \n",
        "  #print(candidato, \":\", pontuacao)\n",
        "  return pontuacao, probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_PZcFRowhqc"
      },
      "source": [
        "### Comparando sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9FabsFKwhqc",
        "outputId": "47564968-ac57-4a40-f9c9-97d34fb144b4"
      },
      "source": [
        "sentenca1 = \"Hoje está calor.\"\n",
        "sentenca2 = \"Vamos a praia.\"\n",
        "sentenca3 = \"O carro estragou.\"\n",
        "sentenca4 = \"Vou levar a oficina.\"\n",
        "\n",
        "print(\"Sentença 1:\", sentenca1)\n",
        "print(\"Sentença 2:\", sentenca2)\n",
        "resultado, probabilidade = pontuacaoSentenca2(sentenca1, sentenca2)\n",
        "print(\"Resultado da relação da sentença 2:\", resultado)\n",
        "print(\"Probabilidade:\", probabilidade)\n",
        "\n",
        "print(\"\\nSentença 1:\", sentenca1)\n",
        "print(\"Sentença 3:\", sentenca3)\n",
        "resultado, probabilidade = pontuacaoSentenca2(sentenca1, sentenca3)\n",
        "print(\"Resultado da relação da sentença 3:\", resultado)\n",
        "print(\"Probabilidade:\", probabilidade)\n",
        "\n",
        "print(\"\\nSentença 3:\", sentenca3)\n",
        "print(\"Sentença 4:\", sentenca4)\n",
        "resultado, probabilidade = pontuacaoSentenca2(sentenca3, sentenca4)\n",
        "print(\"Resultado da relação da sentença 4:\", resultado)\n",
        "print(\"Probabilidade:\", probabilidade)\n",
        "\n",
        "print(\"\\nSentença 3:\", sentenca3)\n",
        "print(\"Sentença 1:\", sentenca1)\n",
        "resultado, probabilidade = pontuacaoSentenca2(sentenca3, sentenca1)\n",
        "print(\"Resultado da relação da sentença 1:\", resultado)\n",
        "print(\"Probabilidade:\", probabilidade)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentença 1: Hoje está calor.\n",
            "Sentença 2: Vamos a praia.\n",
            "Resultado da relação da sentença 2: 2.4943301677703857\n",
            "Probabilidade: tensor([[0.9903, 0.0097]], grad_fn=<SoftmaxBackward>)\n",
            "\n",
            "Sentença 1: Hoje está calor.\n",
            "Sentença 3: O carro estragou.\n",
            "Resultado da relação da sentença 3: 0.8492786884307861\n",
            "Probabilidade: tensor([[0.9167, 0.0833]], grad_fn=<SoftmaxBackward>)\n",
            "\n",
            "Sentença 3: O carro estragou.\n",
            "Sentença 4: Vou levar a oficina.\n",
            "Resultado da relação da sentença 4: 3.924736499786377\n",
            "Probabilidade: tensor([[0.9947, 0.0053]], grad_fn=<SoftmaxBackward>)\n",
            "\n",
            "Sentença 3: O carro estragou.\n",
            "Sentença 1: Hoje está calor.\n",
            "Resultado da relação da sentença 1: 0.8521135449409485\n",
            "Probabilidade: tensor([[0.9088, 0.0912]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-stq4ZZwT3u"
      },
      "source": [
        "### Comparando uma sequência de sentenças 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrWn5ju2wT3u",
        "outputId": "d6017e15-0c4c-40e1-b07f-b272eb380709"
      },
      "source": [
        "# Define um texto\n",
        "texto = ['Fui de carro.',\n",
        "         'O caminhão tombou.',              \n",
        "         'O ônibus atrasou.']\n",
        "\n",
        "total = 0\n",
        "for i in range(len(texto)-1):\n",
        "    pontuacao, probabilidade = pontuacaoSentenca2(texto[i], texto[i+1])\n",
        "    total = total + abs(pontuacao)\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", pontuacao)\n",
        "    print(\"    Probabilidade:\", probabilidade)\n",
        "\n",
        "print(\"Total sentenças:\", len(texto))\n",
        "print(\"Total:\",total)\n",
        "print(\"Média:\",total/len(texto))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fui de carro.  =>  O caminhão tombou. : 1.0553452968597412\n",
            "    Probabilidade: tensor([[0.9119, 0.0881]], grad_fn=<SoftmaxBackward>)\n",
            "O caminhão tombou.  =>  O ônibus atrasou. : 9.274107933044434\n",
            "    Probabilidade: tensor([[9.9913e-01, 8.7166e-04]], grad_fn=<SoftmaxBackward>)\n",
            "Total sentenças: 3\n",
            "Total: 10.329453229904175\n",
            "Média: 3.443151076634725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7dp-bHawT3u"
      },
      "source": [
        "### Comparando uma sequência de sentenças 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwCJNCxDwT3u",
        "outputId": "9e2eb89c-2aff-47a2-fc72-4b250a61d06c"
      },
      "source": [
        "# Define um texto com a permutação das sentenças do texto original\n",
        "texto = ['O gato saiu correndo.',   \n",
        "             'O cachorro latiu.',             \n",
        "             'O passáro está no ninho.']    \n",
        "\n",
        "total = 0\n",
        "for i in range(len(texto)-1):\n",
        "    pontuacao, probabilidade = pontuacaoSentenca2(texto[i], texto[i+1])\n",
        "    total = total + abs(pontuacao)\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", pontuacao)\n",
        "    print(\"    Probabilidade:\", probabilidade)\n",
        "\n",
        "print(\"Total sentenças:\", len(texto))\n",
        "print(\"Total:\",total)\n",
        "print(\"Média:\",total/len(texto))           "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O gato saiu correndo.  =>  O cachorro latiu. : 13.274903297424316\n",
            "    Probabilidade: tensor([[9.9991e-01, 8.9398e-05]], grad_fn=<SoftmaxBackward>)\n",
            "O cachorro latiu.  =>  O passáro está no ninho. : 3.625040054321289\n",
            "    Probabilidade: tensor([[0.9946, 0.0054]], grad_fn=<SoftmaxBackward>)\n",
            "Total sentenças: 3\n",
            "Total: 16.899943351745605\n",
            "Média: 5.633314450581868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BucZI8uNwT3v"
      },
      "source": [
        "### Comparando texto original com permutado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJHG6Y2JwT3v",
        "outputId": "c93565ea-f96f-4ae3-b7fe-3998900e5e82"
      },
      "source": [
        "print(\"Texto Original\")\n",
        "\n",
        "# Define um texto com 4 sentenças\n",
        "texto_original = ['Bom Dia, professor.',\n",
        "             'Qual o conteúdo da prova?',              \n",
        "             'Vai cair tudo na prova?',\n",
        "             'Aguardo uma resposta, João.']\n",
        "\n",
        "texto = texto_original\n",
        "\n",
        "total = 0\n",
        "for i in range(len(texto)-1):    \n",
        "    pontuacao, probabilidade = pontuacaoSentenca2(texto[i], texto[i+1])\n",
        "    total = total + abs(pontuacao)\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", pontuacao)\n",
        "    print(\"    Probabilidade:\", probabilidade)\n",
        "\n",
        "print(\"Total sentenças:\", len(texto))\n",
        "print(\"Total:\",total)\n",
        "print(\"Média:\",total/len(texto))           \n",
        "\n",
        "print(\"\\nTexto permutado\")\n",
        "# Define um texto com a permutação das sentenças do texto original\n",
        "texto = [texto_original[3],   # 'Aguardo uma resposta, João.',\n",
        "             texto_original[1],             # 'Qual o conteúdo da prova?',              \n",
        "             texto_original[0],             # 'Vai cair tudo na prova?',\n",
        "             texto_original[2]]             # 'Bom Dia, professor.']                 \n",
        "\n",
        "total = 0\n",
        "for i in range(len(texto)-1):\n",
        "    pontuacao, probabilidade = pontuacaoSentenca2(texto[i], texto[i+1])\n",
        "    total = total + abs(pontuacao)\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", pontuacao)\n",
        "    print(\"    Probabilidade:\", probabilidade)\n",
        "\n",
        "print(\"Total sentenças:\", len(texto))\n",
        "print(\"Total:\",total)\n",
        "print(\"Média:\",total/len(texto))           "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original\n",
            "Bom Dia, professor.  =>  Qual o conteúdo da prova? : 2.0516791343688965\n",
            "    Probabilidade: tensor([[0.9534, 0.0466]], grad_fn=<SoftmaxBackward>)\n",
            "Qual o conteúdo da prova?  =>  Vai cair tudo na prova? : 6.653902053833008\n",
            "    Probabilidade: tensor([[0.9985, 0.0015]], grad_fn=<SoftmaxBackward>)\n",
            "Vai cair tudo na prova?  =>  Aguardo uma resposta, João. : 2.2361972332000732\n",
            "    Probabilidade: tensor([[0.9813, 0.0187]], grad_fn=<SoftmaxBackward>)\n",
            "Total sentenças: 4\n",
            "Total: 10.941778421401978\n",
            "Média: 2.7354446053504944\n",
            "\n",
            "Texto permutado\n",
            "Aguardo uma resposta, João.  =>  Qual o conteúdo da prova? : 0.10518847405910492\n",
            "    Probabilidade: tensor([[0.2178, 0.7822]], grad_fn=<SoftmaxBackward>)\n",
            "Qual o conteúdo da prova?  =>  Bom Dia, professor. : 1.3705203533172607\n",
            "    Probabilidade: tensor([[0.9487, 0.0513]], grad_fn=<SoftmaxBackward>)\n",
            "Bom Dia, professor.  =>  Vai cair tudo na prova? : 1.2606265544891357\n",
            "    Probabilidade: tensor([[0.8051, 0.1949]], grad_fn=<SoftmaxBackward>)\n",
            "Total sentenças: 4\n",
            "Total: 2.7363353818655014\n",
            "Média: 0.6840838454663754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFekj_F-wT3v"
      },
      "source": [
        "### Comparando palavras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6imhnfd_wT3v",
        "outputId": "12a140ee-be9f-4a4c-dbbf-20565ded4a09"
      },
      "source": [
        "sentenca1 = \"cachorro\"\n",
        "sentenca2 = \"gato\"\n",
        "sentenca3 = \"avião\"\n",
        "sentenca4 = \"ônibus\"\n",
        "\n",
        "print(\"Sentença 1:\", sentenca1)\n",
        "print(\"Sentença 2:\", sentenca2)\n",
        "resultado, probabilidade = pontuacaoSentenca2(sentenca1, sentenca2)\n",
        "print(\"Resultado da relação da sentença 2:\", resultado)\n",
        "print(\"Probabilidade:\", probabilidade)\n",
        "\n",
        "print(\"\\nSentença 1:\", sentenca1)\n",
        "print(\"Sentença 3:\", sentenca3)\n",
        "resultado, probabilidade = pontuacaoSentenca2(sentenca1, sentenca3)\n",
        "print(\"Resultado da relação da sentença 3:\", resultado)\n",
        "print(\"Probabilidade:\", probabilidade)\n",
        "\n",
        "print(\"\\nSentença 3:\", sentenca3)\n",
        "print(\"Sentença 4:\", sentenca4)\n",
        "resultado, probabilidade = pontuacaoSentenca2(sentenca3, sentenca4)\n",
        "print(\"Resultado da relação da sentença 4:\", resultado)\n",
        "print(\"Probabilidade:\", probabilidade)\n",
        "\n",
        "print(\"\\nSentença 3:\", sentenca3)\n",
        "print(\"Sentença 1:\", sentenca1)\n",
        "resultado, probabilidade = pontuacaoSentenca2(sentenca3, sentenca1)\n",
        "print(\"Resultado da relação da sentença 1:\", resultado)\n",
        "print(\"Probabilidade:\", probabilidade)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentença 1: cachorro\n",
            "Sentença 2: gato\n",
            "Resultado da relação da sentença 2: 13.916265487670898\n",
            "Probabilidade: tensor([[9.9992e-01, 8.0443e-05]], grad_fn=<SoftmaxBackward>)\n",
            "\n",
            "Sentença 1: cachorro\n",
            "Sentença 3: avião\n",
            "Resultado da relação da sentença 3: 6.6345343589782715\n",
            "Probabilidade: tensor([[0.9980, 0.0020]], grad_fn=<SoftmaxBackward>)\n",
            "\n",
            "Sentença 3: avião\n",
            "Sentença 4: ônibus\n",
            "Resultado da relação da sentença 4: 6.271944999694824\n",
            "Probabilidade: tensor([[0.9977, 0.0023]], grad_fn=<SoftmaxBackward>)\n",
            "\n",
            "Sentença 3: avião\n",
            "Sentença 1: cachorro\n",
            "Resultado da relação da sentença 1: 4.632396221160889\n",
            "Probabilidade: tensor([[0.9963, 0.0037]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccUrj-w7wT3v"
      },
      "source": [
        "### Grupo de palavras relacionadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEz3yTeOwT3w",
        "outputId": "03b51b99-26a8-4183-8748-7fb10d89fd66"
      },
      "source": [
        "print(\"Grupo palavras\")\n",
        "\n",
        "# Define uma lista com 4 palavras\n",
        "texto = ['cachorro',\n",
        "         'gato',              \n",
        "         'cavalo',\n",
        "         'zebra']\n",
        "\n",
        "total = 0\n",
        "for i in range(len(texto)-1):    \n",
        "    pontuacao, probabilidade = pontuacaoSentenca2(texto[i], texto[i+1])\n",
        "    total = total + abs(pontuacao)\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", pontuacao)\n",
        "    print(\"    Probabilidade:\", probabilidade)\n",
        "\n",
        "print(\"Total sentenças:\", len(texto))\n",
        "print(\"Total:\",total)\n",
        "print(\"Média:\",total/len(texto))           "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Grupo palavras\n",
            "cachorro  =>  gato : 13.916265487670898\n",
            "    Probabilidade: tensor([[9.9992e-01, 8.0443e-05]], grad_fn=<SoftmaxBackward>)\n",
            "gato  =>  cavalo : 10.360709190368652\n",
            "    Probabilidade: tensor([[9.9962e-01, 3.8360e-04]], grad_fn=<SoftmaxBackward>)\n",
            "cavalo  =>  zebra : 3.6907591819763184\n",
            "    Probabilidade: tensor([[0.9909, 0.0091]], grad_fn=<SoftmaxBackward>)\n",
            "Total sentenças: 4\n",
            "Total: 27.96773386001587\n",
            "Média: 6.991933465003967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOPs-HB5wT3w"
      },
      "source": [
        "### Grupo de palavras relacionadas com ruído"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdHNWJG4wT3w",
        "outputId": "59e20969-0b8b-44db-e694-eb08ee31de68"
      },
      "source": [
        "print(\"Grupo palavras\")\n",
        "\n",
        "# Define uma lista com 4 palavras\n",
        "texto = ['cachorro',\n",
        "         'gato',              \n",
        "         'avião', #<= Ruído\n",
        "         'zebra']\n",
        "\n",
        "total = 0\n",
        "for i in range(len(texto)-1):    \n",
        "    pontuacao, probabilidade = pontuacaoSentenca2(texto[i], texto[i+1])\n",
        "    total = total + abs(pontuacao)\n",
        "    print(texto[i], \" => \",texto[i+1], \":\", pontuacao)\n",
        "    print(\"    Probabilidade:\", probabilidade)\n",
        "\n",
        "print(\"Total sentenças:\", len(texto))\n",
        "print(\"Total:\",total)\n",
        "print(\"Média:\",total/len(texto))           "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Grupo palavras\n",
            "cachorro  =>  gato : 13.916265487670898\n",
            "    Probabilidade: tensor([[9.9992e-01, 8.0443e-05]], grad_fn=<SoftmaxBackward>)\n",
            "gato  =>  avião : 6.556914329528809\n",
            "    Probabilidade: tensor([[0.9975, 0.0025]], grad_fn=<SoftmaxBackward>)\n",
            "avião  =>  zebra : 1.603911280632019\n",
            "    Probabilidade: tensor([[0.9563, 0.0437]], grad_fn=<SoftmaxBackward>)\n",
            "Total sentenças: 4\n",
            "Total: 22.077091097831726\n",
            "Média: 5.5192727744579315\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}