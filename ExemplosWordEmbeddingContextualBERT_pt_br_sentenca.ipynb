{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExemplosWordEmbeddingContextualBERT_pt_br_sentenca.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osmarbraz/exemplos_BERT/blob/main/ExemplosWordEmbeddingContextualBERT_pt_br_sentenca.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78HE8FLsKN9Q"
      },
      "source": [
        "#Exemplo de Word Embeddings(pt-br) Contextual usando BERT Transformers by HuggingFace\n",
        "\n",
        "## **A execução pode ser feita através do menu Ambiente de Execução opção Executar tudo.**\n",
        "\n",
        "Exemplos de uso de **Word Embeddings Contextuais** para **desambiguação** de textos originais e permutados utilizando suas sentenças. No final do notebook estão os exemplos com os textos:\n",
        "\n",
        "*   texto original e permutado\n",
        "\n",
        "**Link biblioteca Huggingface:**\n",
        "https://github.com/huggingface/transformers\n",
        "\n",
        "\n",
        "**Artigo original BERT Jacob Devlin:**\n",
        "https://arxiv.org/pdf/1506.06724.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyxb5Px3p1-e"
      },
      "source": [
        "## 0 - Preparação do ambiente\n",
        "Preparação do ambiente para execução do exemplo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAPVtRXQqDim"
      },
      "source": [
        "###Tratamento de logs\n",
        "\n",
        "Método para tratamento dos logs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcopxbGZqDip"
      },
      "source": [
        "# Biblioteca de logging\n",
        "import logging\n",
        "\n",
        "# Formatando a mensagem de logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GjYtXcMnSAe"
      },
      "source": [
        "### Identificando o ambiente Colab\n",
        "\n",
        "Cria uma variável para identificar que o notebook está sendo executado no Google Colaboratory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMiH0E3OnRa1"
      },
      "source": [
        "# Se estiver executando no Google Colaboratory\n",
        "import sys\n",
        "\n",
        "# Retorna true ou false se estiver no Google Colaboratory\n",
        "IN_COLAB = 'google.colab' in sys.modules"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RufkKnojlwzu"
      },
      "source": [
        "### Instalação do spaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0LeiOTx0Dlk"
      },
      "source": [
        "https://spacy.io/\n",
        "\n",
        "Modelos do spaCy para português:\n",
        "https://spacy.io/models/pt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2Fvx0TVRQUw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aafd734d-bbf0-425f-8e9a-f2993983bec7"
      },
      "source": [
        "# Instala o spacy\n",
        "!pip install -U spacy==2.3.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy==2.3.5\n",
            "  Downloading spacy-2.3.5-cp37-cp37m-manylinux2014_x86_64.whl (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (3.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (4.62.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (2.23.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (57.2.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (2.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (1.19.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (0.8.2)\n",
            "Collecting thinc<7.5.0,>=7.4.1\n",
            "  Downloading thinc-7.4.5-cp37-cp37m-manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 36.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.3.5) (4.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.5) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (2.10)\n",
            "Installing collected packages: thinc, spacy\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed spacy-2.3.5 thinc-7.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35GwcgkOlWi3"
      },
      "source": [
        "Realiza o download e carrega os modelos necessários a biblioteca\n",
        "\n",
        "https://spacy.io/models/pt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4LqE5kTwDYm"
      },
      "source": [
        "# Definição do nome do arquivo do modelo\n",
        "#ARQUIVOMODELO = 'pt_core_news_sm'\n",
        "#ARQUIVOMODELO = 'pt_core_news_md'\n",
        "ARQUIVOMODELO = 'pt_core_news_lg'\n",
        "\n",
        "# Definição da versão da spaCy\n",
        "#VERSAOSPACY = '-3.0.0a0'\n",
        "VERSAOSPACY = '-2.3.0'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ2KB3UCp-ws"
      },
      "source": [
        "#Baixa automaticamente o arquivo do modelo.\n",
        "#!python -m spacy download {ARQUIVOMODELO}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASk5iFeUp9LE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe6fc59c-d0b6-4b8d-b087-512bbc230fa6"
      },
      "source": [
        "# Realiza o download do arquivo do modelo para o diretório corrente\n",
        "!wget https://github.com/explosion/spacy-models/releases/download/{ARQUIVOMODELO}{VERSAOSPACY}/{ARQUIVOMODELO}{VERSAOSPACY}.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-16 11:26:37--  https://github.com/explosion/spacy-models/releases/download/pt_core_news_lg-2.3.0/pt_core_news_lg-2.3.0.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/84940268/a899e480-ab07-11ea-831b-b5aa9cc04510?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210816%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210816T112637Z&X-Amz-Expires=300&X-Amz-Signature=1f394677854d4d6444afec47061b957026509e0352907a23ead74654e6112d93&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=84940268&response-content-disposition=attachment%3B%20filename%3Dpt_core_news_lg-2.3.0.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-08-16 11:26:37--  https://github-releases.githubusercontent.com/84940268/a899e480-ab07-11ea-831b-b5aa9cc04510?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210816%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210816T112637Z&X-Amz-Expires=300&X-Amz-Signature=1f394677854d4d6444afec47061b957026509e0352907a23ead74654e6112d93&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=84940268&response-content-disposition=attachment%3B%20filename%3Dpt_core_news_lg-2.3.0.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 576599832 (550M) [application/octet-stream]\n",
            "Saving to: ‘pt_core_news_lg-2.3.0.tar.gz’\n",
            "\n",
            "pt_core_news_lg-2.3 100%[===================>] 549.89M  68.9MB/s    in 8.4s    \n",
            "\n",
            "2021-08-16 11:26:46 (65.5 MB/s) - ‘pt_core_news_lg-2.3.0.tar.gz’ saved [576599832/576599832]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu_LkF7Nfm8_"
      },
      "source": [
        "Descompacta o arquivo do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9fCQQJGeVEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f2d5f1b-a70f-48b5-8934-6837890afb77"
      },
      "source": [
        "# Descompacta o arquivo do modelo\n",
        "!tar -xvf  /content/{ARQUIVOMODELO}{VERSAOSPACY}.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pt_core_news_lg-2.3.0/\n",
            "pt_core_news_lg-2.3.0/PKG-INFO\n",
            "pt_core_news_lg-2.3.0/setup.py\n",
            "pt_core_news_lg-2.3.0/setup.cfg\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/dependency_links.txt\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/PKG-INFO\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/SOURCES.txt\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/requires.txt\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/top_level.txt\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/not-zip-safe\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/__init__.py\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/parser/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/parser/cfg\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/parser/moves\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/parser/model\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/ner/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/ner/cfg\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/ner/moves\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/ner/model\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tokenizer\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/lookups.bin\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/vectors\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/key2row\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/lookups_extra.bin\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/strings.json\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/accuracy.json\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tagger/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tagger/cfg\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tagger/tag_map\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tagger/model\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/meta.json\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/meta.json\n",
            "pt_core_news_lg-2.3.0/MANIFEST.in\n",
            "pt_core_news_lg-2.3.0/meta.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovOx-3Wb-JJW"
      },
      "source": [
        "# Coloca a pasta do modelo descompactado em uma pasta de nome mais simples\n",
        "!mv /content/{ARQUIVOMODELO}{VERSAOSPACY}/{ARQUIVOMODELO}/{ARQUIVOMODELO}{VERSAOSPACY} /content/{ARQUIVOMODELO}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STHT2c89qvwK"
      },
      "source": [
        "Carrega o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbELnrpgA4T1"
      },
      "source": [
        "import spacy\n",
        "\n",
        "CAMINHOMODELO = \"/content/\" + ARQUIVOMODELO\n",
        "\n",
        "#nlp = spacy.load(CAMINHOMODELO)\n",
        "# Necessário 'tagger' para encontrar os substantivos\n",
        "nlp = spacy.load(CAMINHOMODELO, disable=['tokenizer', 'lemmatizer', 'ner', 'parser', 'textcat', 'custom'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFTTdqxKQ1Ay"
      },
      "source": [
        "Recupera os stopwords do spaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBInu7ayQ31J"
      },
      "source": [
        "# Recupera as stop words\n",
        "spacy_stopwords = nlp.Defaults.stop_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_EYNu-_RX7k"
      },
      "source": [
        "Lista dos stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUSaUJEWRbnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6505ddb1-6bc8-476c-99a7-6f7ca25893e3"
      },
      "source": [
        "print(\"Quantidade de stopwords:\", len(spacy_stopwords))\n",
        "\n",
        "print(spacy_stopwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quantidade de stopwords: 413\n",
            "{'caminho', 'somente', 'vinte', 'tente', 'esse', 'diz', 'eventual', 'neste', 'obrigado', 'fazer', 'teu', 'daquela', 'custa', 'cedo', 'mil', 'estava', 'do', 'pegar', 'com', 'números', 'aquela', 'momento', 'saber', 'três', 'dar', 'mas', 'sua', 'ambas', 'direita', 'grande', 'comprido', 'seus', 'todas', 'meses', 'deve', 'meio', 'quieto', 'vem', 'aos', 'bem', 'final', 'dão', 'nosso', 'ambos', 'as', 'duas', 'disso', 'cento', 'oito', 'próximo', 'vão', 'naquela', 'nós', 'parte', 'esses', 'ser', 'poder', 'vocês', 'vens', 'estas', 'dentro', 'nessa', 'essa', 'onde', 'deste', 'pode', 'tiveram', 'nível', 'quarta', 'te', 'esta', 'conselho', 'em', 'inicio', 'nove', 'vossas', 'és', 'estivemos', 'estiveste', 'ir', 'minha', 'isto', 'esteve', 'menor', 'sempre', 'também', 'des', 'pelo', 'ainda', 'num', 'fará', 'fazia', 'apontar', 'tens', 'dizem', 'qual', 'faço', 'nos', 'mais', 'ter', 'quais', 'lhe', 'baixo', 'lá', 'tanto', 'obrigada', 'vários', 'quatro', 'porém', 'tentei', 'quando', 'teve', 'todos', 'ou', 'suas', 'vindo', 'somos', 'menos', 'portanto', 'máximo', 'nuns', 'bom', 'relação', 'sob', 'estado', 'contudo', 'fazeis', 'apoio', 'novos', 'algo', 'da', 'fazem', 'ora', 'breve', 'aquele', 'foram', 'vai', 'iniciar', 'naquele', 'são', 'tipo', 'conhecida', 'fora', 'sei', 'tais', 'doze', 'muito', 'ontem', 'sétima', 'lado', 'inclusive', 'tu', 'cá', 'tanta', 'foste', 'grandes', 'onze', 'quero', 'vez', 'outra', 'dizer', 'você', 'deverá', 'alguns', 'ademais', 'sexta', 'me', 'querem', 'longe', 'já', 'dezoito', 'até', 'conhecido', 'os', 'das', 'foi', 'porquê', 'então', 'tarde', 'cujo', 'depois', 'ali', 'fim', 'quanto', 'tiveste', 'porquanto', 'têm', 'outras', 'vos', 'aquelas', 'seria', 'nenhuma', 'eu', 'posso', 'dezanove', 'falta', 'fazemos', 'além', 'dezasseis', 'pelas', 'meus', 'tentaram', 'oitavo', 'talvez', 'adeus', 'às', 'nossa', 'exemplo', 'estive', 'estão', 'cima', 'vosso', 'vossa', 'atrás', 'cada', 'estes', 'isso', 'terceira', 'perto', 'tenho', 'segundo', 'temos', 'sou', 'tentar', 'possível', 'nada', 'numa', 'nas', 'tudo', 'tivemos', 'pelos', 'devem', 'uns', 'estivestes', 'desta', 'maior', 'essas', 'oitava', 'no', 'novas', 'muitos', 'umas', 'dá', 'daquele', 'vêm', 'tempo', 'ele', 'tivestes', 'apenas', 'sois', 'está', 'desde', 'usar', 'certeza', 'ao', 'contra', 'pois', 'pela', 'próprio', 'forma', 'veja', 'grupo', 'lugar', 'quinto', 'eles', 'por', 'bastante', 'dessa', 'após', 'seis', 'uma', 'acerca', 'entre', 'vossos', 'tal', 'vinda', 'aí', 'podia', 'era', 'maioria', 'pontos', 'quem', 'quieta', 'põem', 'povo', 'puderam', 'qualquer', 'através', 'nossos', 'sabe', 'fazes', 'quarto', 'aquilo', 'vezes', 'questão', 'pouco', 'seu', 'corrente', 'valor', 'quê', 'se', 'de', 'faz', 'catorze', 'mesmo', 'ver', 'mês', 'fez', 'estar', 'tua', 'toda', 'nossas', 'ela', 'boa', 'estou', 'ponto', 'porque', 'quinta', 'nesse', 'nova', 'dezassete', 'estás', 'segunda', 'sobre', 'logo', 'apoia', 'primeiro', 'partir', 'agora', 'sete', 'minhas', 'é', 'debaixo', 'dois', 'para', 'número', 'sem', 'fui', 'dos', 'põe', 'certamente', 'aqueles', 'vais', 'assim', 'embora', 'possivelmente', 'fostes', 'teus', 'primeira', 'pôde', 'um', 'vós', 'na', 'podem', 'for', 'irá', 'tive', 'quinze', 'aqui', 'todo', 'terceiro', 'nunca', 'desse', 'diante', 'antes', 'cinco', 'dez', 'geral', 'coisa', 'enquanto', 'quer', 'elas', 'sexto', 'como', 'local', 'sistema', 'favor', 'fomos', 'mal', 'tem', 'cuja', 'estará', 'não', 'demais', 'último', 'maiorias', 'parece', 'só', 'novo', 'treze', 'meu', 'pouca', 'usa', 'próxima', 'nesta', 'tendes', 'área', 'estiveram', 'tuas', 'posição', 'poderá', 'que', 'ligado', 'outros', 'sétimo', 'nem', 'comprida', 'zero', 'tão', 'este', 'à', 'algumas', 'sim'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqa-7WXBAw8q"
      },
      "source": [
        "### Instalação do BERT da Hugging Face"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCdqJCtQN52l"
      },
      "source": [
        "Instala a interface pytorch para o BERT by Hugging Face. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RfUN_KolV-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a7d556d-8b63-48d1-ca70-5137068857ee"
      },
      "source": [
        "# Instala a última versão da biblioteca\n",
        "#!pip install transformers\n",
        "\n",
        "# Instala uma versão específica da biblioteca\n",
        "!pip install -U transformers==4.5.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==4.5.1\n",
            "  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 61.5 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 49.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.62.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.1) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQj2wmKDpkrH"
      },
      "source": [
        "## 2 - Download do arquivo do PyTorch Checkpoint\n",
        "\n",
        "Lista de modelos da comunidade:\n",
        "* https://huggingface.co/models\n",
        "\n",
        "Português(https://github.com/neuralmind-ai/portuguese-bert):  \n",
        "* **'neuralmind/bert-base-portuguese-cased'**\n",
        "* **'neuralmind/bert-large-portuguese-cased'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajrTjZzapkrK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49680f26-4275-41a2-861b-a12aea367384"
      },
      "source": [
        "# Importando as bibliotecas\n",
        "import os\n",
        "\n",
        "# Variável para setar o arquivo\n",
        "URL_MODELO = None\n",
        "\n",
        "# Comente uma das urls para carregar modelos de tamanhos diferentes(base/large)\n",
        "# URL_MODELO do arquivo do modelo tensorflow\n",
        "# arquivo menor(base) 1.1 Gbytes\n",
        "#URL_MODELO = 'https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip'\n",
        "\n",
        "# arquivo grande(large) 3.5 Gbytes\n",
        "URL_MODELO = 'https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip'\n",
        "\n",
        "# Se a variável foi setada\n",
        "if URL_MODELO:\n",
        "\n",
        "    # Diretório descompactação\n",
        "    DIRETORIO_MODELO = '/content/modelo'\n",
        "\n",
        "    # Recupera o nome do arquivo do modelo da URL_MODELO\n",
        "    arquivo = URL_MODELO.split('/')[-1]\n",
        "\n",
        "    # Nome do arquivo do vocabulário\n",
        "    arquivo_vocab = 'vocab.txt'\n",
        "\n",
        "    # Caminho do arquivo na URL_MODELO\n",
        "    caminho = URL_MODELO[0:len(URL_MODELO)-len(arquivo)]\n",
        "\n",
        "    # Verifica se a pasta de descompactação existe na pasta corrente\n",
        "    if os.path.exists(DIRETORIO_MODELO):\n",
        "      print('Apagando diretório existente do modelo!')\n",
        "      # Apaga a pasta e os arquivos existentes\n",
        "      !rm -rf $DIRETORIO_MODELO      \n",
        "    \n",
        "    # Baixa o arquivo do modelo\n",
        "    !wget $URL_MODELO\n",
        "    # Descompacta o arquivo na pasta de descompactação\n",
        "    !unzip -o $arquivo -d $DIRETORIO_MODELO\n",
        "\n",
        "    # Baixa o arquivo do vocabulário\n",
        "    # O vocabulário não está no arquivo compactado acima, mesma url mas arquivo diferente\n",
        "    URL_MODELO_VOCAB = caminho + arquivo_vocab\n",
        "    !wget $URL_MODELO_VOCAB\n",
        "    \n",
        "    # Coloca o arquivo do vocabulário no diretório de descompactação\n",
        "    !mv $arquivo_vocab $DIRETORIO_MODELO\n",
        "            \n",
        "    # Move o arquivo para pasta de descompactação\n",
        "    !mv $arquivo $DIRETORIO_MODELO\n",
        "       \n",
        "    print('Pasta do ' + DIRETORIO_MODELO + ' pronta!')\n",
        "    \n",
        "    # Lista a pasta corrente\n",
        "    !ls -la $DIRETORIO_MODELO\n",
        "else:\n",
        "    print('Variável URL_MODELO não setada!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-16 11:27:05--  https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\n",
            "Resolving neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)... 52.219.98.82\n",
            "Connecting to neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)|52.219.98.82|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1244275810 (1.2G) [application/zip]\n",
            "Saving to: ‘bert-large-portuguese-cased_pytorch_checkpoint.zip’\n",
            "\n",
            "bert-large-portugue 100%[===================>]   1.16G  46.4MB/s    in 26s     \n",
            "\n",
            "2021-08-16 11:27:31 (45.6 MB/s) - ‘bert-large-portuguese-cased_pytorch_checkpoint.zip’ saved [1244275810/1244275810]\n",
            "\n",
            "Archive:  bert-large-portuguese-cased_pytorch_checkpoint.zip\n",
            "  inflating: /content/modelo/config.json  \n",
            "  inflating: /content/modelo/pytorch_model.bin  \n",
            "--2021-08-16 11:27:46--  https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/vocab.txt\n",
            "Resolving neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)... 52.219.99.18\n",
            "Connecting to neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)|52.219.99.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 209528 (205K) [text/plain]\n",
            "Saving to: ‘vocab.txt’\n",
            "\n",
            "vocab.txt           100%[===================>] 204.62K   822KB/s    in 0.2s    \n",
            "\n",
            "2021-08-16 11:27:46 (822 KB/s) - ‘vocab.txt’ saved [209528/209528]\n",
            "\n",
            "Pasta do /content/modelo pronta!\n",
            "total 2525908\n",
            "drwxr-xr-x 2 root root       4096 Aug 16 11:27 .\n",
            "drwxr-xr-x 1 root root       4096 Aug 16 11:27 ..\n",
            "-rw-r--r-- 1 root root 1244275810 Jan 22  2020 bert-large-portuguese-cased_pytorch_checkpoint.zip\n",
            "-rw-rw-r-- 1 root root        874 Jan 12  2020 config.json\n",
            "-rw-rw-r-- 1 root root 1342014951 Jan 12  2020 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root     209528 Jan 21  2020 vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcpd9t9PpkrX"
      },
      "source": [
        "## 3 - Carregando o Tokenizador BERT\n",
        "\n",
        "O tokenizador utiliza WordPiece, veja em [artigo original](https://arxiv.org/pdf/1609.08144.pdf).\n",
        "\n",
        "Carregando o tokenizador da pasta '/content/modelo/' do diretório padrão se variável `URL_MODELO` setada.\n",
        "\n",
        "**Caso contrário carrega da comunidade**\n",
        "\n",
        "Por default(`do_lower_case=True`) todas as letras são colocadas para minúsculas. Para ignorar a conversão para minúsculo use o parâmetro `do_lower_case=False`. Esta opção também considera as letras acentuadas(ãçéí...), que são necessárias a língua portuguesa.\n",
        "\n",
        "O parâmetro `do_lower_case` interfere na quantidade tokens a ser gerado a partir de um texto. Quando igual a `False` reduz a quantidade de tokens gerados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8cKVs4fpkrY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f1d0718-0d3c-456a-c566-481ff8d4adf7"
      },
      "source": [
        "# Importando as bibliotecas do tokenizador\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Se a variável URL_MODELO foi setada\n",
        "if DIRETORIO_MODELO:\n",
        "    # Carregando o Tokenizador\n",
        "    print('Carrgando o tokenizador BERT do diretório ' + DIRETORIO_MODELO + '...')\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(DIRETORIO_MODELO, \n",
        "                                              do_lower_case=False)    \n",
        "else:\n",
        "    # Carregando o Tokenizador da comunidade\n",
        "    print('Carregando o tokenizador da comunidade...')\n",
        "    \n",
        "    #tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=False)\n",
        "    tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-large-portuguese-cased', do_lower_case=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carrgando o tokenizador BERT do diretório /content/modelo...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m__On2g1a--K"
      },
      "source": [
        "## 4 - Carregando o Modelo BERT(BertModel)\n",
        "\n",
        "Se a variável `URL_MODELO` estiver setada carrega o modelo do diretório `content/modelo`.\n",
        "\n",
        "Caso contrário carrega da comunidade.\n",
        "\n",
        "Carregando o modelo da pasta '/content/modelo/' do diretório padrão.\n",
        "\n",
        "A implementação do huggingface pytorch inclui um conjunto de interfaces projetadas para uma variedade de tarefas de PNL. Embora essas interfaces sejam todas construídas sobre um modelo treinado de BERT, cada uma possui diferentes camadas superiores e tipos de saída projetados para acomodar suas tarefas específicas de PNL.\n",
        "\n",
        "A documentação para estas pode ser encontrada em [aqui](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html).\n",
        "\n",
        "Por default o modelo está em modo avaliação ou seja `model.eval()`.\n",
        "\n",
        "-----------------------\n",
        "\n",
        "Durante a avaliação do modelo, este retorna um número de diferentes objetos com base em como é configurado na chamada do método `from_pretrained`. \n",
        "\n",
        "Quando definimos `output_hidden_states = True` na chamada do método `from_pretrained`, retorno do modelo possui no terceiro item os estados ocultos(**hidden_states**) de todas as camadas.  Veja a documentação para mais detalhes: https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "\n",
        "Quando **`output_hidden_states = True`** model retorna:\n",
        "- outputs[0] = last_hidden_state;\n",
        "- outputs[1] = pooler_output; \n",
        "- outputs[2] = hidden_states.\n",
        "\n",
        "Quando **`output_hidden_states = False`** ou não especificado model retorna:\n",
        "- outputs[0] = last_hidden_state;\n",
        "- outputs[1] = pooler_output.\n",
        "\n",
        "\n",
        "**ATENÇÃO**: O parâmetro ´**output_hidden_states = True**´ habilita gerar as camadas ocultas do modelo. Caso contrário somente a última camada é mantida. Este parâmetro otimiza a memória mas não os resultados.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRV6l_I-qg9s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b15b13a-4776-4459-a10d-238dc980460d"
      },
      "source": [
        "# Importando as bibliotecas do Modelo\n",
        "from transformers import BertModel\n",
        "\n",
        "# Se a variável URL_MODELO1 foi setada\n",
        "if URL_MODELO:\n",
        "    # Carregando o Tokenizador\n",
        "    print('Carregando o modelo BERT do diretório ' + DIRETORIO_MODELO + '...')\n",
        "\n",
        "    model = BertModel.from_pretrained(DIRETORIO_MODELO, \n",
        "                                      output_attentions = False,\n",
        "                                      output_hidden_states = True)    \n",
        "else:\n",
        "    # Carregando o Tokenizador da comunidade\n",
        "    print('Carregando o modelo BERT da comunidade ...')\n",
        "\n",
        "    model = BertModel.from_pretrained('neuralmind/bert-large-portuguese-cased', \n",
        "                                      output_attentions = False,\n",
        "                                      output_hidden_states = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o modelo BERT do diretório /content/modelo...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU3wHzNUmmBP"
      },
      "source": [
        "## 5 - Funções auxiliares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWqMsrb-ew5T"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm98RoojJcqP"
      },
      "source": [
        "# Import das bibliotecas\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xaeX0oTVQ5t"
      },
      "source": [
        "###removeStopWords\n",
        "\n",
        "Remove as stopwords de um texto ou senteça."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIaQ9bzBVQ5t"
      },
      "source": [
        "def removeStopWord(texto, stopwords):\n",
        "  # Remoção das stop words do texto\n",
        "  textoSemStopwords = [palavra for palavra in texto.split() if palavra.lower() not in stopwords]\n",
        "\n",
        "  # Concatena o texto sem os stopwords\n",
        "  textoLimpo = ' '.join(textoSemStopwords)\n",
        "\n",
        "  # Retorna o texto\n",
        "  return textoLimpo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7NAe8ogCf1y"
      },
      "source": [
        "### retornaRelevante\n",
        "\n",
        "Retorna somente os palavras do texto ou sentença do tipo especificado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNNfykypChn-"
      },
      "source": [
        "def retornaRelevante(texto, tipoRelevante='NOUN'):\n",
        "  \n",
        "  # Realiza o parsing no spacy\n",
        "  doc = nlp(texto)\n",
        "\n",
        "  # Retorna a lista das palavras relevantes\n",
        "  textoComSubstantivos = []\n",
        "  for token in doc:\n",
        "    if token.pos_ == tipoRelevante:\n",
        "      textoComSubstantivos.append(token.text)\n",
        "  #textoComSubstantivos = [token.text for token in doc if token.pos_ == tipoRelevante]\n",
        "\n",
        "  # Concatena o texto com os substantivos\n",
        "  textoConcatenado = ' '.join(textoComSubstantivos)\n",
        "\n",
        "  # Retorna o texto\n",
        "  return textoConcatenado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s42mgtmSZ8MR"
      },
      "source": [
        "### getEmbeddingsCamadas\n",
        "\n",
        "Funções que recuperam os embeddings das camadas:\n",
        "- Primeira camada;\n",
        "- Penúltima camada;\n",
        "- Ùltima camada;\n",
        "- Soma das 4 últimas camadas;\n",
        "- Concatenação das 4 últimas camadas;\n",
        "- Soma de todas as camadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgo3EBTRZ9-3"
      },
      "source": [
        "def getEmbeddingPrimeiraCamada(output):\n",
        "  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n",
        "      \n",
        "  # Retorna todas a primeira(-1) camada\n",
        "  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  resultado = output[2][0]\n",
        "  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  \n",
        "  return resultado\n",
        "\n",
        "def getEmbeddingPenultimaCamada(output):\n",
        "  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n",
        "      \n",
        "  # Retorna todas a primeira(-1) camada\n",
        "  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  resultado = output[2][-2]\n",
        "  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  \n",
        "  return resultado\n",
        "\n",
        "def getEmbeddingUltimaCamada(output):\n",
        "  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n",
        "     \n",
        "  # Retorna todas a primeira(-1) camada\n",
        "  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  resultado = output[2][-1]\n",
        "  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  \n",
        "  return resultado    \n",
        "\n",
        "def getEmbeddingSoma4UltimasCamadas(output):\n",
        "  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n",
        "      \n",
        "  # Retorna todas a primeira(-1) camada\n",
        "  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  embeddingCamadas = output[2][-4:]\n",
        "  # Saída: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "\n",
        "  # Usa o método `stack` para criar uma nova dimensão no tensor \n",
        "  # com a concateção dos tensores dos embeddings.        \n",
        "  #Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  resultadoStack = torch.stack(embeddingCamadas, dim=0)\n",
        "  # Saída: <4> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n",
        "  \n",
        "  # Realiza a soma dos embeddings de todos os tokens para as camadas\n",
        "  # Entrada: <4> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n",
        "  resultado = torch.sum(resultadoStack, dim=0)\n",
        "  # Saida: <1(lote)> x <qtde_tokens> x <768 ou 1024>\n",
        "  \n",
        "  return resultado\n",
        "\n",
        "def getEmbeddingConcat4UltimasCamadas(output):  \n",
        "  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n",
        "      \n",
        "  # Cria uma lista com os tensores a serem concatenados\n",
        "  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  # Lista com os tensores a serem concatenados\n",
        "  listaConcat = []\n",
        "  # Percorre os 4 últimos\n",
        "  for i in [-1,-2,-3,-4]:\n",
        "      # Concatena da lista\n",
        "      listaConcat.append(output[2][i])\n",
        "  # Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  \n",
        "  # Realiza a concatenação dos embeddings de todos as camadas\n",
        "  # Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  resultado = torch.cat(listaConcat, dim=-1)\n",
        "  # Saída: Entrada: (<1(lote)> x <qtde_tokens> <3072 ou 4096>)  \n",
        "    \n",
        "  return resultado   \n",
        "\n",
        "def getEmbeddingSomaTodasAsCamada(output):\n",
        "  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n",
        "   \n",
        "  # Retorna todas as camadas descontando a primeira(0)\n",
        "  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  embeddingCamadas = output[2][1:]\n",
        "  # Saída: List das camadas(12 ou 24) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  \n",
        "  # Usa o método `stack` para criar uma nova dimensão no tensor \n",
        "  # com a concateção dos tensores dos embeddings.        \n",
        "  #Entrada: List das camadas(12 ou 24) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  resultadoStack = torch.stack(embeddingCamadas, dim=0)\n",
        "  # Saída: <12 ou 24> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n",
        "    \n",
        "  # Realiza a soma dos embeddings de todos os tokens para as camadas\n",
        "  # Entrada: <12 ou 24> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n",
        "  resultado = torch.sum(resultadoStack, dim=0)\n",
        "  # Saida: <1(lote)> x <qtde_tokens> x <768 ou 1024>\n",
        "    \n",
        "  return resultado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7nx_eZ8hSlr"
      },
      "source": [
        "### getEmbeddingsVisual\n",
        "\n",
        "Função para gerar as coordenadas de plotagem a partir das sentenças de embeddings.\n",
        "\n",
        "Existe uma função para os tipos de camadas utilizadas:\n",
        "- Ùltima camada;\n",
        "- Soma das 4 últimas camadas;\n",
        "- Concatenação das 4 últimas camadas;\n",
        "- Soma de todas as camadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLdbOT8-g43V"
      },
      "source": [
        "def getEmbeddingsVisualUltimaCamada(texto, modelo, tokenizador):\n",
        "    \n",
        "    # Adiciona os tokens especiais\n",
        "    texto_marcado = '[CLS] ' + texto + ' [SEP]'\n",
        "\n",
        "    # Divide a sentença em tokens\n",
        "    texto_tokenizado = tokenizador.tokenize(texto_marcado)\n",
        "\n",
        "    # Mapeia as strings dos tokens em seus índices do vocabuário    \n",
        "    tokens_indexados = tokenizador.convert_tokens_to_ids(texto_tokenizado)\n",
        "    \n",
        "    # Marca cada um dos tokens como pertencentes à sentença '1'.\n",
        "    mascara_atencao = [1] * len(texto_tokenizado)\n",
        "\n",
        "    # Converte a entrada em tensores\n",
        "    tokens_tensores = torch.as_tensor([tokens_indexados])\n",
        "    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n",
        "    \n",
        "    # Prediz os atributos dos estados ocultos para cada camada\n",
        "    with torch.no_grad():        \n",
        "        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n",
        "        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n",
        "\n",
        "    # Camada embedding    \n",
        "    camada = getEmbeddingUltimaCamada(outputs)\n",
        "\n",
        "    # Remove a dimensão 1, o lote 'batches'.\n",
        "    token_embeddings = torch.squeeze(camada, dim=0)\n",
        "\n",
        "    # Recupera os embeddings dos tokens como um vetor\n",
        "    embeddings = token_embeddings.numpy()\n",
        "\n",
        "    # Converte para um array\n",
        "    W = np.array(embeddings)\n",
        "    # Transforma em um array\n",
        "    B = np.array([embeddings[0], embeddings[-1]])\n",
        "    # Invertee B.T\n",
        "    Bi = np.linalg.pinv(B.T)\n",
        "\n",
        "    #Projeta a palavra no espaço\n",
        "    Wp = np.matmul(Bi,W.T)\n",
        "\n",
        "    return Wp, texto_tokenizado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAf9lJJ2hZbt"
      },
      "source": [
        "def getEmbeddingsVisualSoma4UltimasCamadas(texto, modelo, tokenizador):\n",
        "    \n",
        "    # Adiciona os tokens especiais\n",
        "    texto_marcado = '[CLS] ' + texto + ' [SEP]'\n",
        "\n",
        "    # Divide a sentença em tokens\n",
        "    texto_tokenizado = tokenizador.tokenize(texto_marcado)\n",
        "\n",
        "    # Mapeia as strings dos tokens em seus índices do vocabuário    \n",
        "    tokens_indexados = tokenizador.convert_tokens_to_ids(texto_tokenizado)\n",
        "    \n",
        "    # Marca cada um dos tokens como pertencentes à sentença '1'.\n",
        "    mascara_atencao = [1] * len(texto_tokenizado)\n",
        "\n",
        "    # Converte a entrada em tensores\n",
        "    tokens_tensores = torch.as_tensor([tokens_indexados])\n",
        "    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n",
        "    \n",
        "    # Prediz os atributos dos estados ocultos para cada camada\n",
        "    with torch.no_grad():        \n",
        "        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n",
        "        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n",
        "\n",
        "    # Camada embedding    \n",
        "    camada = getEmbeddingSoma4UltimasCamadas(outputs)\n",
        "\n",
        "    # Remove a dimensão 1, o lote 'batches'.\n",
        "    token_embeddings = torch.squeeze(camada, dim=0)\n",
        "\n",
        "    # Recupera os embeddings dos tokens como um vetor\n",
        "    embeddings = token_embeddings.numpy()\n",
        "\n",
        "    # Converte para um array\n",
        "    W = np.array(embeddings)\n",
        "    # Transforma em um array\n",
        "    B = np.array([embeddings[0], embeddings[-1]])\n",
        "    # Invertee B.T\n",
        "    Bi = np.linalg.pinv(B.T)\n",
        "\n",
        "    #Projeta a palavra no espaço\n",
        "    Wp = np.matmul(Bi,W.T)\n",
        "\n",
        "    return Wp, texto_tokenizado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XpwSN1ghpnz"
      },
      "source": [
        "def getEmbeddingsVisualConcat4UltimasCamadas(texto, modelo, tokenizador):\n",
        "    \n",
        "    # Adiciona os tokens especiais\n",
        "    texto_marcado = '[CLS] ' + texto + ' [SEP]'\n",
        "\n",
        "    # Divide a sentença em tokens\n",
        "    texto_tokenizado = tokenizador.tokenize(texto_marcado)\n",
        "\n",
        "    # Mapeia as strings dos tokens em seus índices do vocabuário    \n",
        "    tokens_indexados = tokenizador.convert_tokens_to_ids(texto_tokenizado)\n",
        "    \n",
        "    # Marca cada um dos tokens como pertencentes à sentença '1'.\n",
        "    mascara_atencao = [1] * len(texto_tokenizado)\n",
        "\n",
        "    # Converte a entrada em tensores\n",
        "    tokens_tensores = torch.as_tensor([tokens_indexados])\n",
        "    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n",
        "    \n",
        "    # Prediz os atributos dos estados ocultos para cada camada\n",
        "    with torch.no_grad():        \n",
        "        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n",
        "        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n",
        "\n",
        "    # Camada embedding    \n",
        "    camada = getEmbeddingConcat4UltimasCamadas(outputs)\n",
        "\n",
        "    # Remove a dimensão 1, o lote 'batches'.\n",
        "    token_embeddings = torch.squeeze(camada, dim=0)\n",
        "\n",
        "    # Recupera os embeddings dos tokens como um vetor\n",
        "    embeddings = token_embeddings.numpy()\n",
        "\n",
        "    # Converte para um array\n",
        "    W = np.array(embeddings)\n",
        "    # Transforma em um array\n",
        "    B = np.array([embeddings[0], embeddings[-1]])\n",
        "    # Invertee B.T\n",
        "    Bi = np.linalg.pinv(B.T)\n",
        "\n",
        "    #Projeta a palavra no espaço\n",
        "    Wp = np.matmul(Bi,W.T)\n",
        "\n",
        "    return Wp, texto_tokenizado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3KU1EFrnSPK"
      },
      "source": [
        "def getEmbeddingsVisualSomaTodasAsCamadas(texto, modelo, tokenizador):\n",
        "    \n",
        "    # Adiciona os tokens especiais\n",
        "    texto_marcado = '[CLS] ' + texto + ' [SEP]'\n",
        "\n",
        "    # Divide a sentença em tokens\n",
        "    texto_tokenizado = tokenizador.tokenize(texto_marcado)\n",
        "\n",
        "    # Mapeia as strings dos tokens em seus índices do vocabuário    \n",
        "    tokens_indexados = tokenizador.convert_tokens_to_ids(texto_tokenizado)\n",
        "    \n",
        "    # Marca cada um dos tokens como pertencentes à sentença '1'.\n",
        "    mascara_atencao = [1] * len(texto_tokenizado)\n",
        "\n",
        "    # Converte a entrada em tensores\n",
        "    tokens_tensores = torch.as_tensor([tokens_indexados])\n",
        "    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n",
        "    \n",
        "    # Prediz os atributos dos estados ocultos para cada camada\n",
        "    with torch.no_grad():        \n",
        "        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n",
        "        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n",
        "\n",
        "    # Camada embedding    \n",
        "    camada = getEmbeddingSomaTodasAsCamada(outputs)\n",
        "\n",
        "    # Remove a dimensão 1, o lote 'batches'.\n",
        "    token_embeddings = torch.squeeze(camada, dim=0)\n",
        "\n",
        "    # Recupera os embeddings dos tokens como um vetor\n",
        "    embeddings = token_embeddings.numpy()\n",
        "\n",
        "    # Converte para um array\n",
        "    W = np.array(embeddings)\n",
        "    # Transforma em um array\n",
        "    B = np.array([embeddings[0], embeddings[-1]])\n",
        "    # Invertee B.T\n",
        "    Bi = np.linalg.pinv(B.T)\n",
        "\n",
        "    #Projeta a palavra no espaço\n",
        "    Wp = np.matmul(Bi,W.T)\n",
        "\n",
        "    return Wp, texto_tokenizado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8MjE0utzlZT"
      },
      "source": [
        "### getEmbeddings\n",
        "\n",
        "Função para gerar os embeddings de sentenças.\n",
        "\n",
        "Existe uma função para os tipos de camadas utilizadas:\n",
        "- Ùltima camada;\n",
        "- Soma das 4 últimas camadas;\n",
        "- Concatenação das 4 últimas camadas;\n",
        "- Soma de todas as camadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QcqOuwS067Q"
      },
      "source": [
        "def getEmbeddingsUltimaCamada(texto, modelo, tokenizador):\n",
        "    \n",
        "    # Adiciona os tokens especiais\n",
        "    texto_marcado = \"[CLS] \" + texto + \" [SEP]\"\n",
        "\n",
        "    # Divide a sentença em tokens\n",
        "    texto_tokenizado = tokenizador.tokenize(texto_marcado)\n",
        "\n",
        "    # Mapeia as strings dos tokens em seus índices do vocabuário    \n",
        "    tokens_indexados = tokenizador.convert_tokens_to_ids(texto_tokenizado)\n",
        "    \n",
        "    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n",
        "    mascara_atencao = [1] * len(texto_tokenizado)\n",
        "\n",
        "    # Converte a entrada em tensores\n",
        "    tokens_tensores = torch.as_tensor([tokens_indexados])\n",
        "    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n",
        "    \n",
        "    # Prediz os atributos dos estados ocultos para cada camada\n",
        "    with torch.no_grad():        \n",
        "        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n",
        "        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n",
        "\n",
        "    # Camada embedding    \n",
        "    camada = getEmbeddingUltimaCamada(outputs)\n",
        "\n",
        "    # Remove a dimensão 1, o lote \"batches\".\n",
        "    token_embeddings = torch.squeeze(camada, dim=0)\n",
        " \n",
        "    return token_embeddings, texto_tokenizado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK1wDGBl067Y"
      },
      "source": [
        "def getEmbeddingsSoma4UltimasCamadas(texto, modelo, tokenizador):\n",
        "    \n",
        "    # Adiciona os tokens especiais\n",
        "    texto_marcado = \"[CLS] \" + texto + \" [SEP]\"\n",
        "\n",
        "    # Divide a sentença em tokens\n",
        "    texto_tokenizado = tokenizador.tokenize(texto_marcado)\n",
        "\n",
        "    # Mapeia as strings dos tokens em seus índices do vocabuário    \n",
        "    tokens_indexados = tokenizador.convert_tokens_to_ids(texto_tokenizado)\n",
        "    \n",
        "    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n",
        "    mascara_atencao = [1] * len(texto_tokenizado)\n",
        "\n",
        "    # Converte a entrada em tensores\n",
        "    tokens_tensores = torch.as_tensor([tokens_indexados])\n",
        "    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n",
        "    \n",
        "    # Prediz os atributos dos estados ocultos para cada camada\n",
        "    with torch.no_grad():        \n",
        "        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n",
        "        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n",
        "\n",
        "    # Camada embedding    \n",
        "    camada = getEmbeddingSoma4UltimasCamadas(outputs)\n",
        "\n",
        "    # Remove a dimensão 1, o lote \"batches\".\n",
        "    token_embeddings = torch.squeeze(camada, dim=0)\n",
        "   \n",
        "    return token_embeddings, texto_tokenizado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hym19Hxr067Y"
      },
      "source": [
        "def getEmbeddingsConcat4UltimasCamadas(texto, modelo, tokenizador):\n",
        "    \n",
        "    # Adiciona os tokens especiais\n",
        "    texto_marcado = \"[CLS] \" + texto + \" [SEP]\"\n",
        "\n",
        "    # Divide a sentença em tokens\n",
        "    texto_tokenizado = tokenizador.tokenize(texto_marcado)\n",
        "\n",
        "    # Mapeia as strings dos tokens em seus índices do vocabuário    \n",
        "    tokens_indexados = tokenizador.convert_tokens_to_ids(texto_tokenizado)\n",
        "    \n",
        "    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n",
        "    mascara_atencao = [1] * len(texto_tokenizado)\n",
        "\n",
        "    # Converte a entrada em tensores\n",
        "    tokens_tensores = torch.as_tensor([tokens_indexados])\n",
        "    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n",
        "    \n",
        "    # Prediz os atributos dos estados ocultos para cada camada\n",
        "    with torch.no_grad():        \n",
        "        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n",
        "        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n",
        "\n",
        "    # Camada embedding    \n",
        "    camada = getEmbeddingConcat4UltimasCamadas(outputs)\n",
        "\n",
        "    # Remove a dimensão 1, o lote \"batches\".\n",
        "    token_embeddings = torch.squeeze(camada, dim=0)\n",
        "\n",
        "    return token_embeddings, texto_tokenizado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-PLZiUR067Z"
      },
      "source": [
        "def getEmbeddingsSomaTodasAsCamadas(texto, modelo, tokenizador):\n",
        "    \n",
        "    # Adiciona os tokens especiais\n",
        "    texto_marcado = \"[CLS] \" + texto + \" [SEP]\"\n",
        "\n",
        "    # Divide a sentença em tokens\n",
        "    texto_tokenizado = tokenizador.tokenize(texto_marcado)\n",
        "\n",
        "    # Mapeia as strings dos tokens em seus índices do vocabuário    \n",
        "    tokens_indexados = tokenizador.convert_tokens_to_ids(texto_tokenizado)\n",
        "    \n",
        "    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n",
        "    mascara_atencao = [1] * len(texto_tokenizado)\n",
        "\n",
        "    # Converte a entrada em tensores\n",
        "    tokens_tensores = torch.as_tensor([tokens_indexados])\n",
        "    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n",
        "    \n",
        "    # Prediz os atributos dos estados ocultos para cada camada\n",
        "    with torch.no_grad():        \n",
        "        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n",
        "        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n",
        "\n",
        "    # Camada embedding    \n",
        "    camada = getEmbeddingSomaTodasAsCamada(outputs)\n",
        "\n",
        "    # Remove a dimensão 1, o lote \"batches\".\n",
        "    token_embeddings = torch.squeeze(camada, dim=0)\n",
        "\n",
        "    return token_embeddings, texto_tokenizado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFd1rse11DpZ"
      },
      "source": [
        "### getTextoTokenizado \n",
        "Retorna o texto tokenizado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvWIBFTLJ7z9"
      },
      "source": [
        "def getTextoTokenizado(texto, tokenizador):\n",
        "\n",
        "    # Adiciona os tokens especiais.\n",
        "    textoMarcado = '[CLS] ' + texto + ' [SEP]'\n",
        "\n",
        "    # Texto tokenizado\n",
        "    textoTokenizado = tokenizador.tokenize(textoMarcado)\n",
        "\n",
        "    return textoTokenizado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wvgXwN81RCz"
      },
      "source": [
        "### encontrarIndiceSubLista \n",
        "\n",
        "Retorna os índices de início e fim da sublista na lista"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abS44M4yvFxf"
      },
      "source": [
        "# Localiza os índices de início e fim de uma sublista em uma lista\n",
        "def encontrarIndiceSubLista(lista, sublista):\n",
        "    # Recupera o tamanho da lista \n",
        "    h = len(lista)\n",
        "    # Recupera o tamanho da sublista\n",
        "    n = len(sublista)    \n",
        "    skip = {sublista[i]: n - i - 1 for i in range(n - 1)}\n",
        "    i = n - 1\n",
        "    while i < h:\n",
        "        for j in range(n):\n",
        "            if lista[i - j] != sublista[-j - 1]:\n",
        "                i += skip.get(lista[i], n)\n",
        "                break\n",
        "        else:\n",
        "            indiceInicio = i - n + 1\n",
        "            indiceFim = indiceInicio + len(sublista)-1\n",
        "            return indiceInicio, indiceFim\n",
        "    return -1, -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_pnIh1h1Z_J"
      },
      "source": [
        "### getEmbeddingSentencaEmbeddingTextoComTodasPalavras\n",
        "\n",
        "Retorna os embeddings de uma sentença com todas as palavras a partir dos embeddings do texto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSQs3O5QpJSj"
      },
      "source": [
        "def getEmbeddingSentencaEmbeddingTextoComTodasPalavras(embeddingTexto, texto, sentenca, tokenizador):\n",
        "  \n",
        "  # Tokeniza o texto\n",
        "  textoTokenizado = getTextoTokenizado(texto, tokenizador)  \n",
        "  #print(textoTokenizado)\n",
        "\n",
        "  # Tokeniza a sentença\n",
        "  sentencaTokenizada = getTextoTokenizado(sentenca, tokenizador)\n",
        "  \n",
        "  # Remove os tokens de início e fim da sentença\n",
        "  sentencaTokenizada.remove('[CLS]')\n",
        "  sentencaTokenizada.remove('[SEP]')  \n",
        "  #print(sentencaTokenizada)\n",
        "  #print(len(sentencaTokenizada))\n",
        "  \n",
        "  # Localiza os índices dos tokens da sentença no texto\n",
        "  inicio, fim = encontrarIndiceSubLista(textoTokenizado,sentencaTokenizada)\n",
        "  #print('Sentença inicia em:', inicio, 'até', fim) \n",
        " \n",
        "  # Recupera os embeddings dos tokens da sentença a partir dos embeddings do texto\n",
        "  embeddingSentenca = embeddingTexto[inicio:fim+1]\n",
        "  #print('embeddingSentenca=', embeddingSentenca.shape)\n",
        "  \n",
        "  # Retorna o embedding da sentença do texto\n",
        "  return embeddingSentenca"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd9xmB9jwZZN"
      },
      "source": [
        "### getEmbeddingSentencaEmbeddingTextoSemStopWord\n",
        "\n",
        "Retorna os embeddings de uma sentença sem stopwords a partir dos embeddings do texto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5XVsCsdwZZP"
      },
      "source": [
        "def getEmbeddingSentencaEmbeddingTextoSemStopWord(embeddingTexto, texto, sentenca, tokenizador):\n",
        "  \n",
        "  # Tokeniza o texto\n",
        "  textoTokenizado = getTextoTokenizado(texto, tokenizador)  \n",
        "  #print(textoTokenizado)\n",
        "  \n",
        "  # Remove as stopword da sentença\n",
        "  sentencaSemStopWord = removeStopWord(sentenca, spacy_stopwords)\n",
        "\n",
        "  # Tokeniza a sentença sem stopword\n",
        "  sentencaTokenizadaSemStopWord = getTextoTokenizado(sentencaSemStopWord, tokenizador)\n",
        "\n",
        "  # Remove os tokens de início e fim da sentença\n",
        "  sentencaTokenizadaSemStopWord.remove('[CLS]')\n",
        "  sentencaTokenizadaSemStopWord.remove('[SEP]')  \n",
        "  #print(sentencaTokenizadaSemStopWord)\n",
        "  #print(len(sentencaTokenizadaSemStopWord))\n",
        "\n",
        "  # Tokeniza a sentença\n",
        "  sentencaTokenizada = getTextoTokenizado(sentenca, tokenizador)\n",
        "  \n",
        "  # Remove os tokens de início e fim da sentença\n",
        "  sentencaTokenizada.remove('[CLS]')\n",
        "  sentencaTokenizada.remove('[SEP]')  \n",
        "  #print(sentencaTokenizada)\n",
        "  #print(len(sentencaTokenizada))\n",
        "\n",
        "  # Localiza os índices dos tokens da sentença no texto\n",
        "  inicio, fim = encontrarIndiceSubLista(textoTokenizado,sentencaTokenizada)\n",
        "  #print('Sentença inicia em:', inicio, 'até', fim) \n",
        "   \n",
        "  # Recupera os embeddings dos tokens da sentença a partir dos embeddings do texto\n",
        "  embeddingSentenca = embeddingTexto[inicio:fim+1]\n",
        "  #print('embeddingSentenca=', embeddingSentenca.shape)\n",
        "\n",
        "  # Lista com os tensores selecionados\n",
        "  listaTokensSelecionados = []\n",
        "  # Localizar os embeddings dos tokens da sentença tokenizada sem stop word na sentença \n",
        "  # Procura somente no intervalo da sentença\n",
        "  for i, tokenSentenca in enumerate(sentencaTokenizada):\n",
        "    for tokenSentencaSemStopWord in sentencaTokenizadaSemStopWord: \n",
        "      if tokenSentenca == tokenSentencaSemStopWord:        \n",
        "        listaTokensSelecionados.append(embeddingSentenca[i:i+1])\n",
        "  \n",
        "  # Concatena os vetores da lista pela dimensão 0\n",
        "  embeddingSentencaSemStopWord = torch.cat(listaTokensSelecionados, dim=0)\n",
        "  #print(\"embeddingSentencaSemStopWord:\",embeddingSentencaSemStopWord.shape)\n",
        "\n",
        "  # Retorna o embedding da sentença do texto\n",
        "  return embeddingSentencaSemStopWord"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgW4gfEzh34J"
      },
      "source": [
        "### getEmbeddingSentencaEmbeddingTextoSomenteRelevante\n",
        "\n",
        "Retorna os embeddings de uma sentença somente com as palavras relevantes a partir dos embeddings do texto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHbQJhzSh34T"
      },
      "source": [
        "def getEmbeddingSentencaEmbeddingTextoSomenteRelevante(embeddingTexto, texto, sentenca, tokenizador, tipoRelevante='NOUN'):\n",
        "  \n",
        "  # Tokeniza o texto\n",
        "  textoTokenizado = getTextoTokenizado(texto, tokenizador)  \n",
        "  #print(textoTokenizado)\n",
        "  \n",
        "  # Retorna as palavras relevantes da sentença do tipo especificado\n",
        "  sentencaSomenteRelevante = retornaRelevante(sentenca,tipoRelevante)\n",
        "\n",
        "  # Tokeniza a sentença \n",
        "  sentencaTokenizadaSomenteRelevante = getTextoTokenizado(sentencaSomenteRelevante, tokenizador)\n",
        "\n",
        "  # Remove os tokens de início e fim da sentença\n",
        "  sentencaTokenizadaSomenteRelevante.remove('[CLS]')\n",
        "  sentencaTokenizadaSomenteRelevante.remove('[SEP]')  \n",
        "  #print(sentencaTokenizadaSomenteRelevante)\n",
        "  #print(len(sentencaTokenizadaSomenteRelevante))\n",
        "\n",
        "  # Tokeniza a sentença\n",
        "  sentencaTokenizada = getTextoTokenizado(sentenca, tokenizador)\n",
        "  \n",
        "  # Remove os tokens de início e fim da sentença\n",
        "  sentencaTokenizada.remove('[CLS]')\n",
        "  sentencaTokenizada.remove('[SEP]')  \n",
        "  #print(sentencaTokenizada)\n",
        "  #print(len(sentencaTokenizada))\n",
        "\n",
        "  # Localiza os índices dos tokens da sentença no texto\n",
        "  inicio, fim = encontrarIndiceSubLista(textoTokenizado,sentencaTokenizada)\n",
        "  #print('Sentença inicia em:', inicio, 'até', fim) \n",
        "   \n",
        "  # Recupera os embeddings dos tokens da sentença a partir dos embeddings do texto\n",
        "  embeddingSentenca = embeddingTexto[inicio:fim+1]\n",
        "  #print('embeddingSentenca=', embeddingSentenca.shape)\n",
        "\n",
        "  # Lista com os tensores selecionados\n",
        "  listaTokensSelecionados = []\n",
        "  # Localizar os embeddings dos tokens da sentença tokenizada sem stop word na sentença \n",
        "  # Procura somente no intervalo da sentença\n",
        "  for i, tokenSentenca in enumerate(sentencaTokenizada):\n",
        "    for tokenSentencaSomenteRelevante in sentencaTokenizadaSomenteRelevante: \n",
        "      if tokenSentenca == tokenSentencaSomenteRelevante:        \n",
        "        listaTokensSelecionados.append(embeddingSentenca[i:i+1])\n",
        "  \n",
        "  # Concatena os vetores da lista pela dimensão 0\n",
        "  embeddingSentencComSubstantivo = torch.cat(listaTokensSelecionados, dim=0)\n",
        "  #print(\"embeddingSentencComSubstantivo:\",embeddingSentencComSubstantivo.shape)\n",
        "\n",
        "  # Retorna o embedding da sentença do texto\n",
        "  return embeddingSentencComSubstantivo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jccxPKRSbBoK"
      },
      "source": [
        "### getEmbeddingSentencaEmbeddingTexto\n",
        "\n",
        "Retorna os embeddings de uma sentença com ou sem stopwords a partir dos embeddings do texto sem os StopWords.\n",
        "\n",
        "Filtros:\n",
        "- ALL - Sentença com todas as palavras\n",
        "- CLEAN - Sentença sem as stopwords\n",
        "- NOUN - Sentença somente com substantivos\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRPeALoFbCAx"
      },
      "source": [
        "def getEmbeddingSentencaEmbeddingTexto(embeddingTexto, texto, sentenca, tokenizador, filtro='ALL'):\n",
        "  if filtro == 'ALL':\n",
        "    return getEmbeddingSentencaEmbeddingTextoComTodasPalavras(embeddingTexto, texto, sentenca, tokenizador)\n",
        "  else:\n",
        "    if filtro == 'CLEAN':\n",
        "        return getEmbeddingSentencaEmbeddingTextoSemStopWord(embeddingTexto, texto, sentenca, tokenizador)\n",
        "    else:\n",
        "      if filtro == 'NOUN':\n",
        "        return getEmbeddingSentencaEmbeddingTextoSomenteRelevante(embeddingTexto, texto, sentenca, tokenizador, tipoRelevante='NOUN')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-3QzDMwmfiJ"
      },
      "source": [
        "## 6 - Exemplo sentenças de texto original e permutado utilizando embedding da última camada do BERT usando a estratégia MEAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTmrN_IRmfiO"
      },
      "source": [
        "### Texto Original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYKIVpzTmfiP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccf1ed3e-9d77-4650-aa22-8527367b3b4a"
      },
      "source": [
        "# Define um texto com 4 sentenças\n",
        "texto_original = ['Bom Dia, professor.',\n",
        "             'Qual o conteúdo da prova?',              \n",
        "             'Vai cair tudo na prova?',\n",
        "             'Aguardo uma resposta, João.']\n",
        "\n",
        "# Concatena as sentenças do texto em uma string\n",
        "textoOriginalConcatenado = ' '.join(texto_original)\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado_original = '[CLS] ' + textoOriginalConcatenado + ' [SEP]'\n",
        "\n",
        "# Divide a sentença em tokens\n",
        "texto_tokenizado_original = tokenizer.tokenize(texto_marcado_original)\n",
        "\n",
        "# Mapeia os tokens em seus índices do vocabulário\n",
        "texto_tokens_indexados_original = tokenizer.convert_tokens_to_ids(texto_tokenizado_original)\n",
        "\n",
        "# Mostra os tokens com seus índices\n",
        "i = 0\n",
        "for tup in zip(texto_tokenizado_original, texto_tokens_indexados_original):\n",
        "    print('{:>3} {:<12} {:>6,}'.format(i, tup[0], tup[1]))\n",
        "    i = i + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0 [CLS]           101\n",
            "  1 Bom           8,399\n",
            "  2 Dia           3,616\n",
            "  3 ,               117\n",
            "  4 professor     2,917\n",
            "  5 .               119\n",
            "  6 Qual         13,082\n",
            "  7 o               146\n",
            "  8 conteúdo      5,015\n",
            "  9 da              180\n",
            " 10 prova         2,310\n",
            " 11 ?               136\n",
            " 12 Vai          20,805\n",
            " 13 cair          9,322\n",
            " 14 tudo          2,745\n",
            " 15 na              229\n",
            " 16 prova         2,310\n",
            " 17 ?               136\n",
            " 18 Agu           8,125\n",
            " 19 ##ardo        2,222\n",
            " 20 uma             230\n",
            " 21 resposta      4,299\n",
            " 22 ,               117\n",
            " 23 João          1,453\n",
            " 24 .               119\n",
            " 25 [SEP]           102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLsHMNz9mfiQ"
      },
      "source": [
        "Máscara de atenção das palavras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pXg2A6zmfiR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f7c40a4-93e4-4258-f7d6-714c2121c626"
      },
      "source": [
        "# Marca cada um dos tokens como pertencentes à sentença '1'.\n",
        "mascara_atencao_original = [1] * len(texto_tokenizado_original)\n",
        "\n",
        "print (mascara_atencao_original)\n",
        "print (len(mascara_atencao_original))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM5GUtVNmfiR"
      },
      "source": [
        "Convertendo as listas em tensores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ePiuflemfiS"
      },
      "source": [
        "# Importa a biblioteca\n",
        "import torch\n",
        "\n",
        "# Converte as entradas de listas para tensores do torch\n",
        "tokens_tensores_original = torch.as_tensor([texto_tokens_indexados_original])\n",
        "mascara_atencao_tensores_original = torch.as_tensor([mascara_atencao_original])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qhHUUoAmfiS"
      },
      "source": [
        "Gera os embeddings para o textoginal. Guarda somente a última camada da rede em `outputs`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o970gzwhmfiS"
      },
      "source": [
        "# Prediz os atributos dos estados ocultos para cada camada\n",
        "with torch.no_grad():\n",
        "    # output[0] contém last_hidden_states\n",
        "    outputs = model(tokens_tensores_original, mascara_atencao_tensores_original)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnXcn_dvmfiT"
      },
      "source": [
        "Recupera a saída da última camada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSiGmlpjmfiT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbf7ae10-21f5-4f07-c53b-b28d924d7ef9"
      },
      "source": [
        "# Recupera a última e única camada da saída\n",
        "last_hidden_states = outputs[0]\n",
        "\n",
        "print ('O vetor da última camada oculta tem o formato:', last_hidden_states.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O vetor da última camada oculta tem o formato: torch.Size([1, 26, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFDtOmN_mfiV"
      },
      "source": [
        "Vamos nos livrar da dimensão lotes 'batches', pois não precisamos dela."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM4Aosw4mfiV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b80b563-e4b9-4d89-810f-37ca27ba4278"
      },
      "source": [
        "# Remove a dimensão 1, o lote 'batches'.\n",
        "#O método squeeze remove a primeira dimensão(0) pois possui tamanho 1\n",
        "embeddingTextoOriginal = torch.squeeze(last_hidden_states, dim=0)\n",
        "\n",
        "print ('O vetor de tokens de embedding do texto original tem o formato:', embeddingTextoOriginal.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O vetor de tokens de embedding do texto original tem o formato: torch.Size([26, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T68Aje2tmfiW"
      },
      "source": [
        "Confirmando vetores dependentes do contexto\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeNaW--hmfiW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3271d1f-8a96-426f-b3d5-c9c983f6361f"
      },
      "source": [
        "for i, token_str in enumerate(texto_tokenizado_original):\n",
        "  print (i, token_str)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [CLS]\n",
            "1 Bom\n",
            "2 Dia\n",
            "3 ,\n",
            "4 professor\n",
            "5 .\n",
            "6 Qual\n",
            "7 o\n",
            "8 conteúdo\n",
            "9 da\n",
            "10 prova\n",
            "11 ?\n",
            "12 Vai\n",
            "13 cair\n",
            "14 tudo\n",
            "15 na\n",
            "16 prova\n",
            "17 ?\n",
            "18 Agu\n",
            "19 ##ardo\n",
            "20 uma\n",
            "21 resposta\n",
            "22 ,\n",
            "23 João\n",
            "24 .\n",
            "25 [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVDBdrHWmfiX"
      },
      "source": [
        "Exibe os embenddings das sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkZrVaVFmfiX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e6e5a9d-bd99-4049-a1ea-77fc96ec6456"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Original = texto_original[0]\n",
        "sentenca2Original = texto_original[1]\n",
        "sentenca3Original = texto_original[2]\n",
        "sentenca4Original = texto_original[3]\n",
        "\n",
        "embeddingSentenca1Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca1Original, tokenizer)\n",
        "embeddingSentenca2Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca2Original, tokenizer)\n",
        "embeddingSentenca3Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca3Original, tokenizer)\n",
        "embeddingSentenca4Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca4Original, tokenizer)\n",
        "\n",
        "print('Os primeiros 4 valores de cada sentença do texto original.')\n",
        "\n",
        "print('\\nSentença 1:', sentenca1Original,'-', str(embeddingSentenca1Original[:4]))\n",
        "print('Soma embedding Sentença1:', sentenca1Original,'-', str(torch.sum(embeddingSentenca1Original[:4])))\n",
        "\n",
        "print('\\nSentença 2:', sentenca2Original,'-', str(embeddingSentenca2Original[:4]))\n",
        "print('Soma embedding Sentença2:', sentenca2Original,'-', str(torch.sum(embeddingSentenca2Original[:4])))\n",
        "\n",
        "print('\\nSentença 3:', sentenca3Original,'-', str(embeddingSentenca3Original[:4]))\n",
        "print('Soma embedding Sentença3:', sentenca3Original,'-', str(torch.sum(embeddingSentenca3Original[:4])))\n",
        "\n",
        "print('\\nSentença 4:', sentenca4Original,'-', str(embeddingSentenca4Original[:4]))\n",
        "print('Soma embedding Sentença4:', sentenca4Original,'-', str(torch.sum(embeddingSentenca4Original[:4])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Os primeiros 4 valores de cada sentença do texto original.\n",
            "\n",
            "Sentença 1: Bom Dia, professor. - tensor([[-0.5098, -0.2877,  0.0873,  ...,  0.5436, -0.9302,  0.4668],\n",
            "        [ 0.6078, -0.8869,  0.3736,  ..., -0.3517, -1.2140, -0.3077],\n",
            "        [ 0.9075, -1.1233, -0.0093,  ...,  0.4433, -0.4633, -0.0113],\n",
            "        [ 0.2499, -0.4717, -0.1217,  ...,  0.7079, -0.2300,  0.4911]])\n",
            "Soma embedding Sentença1: Bom Dia, professor. - tensor(-113.4554)\n",
            "\n",
            "Sentença 2: Qual o conteúdo da prova? - tensor([[-0.3987, -0.9450,  0.1785,  ...,  0.7189, -0.6772, -0.1452],\n",
            "        [ 0.2067, -0.2705,  0.7145,  ...,  0.3047, -0.2718,  0.7577],\n",
            "        [ 0.2355,  0.2686,  0.5669,  ...,  1.0817,  0.5614,  0.3750],\n",
            "        [ 0.5264, -0.4600,  0.4810,  ..., -0.5559, -0.2941,  0.0378]])\n",
            "Soma embedding Sentença2: Qual o conteúdo da prova? - tensor(-115.8800)\n",
            "\n",
            "Sentença 3: Vai cair tudo na prova? - tensor([[ 0.5178,  0.0863,  0.7394,  ..., -0.5765, -0.6208, -0.2230],\n",
            "        [ 0.1617,  1.1516, -0.0350,  ...,  0.1730,  0.2104, -0.0207],\n",
            "        [ 0.9252,  0.5806,  0.2491,  ...,  0.1687,  0.0772, -0.1173],\n",
            "        [ 0.5782,  1.3571, -0.5161,  ..., -0.0942,  0.0404, -0.0390]])\n",
            "Soma embedding Sentença3: Vai cair tudo na prova? - tensor(-110.5299)\n",
            "\n",
            "Sentença 4: Aguardo uma resposta, João. - tensor([[ 0.4339, -0.7168,  0.1173,  ...,  0.0768, -1.2036,  0.3863],\n",
            "        [-0.6806, -1.0194, -0.0765,  ..., -0.1768, -0.6326,  0.2895],\n",
            "        [ 1.1384, -0.8541,  0.8992,  ...,  0.2798, -0.0381,  0.5061],\n",
            "        [ 0.9206, -0.9862,  0.1347,  ...,  0.4182, -1.0164,  0.4713]])\n",
            "Soma embedding Sentença4: Aguardo uma resposta, João. - tensor(-116.1903)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exqsxerrmfiY"
      },
      "source": [
        "Examinando os embeddings do textoginal\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5py_A7lVmfiY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0ac2889-3edf-4270-8a00-132639df3c4d"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Original = texto_original[0]\n",
        "sentenca2Original = texto_original[1]\n",
        "sentenca3Original = texto_original[2]\n",
        "sentenca4Original = texto_original[3]\n",
        "\n",
        "print('Texto Original:', texto_original)\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca1TokenizadaOriginal = tokenizer.tokenize(sentenca1Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca1TokenizadaOriginal)\n",
        "embeddingSentenca1Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca1Original, tokenizer)\n",
        "print('\\nSentença 1 Original=\\'', sentenca1Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca1TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca1Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca1Original))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca2TokenizadaOriginal = tokenizer.tokenize(sentenca2Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca2TokenizadaOriginal)\n",
        "embeddingSentenca2Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca2Original, tokenizer)\n",
        "print('\\nSentença 2 Original=\\'', sentenca2Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca2TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca2Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca2Original))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca3TokenizadaOriginal = tokenizer.tokenize(sentenca3Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca3TokenizadaOriginal)\n",
        "embeddingSentenca3Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca3Original, tokenizer)\n",
        "print('\\nSentença 3 Original=\\'', sentenca3Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca3TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca3Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca3Original))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca4TokenizadaOriginal = tokenizer.tokenize(sentenca4Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca4TokenizadaOriginal)\n",
        "embeddingSentenca4Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca4Original, tokenizer)\n",
        "print('\\nSentença 4 Original=\\'', sentenca4Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca4TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca4Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca4Original))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original: ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "\n",
            "Sentença 1 Original=' Bom Dia, professor. '\n",
            "    Sentença tokenizada: ['Bom', 'Dia', ',', 'professor', '.']\n",
            "    => inicio em 1 e término em 5\n",
            "    Formato modelo : torch.Size([5, 1024])\n",
            "    Soma embeddings:  -141.45\n",
            "\n",
            "Sentença 2 Original=' Qual o conteúdo da prova? '\n",
            "    Sentença tokenizada: ['Qual', 'o', 'conteúdo', 'da', 'prova', '?']\n",
            "    => inicio em 6 e término em 11\n",
            "    Formato modelo : torch.Size([6, 1024])\n",
            "    Soma embeddings:  -173.58\n",
            "\n",
            "Sentença 3 Original=' Vai cair tudo na prova? '\n",
            "    Sentença tokenizada: ['Vai', 'cair', 'tudo', 'na', 'prova', '?']\n",
            "    => inicio em 12 e término em 17\n",
            "    Formato modelo : torch.Size([6, 1024])\n",
            "    Soma embeddings:  -167.58\n",
            "\n",
            "Sentença 4 Original=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    => inicio em 18 e término em 24\n",
            "    Formato modelo : torch.Size([7, 1024])\n",
            "    Soma embeddings:  -200.72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Hg9eKyjEfE5"
      },
      "source": [
        "### Texto Permutado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqHzON3PCa49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b31d996-113e-42ac-9dbf-a23114d695d7"
      },
      "source": [
        "# Define um texto com a permutação das sentenças do texto original\n",
        "texto_permutado = [texto_original[3],   # 'Aguardo uma resposta, João.',\n",
        "             texto_original[1],             # 'Qual o conteúdo da prova?',              \n",
        "             texto_original[0],             # 'Vai cair tudo na prova?',\n",
        "             texto_original[2]]             # 'Bom Dia, professor.']     \n",
        "\n",
        "# Use o texto permutado igual ao original para testar se as medidas estão corretas\n",
        "#texto_permutado = texto_original\n",
        "\n",
        "# Concatena as sentenças do texto em uma string\n",
        "textoPermutadoConcatenado = ' '.join(texto_permutado)\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado_permutado = '[CLS] ' + textoPermutadoConcatenado + ' [SEP]'\n",
        "\n",
        "# Divide a sentença em tokens\n",
        "texto_tokenizado_permutado = tokenizer.tokenize(texto_marcado_permutado)\n",
        "\n",
        "# Mapeia os tokens em seus índices do vocabulário\n",
        "texto_tokens_indexados_permutado = tokenizer.convert_tokens_to_ids(texto_tokenizado_permutado)\n",
        "\n",
        "# Mostra os tokens com seus índices\n",
        "i = 0\n",
        "for tup in zip(texto_tokenizado_permutado, texto_tokens_indexados_permutado):\n",
        "    print('{:>3} {:<12} {:>6,}'.format(i, tup[0], tup[1]))\n",
        "    i = i + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0 [CLS]           101\n",
            "  1 Agu           8,125\n",
            "  2 ##ardo        2,222\n",
            "  3 uma             230\n",
            "  4 resposta      4,299\n",
            "  5 ,               117\n",
            "  6 João          1,453\n",
            "  7 .               119\n",
            "  8 Qual         13,082\n",
            "  9 o               146\n",
            " 10 conteúdo      5,015\n",
            " 11 da              180\n",
            " 12 prova         2,310\n",
            " 13 ?               136\n",
            " 14 Bom           8,399\n",
            " 15 Dia           3,616\n",
            " 16 ,               117\n",
            " 17 professor     2,917\n",
            " 18 .               119\n",
            " 19 Vai          20,805\n",
            " 20 cair          9,322\n",
            " 21 tudo          2,745\n",
            " 22 na              229\n",
            " 23 prova         2,310\n",
            " 24 ?               136\n",
            " 25 [SEP]           102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5Snv8-ACy47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8970c275-b657-485d-8e16-4478d9697e91"
      },
      "source": [
        "# Marca cada um dos tokens como pertencentes à sentença '1'.\n",
        "mascara_atencao_permutado = [1] * len(texto_tokenizado_permutado)\n",
        "\n",
        "print (mascara_atencao_permutado)\n",
        "print (len(mascara_atencao_permutado))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLv52fBItM3I"
      },
      "source": [
        "Convertendo as listas em tensores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMFR5tSiCy48"
      },
      "source": [
        "# Importa a biblioteca\n",
        "import torch\n",
        "\n",
        "# Converte as entradas de listas para tensores do torch\n",
        "tokens_tensores_permutado = torch.as_tensor([texto_tokens_indexados_permutado])\n",
        "mascara_atencao_tensores_permutado = torch.as_tensor([mascara_atencao_permutado])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDFnt2yntIgn"
      },
      "source": [
        "Gera os embeddings para o texto original. Guarda somente a última camada da rede em `outputs`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je2zyykXCy49"
      },
      "source": [
        "# Prediz os atributos dos estados ocultos para cada camada\n",
        "with torch.no_grad():\n",
        "    # output[0] contém last_hidden_states\n",
        "    outputs = model(tokens_tensores_permutado, mascara_atencao_tensores_permutado)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZSIxolutQSp"
      },
      "source": [
        "Recupera a saída da última camada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z09FmGtnCy49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea54987c-f53e-4410-b857-3f14967dd52e"
      },
      "source": [
        "# Recupera a última e única camada da saída\n",
        "last_hidden_states = outputs[0]\n",
        "\n",
        "print ('O vetor da última camada oculta tem o formato:', last_hidden_states.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O vetor da última camada oculta tem o formato: torch.Size([1, 26, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aetb3LVYtXnI"
      },
      "source": [
        "Vamos nos livrar da dimensão lotes 'batches', pois não precisamos dela."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkk3Ix9kC93C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "425b8b51-6b30-4e4a-9056-7eb32ae88c84"
      },
      "source": [
        "# Remove a dimensão 1, o lote 'batches'.\n",
        "#O método squeeze remove a primeira dimensão(0) pois possui tamanho 1\n",
        "embeddingTextoPermutado = torch.squeeze(last_hidden_states, dim=0)\n",
        "\n",
        "print ('O vetor de tokens de embedding do texto permutado tem o formato:', embeddingTextoPermutado.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O vetor de tokens de embedding do texto permutado tem o formato: torch.Size([26, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIsMSKxNIUg9"
      },
      "source": [
        "Exibe os embenddings das sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkHr7wEFIUhA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51b9f476-398f-456e-e54b-8e70d453e85a"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Permutado = texto_permutado[0]\n",
        "sentenca2Permutado = texto_permutado[1]\n",
        "sentenca3Permutado = texto_permutado[2]\n",
        "sentenca4Permutado = texto_permutado[3]\n",
        "\n",
        "embeddingSentenca1Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca1Permutado, tokenizer)\n",
        "embeddingSentenca2Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca2Permutado, tokenizer)\n",
        "embeddingSentenca3Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca3Permutado, tokenizer)\n",
        "embeddingSentenca4Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca4Permutado, tokenizer)\n",
        "\n",
        "print('Os primeiros 4 valores de cada sentença do texto permutado.')\n",
        "\n",
        "print('\\nSentença 1:', sentenca1Permutado,'-', str(embeddingSentenca1Permutado[:4]))\n",
        "print('Soma embedding Sentença1:', sentenca1Original,'-', str(torch.sum(embeddingSentenca1Original[:4])))\n",
        "\n",
        "print('\\nSentença 2:', sentenca2Permutado,'-', str(embeddingSentenca2Permutado[:4]))\n",
        "print('Soma embedding Sentença2:', sentenca2Permutado,'-', str(torch.sum(embeddingSentenca2Permutado[:4])))\n",
        "\n",
        "print('\\nSentença 3:', sentenca3Permutado,'-', str(embeddingSentenca3Permutado[:4]))\n",
        "print('Soma embedding Sentença3:', sentenca3Permutado,'-', str(torch.sum(embeddingSentenca3Original[:4])))\n",
        "\n",
        "print('\\nSentença 4:', sentenca4Permutado,'-', str(embeddingSentenca4Permutado[:4]))\n",
        "print('Soma embedding Sentença4:', sentenca4Permutado,'-', str(torch.sum(embeddingSentenca4Permutado[:4])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Os primeiros 4 valores de cada sentença do texto permutado.\n",
            "\n",
            "Sentença 1: Aguardo uma resposta, João. - tensor([[ 0.4152, -0.7838, -0.0364,  ...,  0.2686, -1.3504,  0.4707],\n",
            "        [-0.6012, -1.1043, -0.2660,  ..., -0.1943, -0.8112,  0.2180],\n",
            "        [ 1.2319, -1.1194,  0.9353,  ...,  0.2953, -0.1973,  0.5069],\n",
            "        [ 0.8861, -0.9666,  0.1831,  ...,  0.4595, -1.1045,  0.5615]])\n",
            "Soma embedding Sentença1: Bom Dia, professor. - tensor(-113.4554)\n",
            "\n",
            "Sentença 2: Qual o conteúdo da prova? - tensor([[-0.2957, -1.0942, -0.0024,  ...,  0.5875, -0.7164,  0.0104],\n",
            "        [ 0.2193, -0.4914,  0.7233,  ...,  0.3551, -0.3698,  0.8577],\n",
            "        [ 0.1377,  0.3856,  0.6060,  ...,  1.2662,  0.4965,  0.5211],\n",
            "        [ 0.5271, -0.4796,  0.4135,  ..., -0.5303, -0.3934,  0.1571]])\n",
            "Soma embedding Sentença2: Qual o conteúdo da prova? - tensor(-115.7949)\n",
            "\n",
            "Sentença 3: Bom Dia, professor. - tensor([[-0.2387, -0.2844,  0.3606,  ...,  0.6976, -0.9028,  0.3216],\n",
            "        [ 0.8188, -0.5643,  0.6965,  ..., -0.1439, -0.7018, -0.1933],\n",
            "        [ 0.9349, -1.0496,  0.1645,  ...,  0.4782, -0.3837, -0.2850],\n",
            "        [ 0.0104, -0.4793,  0.0501,  ...,  0.7341, -0.3687,  0.4562]])\n",
            "Soma embedding Sentença3: Bom Dia, professor. - tensor(-110.5299)\n",
            "\n",
            "Sentença 4: Vai cair tudo na prova? - tensor([[ 7.8763e-01, -1.1689e-01,  7.6317e-01,  ..., -4.3840e-01,\n",
            "         -6.5442e-01, -6.2305e-02],\n",
            "        [ 2.1062e-01,  1.0353e+00,  2.5937e-02,  ...,  7.1820e-02,\n",
            "          1.2368e-01,  1.1584e-03],\n",
            "        [ 7.5943e-01,  7.9969e-01,  2.4871e-01,  ...,  1.8792e-01,\n",
            "          9.4661e-02, -9.1651e-02],\n",
            "        [ 6.7000e-01,  1.3208e+00, -5.6431e-01,  ..., -6.3588e-03,\n",
            "          1.6016e-01, -1.4379e-01]])\n",
            "Soma embedding Sentença4: Vai cair tudo na prova? - tensor(-110.7603)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MINDqF2LDA9z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d499def-9206-4cd8-c292-f063c0bf3f31"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Permutado = texto_permutado[0]\n",
        "sentenca2Permutado = texto_permutado[1]\n",
        "sentenca3Permutado = texto_permutado[2]\n",
        "sentenca4Permutado = texto_permutado[3]\n",
        "\n",
        "print('Texto Permutado:', texto_permutado)\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca1TokenizadaPermutado = tokenizer.tokenize(sentenca1Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca1TokenizadaPermutado)\n",
        "embeddingSentenca1Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca1Permutado, tokenizer)\n",
        "print('\\nSentença 1 Permutada=\\'', sentenca1Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca1TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca1Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca1Permutado))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca2TokenizadaPermutado = tokenizer.tokenize(sentenca2Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca2TokenizadaPermutado)\n",
        "embeddingSentenca2Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca2Permutado, tokenizer)\n",
        "print('\\nSentença 2 Permutada=\\'', sentenca2Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca2TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca2Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca2Permutado))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca3TokenizadaPermutado = tokenizer.tokenize(sentenca3Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca3TokenizadaPermutado)\n",
        "embeddingSentenca3Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca3Permutado, tokenizer)\n",
        "print('\\nSentença 3 Permutada=\\'', sentenca3Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca3TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca3Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca3Permutado))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca4TokenizadaPermutado = tokenizer.tokenize(sentenca4Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca4TokenizadaPermutado)\n",
        "embeddingSentenca4Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca4Permutado, tokenizer)\n",
        "print('\\nSentença 4 Permutada=\\'', sentenca4Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca4TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca4Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca4Permutado))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado: ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "\n",
            "Sentença 1 Permutada=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    => inicio em 1 e término em 7\n",
            "    Formato modelo : torch.Size([7, 1024])\n",
            "    Soma embeddings:  -199.90\n",
            "\n",
            "Sentença 2 Permutada=' Qual o conteúdo da prova? '\n",
            "    Sentença tokenizada: ['Qual', 'o', 'conteúdo', 'da', 'prova', '?']\n",
            "    => inicio em 8 e término em 13\n",
            "    Formato modelo : torch.Size([6, 1024])\n",
            "    Soma embeddings:  -173.06\n",
            "\n",
            "Sentença 3 Permutada=' Bom Dia, professor. '\n",
            "    Sentença tokenizada: ['Bom', 'Dia', ',', 'professor', '.']\n",
            "    => inicio em 14 e término em 18\n",
            "    Formato modelo : torch.Size([5, 1024])\n",
            "    Soma embeddings:  -141.81\n",
            "\n",
            "Sentença 4 Permutada=' Vai cair tudo na prova? '\n",
            "    Sentença tokenizada: ['Vai', 'cair', 'tudo', 'na', 'prova', '?']\n",
            "    => inicio em 19 e término em 24\n",
            "    Formato modelo : torch.Size([6, 1024])\n",
            "    Soma embeddings:  -167.47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UILLnj7KvHi"
      },
      "source": [
        "### Examinando as sentenças\n",
        "\n",
        "A mesma sentença apresenta embeddings com valores diferentes, pois se encontram em locais diferentes do texto. A soma de todos os embeddings demonstra isto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eyEbV-7Kz6r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c35bea81-ac42-417d-8f92-83b817db2d38"
      },
      "source": [
        "print('\\nSentença 4 Original=\\'', sentenca4Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca4TokenizadaOriginal)\n",
        "print('    Formato modelo :', embeddingSentenca4Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca4Original))\n",
        "print('    Os 4 primeiros embeddings:', str(embeddingSentenca4Original[:4]))\n",
        "\n",
        "print('\\nSentença 1 Permutada=\\'', sentenca1Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca1TokenizadaPermutado)\n",
        "print('    Formato modelo :', embeddingSentenca1Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca1Permutado))\n",
        "print('    Os 4 primeiros embeddings:', str(embeddingSentenca1Permutado[:4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Sentença 4 Original=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    Formato modelo : torch.Size([7, 1024])\n",
            "    Soma embeddings:  -200.72\n",
            "    Os 4 primeiros embeddings: tensor([[ 0.4339, -0.7168,  0.1173,  ...,  0.0768, -1.2036,  0.3863],\n",
            "        [-0.6806, -1.0194, -0.0765,  ..., -0.1768, -0.6326,  0.2895],\n",
            "        [ 1.1384, -0.8541,  0.8992,  ...,  0.2798, -0.0381,  0.5061],\n",
            "        [ 0.9206, -0.9862,  0.1347,  ...,  0.4182, -1.0164,  0.4713]])\n",
            "\n",
            "Sentença 1 Permutada=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    Formato modelo : torch.Size([7, 1024])\n",
            "    Soma embeddings:  -199.90\n",
            "    Os 4 primeiros embeddings: tensor([[ 0.4152, -0.7838, -0.0364,  ...,  0.2686, -1.3504,  0.4707],\n",
            "        [-0.6012, -1.1043, -0.2660,  ..., -0.1943, -0.8112,  0.2180],\n",
            "        [ 1.2319, -1.1194,  0.9353,  ...,  0.2953, -0.1973,  0.5069],\n",
            "        [ 0.8861, -0.9666,  0.1831,  ...,  0.4595, -1.1045,  0.5615]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JplTToZvDLiX"
      },
      "source": [
        "### Similaridade de cosseno entre os embeddings das sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eERVKqh2uk6S"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "def similaridadeCoseno(sentenca1, sentenca2):\n",
        "  similaridade = 1 - cosine(sentenca1, sentenca2)\n",
        "  return similaridade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av6tZHt6DLiY"
      },
      "source": [
        "#### Calcula a média aritmética da similaridade do coseno entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto original. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOQ9vWuADLiY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9ac80a2-1406-4faf-961c-b1d2b2e4dc1f"
      },
      "source": [
        "print('Texto Original  :', str(texto_original))\n",
        "print('Quantidade de sentenças:',len(texto_original))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "n = len(texto_original)\n",
        "\n",
        "somaScos = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(n-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_original[i]\n",
        "    Sj = texto_original[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto original    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "    # Similaridade entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Scos = similaridadeCoseno(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaScos = somaScos + Scos\n",
        "\n",
        "CcosOriginal = float(somaScos)/float(n-1)\n",
        "print('Ccos Original:', CcosOriginal)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original  : ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "Quantidade de sentenças: 4\n",
            "Ccos Original: 0.7828845977783203\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmTaSFZNDLiY"
      },
      "source": [
        "#### Calcula a média aritmética da similaridade do coseno entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto permutado. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYIO7AXCDLiY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba9a232c-0340-4a47-fc9f-6445498eecdf"
      },
      "source": [
        "print('Texto Permutado :', str(texto_permutado))\n",
        "print('Quantidade de sentenças:', len(texto_permutado))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "np = len(texto_permutado)\n",
        "\n",
        "somaScos = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(np-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_permutado[i]\n",
        "    Sj = texto_permutado[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto permutado    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "   # Similaridade entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Scos = similaridadeCoseno(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaScos = somaScos + Scos\n",
        "\n",
        "CcosPermutado = float(somaScos)/float(np-1)\n",
        "print('Ccos Original:', CcosPermutado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado : ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "Quantidade de sentenças: 4\n",
            "Ccos Original: 0.7326474785804749\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiJ_9-KPDLiY"
      },
      "source": [
        "#### Compara as médias da similaridade de cosseno dos embeddings das sentenças do texto original e permutado\n",
        "\n",
        "Características das medidas:\n",
        "- Textos com sentenças iguais resulta uma medida igual a 1.\n",
        "- Textos com sentenças diferenntes resulta uma medida menor que 1.\n",
        "- Texto com sentenças muito diferentes apresentam valores menores que 1.\n",
        "- Textos iguais resultam em medidas iguais. \n",
        "- É uma medida de similaridade.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ1pRGiEDLiY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe3682c0-83d9-44f2-b419-6362955533f9"
      },
      "source": [
        "print('Ccos Original :', CcosOriginal)\n",
        "print('Ccos Permutado:', CcosPermutado)\n",
        "\n",
        "if (CcosOriginal > CcosPermutado):\n",
        "    print('Texto original tem maior similaridade de cosseno entre as sentenças!')\n",
        "else:\n",
        "    print('Texto Permutado tem menor similaridade de cosseno entre as sentenças!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ccos Original : 0.7828845977783203\n",
            "Ccos Permutado: 0.7326474785804749\n",
            "Texto original tem maior similaridade de cosseno entre as sentenças!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tLfL6BFDLiZ"
      },
      "source": [
        "### Distância euclidiana entre os embeddings das sentenças\n",
        "\n",
        "Possui outros nomes como distância L2 ou norma L2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKrR5hMNDLiZ"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "def distanciaEuclidiana(sentenca1, sentenca2):\n",
        "  distancia = euclidean(sentenca1, sentenca2)\n",
        "\n",
        "  return distancia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scio7VcxDLiZ"
      },
      "source": [
        "#### Calcula a média aritmética da distância euclidiana entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto original. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qPGyX3WDLiZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ef4d731-480c-4f01-e9a2-eddfd8d9ea7e"
      },
      "source": [
        "print('Texto Original  :', str(texto_original))\n",
        "print('Quantidade de sentenças:',len(texto_original))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "n = len(texto_original)\n",
        "\n",
        "somaSeuc = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(n-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_original[i]\n",
        "    Sj = texto_original[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto original    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    # print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "    # Diferença entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Seuc = distanciaEuclidiana(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSeuc = somaSeuc + Seuc\n",
        "\n",
        "CeucOriginal = float(somaSeuc)/float(n-1)\n",
        "print('Ceuc Original:', CeucOriginal)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original  : ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "Quantidade de sentenças: 4\n",
            "Ceuc Original: 11.104771296183268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eiJkQ9tDLiZ"
      },
      "source": [
        "#### Calcula a média aritmética da distância euclidiana entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto permutado. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCa8HJAjDLiZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "433da515-b81b-4b17-c60b-2a84d97fa092"
      },
      "source": [
        "print('Texto Permutado :', str(texto_permutado))\n",
        "print('Quantidade de sentenças:', len(texto_permutado))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "np = len(texto_permutado)\n",
        "\n",
        "somaSeuc = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(np-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_permutado[i]\n",
        "    Sj = texto_permutado[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto permutado\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "    # Diferença entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Seuc = distanciaEuclidiana(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSeuc = somaSeuc + Seuc\n",
        "\n",
        "CeucPermutado = float(somaSeuc)/float(np-1)\n",
        "print('Ceuc Original:', CeucPermutado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado : ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "Quantidade de sentenças: 4\n",
            "Ceuc Original: 12.47801144917806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz5eaOkEDLiZ"
      },
      "source": [
        "#### Compara as médias da distância euclidiana dos embeddings das sentenças do texto original e permutado\n",
        "\n",
        "Características das medidas:\n",
        "- Textos com sentenças iguais resulta uma medida igual a 0.\n",
        "- Textos com sentenças diferenntes resulta uma medida maior que 0.\n",
        "- Texto com sentenças muito diferentes apresentam valores maiores que 0.\n",
        "- Textos iguais resultam em medidas iguais. \n",
        "- É uma medida de diferença.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhelRMqGDLia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "948345fe-314e-4103-b4c8-5b95cc6f90ed"
      },
      "source": [
        "print('Ceuc Original :', CeucOriginal)\n",
        "print('Ceuc Permutado:', CeucPermutado)\n",
        "\n",
        "if (CeucOriginal < CeucPermutado):\n",
        "    print('Texto original tem menor distância euclidiana entre as sentenças!')\n",
        "else:\n",
        "    print('Texto Permutado tem maior distância euclidiana entre as sentenças!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ceuc Original : 11.104771296183268\n",
            "Ceuc Permutado: 12.47801144917806\n",
            "Texto original tem menor distância euclidiana entre as sentenças!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqPCQJ24DLia"
      },
      "source": [
        "### Distância Manhattan entre os embeddings das sentenças\n",
        "\n",
        "Possui outros nomes como distância Cityblock, distância L1, norma L1 e métrica do táxi.\n",
        "\n",
        "Igual a distância de subtração absoluta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCjpuWTRDLib"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "from scipy.spatial.distance import cityblock\n",
        "\n",
        "def distanciaManhattan(sentenca1, sentenca2):\n",
        "  distancia = cityblock(sentenca1, sentenca2)\n",
        "\n",
        "  return distancia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKSaAqoZDLib"
      },
      "source": [
        "#### Calcula a média aritmética da distância de manhattan entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto original. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFLah0Q9DLib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7edc814-d16c-4b2a-d132-748562e79bef"
      },
      "source": [
        "print('Texto Original  :', str(texto_original))\n",
        "print('Quantidade de sentenças:',len(texto_original))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "n = len(texto_original)\n",
        "\n",
        "somaSman = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(n-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_original[i]\n",
        "    Sj = texto_original[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto original    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    # print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "    # Diferença entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Sman = distanciaManhattan(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSman = somaSman + Sman\n",
        "\n",
        "CmanOriginal = float(somaSman)/float(n-1)\n",
        "print('Cman Original:', CmanOriginal)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original  : ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "Quantidade de sentenças: 4\n",
            "Cman Original: 274.52051798502606\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43BxjteRDLib"
      },
      "source": [
        "#### Calcula a média aritmética da distância de manhattan entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto permutado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E6e9k1YDLic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b63864ea-f854-494a-99a7-a66b40d65006"
      },
      "source": [
        "print('Texto Permutado :', str(texto_permutado))\n",
        "print('Quantidade de sentenças:', len(texto_permutado))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "np = len(texto_permutado)\n",
        "\n",
        "somaSman = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(np-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_permutado[i]\n",
        "    Sj = texto_permutado[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto permutado\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    # print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "    # Diferença entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Sman = distanciaManhattan(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSman = somaSman + Sman\n",
        "\n",
        "CmanPermutado = float(somaSman)/float(n-1)\n",
        "print('Cman Permutado:', CmanPermutado)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado : ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "Quantidade de sentenças: 4\n",
            "Cman Permutado: 308.2206522623698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ-427FYDLic"
      },
      "source": [
        "#### Compara as médias da distância de manhattan dos embeddings das sentenças do texto original e permutado\n",
        "\n",
        "Características das medidas:\n",
        "- Textos com sentenças iguais resulta uma medida igual a 0.\n",
        "- Textos com sentenças diferenntes resulta uma medida maior que 0.\n",
        "- Texto com sentenças muito diferentes apresentam valores maiores que 0.\n",
        "- Textos iguais resultam em medidas iguais. \n",
        "- É uma medida de diferença.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3snpqLtIDLic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73d84ef6-1847-45dd-b7bb-ed2d013a43cd"
      },
      "source": [
        "print('Cman Original :', CmanOriginal)\n",
        "print('Cman Permutado:', CmanPermutado)\n",
        "\n",
        "if (CmanOriginal < CmanPermutado):\n",
        "    print('Texto original tem menor distância de manhattan entre as sentenças!')\n",
        "else:\n",
        "    print('Texto Permutado tem maior distância de manhattan entre as sentenças!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cman Original : 274.52051798502606\n",
            "Cman Permutado: 308.2206522623698\n",
            "Texto original tem menor distância de manhattan entre as sentenças!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJRDXLHua9ce"
      },
      "source": [
        "### Resumo\n",
        "\n",
        "Resultado das medidas utilizando a última camada do BERT.\n",
        "\n",
        "Base(MEAN):\n",
        "- Ccos       :   0.62004846          0.54099079\n",
        "- Ceuc       :   7.11709849          7.99353107\n",
        "- Cman       :   153.63694255          171.98441060\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4jEPcWRa9ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e59cea50-22c3-4b39-a3f6-c2c357e5ddac"
      },
      "source": [
        "print('Resultado das medidas utilizando a última camada do BERT')\n",
        "print('Texto  :   Original            Permutado')\n",
        "print('Ccos       :   {:.8f}          {:.8f}'.format(CcosOriginal,CcosPermutado))\n",
        "print('Ceuc       :   {:.8f}          {:.8f}'.format(CeucOriginal,CeucPermutado))\n",
        "print('Cman       :   {:.8f}          {:.8f}'.format(CmanOriginal,CmanPermutado))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resultado das medidas utilizando a última camada do BERT\n",
            "Texto  :   Original            Permutado\n",
            "Ccos       :   0.78288460          0.73264748\n",
            "Ceuc       :   11.10477130          12.47801145\n",
            "Cman       :   274.52051799          308.22065226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5NHv8JQ2Om8"
      },
      "source": [
        "## 7 - Exemplo sentenças de texto original e permutado utilizando embedding da última camada do BERT usando estratégia MAX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuFaynIX2OnA"
      },
      "source": [
        "### Texto Original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ird39LBl2OnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6366424-a0f8-428b-f5cc-2371489d4452"
      },
      "source": [
        "# Define um texto com 4 sentenças\n",
        "texto_original = ['Bom Dia, professor.',\n",
        "             'Qual o conteúdo da prova?',              \n",
        "             'Vai cair tudo na prova?',\n",
        "             'Aguardo uma resposta, João.']\n",
        "\n",
        "# Concatena as sentenças do texto em uma string\n",
        "textoOriginalConcatenado = ' '.join(texto_original)\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado_original = '[CLS] ' + textoOriginalConcatenado + ' [SEP]'\n",
        "\n",
        "# Divide a sentença em tokens\n",
        "texto_tokenizado_original = tokenizer.tokenize(texto_marcado_original)\n",
        "\n",
        "# Mapeia os tokens em seus índices do vocabulário\n",
        "texto_tokens_indexados_original = tokenizer.convert_tokens_to_ids(texto_tokenizado_original)\n",
        "\n",
        "# Mostra os tokens com seus índices\n",
        "i = 0\n",
        "for tup in zip(texto_tokenizado_original, texto_tokens_indexados_original):\n",
        "    print('{:>3} {:<12} {:>6,}'.format(i, tup[0], tup[1]))\n",
        "    i = i + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0 [CLS]           101\n",
            "  1 Bom           8,399\n",
            "  2 Dia           3,616\n",
            "  3 ,               117\n",
            "  4 professor     2,917\n",
            "  5 .               119\n",
            "  6 Qual         13,082\n",
            "  7 o               146\n",
            "  8 conteúdo      5,015\n",
            "  9 da              180\n",
            " 10 prova         2,310\n",
            " 11 ?               136\n",
            " 12 Vai          20,805\n",
            " 13 cair          9,322\n",
            " 14 tudo          2,745\n",
            " 15 na              229\n",
            " 16 prova         2,310\n",
            " 17 ?               136\n",
            " 18 Agu           8,125\n",
            " 19 ##ardo        2,222\n",
            " 20 uma             230\n",
            " 21 resposta      4,299\n",
            " 22 ,               117\n",
            " 23 João          1,453\n",
            " 24 .               119\n",
            " 25 [SEP]           102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCazJyHf2OnB"
      },
      "source": [
        "Máscara de atenção das palavras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkzJFTWX2OnB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "041e4524-cd34-4018-9f66-f53a28f52256"
      },
      "source": [
        "# Marca cada um dos tokens como pertencentes à sentença '1'.\n",
        "mascara_atencao_original = [1] * len(texto_tokenizado_original)\n",
        "\n",
        "print (mascara_atencao_original)\n",
        "print (len(mascara_atencao_original))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H624EpGv2OnB"
      },
      "source": [
        "Convertendo as listas em tensores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBfLtHz92OnB"
      },
      "source": [
        "# Importa a biblioteca\n",
        "import torch\n",
        "\n",
        "# Converte as entradas de listas para tensores do torch\n",
        "tokens_tensores_original = torch.as_tensor([texto_tokens_indexados_original])\n",
        "mascara_atencao_tensores_original = torch.as_tensor([mascara_atencao_original])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SM5nK5Zr2OnB"
      },
      "source": [
        "Gera os embeddings para o texto original. Guarda somente a última camada da rede em `outputs`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0SPckuI2OnC"
      },
      "source": [
        "# Prediz os atributos dos estados ocultos para cada camada\n",
        "with torch.no_grad():\n",
        "    # output[0] contém last_hidden_states\n",
        "    outputs = model(tokens_tensores_original, mascara_atencao_tensores_original)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceWI29Ij2OnC"
      },
      "source": [
        "Recupera a saída da última camada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ReZJfwR2OnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3288c7b-5e18-480c-fc11-342eebd85df3"
      },
      "source": [
        "# Recupera a última e única camada da saída\n",
        "last_hidden_states = outputs[0]\n",
        "\n",
        "print ('O vetor da última camada oculta tem o formato:', last_hidden_states.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O vetor da última camada oculta tem o formato: torch.Size([1, 26, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysFToAty2OnC"
      },
      "source": [
        "Vamos nos livrar da dimensão lotes 'batches', pois não precisamos dela."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp8ImZM52OnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "933a6326-11cd-4a21-df5f-675cb681ad0c"
      },
      "source": [
        "# Remove a dimensão 1, o lote 'batches'.\n",
        "#O método squeeze remove a primeira dimensão(0) pois possui tamanho 1\n",
        "embeddingTextoOriginal = torch.squeeze(last_hidden_states, dim=0)\n",
        "\n",
        "print ('O vetor de tokens de embedding do texto original tem o formato:', embeddingTextoOriginal.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O vetor de tokens de embedding do texto original tem o formato: torch.Size([26, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhiX25CW2OnC"
      },
      "source": [
        "Confirmando vetores dependentes do contexto\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7C8abOy2OnD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27b53699-e24b-4756-b8c9-75ff90b4fa4b"
      },
      "source": [
        "for i, token_str in enumerate(texto_tokenizado_original):\n",
        "  print (i, token_str)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [CLS]\n",
            "1 Bom\n",
            "2 Dia\n",
            "3 ,\n",
            "4 professor\n",
            "5 .\n",
            "6 Qual\n",
            "7 o\n",
            "8 conteúdo\n",
            "9 da\n",
            "10 prova\n",
            "11 ?\n",
            "12 Vai\n",
            "13 cair\n",
            "14 tudo\n",
            "15 na\n",
            "16 prova\n",
            "17 ?\n",
            "18 Agu\n",
            "19 ##ardo\n",
            "20 uma\n",
            "21 resposta\n",
            "22 ,\n",
            "23 João\n",
            "24 .\n",
            "25 [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZCfusGL2OnD"
      },
      "source": [
        "Exibe os embenddings das sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaOvIge52OnD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fca1efb-1db8-4c68-b8f3-befc5dbd5fd5"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Original = texto_original[0]\n",
        "sentenca2Original = texto_original[1]\n",
        "sentenca3Original = texto_original[2]\n",
        "sentenca4Original = texto_original[3]\n",
        "\n",
        "embeddingSentenca1Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca1Original, tokenizer)\n",
        "embeddingSentenca2Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca2Original, tokenizer)\n",
        "embeddingSentenca3Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca3Original, tokenizer)\n",
        "embeddingSentenca4Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca4Original, tokenizer)\n",
        "\n",
        "print('Os primeiros 4 valores de cada sentença do texto original.')\n",
        "\n",
        "print('\\nSentença 1:', sentenca1Original,'-', str(embeddingSentenca1Original[:4]))\n",
        "print('Soma embedding Sentença1:', sentenca1Original,'-', str(torch.sum(embeddingSentenca1Original[:4])))\n",
        "\n",
        "print('\\nSentença 2:', sentenca2Original,'-', str(embeddingSentenca2Original[:4]))\n",
        "print('Soma embedding Sentença2:', sentenca2Original,'-', str(torch.sum(embeddingSentenca2Original[:4])))\n",
        "\n",
        "print('\\nSentença 3:', sentenca3Original,'-', str(embeddingSentenca3Original[:4]))\n",
        "print('Soma embedding Sentença3:', sentenca3Original,'-', str(torch.sum(embeddingSentenca3Original[:4])))\n",
        "\n",
        "print('\\nSentença 4:', sentenca4Original,'-', str(embeddingSentenca4Original[:4]))\n",
        "print('Soma embedding Sentença4:', sentenca4Original,'-', str(torch.sum(embeddingSentenca4Original[:4])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Os primeiros 4 valores de cada sentença do texto original.\n",
            "\n",
            "Sentença 1: Bom Dia, professor. - tensor([[-0.5098, -0.2877,  0.0873,  ...,  0.5436, -0.9302,  0.4668],\n",
            "        [ 0.6078, -0.8869,  0.3736,  ..., -0.3517, -1.2140, -0.3077],\n",
            "        [ 0.9075, -1.1233, -0.0093,  ...,  0.4433, -0.4633, -0.0113],\n",
            "        [ 0.2499, -0.4717, -0.1217,  ...,  0.7079, -0.2300,  0.4911]])\n",
            "Soma embedding Sentença1: Bom Dia, professor. - tensor(-113.4554)\n",
            "\n",
            "Sentença 2: Qual o conteúdo da prova? - tensor([[-0.3987, -0.9450,  0.1785,  ...,  0.7189, -0.6772, -0.1452],\n",
            "        [ 0.2067, -0.2705,  0.7145,  ...,  0.3047, -0.2718,  0.7577],\n",
            "        [ 0.2355,  0.2686,  0.5669,  ...,  1.0817,  0.5614,  0.3750],\n",
            "        [ 0.5264, -0.4600,  0.4810,  ..., -0.5559, -0.2941,  0.0378]])\n",
            "Soma embedding Sentença2: Qual o conteúdo da prova? - tensor(-115.8800)\n",
            "\n",
            "Sentença 3: Vai cair tudo na prova? - tensor([[ 0.5178,  0.0863,  0.7394,  ..., -0.5765, -0.6208, -0.2230],\n",
            "        [ 0.1617,  1.1516, -0.0350,  ...,  0.1730,  0.2104, -0.0207],\n",
            "        [ 0.9252,  0.5806,  0.2491,  ...,  0.1687,  0.0772, -0.1173],\n",
            "        [ 0.5782,  1.3571, -0.5161,  ..., -0.0942,  0.0404, -0.0390]])\n",
            "Soma embedding Sentença3: Vai cair tudo na prova? - tensor(-110.5299)\n",
            "\n",
            "Sentença 4: Aguardo uma resposta, João. - tensor([[ 0.4339, -0.7168,  0.1173,  ...,  0.0768, -1.2036,  0.3863],\n",
            "        [-0.6806, -1.0194, -0.0765,  ..., -0.1768, -0.6326,  0.2895],\n",
            "        [ 1.1384, -0.8541,  0.8992,  ...,  0.2798, -0.0381,  0.5061],\n",
            "        [ 0.9206, -0.9862,  0.1347,  ...,  0.4182, -1.0164,  0.4713]])\n",
            "Soma embedding Sentença4: Aguardo uma resposta, João. - tensor(-116.1903)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbGSdUzw2OnD"
      },
      "source": [
        "Examinando os embeddings do texto original\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okFUjfDG2OnD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32fd0298-f981-4804-e267-bf4cd7dce7c5"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Original = texto_original[0]\n",
        "sentenca2Original = texto_original[1]\n",
        "sentenca3Original = texto_original[2]\n",
        "sentenca4Original = texto_original[3]\n",
        "\n",
        "print('Texto Original:', texto_original)\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca1TokenizadaOriginal = tokenizer.tokenize(sentenca1Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca1TokenizadaOriginal)\n",
        "embeddingSentenca1Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca1Original, tokenizer)\n",
        "print('\\nSentença 1 Original=\\'', sentenca1Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca1TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca1Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca1Original))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca2TokenizadaOriginal = tokenizer.tokenize(sentenca2Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca2TokenizadaOriginal)\n",
        "embeddingSentenca2Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca2Original, tokenizer)\n",
        "print('\\nSentença 2 Original=\\'', sentenca2Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca2TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca2Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca2Original))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca3TokenizadaOriginal = tokenizer.tokenize(sentenca3Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca3TokenizadaOriginal)\n",
        "embeddingSentenca3Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoPermutadoConcatenado, sentenca3Original, tokenizer)\n",
        "print('\\nSentença 3 Original=\\'', sentenca3Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca3TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca3Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca3Original))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca4TokenizadaOriginal = tokenizer.tokenize(sentenca4Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca4TokenizadaOriginal)\n",
        "embeddingSentenca4Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca4Original, tokenizer)\n",
        "print('\\nSentença 4 Original=\\'', sentenca4Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca4TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca4Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca4Original))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original: ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "\n",
            "Sentença 1 Original=' Bom Dia, professor. '\n",
            "    Sentença tokenizada: ['Bom', 'Dia', ',', 'professor', '.']\n",
            "    => inicio em 1 e término em 5\n",
            "    Formato modelo : torch.Size([5, 1024])\n",
            "    Soma embeddings:  -141.45\n",
            "\n",
            "Sentença 2 Original=' Qual o conteúdo da prova? '\n",
            "    Sentença tokenizada: ['Qual', 'o', 'conteúdo', 'da', 'prova', '?']\n",
            "    => inicio em 6 e término em 11\n",
            "    Formato modelo : torch.Size([6, 1024])\n",
            "    Soma embeddings:  -173.58\n",
            "\n",
            "Sentença 3 Original=' Vai cair tudo na prova? '\n",
            "    Sentença tokenizada: ['Vai', 'cair', 'tudo', 'na', 'prova', '?']\n",
            "    => inicio em 12 e término em 17\n",
            "    Formato modelo : torch.Size([6, 1024])\n",
            "    Soma embeddings:  -172.02\n",
            "\n",
            "Sentença 4 Original=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    => inicio em 18 e término em 24\n",
            "    Formato modelo : torch.Size([7, 1024])\n",
            "    Soma embeddings:  -200.72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVL1lBnB2OnD"
      },
      "source": [
        "### Texto Permutado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uMC8h3F2OnE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6757e3ca-6c20-4d06-b85a-79356f4839b4"
      },
      "source": [
        "# Define um texto com a permutação das sentenças do texto original\n",
        "texto_permutado = [texto_original[3],   # 'Aguardo uma resposta, João.',\n",
        "             texto_original[1],             # 'Qual o conteúdo da prova?',              \n",
        "             texto_original[0],             # 'Vai cair tudo na prova?',\n",
        "             texto_original[2]]             # 'Bom Dia, professor.']     \n",
        "\n",
        "# Use o texto permutado igual ao original para testar se as medidas estão corretas\n",
        "#texto_permutado = texto_original\n",
        "\n",
        "# Concatena as sentenças do texto em uma string\n",
        "textoPermutadoConcatenado = ' '.join(texto_permutado)\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado_permutado = '[CLS] ' + textoPermutadoConcatenado + ' [SEP]'\n",
        "\n",
        "# Divide a sentença em tokens\n",
        "texto_tokenizado_permutado = tokenizer.tokenize(texto_marcado_permutado)\n",
        "\n",
        "# Mapeia os tokens em seus índices do vocabulário\n",
        "texto_tokens_indexados_permutado = tokenizer.convert_tokens_to_ids(texto_tokenizado_permutado)\n",
        "\n",
        "# Mostra os tokens com seus índices\n",
        "i = 0\n",
        "for tup in zip(texto_tokenizado_permutado, texto_tokens_indexados_permutado):\n",
        "    print('{:>3} {:<12} {:>6,}'.format(i, tup[0], tup[1]))\n",
        "    i = i + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0 [CLS]           101\n",
            "  1 Agu           8,125\n",
            "  2 ##ardo        2,222\n",
            "  3 uma             230\n",
            "  4 resposta      4,299\n",
            "  5 ,               117\n",
            "  6 João          1,453\n",
            "  7 .               119\n",
            "  8 Qual         13,082\n",
            "  9 o               146\n",
            " 10 conteúdo      5,015\n",
            " 11 da              180\n",
            " 12 prova         2,310\n",
            " 13 ?               136\n",
            " 14 Bom           8,399\n",
            " 15 Dia           3,616\n",
            " 16 ,               117\n",
            " 17 professor     2,917\n",
            " 18 .               119\n",
            " 19 Vai          20,805\n",
            " 20 cair          9,322\n",
            " 21 tudo          2,745\n",
            " 22 na              229\n",
            " 23 prova         2,310\n",
            " 24 ?               136\n",
            " 25 [SEP]           102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPjSfaUR2OnE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89fa5351-49db-4012-fe25-b1ddc4769c88"
      },
      "source": [
        "# Marca cada um dos tokens como pertencentes à sentença '1'.\n",
        "mascara_atencao_permutado = [1] * len(texto_tokenizado_permutado)\n",
        "\n",
        "print (mascara_atencao_permutado)\n",
        "print (len(mascara_atencao_permutado))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXp0WqZa2OnE"
      },
      "source": [
        "Convertendo as listas em tensores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuwXz5Ye2OnE"
      },
      "source": [
        "# Importa a biblioteca\n",
        "import torch\n",
        "\n",
        "# Converte as entradas de listas para tensores do torch\n",
        "tokens_tensores_permutado = torch.as_tensor([texto_tokens_indexados_permutado])\n",
        "mascara_atencao_tensores_permutado = torch.as_tensor([mascara_atencao_permutado])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUmYOo7s2OnE"
      },
      "source": [
        "Gera os embeddings para o texto original. Guarda somente a última camada da rede em `outputs`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gLUe6tT2OnE"
      },
      "source": [
        "# Prediz os atributos dos estados ocultos para cada camada\n",
        "with torch.no_grad():\n",
        "    # output[0] contém last_hidden_states\n",
        "    outputs = model(tokens_tensores_permutado, mascara_atencao_tensores_permutado)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS0h6i4t2OnE"
      },
      "source": [
        "Recupera a saída da última camada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1kcPJU82OnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f1dcd46-5bc8-4949-efb4-e261d5281fe2"
      },
      "source": [
        "# Recupera a última e única camada da saída\n",
        "last_hidden_states = outputs[0]\n",
        "\n",
        "print ('O vetor da última camada oculta tem o formato:', last_hidden_states.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O vetor da última camada oculta tem o formato: torch.Size([1, 26, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0Xu6swe2OnF"
      },
      "source": [
        "Vamos nos livrar da dimensão lotes 'batches', pois não precisamos dela."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOljOpq52OnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfa27d45-af5f-4c5c-cb59-b9331e8afd5c"
      },
      "source": [
        "# Remove a dimensão 1, o lote 'batches'.\n",
        "#O método squeeze remove a primeira dimensão(0) pois possui tamanho 1\n",
        "embeddingTextoPermutado = torch.squeeze(last_hidden_states, dim=0)\n",
        "\n",
        "print ('O vetor de tokens de embedding do texto permutado tem o formato:', embeddingTextoPermutado.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O vetor de tokens de embedding do texto permutado tem o formato: torch.Size([26, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BlaBKoE2OnF"
      },
      "source": [
        "Exibe os embenddings das sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWAJMgs72OnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c01b028-da04-4b62-d621-046b4941210b"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Permutado = texto_permutado[0]\n",
        "sentenca2Permutado = texto_permutado[1]\n",
        "sentenca3Permutado = texto_permutado[2]\n",
        "sentenca4Permutado = texto_permutado[3]\n",
        "\n",
        "embeddingSentenca1Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca1Permutado, tokenizer)\n",
        "embeddingSentenca2Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca2Permutado, tokenizer)\n",
        "embeddingSentenca3Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca3Permutado, tokenizer)\n",
        "embeddingSentenca4Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca4Permutado, tokenizer)\n",
        "\n",
        "print('Os primeiros 4 valores de cada sentença do texto permutado.')\n",
        "\n",
        "print('\\nSentença 1:', sentenca1Permutado,'-', str(embeddingSentenca1Permutado[:4]))\n",
        "print('Soma embedding Sentença1:', sentenca1Original,'-', str(torch.sum(embeddingSentenca1Original[:4])))\n",
        "\n",
        "print('\\nSentença 2:', sentenca2Permutado,'-', str(embeddingSentenca2Permutado[:4]))\n",
        "print('Soma embedding Sentença2:', sentenca2Permutado,'-', str(torch.sum(embeddingSentenca2Permutado[:4])))\n",
        "\n",
        "print('\\nSentença 3:', sentenca3Permutado,'-', str(embeddingSentenca3Permutado[:4]))\n",
        "print('Soma embedding Sentença3:', sentenca3Permutado,'-', str(torch.sum(embeddingSentenca3Original[:4])))\n",
        "\n",
        "print('\\nSentença 4:', sentenca4Permutado,'-', str(embeddingSentenca4Permutado[:4]))\n",
        "print('Soma embedding Sentença4:', sentenca4Permutado,'-', str(torch.sum(embeddingSentenca4Permutado[:4])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Os primeiros 4 valores de cada sentença do texto permutado.\n",
            "\n",
            "Sentença 1: Aguardo uma resposta, João. - tensor([[ 0.4152, -0.7838, -0.0364,  ...,  0.2686, -1.3504,  0.4707],\n",
            "        [-0.6012, -1.1043, -0.2660,  ..., -0.1943, -0.8112,  0.2180],\n",
            "        [ 1.2319, -1.1194,  0.9353,  ...,  0.2953, -0.1973,  0.5069],\n",
            "        [ 0.8861, -0.9666,  0.1831,  ...,  0.4595, -1.1045,  0.5615]])\n",
            "Soma embedding Sentença1: Bom Dia, professor. - tensor(-113.4554)\n",
            "\n",
            "Sentença 2: Qual o conteúdo da prova? - tensor([[-0.2957, -1.0942, -0.0024,  ...,  0.5875, -0.7164,  0.0104],\n",
            "        [ 0.2193, -0.4914,  0.7233,  ...,  0.3551, -0.3698,  0.8577],\n",
            "        [ 0.1377,  0.3856,  0.6060,  ...,  1.2662,  0.4965,  0.5211],\n",
            "        [ 0.5271, -0.4796,  0.4135,  ..., -0.5303, -0.3934,  0.1571]])\n",
            "Soma embedding Sentença2: Qual o conteúdo da prova? - tensor(-115.7949)\n",
            "\n",
            "Sentença 3: Bom Dia, professor. - tensor([[-0.2387, -0.2844,  0.3606,  ...,  0.6976, -0.9028,  0.3216],\n",
            "        [ 0.8188, -0.5643,  0.6965,  ..., -0.1439, -0.7018, -0.1933],\n",
            "        [ 0.9349, -1.0496,  0.1645,  ...,  0.4782, -0.3837, -0.2850],\n",
            "        [ 0.0104, -0.4793,  0.0501,  ...,  0.7341, -0.3687,  0.4562]])\n",
            "Soma embedding Sentença3: Bom Dia, professor. - tensor(-115.7975)\n",
            "\n",
            "Sentença 4: Vai cair tudo na prova? - tensor([[ 7.8763e-01, -1.1689e-01,  7.6317e-01,  ..., -4.3840e-01,\n",
            "         -6.5442e-01, -6.2305e-02],\n",
            "        [ 2.1062e-01,  1.0353e+00,  2.5937e-02,  ...,  7.1820e-02,\n",
            "          1.2368e-01,  1.1584e-03],\n",
            "        [ 7.5943e-01,  7.9969e-01,  2.4871e-01,  ...,  1.8792e-01,\n",
            "          9.4661e-02, -9.1651e-02],\n",
            "        [ 6.7000e-01,  1.3208e+00, -5.6431e-01,  ..., -6.3588e-03,\n",
            "          1.6016e-01, -1.4379e-01]])\n",
            "Soma embedding Sentença4: Vai cair tudo na prova? - tensor(-110.7603)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jktC1hfL2OnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d386a4d0-9969-4f03-dca6-aa8b7dcb8869"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Permutado = texto_permutado[0]\n",
        "sentenca2Permutado = texto_permutado[1]\n",
        "sentenca3Permutado = texto_permutado[2]\n",
        "sentenca4Permutado = texto_permutado[3]\n",
        "\n",
        "print('Texto Permutado:', texto_permutado)\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca1TokenizadaPermutado = tokenizer.tokenize(sentenca1Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca1TokenizadaPermutado)\n",
        "embeddingSentenca1Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca1Permutado, tokenizer)\n",
        "print('\\nSentença 1 Permutada=\\'', sentenca1Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca1TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca1Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca1Permutado))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca2TokenizadaPermutado = tokenizer.tokenize(sentenca2Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca2TokenizadaPermutado)\n",
        "embeddingSentenca2Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca2Permutado, tokenizer)\n",
        "print('\\nSentença 2 Permutada=\\'', sentenca2Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca2TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca2Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca2Permutado))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca3TokenizadaPermutado = tokenizer.tokenize(sentenca3Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca3TokenizadaPermutado)\n",
        "embeddingSentenca3Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca3Permutado, tokenizer)\n",
        "print('\\nSentença 3 Permutada=\\'', sentenca3Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca3TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca3Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca3Permutado))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca4TokenizadaPermutado = tokenizer.tokenize(sentenca4Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca4TokenizadaPermutado)\n",
        "embeddingSentenca4Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca4Permutado, tokenizer)\n",
        "print('\\nSentença 4 Permutada=\\'', sentenca4Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca4TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca4Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca4Permutado))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado: ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "\n",
            "Sentença 1 Permutada=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    => inicio em 1 e término em 7\n",
            "    Formato modelo : torch.Size([7, 1024])\n",
            "    Soma embeddings:  -199.90\n",
            "\n",
            "Sentença 2 Permutada=' Qual o conteúdo da prova? '\n",
            "    Sentença tokenizada: ['Qual', 'o', 'conteúdo', 'da', 'prova', '?']\n",
            "    => inicio em 8 e término em 13\n",
            "    Formato modelo : torch.Size([6, 1024])\n",
            "    Soma embeddings:  -173.06\n",
            "\n",
            "Sentença 3 Permutada=' Bom Dia, professor. '\n",
            "    Sentença tokenizada: ['Bom', 'Dia', ',', 'professor', '.']\n",
            "    => inicio em 14 e término em 18\n",
            "    Formato modelo : torch.Size([5, 1024])\n",
            "    Soma embeddings:  -141.81\n",
            "\n",
            "Sentença 4 Permutada=' Vai cair tudo na prova? '\n",
            "    Sentença tokenizada: ['Vai', 'cair', 'tudo', 'na', 'prova', '?']\n",
            "    => inicio em 19 e término em 24\n",
            "    Formato modelo : torch.Size([6, 1024])\n",
            "    Soma embeddings:  -167.47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45HsR7ey2OnF"
      },
      "source": [
        "### Examinando as sentenças\n",
        "\n",
        "A mesma sentença apresenta embeddings com valores diferentes, pois se encontram em locais diferentes do texto. A soma de todos os embeddings demonstra isto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9pbUlC72OnG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f47f85-d81d-4c0c-aad1-e4159499bc77"
      },
      "source": [
        "print('\\nSentença 4 Original=\\'', sentenca4Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca4TokenizadaOriginal)\n",
        "print('    Formato modelo :', embeddingSentenca4Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca4Original))\n",
        "print('    Os 4 primeiros embeddings:', str(embeddingSentenca4Original[:4]))\n",
        "\n",
        "print('\\nSentença 1 Permutada=\\'', sentenca1Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca1TokenizadaPermutado)\n",
        "print('    Formato modelo :', embeddingSentenca1Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca1Permutado))\n",
        "print('    Os 4 primeiros embeddings:', str(embeddingSentenca1Permutado[:4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Sentença 4 Original=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    Formato modelo : torch.Size([7, 1024])\n",
            "    Soma embeddings:  -200.72\n",
            "    Os 4 primeiros embeddings: tensor([[ 0.4339, -0.7168,  0.1173,  ...,  0.0768, -1.2036,  0.3863],\n",
            "        [-0.6806, -1.0194, -0.0765,  ..., -0.1768, -0.6326,  0.2895],\n",
            "        [ 1.1384, -0.8541,  0.8992,  ...,  0.2798, -0.0381,  0.5061],\n",
            "        [ 0.9206, -0.9862,  0.1347,  ...,  0.4182, -1.0164,  0.4713]])\n",
            "\n",
            "Sentença 1 Permutada=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    Formato modelo : torch.Size([7, 1024])\n",
            "    Soma embeddings:  -199.90\n",
            "    Os 4 primeiros embeddings: tensor([[ 0.4152, -0.7838, -0.0364,  ...,  0.2686, -1.3504,  0.4707],\n",
            "        [-0.6012, -1.1043, -0.2660,  ..., -0.1943, -0.8112,  0.2180],\n",
            "        [ 1.2319, -1.1194,  0.9353,  ...,  0.2953, -0.1973,  0.5069],\n",
            "        [ 0.8861, -0.9666,  0.1831,  ...,  0.4595, -1.1045,  0.5615]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd8YKgnyJuUv"
      },
      "source": [
        "### Similaridade de cosseno entre os embeddings das sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cREd7N1JuUv"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "def similaridadeCoseno(sentenca1, sentenca2):\n",
        "  similaridade = 1 - cosine(sentenca1, sentenca2)\n",
        "  return similaridade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auu-XqHOJuUv"
      },
      "source": [
        "#### Calcula a média aritmética da similaridade do coseno entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto original. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bNpbR0QJuUv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c99832a-bb67-42b6-8a7f-bd78349474c7"
      },
      "source": [
        "print('Texto Original  :', str(texto_original))\n",
        "print('Quantidade de sentenças:',len(texto_original))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "n = len(texto_original)\n",
        "\n",
        "somaScos = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(n-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_original[i]\n",
        "    Sj = texto_original[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto original    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Encontra os maiores embeddings os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSi, linha = torch.max(embeddingSi, dim=0)        \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSi:', len(maiorEmbeddingSi))\n",
        "        \n",
        "    # Encontra os maiores embeddings os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSj, linha = torch.max(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSj:', len(maiorEmbeddingSj))\n",
        "  \n",
        "    # Similaridade entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Scos = similaridadeCoseno(maiorEmbeddingSi, maiorEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaScos = somaScos + Scos\n",
        "\n",
        "CcosOriginal = float(somaScos)/float(n-1)\n",
        "print('Ccos Original:', CcosOriginal)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original  : ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "Quantidade de sentenças: 4\n",
            "Ccos Original: 0.815782348314921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWNj-6i5JuUv"
      },
      "source": [
        "#### Calcula a média aritmética da similaridade do coseno entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto permutado. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQEsVKJ1JuUv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d15ba7e2-4bd6-46e0-a14e-30faa78a596d"
      },
      "source": [
        "print('Texto Permutado :', str(texto_permutado))\n",
        "print('Quantidade de sentenças:', len(texto_permutado))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "np = len(texto_permutado)\n",
        "\n",
        "somaScos = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(np-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_permutado[i]\n",
        "    Sj = texto_permutado[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto permutado    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Encontra os maiores embeddings os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSi, linha = torch.max(embeddingSi, dim=0)        \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSi:', len(maiorEmbeddingSi))\n",
        "        \n",
        "    # Encontra os maiores embeddings os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSj, linha = torch.max(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSj:', len(maiorEmbeddingSj))\n",
        "  \n",
        "    # Similaridade entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Scos = similaridadeCoseno(maiorEmbeddingSi, maiorEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaScos = somaScos + Scos\n",
        "\n",
        "CcosPermutado = float(somaScos)/float(np-1)\n",
        "print('Ccos Original:', CcosPermutado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado : ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "Quantidade de sentenças: 4\n",
            "Ccos Original: 0.7867840925852457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ecHZJrCJuUw"
      },
      "source": [
        "#### Compara as médias da similaridade de cosseno dos embeddings das sentenças do texto original e permutado\n",
        "\n",
        "Características das medidas:\n",
        "- Textos com sentenças iguais resulta uma medida igual a 1.\n",
        "- Textos com sentenças diferenntes resulta uma medida menor que 1.\n",
        "- Texto com sentenças muito diferentes apresentam valores menores que 1.\n",
        "- Textos iguais resultam em medidas iguais. \n",
        "- É uma medida de similaridade.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTxA53uUJuUw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ef2c35e-ee3c-4a4f-a833-9a6be865d5a5"
      },
      "source": [
        "print('Ccos Original :', CcosOriginal)\n",
        "print('Ccos Permutado:', CcosPermutado)\n",
        "\n",
        "if (CcosOriginal > CcosPermutado):\n",
        "    print('Texto original tem maior similaridade de cosseno entre as sentenças!')\n",
        "else:\n",
        "    print('Texto Permutado tem menor similaridade de cosseno entre as sentenças!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ccos Original : 0.815782348314921\n",
            "Ccos Permutado: 0.7867840925852457\n",
            "Texto original tem maior similaridade de cosseno entre as sentenças!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPQwuHf5JuUw"
      },
      "source": [
        "### Distância euclidiana entre os embeddings das sentenças\n",
        "\n",
        "Possui outros nomes como distância L2 ou norma L2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RmL_qXCJuUw"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "def distanciaEuclidiana(sentenca1, sentenca2):\n",
        "  distancia = euclidean(sentenca1, sentenca2)\n",
        "\n",
        "  return distancia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a61ckdmoJuUw"
      },
      "source": [
        "#### Calcula a média aritmética da distância euclidiana entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto original. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yu-uTlhJuUw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7c04e1d-146d-40ca-bed3-75dc5d0b087c"
      },
      "source": [
        "print('Texto Original  :', str(texto_original))\n",
        "print('Quantidade de sentenças:',len(texto_original))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "n = len(texto_original)\n",
        "\n",
        "somaSeuc = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(n-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_original[i]\n",
        "    Sj = texto_original[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto original    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Encontra os maiores embeddings os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSi, linha = torch.max(embeddingSi, dim=0)        \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSi:', len(maiorEmbeddingSi))\n",
        "        \n",
        "    # Encontra os maiores embeddings os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSj, linha = torch.max(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSj:', len(maiorEmbeddingSj))\n",
        "  \n",
        "    # Diferença entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Seuc = distanciaEuclidiana(maiorEmbeddingSi, maiorEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSeuc = somaSeuc + Seuc\n",
        "\n",
        "CeucOriginal = float(somaSeuc)/float(n-1)\n",
        "print('Ceuc Original:', CeucOriginal)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original  : ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "Quantidade de sentenças: 4\n",
            "Ceuc Original: 15.606142044067383\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBRvVkI4JuUw"
      },
      "source": [
        "#### Calcula a média aritmética da distância euclidiana entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto permutado. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNgY1epXJuUw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0038bd3b-ef60-43b5-acbc-cab53fa162bb"
      },
      "source": [
        "print('Texto Permutado :', str(texto_permutado))\n",
        "print('Quantidade de sentenças:', len(texto_permutado))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "np = len(texto_permutado)\n",
        "\n",
        "somaSeuc = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(np-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_permutado[i]\n",
        "    Sj = texto_permutado[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto permutado    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Encontra os maiores embeddings os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSi, linha = torch.max(embeddingSi, dim=0)        \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSi:', len(maiorEmbeddingSi))\n",
        "        \n",
        "    # Encontra os maiores embeddings os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSj, linha = torch.max(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSj:', len(maiorEmbeddingSj))\n",
        "  \n",
        "    # Diferença entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Seuc = distanciaEuclidiana(maiorEmbeddingSi, maiorEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSeuc = somaSeuc + Seuc\n",
        "\n",
        "CeucPermutado = float(somaSeuc)/float(np-1)\n",
        "print('Ceuc Original:', CeucPermutado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado : ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "Quantidade de sentenças: 4\n",
            "Ceuc Original: 16.949796040852863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI4qwrbWJuUx"
      },
      "source": [
        "#### Compara as médias da distância euclidiana dos embeddings das sentenças do texto original e permutado\n",
        "\n",
        "Características das medidas:\n",
        "- Textos com sentenças iguais resulta uma medida igual a 0.\n",
        "- Textos com sentenças diferenntes resulta uma medida maior que 0.\n",
        "- Texto com sentenças muito diferentes apresentam valores maiores que 0.\n",
        "- Textos iguais resultam em medidas iguais. \n",
        "- É uma medida de diferença.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeJFDd5mJuUx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e9fef9e-2f13-44d8-92a6-8076b1efb148"
      },
      "source": [
        "print('Ceuc Original :', CeucOriginal)\n",
        "print('Ceuc Permutado:', CeucPermutado)\n",
        "\n",
        "if (CeucOriginal < CeucPermutado):\n",
        "    print('Texto original tem menor distância euclidiana entre as sentenças!')\n",
        "else:\n",
        "    print('Texto Permutado tem maior distância euclidiana entre as sentenças!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ceuc Original : 15.606142044067383\n",
            "Ceuc Permutado: 16.949796040852863\n",
            "Texto original tem menor distância euclidiana entre as sentenças!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EUoPQNyJuUx"
      },
      "source": [
        "### Distância Manhattan entre os embeddings das sentenças\n",
        "\n",
        "Possui outros nomes como distância Cityblock, distância L1, norma L1 e métrica do táxi.\n",
        "\n",
        "Igual a subtração absoluta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IydTlzptJuUx"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "from scipy.spatial.distance import cityblock\n",
        "\n",
        "def distanciaManhattan(sentenca1, sentenca2):\n",
        "  distancia = cityblock(sentenca1, sentenca2)\n",
        "\n",
        "  return distancia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nuu93cfvJuUx"
      },
      "source": [
        "#### Calcula a média aritmética da distância de manhattan entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto original. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1DavITCJuUx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27cc6cc6-587b-454a-b7fa-38b11094d12a"
      },
      "source": [
        "print('Texto Original  :', str(texto_original))\n",
        "print('Quantidade de sentenças:',len(texto_original))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "n = len(texto_original)\n",
        "\n",
        "somaSman = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(n-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_original[i]\n",
        "    Sj = texto_original[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto original    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Encontra os maiores embeddings os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSi, linha = torch.max(embeddingSi, dim=0)        \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSi:', len(maiorEmbeddingSi))\n",
        "        \n",
        "    # Encontra os maiores embeddings os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSj, linha = torch.max(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSj:', len(maiorEmbeddingSj)) \n",
        "  \n",
        "    # Diferença entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Sman = distanciaManhattan(maiorEmbeddingSi, maiorEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSman = somaSman + Sman\n",
        "\n",
        "CmanOriginal = float(somaSman)/float(n-1)\n",
        "print('Cman Original:', CmanOriginal)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original  : ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "Quantidade de sentenças: 4\n",
            "Cman Original: 375.63962809244794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcWmFXmQJuUx"
      },
      "source": [
        "#### Calcula a média aritmética da distância de manhattan entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto permutado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6mpG5x0JuUy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36f5b1a5-43f0-4bd7-c840-497b5bde1079"
      },
      "source": [
        "print('Texto Permutado :', str(texto_permutado))\n",
        "print('Quantidade de sentenças:', len(texto_permutado))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "np = len(texto_permutado)\n",
        "\n",
        "somaSman = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(np-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_permutado[i]\n",
        "    Sj = texto_permutado[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto permutado    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Encontra os maiores embeddings os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSi, linha = torch.max(embeddingSi, dim=0)        \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSi:', len(maiorEmbeddingSi))\n",
        "        \n",
        "    # Encontra os maiores embeddings os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSj, linha = torch.max(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSj:', len(maiorEmbeddingSj)) \n",
        "  \n",
        "    # Diferença entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Sman = distanciaManhattan(maiorEmbeddingSi, maiorEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSman = somaSman + Sman\n",
        "\n",
        "CmanPermutado = float(somaSman)/float(np-1)\n",
        "print('Ceuc Original:', CmanPermutado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado : ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "Quantidade de sentenças: 4\n",
            "Ceuc Original: 415.24477132161456\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa8RFKDVJuUy"
      },
      "source": [
        "#### Compara as médias da distância de manhattan dos embeddings das sentenças do texto original e permutado\n",
        "\n",
        "Características das medidas:\n",
        "- Textos com sentenças iguais resulta uma medida igual a 0.\n",
        "- Textos com sentenças diferenntes resulta uma medida maior que 0.\n",
        "- Texto com sentenças muito diferentes apresentam valores maiores que 0.\n",
        "- Textos iguais resultam em medidas iguais. \n",
        "- É uma medida de diferença.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YB_oWMJ0JuUy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d24a4eda-5036-4cf6-eef8-5246807e91d1"
      },
      "source": [
        "print('Cman Original :', CmanOriginal)\n",
        "print('Cman Permutado:', CmanPermutado)\n",
        "\n",
        "if (CmanOriginal < CmanPermutado):\n",
        "    print('Texto original tem menor distância de manhattan entre as sentenças!')\n",
        "else:\n",
        "    print('Texto Permutado tem maior distância de manhattan entre as sentenças!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cman Original : 375.63962809244794\n",
            "Cman Permutado: 415.24477132161456\n",
            "Texto original tem menor distância de manhattan entre as sentenças!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRdr2bqZ2OnQ"
      },
      "source": [
        "### Resumo\n",
        "\n",
        "Resultado das medidas utilizando a última camada do BERT.\n",
        "\n",
        "Base(MEAN):\n",
        "- Ccos       :   0.62004846          0.54099079\n",
        "- Ceuc       :   7.11709849          7.99353107\n",
        "- Cman       :   153.63694255          171.98441060\n",
        "\n",
        "Base(MAX):\n",
        "- Ccos       :   0.79404344          0.76070702\n",
        "- Ceuc       :   10.07102553          10.70145098\n",
        "- Cman       :   213.39687602          231.29823303"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW0cKGq52OnQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66aeab84-f4ee-41bf-9b40-73ca668fd609"
      },
      "source": [
        "print('Resultado das medidas utilizando a última camada do BERT')\n",
        "print('Texto  :   Original            Permutado')\n",
        "print('Ccos       :   {:.8f}          {:.8f}'.format(CcosOriginal,CcosPermutado))\n",
        "print('Ceuc       :   {:.8f}          {:.8f}'.format(CeucOriginal,CeucPermutado))\n",
        "print('Cman       :   {:.8f}          {:.8f}'.format(CmanOriginal,CmanPermutado))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resultado das medidas utilizando a última camada do BERT\n",
            "Texto  :   Original            Permutado\n",
            "Ccos       :   0.81578235          0.78678409\n",
            "Ceuc       :   15.60614204          16.94979604\n",
            "Cman       :   375.63962809          415.24477132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru02mC0Estsb"
      },
      "source": [
        "## 8 - Exemplo sentenças de texto original e permutado utilizando embedding a concatenação das 4 últimas camadas do BERT usando estratégia a MEAN\n",
        "\n",
        "Como estamos utilizando os embeddings concatenado das 4 últimas camadas onde ocorre 768 entenda-se 3072 que é o resultado de 768 por 4 que é a dimensão do MCL BERT de tamanho base. E onde ocorre 1024 entenda-se 4096 que é o resultado de 1024 por 4 que é a dimensão do MCL BERT de tamanho large."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1vDmYJTstsg"
      },
      "source": [
        "### Texto Original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJOUyEpistsg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d3542cf-776a-4725-851c-aa878e6f1147"
      },
      "source": [
        "# Define um texto com 4 sentenças\n",
        "texto_original = ['Bom Dia, professor.',\n",
        "             'Qual o conteúdo da prova?',              \n",
        "             'Vai cair tudo na prova?',\n",
        "             'Aguardo uma resposta, João.']\n",
        "\n",
        "# Concatena as sentenças do texto em uma string\n",
        "textoOriginalConcatenado = ' '.join(texto_original)\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado_original = '[CLS] ' + textoOriginalConcatenado + ' [SEP]'\n",
        "\n",
        "# Divide a sentença em tokens\n",
        "texto_tokenizado_original = tokenizer.tokenize(texto_marcado_original)\n",
        "\n",
        "# Mapeia os tokens em seus índices do vocabulário\n",
        "texto_tokens_indexados_original = tokenizer.convert_tokens_to_ids(texto_tokenizado_original)\n",
        "\n",
        "# Mostra os tokens com seus índices\n",
        "i = 0\n",
        "for tup in zip(texto_tokenizado_original, texto_tokens_indexados_original):\n",
        "    print('{:>3} {:<12} {:>6,}'.format(i, tup[0], tup[1]))\n",
        "    i = i + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0 [CLS]           101\n",
            "  1 Bom           8,399\n",
            "  2 Dia           3,616\n",
            "  3 ,               117\n",
            "  4 professor     2,917\n",
            "  5 .               119\n",
            "  6 Qual         13,082\n",
            "  7 o               146\n",
            "  8 conteúdo      5,015\n",
            "  9 da              180\n",
            " 10 prova         2,310\n",
            " 11 ?               136\n",
            " 12 Vai          20,805\n",
            " 13 cair          9,322\n",
            " 14 tudo          2,745\n",
            " 15 na              229\n",
            " 16 prova         2,310\n",
            " 17 ?               136\n",
            " 18 Agu           8,125\n",
            " 19 ##ardo        2,222\n",
            " 20 uma             230\n",
            " 21 resposta      4,299\n",
            " 22 ,               117\n",
            " 23 João          1,453\n",
            " 24 .               119\n",
            " 25 [SEP]           102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4HrZqBfstsh"
      },
      "source": [
        "Máscara de atenção das palavras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0tDxh3Mstsh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd9681cc-4938-445f-f9fc-b271787be24e"
      },
      "source": [
        "# Marca cada um dos tokens como pertencentes à sentença '1'.\n",
        "mascara_atencao_original = [1] * len(texto_tokenizado_original)\n",
        "\n",
        "print (mascara_atencao_original)\n",
        "print (len(mascara_atencao_original))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAQf9nM8stsh"
      },
      "source": [
        "Convertendo as listas em tensores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFqFcnx2stsh"
      },
      "source": [
        "# Importa a biblioteca\n",
        "import torch\n",
        "\n",
        "# Converte as entradas de listas para tensores do torch\n",
        "tokens_tensores_original = torch.as_tensor([texto_tokens_indexados_original])\n",
        "mascara_atencao_tensores_original = torch.as_tensor([mascara_atencao_original])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJbHPnoAstsi"
      },
      "source": [
        "Gera os embeddings para o texto original. Guarda todas as camadas da rede em `outputs`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51R6f4Mistsi"
      },
      "source": [
        "# Prediz os atributos dos estados ocultos para cada camada\n",
        "with torch.no_grad():\n",
        "    # output[0] contém last_hidden_states\n",
        "    outputs = model(tokens_tensores_original, mascara_atencao_tensores_original)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx2_AvR8tbnZ"
      },
      "source": [
        "Recupera a saída e concatena as 4 últimas camada do BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C0KcRUHstsj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda9e73b-38af-4aa3-866b-fc3fa0b9fd26"
      },
      "source": [
        "# Cria uma lista com os tensores a serem concatenados\n",
        "# Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "# Lista com os tensores a serem concatenados\n",
        "listaConcat = []\n",
        "# Percorre os 4 últimos\n",
        "for i in [-1,-2,-3,-4]:\n",
        "    # Concatena da lista\n",
        "    listaConcat.append(outputs[2][i])\n",
        "    # Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "     #print('listaConcat=',len(listaConcat))\n",
        "\n",
        "# Realiza a concatenação dos embeddings de todos as camadas\n",
        "# Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "concat4_hidden_states = torch.cat(listaConcat, dim=-1)\n",
        "# Saída: Entrada: (<1(lote)> x <qtde_tokens> <3072 ou 4096>)  \n",
        "\n",
        "print ('O vetor da  concatenação das 4 últimas camadas oculta tem o formato:', concat4_hidden_states.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O vetor da  concatenação das 4 últimas camadas oculta tem o formato: torch.Size([1, 26, 4096])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM4luftrstsk"
      },
      "source": [
        "Vamos nos livrar da dimensão lotes 'batches', pois não precisamos dela."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f18k_o-stsk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "391eb3bb-25d8-4cea-ce29-437309cb3f5b"
      },
      "source": [
        "# Remove a dimensão 1, o lote 'batches'.\n",
        "#O método squeeze remove a primeira dimensão(0) pois possui tamanho 1\n",
        "embeddingTextoOriginal = torch.squeeze(concat4_hidden_states, dim=0)\n",
        "\n",
        "print ('O vetor de tokens de embedding do texto original tem o formato:', embeddingTextoOriginal.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O vetor de tokens de embedding do texto original tem o formato: torch.Size([26, 4096])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g0E9s2Rstsk"
      },
      "source": [
        "Confirmando vetores dependentes do contexto\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQGOQF-kstsk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea607556-c002-4f11-bc1a-68531d70c60f"
      },
      "source": [
        "for i, token_str in enumerate(texto_tokenizado_original):\n",
        "  print (i, token_str)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [CLS]\n",
            "1 Bom\n",
            "2 Dia\n",
            "3 ,\n",
            "4 professor\n",
            "5 .\n",
            "6 Qual\n",
            "7 o\n",
            "8 conteúdo\n",
            "9 da\n",
            "10 prova\n",
            "11 ?\n",
            "12 Vai\n",
            "13 cair\n",
            "14 tudo\n",
            "15 na\n",
            "16 prova\n",
            "17 ?\n",
            "18 Agu\n",
            "19 ##ardo\n",
            "20 uma\n",
            "21 resposta\n",
            "22 ,\n",
            "23 João\n",
            "24 .\n",
            "25 [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veMZsnAsstsl"
      },
      "source": [
        "Exibe os embenddings das sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9RSPe2Hstsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ec27796-8f8d-4060-de18-2b875dcf2218"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Original = texto_original[0]\n",
        "sentenca2Original = texto_original[1]\n",
        "sentenca3Original = texto_original[2]\n",
        "sentenca4Original = texto_original[3]\n",
        "\n",
        "embeddingSentenca1Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca1Original, tokenizer)\n",
        "embeddingSentenca2Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca2Original, tokenizer)\n",
        "embeddingSentenca3Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca3Original, tokenizer)\n",
        "embeddingSentenca4Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca4Original, tokenizer)\n",
        "\n",
        "print('Os primeiros 4 valores de cada sentença do texto original.')\n",
        "\n",
        "print('\\nSentença 1:', sentenca1Original,'-', str(embeddingSentenca1Original[:4]))\n",
        "print('Soma embedding Sentença1:', sentenca1Original,'-', str(torch.sum(embeddingSentenca1Original[:4])))\n",
        "\n",
        "print('\\nSentença 2:', sentenca2Original,'-', str(embeddingSentenca2Original[:4]))\n",
        "print('Soma embedding Sentença2:', sentenca2Original,'-', str(torch.sum(embeddingSentenca2Original[:4])))\n",
        "\n",
        "print('\\nSentença 3:', sentenca3Original,'-', str(embeddingSentenca3Original[:4]))\n",
        "print('Soma embedding Sentença3:', sentenca3Original,'-', str(torch.sum(embeddingSentenca3Original[:4])))\n",
        "\n",
        "print('\\nSentença 4:', sentenca4Original,'-', str(embeddingSentenca4Original[:4]))\n",
        "print('Soma embedding Sentença4:', sentenca4Original,'-', str(torch.sum(embeddingSentenca4Original[:4])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Os primeiros 4 valores de cada sentença do texto original.\n",
            "\n",
            "Sentença 1: Bom Dia, professor. - tensor([[-0.5098, -0.2877,  0.0873,  ...,  0.9288, -0.0796,  0.3684],\n",
            "        [ 0.6078, -0.8869,  0.3736,  ...,  0.0124,  0.0094, -0.1719],\n",
            "        [ 0.9075, -1.1233, -0.0093,  ...,  0.1359, -0.3067, -0.4078],\n",
            "        [ 0.2499, -0.4717, -0.1217,  ...,  0.4604,  0.0075,  0.1555]])\n",
            "Soma embedding Sentença1: Bom Dia, professor. - tensor(-176.3423)\n",
            "\n",
            "Sentença 2: Qual o conteúdo da prova? - tensor([[-0.3987, -0.9450,  0.1785,  ...,  0.8476, -0.0572,  0.0365],\n",
            "        [ 0.2067, -0.2705,  0.7145,  ...,  0.2113,  0.2899,  0.5135],\n",
            "        [ 0.2355,  0.2686,  0.5669,  ...,  0.7205,  0.2510,  0.0924],\n",
            "        [ 0.5264, -0.4600,  0.4810,  ...,  0.1881,  0.0931,  0.1731]])\n",
            "Soma embedding Sentença2: Qual o conteúdo da prova? - tensor(-165.1487)\n",
            "\n",
            "Sentença 3: Vai cair tudo na prova? - tensor([[ 0.5178,  0.0863,  0.7394,  ..., -0.3301, -0.0115,  0.1168],\n",
            "        [ 0.1617,  1.1516, -0.0350,  ..., -0.2189,  0.1096, -0.3660],\n",
            "        [ 0.9252,  0.5806,  0.2491,  ...,  0.0027,  0.2467, -0.1535],\n",
            "        [ 0.5782,  1.3571, -0.5161,  ...,  0.5285,  0.2553, -0.0197]])\n",
            "Soma embedding Sentença3: Vai cair tudo na prova? - tensor(-177.0387)\n",
            "\n",
            "Sentença 4: Aguardo uma resposta, João. - tensor([[ 0.4339, -0.7168,  0.1173,  ...,  0.3840, -0.0936,  0.1355],\n",
            "        [-0.6806, -1.0194, -0.0765,  ...,  0.2201,  0.2731, -0.0384],\n",
            "        [ 1.1384, -0.8541,  0.8992,  ...,  0.5247,  0.2278,  0.0653],\n",
            "        [ 0.9206, -0.9862,  0.1347,  ...,  0.4393, -0.4792,  0.1743]])\n",
            "Soma embedding Sentença4: Aguardo uma resposta, João. - tensor(-169.8891)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGUkprWbstsl"
      },
      "source": [
        "Examinando os embeddings do texto original\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL-c0aqKstsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a3064d9-d1a5-4d75-f7a3-416a7f3d66ce"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Original = texto_original[0]\n",
        "sentenca2Original = texto_original[1]\n",
        "sentenca3Original = texto_original[2]\n",
        "sentenca4Original = texto_original[3]\n",
        "\n",
        "print('Texto Original:', texto_original)\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca1TokenizadaOriginal = tokenizer.tokenize(sentenca1Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca1TokenizadaOriginal)\n",
        "embeddingSentenca1Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca1Original, tokenizer)\n",
        "print('\\nSentença 1 Original=\\'', sentenca1Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca1TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca1Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca1Original))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca2TokenizadaOriginal = tokenizer.tokenize(sentenca2Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca2TokenizadaOriginal)\n",
        "embeddingSentenca2Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca2Original, tokenizer)\n",
        "print('\\nSentença 2 Original=\\'', sentenca2Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca2TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca2Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca2Original))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca3TokenizadaOriginal = tokenizer.tokenize(sentenca3Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca3TokenizadaOriginal)\n",
        "embeddingSentenca3Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca3Original, tokenizer)\n",
        "print('\\nSentença 3 Original=\\'', sentenca3Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca3TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca3Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca3Original))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca4TokenizadaOriginal = tokenizer.tokenize(sentenca4Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca4TokenizadaOriginal)\n",
        "embeddingSentenca4Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca4Original, tokenizer)\n",
        "print('\\nSentença 4 Original=\\'', sentenca4Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca4TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca4Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca4Original))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original: ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "\n",
            "Sentença 1 Original=' Bom Dia, professor. '\n",
            "    Sentença tokenizada: ['Bom', 'Dia', ',', 'professor', '.']\n",
            "    => inicio em 1 e término em 5\n",
            "    Formato modelo : torch.Size([5, 4096])\n",
            "    Soma embeddings:  -225.64\n",
            "\n",
            "Sentença 2 Original=' Qual o conteúdo da prova? '\n",
            "    Sentença tokenizada: ['Qual', 'o', 'conteúdo', 'da', 'prova', '?']\n",
            "    => inicio em 6 e término em 11\n",
            "    Formato modelo : torch.Size([6, 4096])\n",
            "    Soma embeddings:  -252.06\n",
            "\n",
            "Sentença 3 Original=' Vai cair tudo na prova? '\n",
            "    Sentença tokenizada: ['Vai', 'cair', 'tudo', 'na', 'prova', '?']\n",
            "    => inicio em 12 e término em 17\n",
            "    Formato modelo : torch.Size([6, 4096])\n",
            "    Soma embeddings:  -260.65\n",
            "\n",
            "Sentença 4 Original=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    => inicio em 18 e término em 24\n",
            "    Formato modelo : torch.Size([7, 4096])\n",
            "    Soma embeddings:  -288.69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRdBVlt9stsm"
      },
      "source": [
        "### Texto Permutado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xsxt0Jistsm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87f06180-bf8c-4a97-df76-0d390630c1a5"
      },
      "source": [
        "# Define um texto com a permutação das sentenças do texto original\n",
        "texto_permutado = [texto_original[3],   # 'Aguardo uma resposta, João.',\n",
        "             texto_original[1],             # 'Qual o conteúdo da prova?',              \n",
        "             texto_original[0],             # 'Vai cair tudo na prova?',\n",
        "             texto_original[2]]             # 'Bom Dia, professor.']     \n",
        "\n",
        "# Use o texto permutado igual ao original para testar se as medidas estão corretas\n",
        "#texto_permutado = texto_original\n",
        "\n",
        "# Concatena as sentenças do texto em uma string\n",
        "textoPermutadoConcatenado = ' '.join(texto_permutado)\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado_permutado = '[CLS] ' + textoPermutadoConcatenado + ' [SEP]'\n",
        "\n",
        "# Divide a sentença em tokens\n",
        "texto_tokenizado_permutado = tokenizer.tokenize(texto_marcado_permutado)\n",
        "\n",
        "# Mapeia os tokens em seus índices do vocabulário\n",
        "texto_tokens_indexados_permutado = tokenizer.convert_tokens_to_ids(texto_tokenizado_permutado)\n",
        "\n",
        "# Mostra os tokens com seus índices\n",
        "i = 0\n",
        "for tup in zip(texto_tokenizado_permutado, texto_tokens_indexados_permutado):\n",
        "    print('{:>3} {:<12} {:>6,}'.format(i, tup[0], tup[1]))\n",
        "    i = i + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0 [CLS]           101\n",
            "  1 Agu           8,125\n",
            "  2 ##ardo        2,222\n",
            "  3 uma             230\n",
            "  4 resposta      4,299\n",
            "  5 ,               117\n",
            "  6 João          1,453\n",
            "  7 .               119\n",
            "  8 Qual         13,082\n",
            "  9 o               146\n",
            " 10 conteúdo      5,015\n",
            " 11 da              180\n",
            " 12 prova         2,310\n",
            " 13 ?               136\n",
            " 14 Bom           8,399\n",
            " 15 Dia           3,616\n",
            " 16 ,               117\n",
            " 17 professor     2,917\n",
            " 18 .               119\n",
            " 19 Vai          20,805\n",
            " 20 cair          9,322\n",
            " 21 tudo          2,745\n",
            " 22 na              229\n",
            " 23 prova         2,310\n",
            " 24 ?               136\n",
            " 25 [SEP]           102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM5NtnGRuAsU"
      },
      "source": [
        "Máscara de atenção das palavras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GDGmFc_stsm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edc8502b-f462-4f63-fb0d-8a421bb9be30"
      },
      "source": [
        "# Marca cada um dos tokens como pertencentes à sentença '1'.\n",
        "mascara_atencao_permutado = [1] * len(texto_tokenizado_permutado)\n",
        "\n",
        "print (mascara_atencao_permutado)\n",
        "print (len(mascara_atencao_permutado))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4WehJSxuDvo"
      },
      "source": [
        "Convertendo as listas em tensores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrvEtHp7stsm"
      },
      "source": [
        "# Importa a biblioteca\n",
        "import torch\n",
        "\n",
        "# Converte as entradas de listas para tensores do torch\n",
        "tokens_tensores_permutado = torch.as_tensor([texto_tokens_indexados_permutado])\n",
        "mascara_atencao_tensores_permutado = torch.as_tensor([mascara_atencao_permutado])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQDiqh5UuMnc"
      },
      "source": [
        "Gera os embeddings para o texto original. Guarda todas as camadas da rede em `outputs`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tGQsVMpstsm"
      },
      "source": [
        "# Prediz os atributos dos estados ocultos para cada camada\n",
        "with torch.no_grad():\n",
        "    # output[0] contém last_hidden_states\n",
        "    outputs = model(tokens_tensores_permutado, mascara_atencao_tensores_permutado)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5CmoS1at0YA"
      },
      "source": [
        "Recupera a saída e concatena as 4 últimas camada do BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRDYmUq9stsn"
      },
      "source": [
        "# Cria uma lista com os tensores a serem concatenados\n",
        "# Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "# Lista com os tensores a serem concatenados\n",
        "listaConcat = []\n",
        "# Percorre os 4 últimos\n",
        "for i in [-1,-2,-3,-4]:\n",
        "    # Concatena da lista\n",
        "    listaConcat.append(outputs[2][i])\n",
        "    # Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "     #print('listaConcat=',len(listaConcat))\n",
        "\n",
        "# Realiza a concatenação dos embeddings de todos as camadas\n",
        "# Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "concat4_hidden_states = torch.cat(listaConcat, dim=-1)\n",
        "# Saída: Entrada: (<1(lote)> x <qtde_tokens> <3072 ou 4096>)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm9EVbDauSiI"
      },
      "source": [
        "Vamos nos livrar da dimensão lotes 'batches', pois não precisamos dela."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXNqk-oQstsn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1052d4a1-fec8-4ea8-910e-95092aa0f474"
      },
      "source": [
        "# Remove a dimensão 1, o lote 'batches'.\n",
        "#O método squeeze remove a primeira dimensão(0) pois possui tamanho 1\n",
        "embeddingTextoPermutado = torch.squeeze(concat4_hidden_states, dim=0)\n",
        "\n",
        "print ('O vetor de tokens de embedding do texto permutado tem o formato:', embeddingTextoPermutado.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O vetor de tokens de embedding do texto permutado tem o formato: torch.Size([26, 4096])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbLgVumnstso"
      },
      "source": [
        "Exibe os embenddings das sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1nUZ7OLstso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b848928-668f-460a-97e8-dd841c60c4ad"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Permutado = texto_permutado[0]\n",
        "sentenca2Permutado = texto_permutado[1]\n",
        "sentenca3Permutado = texto_permutado[2]\n",
        "sentenca4Permutado = texto_permutado[3]\n",
        "\n",
        "embeddingSentenca1Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca1Permutado, tokenizer)\n",
        "embeddingSentenca2Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca2Permutado, tokenizer)\n",
        "embeddingSentenca3Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca3Permutado, tokenizer)\n",
        "embeddingSentenca4Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca4Permutado, tokenizer)\n",
        "\n",
        "print('Os primeiros 4 valores de cada sentença do texto permutado.')\n",
        "\n",
        "print('\\nSentença 1:', sentenca1Permutado,'-', str(embeddingSentenca1Permutado[:4]))\n",
        "print('Soma embedding Sentença1:', sentenca1Original,'-', str(torch.sum(embeddingSentenca1Original[:4])))\n",
        "\n",
        "print('\\nSentença 2:', sentenca2Permutado,'-', str(embeddingSentenca2Permutado[:4]))\n",
        "print('Soma embedding Sentença2:', sentenca2Permutado,'-', str(torch.sum(embeddingSentenca2Permutado[:4])))\n",
        "\n",
        "print('\\nSentença 3:', sentenca3Permutado,'-', str(embeddingSentenca3Permutado[:4]))\n",
        "print('Soma embedding Sentença3:', sentenca3Permutado,'-', str(torch.sum(embeddingSentenca3Original[:4])))\n",
        "\n",
        "print('\\nSentença 4:', sentenca4Permutado,'-', str(embeddingSentenca4Permutado[:4]))\n",
        "print('Soma embedding Sentença4:', sentenca4Permutado,'-', str(torch.sum(embeddingSentenca4Permutado[:4])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Os primeiros 4 valores de cada sentença do texto permutado.\n",
            "\n",
            "Sentença 1: Aguardo uma resposta, João. - tensor([[ 0.4152, -0.7838, -0.0364,  ...,  0.4706, -0.1614,  0.1815],\n",
            "        [-0.6012, -1.1043, -0.2660,  ...,  0.1239,  0.2729, -0.0574],\n",
            "        [ 1.2319, -1.1194,  0.9353,  ...,  0.5062,  0.1518,  0.1078],\n",
            "        [ 0.8861, -0.9666,  0.1831,  ...,  0.5239, -0.4849,  0.1787]])\n",
            "Soma embedding Sentença1: Bom Dia, professor. - tensor(-176.3423)\n",
            "\n",
            "Sentença 2: Qual o conteúdo da prova? - tensor([[-0.2957, -1.0942, -0.0024,  ...,  0.6032, -0.1615,  0.4615],\n",
            "        [ 0.2193, -0.4914,  0.7233,  ...,  0.2540,  0.1627,  0.7631],\n",
            "        [ 0.1377,  0.3856,  0.6060,  ...,  0.7089,  0.2763,  0.2866],\n",
            "        [ 0.5271, -0.4796,  0.4135,  ...,  0.3287,  0.1340,  0.4361]])\n",
            "Soma embedding Sentença2: Qual o conteúdo da prova? - tensor(-165.4919)\n",
            "\n",
            "Sentença 3: Bom Dia, professor. - tensor([[-0.2387, -0.2844,  0.3606,  ...,  0.9577, -0.2328,  0.2957],\n",
            "        [ 0.8188, -0.5643,  0.6965,  ..., -0.1356,  0.0236, -0.3090],\n",
            "        [ 0.9349, -1.0496,  0.1645,  ...,  0.1721, -0.3351, -0.5991],\n",
            "        [ 0.0104, -0.4793,  0.0501,  ...,  0.5897, -0.1399,  0.1081]])\n",
            "Soma embedding Sentença3: Bom Dia, professor. - tensor(-177.0387)\n",
            "\n",
            "Sentença 4: Vai cair tudo na prova? - tensor([[ 0.7876, -0.1169,  0.7632,  ..., -0.1344,  0.1030, -0.0097],\n",
            "        [ 0.2106,  1.0353,  0.0259,  ..., -0.2075, -0.0469, -0.3289],\n",
            "        [ 0.7594,  0.7997,  0.2487,  ...,  0.1881,  0.1629, -0.0855],\n",
            "        [ 0.6700,  1.3208, -0.5643,  ...,  0.6387,  0.3624, -0.0947]])\n",
            "Soma embedding Sentença4: Vai cair tudo na prova? - tensor(-176.5751)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E_hSMahstso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0a53197-4e27-457c-cd29-956920530997"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Permutado = texto_permutado[0]\n",
        "sentenca2Permutado = texto_permutado[1]\n",
        "sentenca3Permutado = texto_permutado[2]\n",
        "sentenca4Permutado = texto_permutado[3]\n",
        "\n",
        "print('Texto Permutado:', texto_permutado)\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca1TokenizadaPermutado = tokenizer.tokenize(sentenca1Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca1TokenizadaPermutado)\n",
        "embeddingSentenca1Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca1Permutado, tokenizer)\n",
        "print('\\nSentença 1 Permutada=\\'', sentenca1Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca1TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca1Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca1Permutado))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca2TokenizadaPermutado = tokenizer.tokenize(sentenca2Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca2TokenizadaPermutado)\n",
        "embeddingSentenca2Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca2Permutado, tokenizer)\n",
        "print('\\nSentença 2 Permutada=\\'', sentenca2Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca2TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca2Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca2Permutado))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca3TokenizadaPermutado = tokenizer.tokenize(sentenca3Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca3TokenizadaPermutado)\n",
        "embeddingSentenca3Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca3Permutado, tokenizer)\n",
        "print('\\nSentença 3 Permutada=\\'', sentenca3Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca3TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca3Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca3Permutado))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca4TokenizadaPermutado = tokenizer.tokenize(sentenca4Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca4TokenizadaPermutado)\n",
        "embeddingSentenca4Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca4Permutado, tokenizer)\n",
        "print('\\nSentença 4 Permutada=\\'', sentenca4Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca4TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca4Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca4Permutado))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado: ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "\n",
            "Sentença 1 Permutada=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    => inicio em 1 e término em 7\n",
            "    Formato modelo : torch.Size([7, 4096])\n",
            "    Soma embeddings:  -291.17\n",
            "\n",
            "Sentença 2 Permutada=' Qual o conteúdo da prova? '\n",
            "    Sentença tokenizada: ['Qual', 'o', 'conteúdo', 'da', 'prova', '?']\n",
            "    => inicio em 8 e término em 13\n",
            "    Formato modelo : torch.Size([6, 4096])\n",
            "    Soma embeddings:  -249.21\n",
            "\n",
            "Sentença 3 Permutada=' Bom Dia, professor. '\n",
            "    Sentença tokenizada: ['Bom', 'Dia', ',', 'professor', '.']\n",
            "    => inicio em 14 e término em 18\n",
            "    Formato modelo : torch.Size([5, 4096])\n",
            "    Soma embeddings:  -217.20\n",
            "\n",
            "Sentença 4 Permutada=' Vai cair tudo na prova? '\n",
            "    Sentença tokenizada: ['Vai', 'cair', 'tudo', 'na', 'prova', '?']\n",
            "    => inicio em 19 e término em 24\n",
            "    Formato modelo : torch.Size([6, 4096])\n",
            "    Soma embeddings:  -265.03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CsH6v4Dstso"
      },
      "source": [
        "### Examinando as sentenças\n",
        "\n",
        "A mesma sentença apresenta embeddings com valores diferentes, pois se encontram em locais diferentes do texto. A soma de todos os embeddings demonstra isto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p5iSl9Nstso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b45f7c5-da39-4122-c00c-6ae5fdcbcaf5"
      },
      "source": [
        "print('\\nSentença 4 Original=\\'', sentenca4Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca4TokenizadaOriginal)\n",
        "print('    Formato modelo :', embeddingSentenca4Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca4Original))\n",
        "print('    Os 4 primeiros embeddings:', str(embeddingSentenca4Original[:4]))\n",
        "\n",
        "print('\\nSentença 1 Permutada=\\'', sentenca1Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca1TokenizadaPermutado)\n",
        "print('    Formato modelo :', embeddingSentenca1Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca1Permutado))\n",
        "print('    Os 4 primeiros embeddings:', str(embeddingSentenca1Permutado[:4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Sentença 4 Original=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    Formato modelo : torch.Size([7, 4096])\n",
            "    Soma embeddings:  -288.69\n",
            "    Os 4 primeiros embeddings: tensor([[ 0.4339, -0.7168,  0.1173,  ...,  0.3840, -0.0936,  0.1355],\n",
            "        [-0.6806, -1.0194, -0.0765,  ...,  0.2201,  0.2731, -0.0384],\n",
            "        [ 1.1384, -0.8541,  0.8992,  ...,  0.5247,  0.2278,  0.0653],\n",
            "        [ 0.9206, -0.9862,  0.1347,  ...,  0.4393, -0.4792,  0.1743]])\n",
            "\n",
            "Sentença 1 Permutada=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    Formato modelo : torch.Size([7, 4096])\n",
            "    Soma embeddings:  -291.17\n",
            "    Os 4 primeiros embeddings: tensor([[ 0.4152, -0.7838, -0.0364,  ...,  0.4706, -0.1614,  0.1815],\n",
            "        [-0.6012, -1.1043, -0.2660,  ...,  0.1239,  0.2729, -0.0574],\n",
            "        [ 1.2319, -1.1194,  0.9353,  ...,  0.5062,  0.1518,  0.1078],\n",
            "        [ 0.8861, -0.9666,  0.1831,  ...,  0.5239, -0.4849,  0.1787]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX-s-jyF9UFT"
      },
      "source": [
        "### Similaridade de cosseno entre os embeddings das sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mSSZT6m9UFT"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "def similaridadeCoseno(sentenca1, sentenca2):\n",
        "  similaridade = 1 - cosine(sentenca1, sentenca2)\n",
        "  return similaridade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2xmrGvd9UFT"
      },
      "source": [
        "#### Calcula a média aritmética da similaridade do coseno entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto original. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbyuNamR9UFT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf7ad0b-da42-4c55-fb08-b71530d921a6"
      },
      "source": [
        "print('Texto Original  :', str(texto_original))\n",
        "print('Quantidade de sentenças:',len(texto_original))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "n = len(texto_original)\n",
        "\n",
        "somaScos = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(n-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_original[i]\n",
        "    Sj = texto_original[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto original    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "    # Similaridade entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>) \n",
        "    Scos = similaridadeCoseno(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaScos = somaScos + Scos\n",
        "\n",
        "CcosOriginal = float(somaScos)/float(n-1)\n",
        "print('Ccos Original:', CcosOriginal)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original  : ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "Quantidade de sentenças: 4\n",
            "Ccos Original: 0.8178287744522095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WUjUZw_9UFT"
      },
      "source": [
        "#### Calcula a média aritmética da similaridade do coseno entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto permutado. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unc7fF7i9UFT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8c2f8da-8482-4ecf-9db3-62f13e5f4219"
      },
      "source": [
        "print('Texto Permutado :', str(texto_permutado))\n",
        "print('Quantidade de sentenças:', len(texto_permutado))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "np = len(texto_permutado)\n",
        "\n",
        "somaScos = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(np-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_permutado[i]\n",
        "    Sj = texto_permutado[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto permutado    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "    # Similaridade entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Scos = similaridadeCoseno(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaScos = somaScos + Scos\n",
        "\n",
        "CcosPermutado = float(somaScos)/float(np-1)\n",
        "print('Ccos Original:', CcosPermutado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado : ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "Quantidade de sentenças: 4\n",
            "Ccos Original: 0.7760166923205057\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPygSiX_9UFT"
      },
      "source": [
        "#### Compara as médias da similaridade de cosseno dos embeddings das sentenças do texto original e permutado\n",
        "\n",
        "Características das medidas:\n",
        "- Textos com sentenças iguais resulta uma medida igual a 1.\n",
        "- Textos com sentenças diferenntes resulta uma medida menor que 1.\n",
        "- Texto com sentenças muito diferentes apresentam valores menores que 1.\n",
        "- Textos iguais resultam em medidas iguais. \n",
        "- É uma medida de similaridade.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zD7FTPz9UFT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7e9b867-02d7-4b7b-8a5b-e708424d35ac"
      },
      "source": [
        "print('Ccos Original :', CcosOriginal)\n",
        "print('Ccos Permutado:', CcosPermutado)\n",
        "\n",
        "if (CcosOriginal > CcosPermutado):\n",
        "    print('Texto original tem maior similaridade de cosseno entre as sentenças!')\n",
        "else:\n",
        "    print('Texto Permutado tem menor similaridade de cosseno entre as sentenças!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ccos Original : 0.8178287744522095\n",
            "Ccos Permutado: 0.7760166923205057\n",
            "Texto original tem maior similaridade de cosseno entre as sentenças!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVcRGoM09UFU"
      },
      "source": [
        "### Distância euclidiana entre os embeddings das sentenças\n",
        "\n",
        "Possui outros nomes como distância L2 ou norma L2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqK7DcTJ9UFU"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "def distanciaEuclidiana(sentenca1, sentenca2):\n",
        "  distancia = euclidean(sentenca1, sentenca2)\n",
        "\n",
        "  return distancia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rtzn3Ll69UFU"
      },
      "source": [
        "#### Calcula a média aritmética da distância euclidiana entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto original. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McejBc0P9UFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5de64f16-7876-4650-b366-87a7e6100dab"
      },
      "source": [
        "print('Texto Original  :', str(texto_original))\n",
        "print('Quantidade de sentenças:',len(texto_original))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "n = len(texto_original)\n",
        "\n",
        "somaSeuc = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(n-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_original[i]\n",
        "    Sj = texto_original[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto original    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    # print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "    # Distância euclidiana entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)  \n",
        "    Seuc = distanciaEuclidiana(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSeuc = somaSeuc + Seuc\n",
        "\n",
        "CeucOriginal = float(somaSeuc)/float(n-1)\n",
        "print('Ceuc Original:', CeucOriginal)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original  : ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "Quantidade de sentenças: 4\n",
            "Ceuc Original: 19.390052159627277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7_eRCMV9UFU"
      },
      "source": [
        "#### Calcula a média aritmética da distância euclidiana entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto permutado. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBEbKqiH9UFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f3f681c-a086-49f2-e3be-23d396e10999"
      },
      "source": [
        "print('Texto Permutado :', str(texto_permutado))\n",
        "print('Quantidade de sentenças:', len(texto_permutado))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "np = len(texto_permutado)\n",
        "\n",
        "somaSeuc = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(np-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_permutado[i]\n",
        "    Sj = texto_permutado[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto permutado    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "    # Distância euclidiana entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>) \n",
        "    Seuc = distanciaEuclidiana(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSeuc = somaSeuc + Seuc\n",
        "\n",
        "CeucPermutado = float(somaSeuc)/float(np-1)\n",
        "print('Ceuc Original:', CeucPermutado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado : ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "Quantidade de sentenças: 4\n",
            "Ceuc Original: 21.61820348103841\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5qzdOVy9UFU"
      },
      "source": [
        "#### Compara as médias da distância euclidiana dos embeddings das sentenças do texto original e permutado\n",
        "\n",
        "Características das medidas:\n",
        "- Textos com sentenças iguais resulta uma medida igual a 0.\n",
        "- Textos com sentenças diferenntes resulta uma medida maior que 0.\n",
        "- Texto com sentenças muito diferentes apresentam valores maiores que 0.\n",
        "- Textos iguais resultam em medidas iguais. \n",
        "- É uma medida de diferença.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnBVeDrv9UFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ca1a6d0-0bdc-4b88-fdd0-1f2e78e099cf"
      },
      "source": [
        "print('Ceuc Original :', CeucOriginal)\n",
        "print('Ceuc Permutado:', CeucPermutado)\n",
        "\n",
        "if (CeucOriginal < CeucPermutado):\n",
        "    print('Texto original tem menor distância euclidiana entre as sentenças!')\n",
        "else:\n",
        "    print('Texto Permutado tem maior distância euclidiana entre as sentenças!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ceuc Original : 19.390052159627277\n",
            "Ceuc Permutado: 21.61820348103841\n",
            "Texto original tem menor distância euclidiana entre as sentenças!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojaQA2C49UFV"
      },
      "source": [
        "### Distância Manhattan entre os embeddings das sentenças\n",
        "\n",
        "Possui outros nomes como distância Cityblock, distância L1, norma L1 e métrica do táxi.\n",
        "\n",
        "Igual a subtração absoluta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4VBoLbH9UFV"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "from scipy.spatial.distance import cityblock\n",
        "\n",
        "def distanciaManhattan(sentenca1, sentenca2):\n",
        "  distancia = cityblock(sentenca1, sentenca2)\n",
        "\n",
        "  return distancia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UN96DPuI9UFV"
      },
      "source": [
        "#### Calcula a média aritmética da distância de manhattan entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto original. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyAvO6WV9UFV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb1199aa-6e96-4279-e750-e49745b69e3c"
      },
      "source": [
        "print('Texto Original  :', str(texto_original))\n",
        "print('Quantidade de sentenças:',len(texto_original))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "n = len(texto_original)\n",
        "\n",
        "somaSman = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(n-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_original[i]\n",
        "    Sj = texto_original[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto original    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    # print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "    # Distância de manhattan entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>) \n",
        "    Sman = distanciaManhattan(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSman = somaSman + Sman\n",
        "\n",
        "CmanOriginal = float(somaSman)/float(n-1)\n",
        "print('Cman Original:', CmanOriginal)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original  : ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "Quantidade de sentenças: 4\n",
            "Cman Original: 939.0956420898438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oenwZkqO9UFV"
      },
      "source": [
        "#### Calcula a média aritmética da distância de manhattan entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto permutado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg81Wnik9UFV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66d30296-a259-4829-e5f7-21bae3546153"
      },
      "source": [
        "print('Texto Permutado :', str(texto_permutado))\n",
        "print('Quantidade de sentenças:', len(texto_permutado))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "np = len(texto_permutado)\n",
        "\n",
        "somaSman = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(np-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_permutado[i]\n",
        "    Sj = texto_permutado[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto permutado    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "    # Distância de manhattan entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Sman = distanciaManhattan(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSman = somaSman + Sman\n",
        "\n",
        "CmanPermutado = float(somaSman)/float(np-1)\n",
        "print('Ceuc Original:', CmanPermutado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado : ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "Quantidade de sentenças: 4\n",
            "Ceuc Original: 1060.0678304036458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcTxjUcc9UFV"
      },
      "source": [
        "#### Compara as médias da distância de manhattan dos embeddings das sentenças do texto original e permutado\n",
        "\n",
        "Características das medidas:\n",
        "- Textos com sentenças iguais resulta uma medida igual a 0.\n",
        "- Textos com sentenças diferenntes resulta uma medida maior que 0.\n",
        "- Texto com sentenças muito diferentes apresentam valores maiores que 0.\n",
        "- Textos iguais resultam em medidas iguais. \n",
        "- É uma medida de diferença.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JzGE3he9UFV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "946817e4-43e7-4cb6-a365-4fc84ab27364"
      },
      "source": [
        "print('Cman Original :', CmanOriginal)\n",
        "print('Cman Permutado:', CmanPermutado)\n",
        "\n",
        "if (CmanOriginal > CmanPermutado):\n",
        "    print('Texto original tem menor distância de manhattan entre as sentenças!')\n",
        "else:\n",
        "    print('Texto Permutado tem maior distância de manhattan entre as sentenças!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cman Original : 939.0956420898438\n",
            "Cman Permutado: 1060.0678304036458\n",
            "Texto Permutado tem maior distância de manhattan entre as sentenças!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaWJ6lU1a3RN"
      },
      "source": [
        "### Resumo\n",
        "\n",
        "Resultado das medidas utilizando as quatro últimas camadas do BERT.\n",
        "\n",
        "\n",
        "Base(MEAN):\n",
        "- Ccos       :   0.62004846          0.54099079\n",
        "- Ceuc       :   7.11709849          7.99353107\n",
        "- Cman       :   153.63694255          171.98441060\n",
        "\n",
        "Base(MAX):\n",
        "- Ccos       :   0.79404344          0.76070702\n",
        "- Ceuc       :   10.07102553          10.70145098\n",
        "- Cman       :   213.39687602          231.29823303\n",
        "\n",
        "Base(MEAN):\n",
        "- Ccos       :   0.80771943          0.77137093\n",
        "- Ceuc       :   20.71080144          23.16955884\n",
        "- Cman       :   883.51291911          983.28851318"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhAP-gfja3RN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ec68e76-e697-43c2-832d-778468bff6f7"
      },
      "source": [
        "print('Resultado das medidas utilizando as quatro últimas camada do BERT')\n",
        "print('Texto  :   Original            Permutado')\n",
        "print('Ccos       :   {:.8f}          {:.8f}'.format(CcosOriginal,CcosPermutado))\n",
        "print('Ceuc       :   {:.8f}          {:.8f}'.format(CeucOriginal,CeucPermutado))\n",
        "print('Cman       :   {:.8f}          {:.8f}'.format(CmanOriginal,CmanPermutado))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resultado das medidas utilizando as quatro últimas camada do BERT\n",
            "Texto  :   Original            Permutado\n",
            "Ccos       :   0.81782877          0.77601669\n",
            "Ceuc       :   19.39005216          21.61820348\n",
            "Cman       :   939.09564209          1060.06783040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJKcCTMPL341"
      },
      "source": [
        "## 9 - Exemplo sentenças de texto original e permutado utilizando embedding da concatenação das 4 últimas camadas do BERT usando estratégia MAX e todas as palavras.\n",
        "\n",
        "Como estamos utilizando os embeddings concatenado das 4 últimas camadas onde ocorre 768 entenda-se 3072 que é o resultado de 768 por 4 que é a dimensão do MCL BERT de tamanho base. E onde ocorre 1024 entenda-se 4096 que é o resultado de 1024 por 4 que é a dimensão do MCL BERT de tamanho large."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC_lpJhbM0iL"
      },
      "source": [
        "### Texto Original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzLY--ZCM0iS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4e9f1b5-9e31-45d5-c231-4a6b9140725b"
      },
      "source": [
        "# Define um texto com 4 sentenças\n",
        "texto_original = ['Bom Dia, professor.',\n",
        "             'Qual o conteúdo da prova?',              \n",
        "             'Vai cair tudo na prova?',\n",
        "             'Aguardo uma resposta, João.']\n",
        "\n",
        "# Concatena as sentenças do texto em uma string\n",
        "textoOriginalConcatenado = ' '.join(texto_original)\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado_original = '[CLS] ' + textoOriginalConcatenado + ' [SEP]'\n",
        "\n",
        "# Divide a sentença em tokens\n",
        "texto_tokenizado_original = tokenizer.tokenize(texto_marcado_original)\n",
        "\n",
        "# Mapeia os tokens em seus índices do vocabulário\n",
        "texto_tokens_indexados_original = tokenizer.convert_tokens_to_ids(texto_tokenizado_original)\n",
        "\n",
        "# Mostra os tokens com seus índices\n",
        "i = 0\n",
        "for tup in zip(texto_tokenizado_original, texto_tokens_indexados_original):\n",
        "    print('{:>3} {:<12} {:>6,}'.format(i, tup[0], tup[1]))\n",
        "    i = i + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0 [CLS]           101\n",
            "  1 Bom           8,399\n",
            "  2 Dia           3,616\n",
            "  3 ,               117\n",
            "  4 professor     2,917\n",
            "  5 .               119\n",
            "  6 Qual         13,082\n",
            "  7 o               146\n",
            "  8 conteúdo      5,015\n",
            "  9 da              180\n",
            " 10 prova         2,310\n",
            " 11 ?               136\n",
            " 12 Vai          20,805\n",
            " 13 cair          9,322\n",
            " 14 tudo          2,745\n",
            " 15 na              229\n",
            " 16 prova         2,310\n",
            " 17 ?               136\n",
            " 18 Agu           8,125\n",
            " 19 ##ardo        2,222\n",
            " 20 uma             230\n",
            " 21 resposta      4,299\n",
            " 22 ,               117\n",
            " 23 João          1,453\n",
            " 24 .               119\n",
            " 25 [SEP]           102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWF6G0EqM0iT"
      },
      "source": [
        "Máscara de atenção das palavras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPokJjkHM0iT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9daccff6-3c80-4079-db60-e930a741b0c4"
      },
      "source": [
        "# Marca cada um dos tokens como pertencentes à sentença '1'.\n",
        "mascara_atencao_original = [1] * len(texto_tokenizado_original)\n",
        "\n",
        "print (mascara_atencao_original)\n",
        "print (len(mascara_atencao_original))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvGb4Lr9M0iT"
      },
      "source": [
        "Convertendo as listas em tensores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x23ik0ehM0iU"
      },
      "source": [
        "# Importa a biblioteca\n",
        "import torch\n",
        "\n",
        "# Converte as entradas de listas para tensores do torch\n",
        "tokens_tensores_original = torch.as_tensor([texto_tokens_indexados_original])\n",
        "mascara_atencao_tensores_original = torch.as_tensor([mascara_atencao_original])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpDIoOYgM0iU"
      },
      "source": [
        "Gera os embeddings para o texto original. Guarda todas as camadas da rede em `outputs`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mGvXQN2M0iU"
      },
      "source": [
        "# Prediz os atributos dos estados ocultos para cada camada\n",
        "with torch.no_grad():\n",
        "    # output[0] contém last_hidden_states\n",
        "    outputs = model(tokens_tensores_original, mascara_atencao_tensores_original)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VajVWPxSM0iU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2bd5085-f81c-4d41-c83d-b8c098021a20"
      },
      "source": [
        "# Cria uma lista com os tensores a serem concatenados\n",
        "# Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "# Lista com os tensores a serem concatenados\n",
        "listaConcat = []\n",
        "# Percorre os 4 últimos\n",
        "for i in [-1,-2,-3,-4]:\n",
        "    # Concatena da lista\n",
        "    listaConcat.append(outputs[2][i])\n",
        "    # Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "     #print('listaConcat=',len(listaConcat))\n",
        "\n",
        "# Realiza a concatenação dos embeddings de todos as camadas\n",
        "# Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "concat4_hidden_states = torch.cat(listaConcat, dim=-1)\n",
        "# Saída: Entrada: (<1(lote)> x <qtde_tokens> <3072 ou 4096>)  \n",
        "\n",
        "print ('O vetor da  concatenação das 4 últimas camadas oculta tem o formato:', concat4_hidden_states.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O vetor da  concatenação das 4 últimas camadas oculta tem o formato: torch.Size([1, 26, 4096])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f-UKTRuM0iU"
      },
      "source": [
        "Vamos nos livrar da dimensão lotes 'batches', pois não precisamos dela."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ue_2PX2M0iV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfbcb923-2f0e-4ca3-c828-26018a633248"
      },
      "source": [
        "# Remove a dimensão 1, o lote 'batches'.\n",
        "#O método squeeze remove a primeira dimensão(0) pois possui tamanho 1\n",
        "embeddingTextoOriginal = torch.squeeze(concat4_hidden_states, dim=0)\n",
        "\n",
        "print ('O vetor de tokens de embedding do texto original tem o formato:', embeddingTextoOriginal.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O vetor de tokens de embedding do texto original tem o formato: torch.Size([26, 4096])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCwadAdmM0iV"
      },
      "source": [
        "Confirmando vetores dependentes do contexto\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb8Cm77zM0iV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3ccbefc-eda8-4947-f575-7c9057ad80ba"
      },
      "source": [
        "for i, token_str in enumerate(texto_tokenizado_original):\n",
        "  print (i, token_str)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [CLS]\n",
            "1 Bom\n",
            "2 Dia\n",
            "3 ,\n",
            "4 professor\n",
            "5 .\n",
            "6 Qual\n",
            "7 o\n",
            "8 conteúdo\n",
            "9 da\n",
            "10 prova\n",
            "11 ?\n",
            "12 Vai\n",
            "13 cair\n",
            "14 tudo\n",
            "15 na\n",
            "16 prova\n",
            "17 ?\n",
            "18 Agu\n",
            "19 ##ardo\n",
            "20 uma\n",
            "21 resposta\n",
            "22 ,\n",
            "23 João\n",
            "24 .\n",
            "25 [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGjE2y_pM0iV"
      },
      "source": [
        "Exibe os embenddings das sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W28pu2G9M0iV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88fd61ff-199e-449c-fd57-6dd61e620bd8"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Original = texto_original[0]\n",
        "sentenca2Original = texto_original[1]\n",
        "sentenca3Original = texto_original[2]\n",
        "sentenca4Original = texto_original[3]\n",
        "\n",
        "embeddingSentenca1Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca1Original, tokenizer)\n",
        "embeddingSentenca2Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca2Original, tokenizer)\n",
        "embeddingSentenca3Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca3Original, tokenizer)\n",
        "embeddingSentenca4Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca4Original, tokenizer)\n",
        "\n",
        "print('Os primeiros 4 valores de cada sentença do texto original.')\n",
        "\n",
        "print('\\nSentença 1:', sentenca1Original,'-', str(embeddingSentenca1Original[:4]))\n",
        "print('Soma embedding Sentença1:', sentenca1Original,'-', str(torch.sum(embeddingSentenca1Original[:4])))\n",
        "\n",
        "print('\\nSentença 2:', sentenca2Original,'-', str(embeddingSentenca2Original[:4]))\n",
        "print('Soma embedding Sentença2:', sentenca2Original,'-', str(torch.sum(embeddingSentenca2Original[:4])))\n",
        "\n",
        "print('\\nSentença 3:', sentenca3Original,'-', str(embeddingSentenca3Original[:4]))\n",
        "print('Soma embedding Sentença3:', sentenca3Original,'-', str(torch.sum(embeddingSentenca3Original[:4])))\n",
        "\n",
        "print('\\nSentença 4:', sentenca4Original,'-', str(embeddingSentenca4Original[:4]))\n",
        "print('Soma embedding Sentença4:', sentenca4Original,'-', str(torch.sum(embeddingSentenca4Original[:4])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Os primeiros 4 valores de cada sentença do texto original.\n",
            "\n",
            "Sentença 1: Bom Dia, professor. - tensor([[-0.5098, -0.2877,  0.0873,  ...,  0.9288, -0.0796,  0.3684],\n",
            "        [ 0.6078, -0.8869,  0.3736,  ...,  0.0124,  0.0094, -0.1719],\n",
            "        [ 0.9075, -1.1233, -0.0093,  ...,  0.1359, -0.3067, -0.4078],\n",
            "        [ 0.2499, -0.4717, -0.1217,  ...,  0.4604,  0.0075,  0.1555]])\n",
            "Soma embedding Sentença1: Bom Dia, professor. - tensor(-176.3423)\n",
            "\n",
            "Sentença 2: Qual o conteúdo da prova? - tensor([[-0.3987, -0.9450,  0.1785,  ...,  0.8476, -0.0572,  0.0365],\n",
            "        [ 0.2067, -0.2705,  0.7145,  ...,  0.2113,  0.2899,  0.5135],\n",
            "        [ 0.2355,  0.2686,  0.5669,  ...,  0.7205,  0.2510,  0.0924],\n",
            "        [ 0.5264, -0.4600,  0.4810,  ...,  0.1881,  0.0931,  0.1731]])\n",
            "Soma embedding Sentença2: Qual o conteúdo da prova? - tensor(-165.1487)\n",
            "\n",
            "Sentença 3: Vai cair tudo na prova? - tensor([[ 0.5178,  0.0863,  0.7394,  ..., -0.3301, -0.0115,  0.1168],\n",
            "        [ 0.1617,  1.1516, -0.0350,  ..., -0.2189,  0.1096, -0.3660],\n",
            "        [ 0.9252,  0.5806,  0.2491,  ...,  0.0027,  0.2467, -0.1535],\n",
            "        [ 0.5782,  1.3571, -0.5161,  ...,  0.5285,  0.2553, -0.0197]])\n",
            "Soma embedding Sentença3: Vai cair tudo na prova? - tensor(-177.0387)\n",
            "\n",
            "Sentença 4: Aguardo uma resposta, João. - tensor([[ 0.4339, -0.7168,  0.1173,  ...,  0.3840, -0.0936,  0.1355],\n",
            "        [-0.6806, -1.0194, -0.0765,  ...,  0.2201,  0.2731, -0.0384],\n",
            "        [ 1.1384, -0.8541,  0.8992,  ...,  0.5247,  0.2278,  0.0653],\n",
            "        [ 0.9206, -0.9862,  0.1347,  ...,  0.4393, -0.4792,  0.1743]])\n",
            "Soma embedding Sentença4: Aguardo uma resposta, João. - tensor(-169.8891)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDAG_xYHM0iV"
      },
      "source": [
        "Examinando os embeddings do texto original\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN1ZnWWLM0iW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95d69b84-8ad6-4969-bd04-2503f3370dee"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Original = texto_original[0]\n",
        "sentenca2Original = texto_original[1]\n",
        "sentenca3Original = texto_original[2]\n",
        "sentenca4Original = texto_original[3]\n",
        "\n",
        "print('Texto Original:', texto_original)\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca1TokenizadaOriginal = tokenizer.tokenize(sentenca1Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca1TokenizadaOriginal)\n",
        "embeddingSentenca1Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca1Original, tokenizer)\n",
        "print('\\nSentença 1 Original=\\'', sentenca1Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca1TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca1Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca1Original))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca2TokenizadaOriginal = tokenizer.tokenize(sentenca2Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca2TokenizadaOriginal)\n",
        "embeddingSentenca2Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca2Original, tokenizer)\n",
        "print('\\nSentença 2 Original=\\'', sentenca2Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca2TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca2Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca2Original))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca3TokenizadaOriginal = tokenizer.tokenize(sentenca3Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca3TokenizadaOriginal)\n",
        "embeddingSentenca3Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca3Original, tokenizer)\n",
        "print('\\nSentença 3 Original=\\'', sentenca3Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca3TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca3Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca3Original))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca4TokenizadaOriginal = tokenizer.tokenize(sentenca4Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca4TokenizadaOriginal)\n",
        "embeddingSentenca4Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca4Original, tokenizer)\n",
        "print('\\nSentença 4 Original=\\'', sentenca4Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca4TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca4Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca4Original))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original: ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "\n",
            "Sentença 1 Original=' Bom Dia, professor. '\n",
            "    Sentença tokenizada: ['Bom', 'Dia', ',', 'professor', '.']\n",
            "    => inicio em 1 e término em 5\n",
            "    Formato modelo : torch.Size([5, 4096])\n",
            "    Soma embeddings:  -225.64\n",
            "\n",
            "Sentença 2 Original=' Qual o conteúdo da prova? '\n",
            "    Sentença tokenizada: ['Qual', 'o', 'conteúdo', 'da', 'prova', '?']\n",
            "    => inicio em 6 e término em 11\n",
            "    Formato modelo : torch.Size([6, 4096])\n",
            "    Soma embeddings:  -252.06\n",
            "\n",
            "Sentença 3 Original=' Vai cair tudo na prova? '\n",
            "    Sentença tokenizada: ['Vai', 'cair', 'tudo', 'na', 'prova', '?']\n",
            "    => inicio em 12 e término em 17\n",
            "    Formato modelo : torch.Size([6, 4096])\n",
            "    Soma embeddings:  -260.65\n",
            "\n",
            "Sentença 4 Original=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    => inicio em 18 e término em 24\n",
            "    Formato modelo : torch.Size([7, 4096])\n",
            "    Soma embeddings:  -288.69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWXVLJ1bM0iW"
      },
      "source": [
        "### Texto Permutado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPWjgUWeM0iW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "068f54b9-e4e4-483e-d577-604650966e2c"
      },
      "source": [
        "# Define um texto com a permutação das sentenças do texto original\n",
        "texto_permutado = [texto_original[3],   # 'Aguardo uma resposta, João.',\n",
        "             texto_original[1],             # 'Qual o conteúdo da prova?',              \n",
        "             texto_original[0],             # 'Vai cair tudo na prova?',\n",
        "             texto_original[2]]             # 'Bom Dia, professor.']     \n",
        "\n",
        "# Use o texto permutado igual ao original para testar se as medidas estão corretas\n",
        "#texto_permutado = texto_original\n",
        "\n",
        "# Concatena as sentenças do texto em uma string\n",
        "textoPermutadoConcatenado = ' '.join(texto_permutado)\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado_permutado = '[CLS] ' + textoPermutadoConcatenado + ' [SEP]'\n",
        "\n",
        "# Divide a sentença em tokens\n",
        "texto_tokenizado_permutado = tokenizer.tokenize(texto_marcado_permutado)\n",
        "\n",
        "# Mapeia os tokens em seus índices do vocabulário\n",
        "texto_tokens_indexados_permutado = tokenizer.convert_tokens_to_ids(texto_tokenizado_permutado)\n",
        "\n",
        "# Mostra os tokens com seus índices\n",
        "i = 0\n",
        "for tup in zip(texto_tokenizado_permutado, texto_tokens_indexados_permutado):\n",
        "    print('{:>3} {:<12} {:>6,}'.format(i, tup[0], tup[1]))\n",
        "    i = i + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0 [CLS]           101\n",
            "  1 Agu           8,125\n",
            "  2 ##ardo        2,222\n",
            "  3 uma             230\n",
            "  4 resposta      4,299\n",
            "  5 ,               117\n",
            "  6 João          1,453\n",
            "  7 .               119\n",
            "  8 Qual         13,082\n",
            "  9 o               146\n",
            " 10 conteúdo      5,015\n",
            " 11 da              180\n",
            " 12 prova         2,310\n",
            " 13 ?               136\n",
            " 14 Bom           8,399\n",
            " 15 Dia           3,616\n",
            " 16 ,               117\n",
            " 17 professor     2,917\n",
            " 18 .               119\n",
            " 19 Vai          20,805\n",
            " 20 cair          9,322\n",
            " 21 tudo          2,745\n",
            " 22 na              229\n",
            " 23 prova         2,310\n",
            " 24 ?               136\n",
            " 25 [SEP]           102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN2heM1aM0iW"
      },
      "source": [
        "Máscara de atenção das palavras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjakxc4xM0iW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bab88fb-2067-4deb-de84-5693957b0dbe"
      },
      "source": [
        "# Marca cada um dos tokens como pertencentes à sentença '1'.\n",
        "mascara_atencao_permutado = [1] * len(texto_tokenizado_permutado)\n",
        "\n",
        "print (mascara_atencao_permutado)\n",
        "print (len(mascara_atencao_permutado))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkJeVNRgM0iW"
      },
      "source": [
        "Convertendo as listas em tensores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67NUmOkIM0iX"
      },
      "source": [
        "# Importa a biblioteca\n",
        "import torch\n",
        "\n",
        "# Converte as entradas de listas para tensores do torch\n",
        "tokens_tensores_permutado = torch.as_tensor([texto_tokens_indexados_permutado])\n",
        "mascara_atencao_tensores_permutado = torch.as_tensor([mascara_atencao_permutado])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TIWhsT3M0iX"
      },
      "source": [
        "Gera os embeddings para o texto original. Guarda todas as camadas da rede em `outputs`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07xtO-rnM0iX"
      },
      "source": [
        "# Prediz os atributos dos estados ocultos para cada camada\n",
        "with torch.no_grad():\n",
        "    # output[0] contém last_hidden_states\n",
        "    outputs = model(tokens_tensores_permutado, mascara_atencao_tensores_permutado)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvV4gue4M0iX"
      },
      "source": [
        "Recupera a saída e concatena as 4 últimas camada do BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svq_3keEM0iX"
      },
      "source": [
        "# Cria uma lista com os tensores a serem concatenados\n",
        "# Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "# Lista com os tensores a serem concatenados\n",
        "listaConcat = []\n",
        "# Percorre os 4 últimos\n",
        "for i in [-1,-2,-3,-4]:\n",
        "    # Concatena da lista\n",
        "    listaConcat.append(outputs[2][i])\n",
        "    # Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "     #print('listaConcat=',len(listaConcat))\n",
        "\n",
        "# Realiza a concatenação dos embeddings de todos as camadas\n",
        "# Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "concat4_hidden_states = torch.cat(listaConcat, dim=-1)\n",
        "# Saída: Entrada: (<1(lote)> x <qtde_tokens> <3072 ou 4096>)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybtNemHbM0iX"
      },
      "source": [
        "Vamos nos livrar da dimensão lotes 'batches', pois não precisamos dela."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSav8HKIM0iX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f362262-c893-42c3-c391-f034309769ba"
      },
      "source": [
        "# Remove a dimensão 1, o lote 'batches'.\n",
        "#O método squeeze remove a primeira dimensão(0) pois possui tamanho 1\n",
        "embeddingTextoPermutado = torch.squeeze(concat4_hidden_states, dim=0)\n",
        "\n",
        "print ('O vetor de tokens de embedding do texto permutado tem o formato:', embeddingTextoPermutado.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O vetor de tokens de embedding do texto permutado tem o formato: torch.Size([26, 4096])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2EqEuq6M0iY"
      },
      "source": [
        "Exibe os embenddings das sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_hCQhZnM0iY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7ac95e5-b284-4784-a15a-4d93b6cac3b7"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Permutado = texto_permutado[0]\n",
        "sentenca2Permutado = texto_permutado[1]\n",
        "sentenca3Permutado = texto_permutado[2]\n",
        "sentenca4Permutado = texto_permutado[3]\n",
        "\n",
        "embeddingSentenca1Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca1Permutado, tokenizer)\n",
        "embeddingSentenca2Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca2Permutado, tokenizer)\n",
        "embeddingSentenca3Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca3Permutado, tokenizer)\n",
        "embeddingSentenca4Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca4Permutado, tokenizer)\n",
        "\n",
        "print('Os primeiros 4 valores de cada sentença do texto permutado.')\n",
        "\n",
        "print('\\nSentença 1:', sentenca1Permutado,'-', str(embeddingSentenca1Permutado[:4]))\n",
        "print('Soma embedding Sentença1:', sentenca1Original,'-', str(torch.sum(embeddingSentenca1Original[:4])))\n",
        "\n",
        "print('\\nSentença 2:', sentenca2Permutado,'-', str(embeddingSentenca2Permutado[:4]))\n",
        "print('Soma embedding Sentença2:', sentenca2Permutado,'-', str(torch.sum(embeddingSentenca2Permutado[:4])))\n",
        "\n",
        "print('\\nSentença 3:', sentenca3Permutado,'-', str(embeddingSentenca3Permutado[:4]))\n",
        "print('Soma embedding Sentença3:', sentenca3Permutado,'-', str(torch.sum(embeddingSentenca3Original[:4])))\n",
        "\n",
        "print('\\nSentença 4:', sentenca4Permutado,'-', str(embeddingSentenca4Permutado[:4]))\n",
        "print('Soma embedding Sentença4:', sentenca4Permutado,'-', str(torch.sum(embeddingSentenca4Permutado[:4])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Os primeiros 4 valores de cada sentença do texto permutado.\n",
            "\n",
            "Sentença 1: Aguardo uma resposta, João. - tensor([[ 0.4152, -0.7838, -0.0364,  ...,  0.4706, -0.1614,  0.1815],\n",
            "        [-0.6012, -1.1043, -0.2660,  ...,  0.1239,  0.2729, -0.0574],\n",
            "        [ 1.2319, -1.1194,  0.9353,  ...,  0.5062,  0.1518,  0.1078],\n",
            "        [ 0.8861, -0.9666,  0.1831,  ...,  0.5239, -0.4849,  0.1787]])\n",
            "Soma embedding Sentença1: Bom Dia, professor. - tensor(-176.3423)\n",
            "\n",
            "Sentença 2: Qual o conteúdo da prova? - tensor([[-0.2957, -1.0942, -0.0024,  ...,  0.6032, -0.1615,  0.4615],\n",
            "        [ 0.2193, -0.4914,  0.7233,  ...,  0.2540,  0.1627,  0.7631],\n",
            "        [ 0.1377,  0.3856,  0.6060,  ...,  0.7089,  0.2763,  0.2866],\n",
            "        [ 0.5271, -0.4796,  0.4135,  ...,  0.3287,  0.1340,  0.4361]])\n",
            "Soma embedding Sentença2: Qual o conteúdo da prova? - tensor(-165.4919)\n",
            "\n",
            "Sentença 3: Bom Dia, professor. - tensor([[-0.2387, -0.2844,  0.3606,  ...,  0.9577, -0.2328,  0.2957],\n",
            "        [ 0.8188, -0.5643,  0.6965,  ..., -0.1356,  0.0236, -0.3090],\n",
            "        [ 0.9349, -1.0496,  0.1645,  ...,  0.1721, -0.3351, -0.5991],\n",
            "        [ 0.0104, -0.4793,  0.0501,  ...,  0.5897, -0.1399,  0.1081]])\n",
            "Soma embedding Sentença3: Bom Dia, professor. - tensor(-177.0387)\n",
            "\n",
            "Sentença 4: Vai cair tudo na prova? - tensor([[ 0.7876, -0.1169,  0.7632,  ..., -0.1344,  0.1030, -0.0097],\n",
            "        [ 0.2106,  1.0353,  0.0259,  ..., -0.2075, -0.0469, -0.3289],\n",
            "        [ 0.7594,  0.7997,  0.2487,  ...,  0.1881,  0.1629, -0.0855],\n",
            "        [ 0.6700,  1.3208, -0.5643,  ...,  0.6387,  0.3624, -0.0947]])\n",
            "Soma embedding Sentença4: Vai cair tudo na prova? - tensor(-176.5751)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXJIz3jPM0iY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55cd586d-5846-4e80-d86e-97fd6eeb2278"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Permutado = texto_permutado[0]\n",
        "sentenca2Permutado = texto_permutado[1]\n",
        "sentenca3Permutado = texto_permutado[2]\n",
        "sentenca4Permutado = texto_permutado[3]\n",
        "\n",
        "print('Texto Permutado:', texto_permutado)\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca1TokenizadaPermutado = tokenizer.tokenize(sentenca1Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca1TokenizadaPermutado)\n",
        "embeddingSentenca1Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca1Permutado, tokenizer)\n",
        "print('\\nSentença 1 Permutada=\\'', sentenca1Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca1TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca1Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca1Permutado))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca2TokenizadaPermutado = tokenizer.tokenize(sentenca2Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca2TokenizadaPermutado)\n",
        "embeddingSentenca2Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca2Permutado, tokenizer)\n",
        "print('\\nSentença 2 Permutada=\\'', sentenca2Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca2TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca2Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca2Permutado))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca3TokenizadaPermutado = tokenizer.tokenize(sentenca3Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca3TokenizadaPermutado)\n",
        "embeddingSentenca3Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca3Permutado, tokenizer)\n",
        "print('\\nSentença 3 Permutada=\\'', sentenca3Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca3TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca3Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca3Permutado))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca4TokenizadaPermutado = tokenizer.tokenize(sentenca4Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca4TokenizadaPermutado)\n",
        "embeddingSentenca4Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca4Permutado, tokenizer)\n",
        "print('\\nSentença 4 Permutada=\\'', sentenca4Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca4TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca4Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca4Permutado))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado: ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "\n",
            "Sentença 1 Permutada=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    => inicio em 1 e término em 7\n",
            "    Formato modelo : torch.Size([7, 4096])\n",
            "    Soma embeddings:  -291.17\n",
            "\n",
            "Sentença 2 Permutada=' Qual o conteúdo da prova? '\n",
            "    Sentença tokenizada: ['Qual', 'o', 'conteúdo', 'da', 'prova', '?']\n",
            "    => inicio em 8 e término em 13\n",
            "    Formato modelo : torch.Size([6, 4096])\n",
            "    Soma embeddings:  -249.21\n",
            "\n",
            "Sentença 3 Permutada=' Bom Dia, professor. '\n",
            "    Sentença tokenizada: ['Bom', 'Dia', ',', 'professor', '.']\n",
            "    => inicio em 14 e término em 18\n",
            "    Formato modelo : torch.Size([5, 4096])\n",
            "    Soma embeddings:  -217.20\n",
            "\n",
            "Sentença 4 Permutada=' Vai cair tudo na prova? '\n",
            "    Sentença tokenizada: ['Vai', 'cair', 'tudo', 'na', 'prova', '?']\n",
            "    => inicio em 19 e término em 24\n",
            "    Formato modelo : torch.Size([6, 4096])\n",
            "    Soma embeddings:  -265.03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyOCD7COM0iY"
      },
      "source": [
        "### Examinando as sentenças\n",
        "\n",
        "A mesma sentença apresenta embeddings com valores diferentes, pois se encontram em locais diferentes do texto. A soma de todos os embeddings demonstra isto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ucrFp95M0iY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c1f6ae3-70b0-41d2-d90c-fc47cf23d25b"
      },
      "source": [
        "print('\\nSentença 4 Original=\\'', sentenca4Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca4TokenizadaOriginal)\n",
        "print('    Formato modelo :', embeddingSentenca4Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca4Original))\n",
        "print('    Os 4 primeiros embeddings:', str(embeddingSentenca4Original[:4]))\n",
        "\n",
        "print('\\nSentença 1 Permutada=\\'', sentenca1Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca1TokenizadaPermutado)\n",
        "print('    Formato modelo :', embeddingSentenca1Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca1Permutado))\n",
        "print('    Os 4 primeiros embeddings:', str(embeddingSentenca1Permutado[:4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Sentença 4 Original=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    Formato modelo : torch.Size([7, 4096])\n",
            "    Soma embeddings:  -288.69\n",
            "    Os 4 primeiros embeddings: tensor([[ 0.4339, -0.7168,  0.1173,  ...,  0.3840, -0.0936,  0.1355],\n",
            "        [-0.6806, -1.0194, -0.0765,  ...,  0.2201,  0.2731, -0.0384],\n",
            "        [ 1.1384, -0.8541,  0.8992,  ...,  0.5247,  0.2278,  0.0653],\n",
            "        [ 0.9206, -0.9862,  0.1347,  ...,  0.4393, -0.4792,  0.1743]])\n",
            "\n",
            "Sentença 1 Permutada=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    Formato modelo : torch.Size([7, 4096])\n",
            "    Soma embeddings:  -291.17\n",
            "    Os 4 primeiros embeddings: tensor([[ 0.4152, -0.7838, -0.0364,  ...,  0.4706, -0.1614,  0.1815],\n",
            "        [-0.6012, -1.1043, -0.2660,  ...,  0.1239,  0.2729, -0.0574],\n",
            "        [ 1.2319, -1.1194,  0.9353,  ...,  0.5062,  0.1518,  0.1078],\n",
            "        [ 0.8861, -0.9666,  0.1831,  ...,  0.5239, -0.4849,  0.1787]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJLbGeGl9rXA"
      },
      "source": [
        "### Similaridade de cosseno entre os embeddings das sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txsn241y9rXA"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "def similaridadeCoseno(sentenca1, sentenca2):\n",
        "  similaridade = 1 - cosine(sentenca1, sentenca2)\n",
        "  return similaridade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5MH4W1E9rXA"
      },
      "source": [
        "#### Calcula a média aritmética da similaridade do coseno entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto original. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q30qFwSb9rXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4dc450f-7b1b-4eea-bd6b-fffb2c38c2cb"
      },
      "source": [
        "print('Texto Original  :', str(texto_original))\n",
        "print('Quantidade de sentenças:',len(texto_original))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "n = len(texto_original)\n",
        "\n",
        "somaScos = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(n-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_original[i]\n",
        "    Sj = texto_original[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto original    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Encontra os maiores embeddings os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSi, linha = torch.max(embeddingSi, dim=0)        \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSi:', len(maiorEmbeddingSi))\n",
        "        \n",
        "    # Encontra os maiores embeddings os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSj, linha = torch.max(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSj:', len(maiorEmbeddingSj))\n",
        "  \n",
        "    # Similaridade entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Scos = similaridadeCoseno(maiorEmbeddingSi, maiorEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaScos = somaScos + Scos\n",
        "\n",
        "CcosOriginal = float(somaScos)/float(n-1)\n",
        "print('Ccos Original:', CcosOriginal)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original  : ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "Quantidade de sentenças: 4\n",
            "Ccos Original: 0.8147226969401041\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZLT9K6r9rXA"
      },
      "source": [
        "#### Calcula a média aritmética da similaridade do coseno entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto permutado. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF5f2DSb9rXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df2afdc9-2f18-4624-8a43-87cde3acf076"
      },
      "source": [
        "print('Texto Permutado :', str(texto_permutado))\n",
        "print('Quantidade de sentenças:', len(texto_permutado))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "np = len(texto_permutado)\n",
        "\n",
        "somaScos = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(np-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_permutado[i]\n",
        "    Sj = texto_permutado[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto permutado    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Encontra os maiores embeddings os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSi, linha = torch.max(embeddingSi, dim=0)        \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSi:', len(maiorEmbeddingSi))\n",
        "        \n",
        "    # Encontra os maiores embeddings os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSj, linha = torch.max(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSj:', len(maiorEmbeddingSj))\n",
        "  \n",
        "    # Similaridade entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Scos = similaridadeCoseno(maiorEmbeddingSi, maiorEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaScos = somaScos + Scos\n",
        "\n",
        "CcosPermutado = float(somaScos)/float(np-1)\n",
        "print('Ccos Original:', CcosPermutado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado : ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "Quantidade de sentenças: 4\n",
            "Ccos Original: 0.7936708529790243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIKvfbWo9rXB"
      },
      "source": [
        "#### Compara as médias da similaridade de cosseno dos embeddings das sentenças do texto original e permutado\n",
        "\n",
        "Características das medidas:\n",
        "- Textos com sentenças iguais resulta uma medida igual a 1.\n",
        "- Textos com sentenças diferenntes resulta uma medida menor que 1.\n",
        "- Texto com sentenças muito diferentes apresentam valores menores que 1.\n",
        "- Textos iguais resultam em medidas iguais. \n",
        "- É uma medida de similaridade.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCITgUD59rXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a95ce1e-b1ec-4f87-fdec-6f5153a921c4"
      },
      "source": [
        "print('Ccos Original :', CcosOriginal)\n",
        "print('Ccos Permutado:', CcosPermutado)\n",
        "\n",
        "if (CcosOriginal > CcosPermutado):\n",
        "    print('Texto original tem maior similaridade de cosseno entre as sentenças!')\n",
        "else:\n",
        "    print('Texto Permutado tem menor similaridade de cosseno entre as sentenças!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ccos Original : 0.8147226969401041\n",
            "Ccos Permutado: 0.7936708529790243\n",
            "Texto original tem maior similaridade de cosseno entre as sentenças!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poXedMfZ9rXB"
      },
      "source": [
        "### Distância euclidiana entre os embeddings das sentenças\n",
        "\n",
        "Possui outros nomes como distância L2 ou norma L2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgMLv7Xr9rXB"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "def distanciaEuclidiana(sentenca1, sentenca2):\n",
        "  distancia = euclidean(sentenca1, sentenca2)\n",
        "\n",
        "  return distancia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFcLYcv_9rXB"
      },
      "source": [
        "#### Calcula a média aritmética da distância euclidiana entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto original. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLPkoJU49rXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2dce4ac-fd9c-4bd2-fb1f-7bbe5a99ab6c"
      },
      "source": [
        "print('Texto Original  :', str(texto_original))\n",
        "print('Quantidade de sentenças:',len(texto_original))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "n = len(texto_original)\n",
        "\n",
        "somaSeuc = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(n-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_original[i]\n",
        "    Sj = texto_original[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto original    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Encontra os maiores embeddings os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSi, linha = torch.max(embeddingSi, dim=0)        \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSi:', len(maiorEmbeddingSi))\n",
        "        \n",
        "    # Encontra os maiores embeddings os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSj, linha = torch.max(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSj:', len(maiorEmbeddingSj))\n",
        "  \n",
        "    # Diferença entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Seuc = distanciaEuclidiana(maiorEmbeddingSi, maiorEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSeuc = somaSeuc + Seuc\n",
        "\n",
        "CeucOriginal = float(somaSeuc)/float(n-1)\n",
        "print('Ceuc Original:', CeucOriginal)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original  : ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "Quantidade de sentenças: 4\n",
            "Ceuc Original: 27.702426274617512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYF1Bm-g9rXB"
      },
      "source": [
        "#### Calcula a média aritmética da distância euclidiana entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto permutado. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1rSfTES9rXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ed3c0c2-bfaf-495e-ef73-499b7f0560b8"
      },
      "source": [
        "print('Texto Permutado :', str(texto_permutado))\n",
        "print('Quantidade de sentenças:', len(texto_permutado))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "np = len(texto_permutado)\n",
        "\n",
        "somaSeuc = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(np-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_permutado[i]\n",
        "    Sj = texto_permutado[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto permutado    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Encontra os maiores embeddings os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSi, linha = torch.max(embeddingSi, dim=0)        \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSi:', len(maiorEmbeddingSi))\n",
        "        \n",
        "    # Encontra os maiores embeddings os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSj, linha = torch.max(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSj:', len(maiorEmbeddingSj))\n",
        "  \n",
        "    # Diferença entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Seuc = distanciaEuclidiana(maiorEmbeddingSi, maiorEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSeuc = somaSeuc + Seuc\n",
        "\n",
        "CeucPermutado = float(somaSeuc)/float(np-1)\n",
        "print('Ceuc Original:', CeucPermutado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado : ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "Quantidade de sentenças: 4\n",
            "Ceuc Original: 29.813594182332356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_kqtJxd9rXC"
      },
      "source": [
        "#### Compara as médias da distância euclidiana dos embeddings das sentenças do texto original e permutado\n",
        "\n",
        "Características das medidas:\n",
        "- Textos com sentenças iguais resulta uma medida igual a 0.\n",
        "- Textos com sentenças diferenntes resulta uma medida maior que 0.\n",
        "- Texto com sentenças muito diferentes apresentam valores maiores que 0.\n",
        "- Textos iguais resultam em medidas iguais. \n",
        "- É uma medida de diferença.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC4IlKjS9rXC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68bba471-d65d-4f98-9a51-ee087944de29"
      },
      "source": [
        "print('Ceuc Original :', CeucOriginal)\n",
        "print('Ceuc Permutado:', CeucPermutado)\n",
        "\n",
        "if (CeucOriginal < CeucPermutado):\n",
        "    print('Texto original tem menor distância euclidiana entre as sentenças!')\n",
        "else:\n",
        "    print('Texto Permutado tem maior distância euclidiana entre as sentenças!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ceuc Original : 27.702426274617512\n",
            "Ceuc Permutado: 29.813594182332356\n",
            "Texto original tem menor distância euclidiana entre as sentenças!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ron62mX39rXC"
      },
      "source": [
        "### Distância Manhattan entre os embeddings das sentenças\n",
        "\n",
        "Possui outros nomes como distância Cityblock, distância L1, norma L1 e métrica do táxi.\n",
        "\n",
        "\n",
        "Igual a subtração absoluta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU8WUSNJ9rXC"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "from scipy.spatial.distance import cityblock\n",
        "\n",
        "def distanciaManhattan(sentenca1, sentenca2):\n",
        "  distancia = cityblock(sentenca1, sentenca2)\n",
        "\n",
        "  return distancia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp7lYFkQ9rXC"
      },
      "source": [
        "#### Calcula a média aritmética da distância de manhattan entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto original. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZsETQjN9rXC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "342f0836-74bc-4f77-c24f-c44ab6addf53"
      },
      "source": [
        "print('Texto Original  :', str(texto_original))\n",
        "print('Quantidade de sentenças:',len(texto_original))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "n = len(texto_original)\n",
        "\n",
        "somaSman = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(n-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_original[i]\n",
        "    Sj = texto_original[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto original    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Encontra os maiores embeddings os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSi, linha = torch.max(embeddingSi, dim=0)        \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSi:', len(maiorEmbeddingSi))\n",
        "        \n",
        "    # Encontra os maiores embeddings os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSj, linha = torch.max(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSj:', len(maiorEmbeddingSj)) \n",
        "  \n",
        "    # Diferença entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Sman = distanciaManhattan(maiorEmbeddingSi, maiorEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSman = somaSman + Sman\n",
        "\n",
        "CmanOriginal = float(somaSman)/float(n-1)\n",
        "print('Cman Original:', CmanOriginal)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original  : ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "Quantidade de sentenças: 4\n",
            "Cman Original: 1287.9197184244792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hraWMnO49rXC"
      },
      "source": [
        "#### Calcula a média aritmética da distância de manhattan entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto permutado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1lpFQpW9rXC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb689c67-3618-4a2f-862f-a0762dfd2175"
      },
      "source": [
        "print('Texto Permutado :', str(texto_permutado))\n",
        "print('Quantidade de sentenças:', len(texto_permutado))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "np = len(texto_permutado)\n",
        "\n",
        "somaSman = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(np-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_permutado[i]\n",
        "    Sj = texto_permutado[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto permutado    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Si, tokenizer)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Sj, tokenizer)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Encontra os maiores embeddings os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSi, linha = torch.max(embeddingSi, dim=0)        \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSi:', len(maiorEmbeddingSi))\n",
        "        \n",
        "    # Encontra os maiores embeddings os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    maiorEmbeddingSj, linha = torch.max(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('maiorEmbeddingSj:', len(maiorEmbeddingSj)) \n",
        "  \n",
        "    # Diferença entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Sman = distanciaManhattan(maiorEmbeddingSi, maiorEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSman = somaSman + Sman\n",
        "\n",
        "CmanPermutado = float(somaSman)/float(np-1)\n",
        "print('Ceuc Original:', CmanPermutado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado : ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "Quantidade de sentenças: 4\n",
            "Ceuc Original: 1404.3885904947917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW9oqevL9rXD"
      },
      "source": [
        "#### Compara as médias da distância de manhattan dos embeddings das sentenças do texto original e permutado\n",
        "\n",
        "Características das medidas:\n",
        "- Textos com sentenças iguais resulta uma medida igual a 0.\n",
        "- Textos com sentenças diferenntes resulta uma medida maior que 0.\n",
        "- Texto com sentenças muito diferentes apresentam valores maiores que 0.\n",
        "- Textos iguais resultam em medidas iguais. \n",
        "- É uma medida de diferença.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E71-ic6l9rXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b549879f-8370-4e13-9f5a-cfc2cf42912f"
      },
      "source": [
        "print('Cman Original :', CmanOriginal)\n",
        "print('Cman Permutado:', CmanPermutado)\n",
        "\n",
        "if (CmanOriginal < CmanPermutado):\n",
        "    print('Texto original tem menor distância de manhattan entre as sentenças!')\n",
        "else:\n",
        "    print('Texto Permutado tem maior distância de manhattan entre as sentenças!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cman Original : 1287.9197184244792\n",
            "Cman Permutado: 1404.3885904947917\n",
            "Texto original tem menor distância de manhattan entre as sentenças!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqVSa_XBL35H"
      },
      "source": [
        "### Resumo\n",
        "\n",
        "Resultado das medidas utilizando as quatro últimas camadas do BERT.\n",
        "\n",
        "Base(MEAN):\n",
        "- Ccos       :   0.62004846          0.54099079\n",
        "- Ceuc       :   7.11709849          7.99353107\n",
        "- Cman       :   153.63694255          171.98441060\n",
        "\n",
        "Base(MAX):\n",
        "- Ccos       :   0.79404344          0.76070702\n",
        "- Ceuc       :   10.07102553          10.70145098\n",
        "- Cman       :   213.39687602          231.29823303\n",
        "\n",
        "Base(MEAN):\n",
        "- Ccos       :   0.80771943          0.77137093\n",
        "- Ceuc       :   20.71080144          23.16955884\n",
        "- Cman       :   883.51291911          983.28851318\n",
        "\n",
        "Base(MAX):\n",
        "- Ccos       :   0.83094325          0.80360138\n",
        "- Ceuc       :   27.86794090          30.03283564\n",
        "- Cman       :   1175.89337158          1273.93892415"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yac6Etu7L35I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fa03557-6ddd-4c6a-93bf-99025c984f31"
      },
      "source": [
        "print('Resultado das medidas utilizando a última camada do BERT')\n",
        "print('Texto  :   Original            Permutado')\n",
        "print('Ccos       :   {:.8f}          {:.8f}'.format(CcosOriginal,CcosPermutado))\n",
        "print('Ceuc       :   {:.8f}          {:.8f}'.format(CeucOriginal,CeucPermutado))\n",
        "print('Cman       :   {:.8f}          {:.8f}'.format(CmanOriginal,CmanPermutado))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resultado das medidas utilizando a última camada do BERT\n",
            "Texto  :   Original            Permutado\n",
            "Ccos       :   0.81472270          0.79367085\n",
            "Ceuc       :   27.70242627          29.81359418\n",
            "Cman       :   1287.91971842          1404.38859049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsBQPbuNsFmj"
      },
      "source": [
        "## 10 - Exemplo sentenças de texto original e permutado utilizando embedding da última camada do BERT usando a estratégia MEAN e palavras relevantes(CLEAN - Stopword)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19AATfMisFmo"
      },
      "source": [
        "### Texto Original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU9FaJm4sFmo",
        "outputId": "2a056191-e18d-46fe-cc2b-cf4da7589ff1"
      },
      "source": [
        "# Define um texto com 4 sentenças\n",
        "texto_original = ['Bom Dia, professor.',\n",
        "             'Qual o conteúdo da prova?',              \n",
        "             'Vai cair tudo na prova?',\n",
        "             'Aguardo uma resposta, João.']\n",
        "\n",
        "# Concatena as sentenças do texto em uma string\n",
        "textoOriginalConcatenado = ' '.join(texto_original)\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado_original = '[CLS] ' + textoOriginalConcatenado + ' [SEP]'\n",
        "\n",
        "# Divide a sentença em tokens\n",
        "texto_tokenizado_original = tokenizer.tokenize(texto_marcado_original)\n",
        "\n",
        "# Mapeia os tokens em seus índices do vocabulário\n",
        "texto_tokens_indexados_original = tokenizer.convert_tokens_to_ids(texto_tokenizado_original)\n",
        "\n",
        "# Mostra os tokens com seus índices\n",
        "i = 0\n",
        "for tup in zip(texto_tokenizado_original, texto_tokens_indexados_original):\n",
        "    print('{:>3} {:<12} {:>6,}'.format(i, tup[0], tup[1]))\n",
        "    i = i + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0 [CLS]           101\n",
            "  1 Bom           8,399\n",
            "  2 Dia           3,616\n",
            "  3 ,               117\n",
            "  4 professor     2,917\n",
            "  5 .               119\n",
            "  6 Qual         13,082\n",
            "  7 o               146\n",
            "  8 conteúdo      5,015\n",
            "  9 da              180\n",
            " 10 prova         2,310\n",
            " 11 ?               136\n",
            " 12 Vai          20,805\n",
            " 13 cair          9,322\n",
            " 14 tudo          2,745\n",
            " 15 na              229\n",
            " 16 prova         2,310\n",
            " 17 ?               136\n",
            " 18 Agu           8,125\n",
            " 19 ##ardo        2,222\n",
            " 20 uma             230\n",
            " 21 resposta      4,299\n",
            " 22 ,               117\n",
            " 23 João          1,453\n",
            " 24 .               119\n",
            " 25 [SEP]           102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGAC2fxisFmr"
      },
      "source": [
        "Máscara de atenção das palavras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRDaFwzosFmr",
        "outputId": "984d7f56-cc17-456e-b83e-5f3389ee04a2"
      },
      "source": [
        "# Marca cada um dos tokens como pertencentes à sentença '1'.\n",
        "mascara_atencao_original = [1] * len(texto_tokenizado_original)\n",
        "\n",
        "print (mascara_atencao_original)\n",
        "print (len(mascara_atencao_original))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2Ky0UDDsFms"
      },
      "source": [
        "Convertendo as listas em tensores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p30SEmzsFms"
      },
      "source": [
        "# Importa a bibliotecaaaaaaaa\n",
        "import torch\n",
        "\n",
        "# Converte as entradas de listas para tensores do torch\n",
        "tokens_tensores_original = torch.as_tensor([texto_tokens_indexados_original])\n",
        "mascara_atencao_tensores_original = torch.as_tensor([mascara_atencao_original])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtpDq1ACsFmt"
      },
      "source": [
        "Gera os embeddings para o texto original. Guarda somente a última camada da rede em `outputs`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX-Rty6PsFmt"
      },
      "source": [
        "# Prediz os atributos dos estados ocultos para cada camada\n",
        "with torch.no_grad():\n",
        "    # output[0] contém last_hidden_states\n",
        "    outputs = model(tokens_tensores_original, mascara_atencao_tensores_original)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdxPC0A8sFmt"
      },
      "source": [
        "Recupera a saída da última camada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVj5fIjjsFmu",
        "outputId": "7f7bc843-3dd3-4046-8539-a5a54d350b7e"
      },
      "source": [
        "# Recupera a última e única camada da saída\n",
        "last_hidden_states = outputs[0]\n",
        "\n",
        "print ('O vetor da última camada oculta tem o formato:', last_hidden_states.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O vetor da última camada oculta tem o formato: torch.Size([1, 26, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJrBKm9DsFmu"
      },
      "source": [
        "Vamos nos livrar da dimensão lotes 'batches', pois não precisamos dela."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zauxa9psFmu",
        "outputId": "56856785-1d40-4dd3-e10e-c6e4e62f8bcb"
      },
      "source": [
        "# Remove a dimensão 1, o lote 'batches'.\n",
        "#O método squeeze remove a primeira dimensão(0) pois possui tamanho 1\n",
        "embeddingTextoOriginal = torch.squeeze(last_hidden_states, dim=0)\n",
        "\n",
        "print ('O vetor de tokens de embedding do texto original tem o formato:', embeddingTextoOriginal.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O vetor de tokens de embedding do texto original tem o formato: torch.Size([26, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBreB1FdsFmv"
      },
      "source": [
        "Confirmando vetores dependentes do contexto\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp6eo0DCsFmv",
        "outputId": "ca24ffb3-8470-4c49-e2d4-e496172bbd05"
      },
      "source": [
        "for i, token_str in enumerate(texto_tokenizado_original):\n",
        "  print (i, token_str)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [CLS]\n",
            "1 Bom\n",
            "2 Dia\n",
            "3 ,\n",
            "4 professor\n",
            "5 .\n",
            "6 Qual\n",
            "7 o\n",
            "8 conteúdo\n",
            "9 da\n",
            "10 prova\n",
            "11 ?\n",
            "12 Vai\n",
            "13 cair\n",
            "14 tudo\n",
            "15 na\n",
            "16 prova\n",
            "17 ?\n",
            "18 Agu\n",
            "19 ##ardo\n",
            "20 uma\n",
            "21 resposta\n",
            "22 ,\n",
            "23 João\n",
            "24 .\n",
            "25 [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMxG57QasFmw"
      },
      "source": [
        "Exibe os embenddings das sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfWmF0eOsFmw",
        "outputId": "4920e6b2-f159-4de8-b56a-3630e2850ecf"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Original = texto_original[0]\n",
        "sentenca2Original = texto_original[1]\n",
        "sentenca3Original = texto_original[2]\n",
        "sentenca4Original = texto_original[3]\n",
        "\n",
        "embeddingSentenca1Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca1Original, tokenizer)\n",
        "embeddingSentenca2Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca2Original, tokenizer)\n",
        "embeddingSentenca3Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca3Original, tokenizer)\n",
        "embeddingSentenca4Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca4Original, tokenizer)\n",
        "\n",
        "print('Os primeiros 4 valores de cada sentença do texto original.')\n",
        "\n",
        "print('\\nSentença 1:', sentenca1Original,'-', str(embeddingSentenca1Original[:4]))\n",
        "print('Soma embedding Sentença1:', sentenca1Original,'-', str(torch.sum(embeddingSentenca1Original[:4])))\n",
        "\n",
        "print('\\nSentença 2:', sentenca2Original,'-', str(embeddingSentenca2Original[:4]))\n",
        "print('Soma embedding Sentença2:', sentenca2Original,'-', str(torch.sum(embeddingSentenca2Original[:4])))\n",
        "\n",
        "print('\\nSentença 3:', sentenca3Original,'-', str(embeddingSentenca3Original[:4]))\n",
        "print('Soma embedding Sentença3:', sentenca3Original,'-', str(torch.sum(embeddingSentenca3Original[:4])))\n",
        "\n",
        "print('\\nSentença 4:', sentenca4Original,'-', str(embeddingSentenca4Original[:4]))\n",
        "print('Soma embedding Sentença4:', sentenca4Original,'-', str(torch.sum(embeddingSentenca4Original[:4])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Os primeiros 4 valores de cada sentença do texto original.\n",
            "\n",
            "Sentença 1: Bom Dia, professor. - tensor([[-0.5098, -0.2877,  0.0873,  ...,  0.5436, -0.9302,  0.4668],\n",
            "        [ 0.6078, -0.8869,  0.3736,  ..., -0.3517, -1.2140, -0.3077],\n",
            "        [ 0.9075, -1.1233, -0.0093,  ...,  0.4433, -0.4633, -0.0113],\n",
            "        [ 0.2499, -0.4717, -0.1217,  ...,  0.7079, -0.2300,  0.4911]])\n",
            "Soma embedding Sentença1: Bom Dia, professor. - tensor(-113.4554)\n",
            "\n",
            "Sentença 2: Qual o conteúdo da prova? - tensor([[-0.3987, -0.9450,  0.1785,  ...,  0.7189, -0.6772, -0.1452],\n",
            "        [ 0.2067, -0.2705,  0.7145,  ...,  0.3047, -0.2718,  0.7577],\n",
            "        [ 0.2355,  0.2686,  0.5669,  ...,  1.0817,  0.5614,  0.3750],\n",
            "        [ 0.5264, -0.4600,  0.4810,  ..., -0.5559, -0.2941,  0.0378]])\n",
            "Soma embedding Sentença2: Qual o conteúdo da prova? - tensor(-115.8800)\n",
            "\n",
            "Sentença 3: Vai cair tudo na prova? - tensor([[ 0.5178,  0.0863,  0.7394,  ..., -0.5765, -0.6208, -0.2230],\n",
            "        [ 0.1617,  1.1516, -0.0350,  ...,  0.1730,  0.2104, -0.0207],\n",
            "        [ 0.9252,  0.5806,  0.2491,  ...,  0.1687,  0.0772, -0.1173],\n",
            "        [ 0.5782,  1.3571, -0.5161,  ..., -0.0942,  0.0404, -0.0390]])\n",
            "Soma embedding Sentença3: Vai cair tudo na prova? - tensor(-110.5299)\n",
            "\n",
            "Sentença 4: Aguardo uma resposta, João. - tensor([[ 0.4339, -0.7168,  0.1173,  ...,  0.0768, -1.2036,  0.3863],\n",
            "        [-0.6806, -1.0194, -0.0765,  ..., -0.1768, -0.6326,  0.2895],\n",
            "        [ 1.1384, -0.8541,  0.8992,  ...,  0.2798, -0.0381,  0.5061],\n",
            "        [ 0.9206, -0.9862,  0.1347,  ...,  0.4182, -1.0164,  0.4713]])\n",
            "Soma embedding Sentença4: Aguardo uma resposta, João. - tensor(-116.1903)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AT4hmrosFmw"
      },
      "source": [
        "Examinando os embeddings do texto original\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlNrBzHFsFmx",
        "outputId": "503a9be5-a9fc-40fa-ec11-1ddfb3dd6c46"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Original = texto_original[0]\n",
        "sentenca2Original = texto_original[1]\n",
        "sentenca3Original = texto_original[2]\n",
        "sentenca4Original = texto_original[3]\n",
        "\n",
        "print('Texto Original:', texto_original)\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca1TokenizadaOriginal = tokenizer.tokenize(sentenca1Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca1TokenizadaOriginal)\n",
        "embeddingSentenca1Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca1Original, tokenizer)\n",
        "print('\\nSentença 1 Original=\\'', sentenca1Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca1TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca1Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca1Original))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca2TokenizadaOriginal = tokenizer.tokenize(sentenca2Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca2TokenizadaOriginal)\n",
        "embeddingSentenca2Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca2Original, tokenizer)\n",
        "print('\\nSentença 2 Original=\\'', sentenca2Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca2TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca2Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca2Original))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca3TokenizadaOriginal = tokenizer.tokenize(sentenca3Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca3TokenizadaOriginal)\n",
        "embeddingSentenca3Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca3Original, tokenizer)\n",
        "print('\\nSentença 3 Original=\\'', sentenca3Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca3TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca3Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca3Original))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca4TokenizadaOriginal = tokenizer.tokenize(sentenca4Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca4TokenizadaOriginal)\n",
        "embeddingSentenca4Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca4Original, tokenizer)\n",
        "print('\\nSentença 4 Original=\\'', sentenca4Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca4TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca4Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca4Original))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original: ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "\n",
            "Sentença 1 Original=' Bom Dia, professor. '\n",
            "    Sentença tokenizada: ['Bom', 'Dia', ',', 'professor', '.']\n",
            "    => inicio em 1 e término em 5\n",
            "    Formato modelo : torch.Size([5, 1024])\n",
            "    Soma embeddings:  -141.45\n",
            "\n",
            "Sentença 2 Original=' Qual o conteúdo da prova? '\n",
            "    Sentença tokenizada: ['Qual', 'o', 'conteúdo', 'da', 'prova', '?']\n",
            "    => inicio em 6 e término em 11\n",
            "    Formato modelo : torch.Size([6, 1024])\n",
            "    Soma embeddings:  -173.58\n",
            "\n",
            "Sentença 3 Original=' Vai cair tudo na prova? '\n",
            "    Sentença tokenizada: ['Vai', 'cair', 'tudo', 'na', 'prova', '?']\n",
            "    => inicio em 12 e término em 17\n",
            "    Formato modelo : torch.Size([6, 1024])\n",
            "    Soma embeddings:  -167.58\n",
            "\n",
            "Sentença 4 Original=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    => inicio em 18 e término em 24\n",
            "    Formato modelo : torch.Size([7, 1024])\n",
            "    Soma embeddings:  -200.72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWsYpv_bsFmx"
      },
      "source": [
        "### Texto Permutado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e-102FSsFmx",
        "outputId": "920e929c-c44f-429d-c3ac-fec53c747a12"
      },
      "source": [
        "# Define um texto com a permutação das sentenças do texto original\n",
        "texto_permutado = [texto_original[3],   # 'Aguardo uma resposta, João.',\n",
        "             texto_original[1],             # 'Qual o conteúdo da prova?',              \n",
        "             texto_original[0],             # 'Vai cair tudo na prova?',\n",
        "             texto_original[2]]             # 'Bom Dia, professor.']     \n",
        "\n",
        "# Use o texto permutado igual ao original para testar se as medidas estão corretas\n",
        "#texto_permutado = texto_original\n",
        "\n",
        "# Concatena as sentenças do texto em uma string\n",
        "textoPermutadoConcatenado = ' '.join(texto_permutado)\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado_permutado = '[CLS] ' + textoPermutadoConcatenado + ' [SEP]'\n",
        "\n",
        "# Divide a sentença em tokens\n",
        "texto_tokenizado_permutado = tokenizer.tokenize(texto_marcado_permutado)\n",
        "\n",
        "# Mapeia os tokens em seus índices do vocabulário\n",
        "texto_tokens_indexados_permutado = tokenizer.convert_tokens_to_ids(texto_tokenizado_permutado)\n",
        "\n",
        "# Mostra os tokens com seus índices\n",
        "i = 0\n",
        "for tup in zip(texto_tokenizado_permutado, texto_tokens_indexados_permutado):\n",
        "    print('{:>3} {:<12} {:>6,}'.format(i, tup[0], tup[1]))\n",
        "    i = i + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0 [CLS]           101\n",
            "  1 Agu           8,125\n",
            "  2 ##ardo        2,222\n",
            "  3 uma             230\n",
            "  4 resposta      4,299\n",
            "  5 ,               117\n",
            "  6 João          1,453\n",
            "  7 .               119\n",
            "  8 Qual         13,082\n",
            "  9 o               146\n",
            " 10 conteúdo      5,015\n",
            " 11 da              180\n",
            " 12 prova         2,310\n",
            " 13 ?               136\n",
            " 14 Bom           8,399\n",
            " 15 Dia           3,616\n",
            " 16 ,               117\n",
            " 17 professor     2,917\n",
            " 18 .               119\n",
            " 19 Vai          20,805\n",
            " 20 cair          9,322\n",
            " 21 tudo          2,745\n",
            " 22 na              229\n",
            " 23 prova         2,310\n",
            " 24 ?               136\n",
            " 25 [SEP]           102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoWi9iDGsFmy",
        "outputId": "1edb78e2-dbe5-4439-e31b-6b85de444d46"
      },
      "source": [
        "# Marca cada um dos tokens como pertencentes à sentença '1'.\n",
        "mascara_atencao_permutado = [1] * len(texto_tokenizado_permutado)\n",
        "\n",
        "print (mascara_atencao_permutado)\n",
        "print (len(mascara_atencao_permutado))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUf--8eJsFmy"
      },
      "source": [
        "Convertendo as listas em tensores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPXl21tpsFmz"
      },
      "source": [
        "# Importa a biblioteca\n",
        "import torch\n",
        "\n",
        "# Converte as entradas de listas para tensores do torch\n",
        "tokens_tensores_permutado = torch.as_tensor([texto_tokens_indexados_permutado])\n",
        "mascara_atencao_tensores_permutado = torch.as_tensor([mascara_atencao_permutado])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx2aMCAcsFmz"
      },
      "source": [
        "Gera os embeddings para o texto original. Guarda somente a última camada da rede em `outputs`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLkXV0DvsFmz"
      },
      "source": [
        "# Prediz os atributos dos estados ocultos para cada camada\n",
        "with torch.no_grad():\n",
        "    # output[0] contém last_hidden_states\n",
        "    outputs = model(tokens_tensores_permutado, mascara_atencao_tensores_permutado)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eRSCaP4sFm0"
      },
      "source": [
        "Recupera a saída da última camada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUMEhXZjsFm0",
        "outputId": "f71c3440-d88e-497f-b27a-4face3c25aa4"
      },
      "source": [
        "# Recupera a última e única camada da saída\n",
        "last_hidden_states = outputs[0]\n",
        "\n",
        "print ('O vetor da última camada oculta tem o formato:', last_hidden_states.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O vetor da última camada oculta tem o formato: torch.Size([1, 26, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAOnH5jBsFm1"
      },
      "source": [
        "Vamos nos livrar da dimensão lotes 'batches', pois não precisamos dela."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzMYCJr5sFm1",
        "outputId": "88e4f256-ee9a-492f-8e63-9cbb797e678b"
      },
      "source": [
        "# Remove a dimensão 1, o lote 'batches'.\n",
        "#O método squeeze remove a primeira dimensão(0) pois possui tamanho 1\n",
        "embeddingTextoPermutado = torch.squeeze(last_hidden_states, dim=0)\n",
        "\n",
        "print ('O vetor de tokens de embedding do texto permutado tem o formato:', embeddingTextoPermutado.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O vetor de tokens de embedding do texto permutado tem o formato: torch.Size([26, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E_mRhwVsFm1"
      },
      "source": [
        "Exibe os embenddings das sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QEGPIF7sFm2",
        "outputId": "d1fa6718-6930-4f74-a058-91b41895edca"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Permutado = texto_permutado[0]\n",
        "sentenca2Permutado = texto_permutado[1]\n",
        "sentenca3Permutado = texto_permutado[2]\n",
        "sentenca4Permutado = texto_permutado[3]\n",
        "\n",
        "embeddingSentenca1Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca1Permutado, tokenizer)\n",
        "embeddingSentenca2Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca2Permutado, tokenizer)\n",
        "embeddingSentenca3Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca3Permutado, tokenizer)\n",
        "embeddingSentenca4Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca4Permutado, tokenizer)\n",
        "\n",
        "print('Os primeiros 4 valores de cada sentença do texto permutado.')\n",
        "\n",
        "print('\\nSentença 1:', sentenca1Permutado,'-', str(embeddingSentenca1Permutado[:4]))\n",
        "print('Soma embedding Sentença1:', sentenca1Original,'-', str(torch.sum(embeddingSentenca1Original[:4])))\n",
        "\n",
        "print('\\nSentença 2:', sentenca2Permutado,'-', str(embeddingSentenca2Permutado[:4]))\n",
        "print('Soma embedding Sentença2:', sentenca2Permutado,'-', str(torch.sum(embeddingSentenca2Permutado[:4])))\n",
        "\n",
        "print('\\nSentença 3:', sentenca3Permutado,'-', str(embeddingSentenca3Permutado[:4]))\n",
        "print('Soma embedding Sentença3:', sentenca3Permutado,'-', str(torch.sum(embeddingSentenca3Original[:4])))\n",
        "\n",
        "print('\\nSentença 4:', sentenca4Permutado,'-', str(embeddingSentenca4Permutado[:4]))\n",
        "print('Soma embedding Sentença4:', sentenca4Permutado,'-', str(torch.sum(embeddingSentenca4Permutado[:4])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Os primeiros 4 valores de cada sentença do texto permutado.\n",
            "\n",
            "Sentença 1: Aguardo uma resposta, João. - tensor([[ 0.4152, -0.7838, -0.0364,  ...,  0.2686, -1.3504,  0.4707],\n",
            "        [-0.6012, -1.1043, -0.2660,  ..., -0.1943, -0.8112,  0.2180],\n",
            "        [ 1.2319, -1.1194,  0.9353,  ...,  0.2953, -0.1973,  0.5069],\n",
            "        [ 0.8861, -0.9666,  0.1831,  ...,  0.4595, -1.1045,  0.5615]])\n",
            "Soma embedding Sentença1: Bom Dia, professor. - tensor(-113.4554)\n",
            "\n",
            "Sentença 2: Qual o conteúdo da prova? - tensor([[-0.2957, -1.0942, -0.0024,  ...,  0.5875, -0.7164,  0.0104],\n",
            "        [ 0.2193, -0.4914,  0.7233,  ...,  0.3551, -0.3698,  0.8577],\n",
            "        [ 0.1377,  0.3856,  0.6060,  ...,  1.2662,  0.4965,  0.5211],\n",
            "        [ 0.5271, -0.4796,  0.4135,  ..., -0.5303, -0.3934,  0.1571]])\n",
            "Soma embedding Sentença2: Qual o conteúdo da prova? - tensor(-115.7949)\n",
            "\n",
            "Sentença 3: Bom Dia, professor. - tensor([[-0.2387, -0.2844,  0.3606,  ...,  0.6976, -0.9028,  0.3216],\n",
            "        [ 0.8188, -0.5643,  0.6965,  ..., -0.1439, -0.7018, -0.1933],\n",
            "        [ 0.9349, -1.0496,  0.1645,  ...,  0.4782, -0.3837, -0.2850],\n",
            "        [ 0.0104, -0.4793,  0.0501,  ...,  0.7341, -0.3687,  0.4562]])\n",
            "Soma embedding Sentença3: Bom Dia, professor. - tensor(-110.5299)\n",
            "\n",
            "Sentença 4: Vai cair tudo na prova? - tensor([[ 7.8763e-01, -1.1689e-01,  7.6317e-01,  ..., -4.3840e-01,\n",
            "         -6.5442e-01, -6.2305e-02],\n",
            "        [ 2.1062e-01,  1.0353e+00,  2.5937e-02,  ...,  7.1820e-02,\n",
            "          1.2368e-01,  1.1584e-03],\n",
            "        [ 7.5943e-01,  7.9969e-01,  2.4871e-01,  ...,  1.8792e-01,\n",
            "          9.4661e-02, -9.1651e-02],\n",
            "        [ 6.7000e-01,  1.3208e+00, -5.6431e-01,  ..., -6.3588e-03,\n",
            "          1.6016e-01, -1.4379e-01]])\n",
            "Soma embedding Sentença4: Vai cair tudo na prova? - tensor(-110.7603)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kehz0vDBsFm2",
        "outputId": "3b74d99d-bb0c-484b-e088-089a0845d6fe"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Permutado = texto_permutado[0]\n",
        "sentenca2Permutado = texto_permutado[1]\n",
        "sentenca3Permutado = texto_permutado[2]\n",
        "sentenca4Permutado = texto_permutado[3]\n",
        "\n",
        "print('Texto Permutado:', texto_permutado)\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca1TokenizadaPermutado = tokenizer.tokenize(sentenca1Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca1TokenizadaPermutado)\n",
        "embeddingSentenca1Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca1Permutado, tokenizer)\n",
        "print('\\nSentença 1 Permutada=\\'', sentenca1Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca1TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca1Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca1Permutado))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca2TokenizadaPermutado = tokenizer.tokenize(sentenca2Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca2TokenizadaPermutado)\n",
        "embeddingSentenca2Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca2Permutado, tokenizer)\n",
        "print('\\nSentença 2 Permutada=\\'', sentenca2Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca2TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca2Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca2Permutado))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca3TokenizadaPermutado = tokenizer.tokenize(sentenca3Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca3TokenizadaPermutado)\n",
        "embeddingSentenca3Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca3Permutado, tokenizer)\n",
        "print('\\nSentença 3 Permutada=\\'', sentenca3Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca3TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca3Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca3Permutado))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca4TokenizadaPermutado = tokenizer.tokenize(sentenca4Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca4TokenizadaPermutado)\n",
        "embeddingSentenca4Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca4Permutado, tokenizer)\n",
        "print('\\nSentença 4 Permutada=\\'', sentenca4Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca4TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca4Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca4Permutado))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado: ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "\n",
            "Sentença 1 Permutada=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    => inicio em 1 e término em 7\n",
            "    Formato modelo : torch.Size([7, 1024])\n",
            "    Soma embeddings:  -199.90\n",
            "\n",
            "Sentença 2 Permutada=' Qual o conteúdo da prova? '\n",
            "    Sentença tokenizada: ['Qual', 'o', 'conteúdo', 'da', 'prova', '?']\n",
            "    => inicio em 8 e término em 13\n",
            "    Formato modelo : torch.Size([6, 1024])\n",
            "    Soma embeddings:  -173.06\n",
            "\n",
            "Sentença 3 Permutada=' Bom Dia, professor. '\n",
            "    Sentença tokenizada: ['Bom', 'Dia', ',', 'professor', '.']\n",
            "    => inicio em 14 e término em 18\n",
            "    Formato modelo : torch.Size([5, 1024])\n",
            "    Soma embeddings:  -141.81\n",
            "\n",
            "Sentença 4 Permutada=' Vai cair tudo na prova? '\n",
            "    Sentença tokenizada: ['Vai', 'cair', 'tudo', 'na', 'prova', '?']\n",
            "    => inicio em 19 e término em 24\n",
            "    Formato modelo : torch.Size([6, 1024])\n",
            "    Soma embeddings:  -167.47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvUnrHFysFm2"
      },
      "source": [
        "### Examinando as sentenças\n",
        "\n",
        "A mesma sentença apresenta embeddings com valores diferentes, pois se encontram em locais diferentes do texto. A soma de todos os embeddings demonstra isto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRXHN3O-sFm2",
        "outputId": "9dcf44b1-dc0b-491e-c6ee-3ffa3ef6ea4d"
      },
      "source": [
        "print('\\nSentença 4 Original=\\'', sentenca4Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca4TokenizadaOriginal)\n",
        "print('    Formato modelo :', embeddingSentenca4Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca4Original))\n",
        "print('    Os 4 primeiros embeddings:', str(embeddingSentenca4Original[:4]))\n",
        "\n",
        "print('\\nSentença 1 Permutada=\\'', sentenca1Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca1TokenizadaPermutado)\n",
        "print('    Formato modelo :', embeddingSentenca1Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca1Permutado))\n",
        "print('    Os 4 primeiros embeddings:', str(embeddingSentenca1Permutado[:4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Sentença 4 Original=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    Formato modelo : torch.Size([7, 1024])\n",
            "    Soma embeddings:  -200.72\n",
            "    Os 4 primeiros embeddings: tensor([[ 0.4339, -0.7168,  0.1173,  ...,  0.0768, -1.2036,  0.3863],\n",
            "        [-0.6806, -1.0194, -0.0765,  ..., -0.1768, -0.6326,  0.2895],\n",
            "        [ 1.1384, -0.8541,  0.8992,  ...,  0.2798, -0.0381,  0.5061],\n",
            "        [ 0.9206, -0.9862,  0.1347,  ...,  0.4182, -1.0164,  0.4713]])\n",
            "\n",
            "Sentença 1 Permutada=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    Formato modelo : torch.Size([7, 1024])\n",
            "    Soma embeddings:  -199.90\n",
            "    Os 4 primeiros embeddings: tensor([[ 0.4152, -0.7838, -0.0364,  ...,  0.2686, -1.3504,  0.4707],\n",
            "        [-0.6012, -1.1043, -0.2660,  ..., -0.1943, -0.8112,  0.2180],\n",
            "        [ 1.2319, -1.1194,  0.9353,  ...,  0.2953, -0.1973,  0.5069],\n",
            "        [ 0.8861, -0.9666,  0.1831,  ...,  0.4595, -1.1045,  0.5615]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvXgM6N1sFm3"
      },
      "source": [
        "### Similaridade de cosseno entre os embeddings das sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKzuxFWJsFm3"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "def similaridadeCoseno(sentenca1, sentenca2):\n",
        "  similaridade = 1 - cosine(sentenca1, sentenca2)\n",
        "  return similaridade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDib4hLGsFm3"
      },
      "source": [
        "#### Calcula a média aritmética da similaridade do coseno entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto original. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHXaYmvGsFm3",
        "outputId": "3fabb069-ea00-4377-c141-a7b87e79efc1"
      },
      "source": [
        "print('Texto Original  :', str(texto_original))\n",
        "print('Quantidade de sentenças:',len(texto_original))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "n = len(texto_original)\n",
        "\n",
        "somaScos = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(n-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_original[i]\n",
        "    Sj = texto_original[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto original    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Si, tokenizer, filtro='CLEAN')        \n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Sj, tokenizer, filtro='CLEAN')\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "    # Similaridade entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Scos = similaridadeCoseno(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaScos = somaScos + Scos\n",
        "\n",
        "CcosOriginal = float(somaScos)/float(n-1)\n",
        "print('Ccos Original:', CcosOriginal)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original  : ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "Quantidade de sentenças: 4\n",
            "Ccos Original: 0.7745923201243082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeDBXHS7sFm4"
      },
      "source": [
        "#### Calcula a média aritmética da similaridade do coseno entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto permutado. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEUtq3GXsFm4",
        "outputId": "214ff3aa-ac03-4b1e-ad93-e41fa1e88db8"
      },
      "source": [
        "print('Texto Permutado :', str(texto_permutado))\n",
        "print('Quantidade de sentenças:', len(texto_permutado))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "np = len(texto_permutado)\n",
        "\n",
        "somaScos = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(np-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_permutado[i]\n",
        "    Sj = texto_permutado[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto permutado    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Si, tokenizer, filtro='CLEAN')\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Sj, tokenizer, filtro='CLEAN')\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "   # Similaridade entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Scos = similaridadeCoseno(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaScos = somaScos + Scos\n",
        "\n",
        "CcosPermutado = float(somaScos)/float(np-1)\n",
        "print('Ccos Original:', CcosPermutado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado : ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "Quantidade de sentenças: 4\n",
            "Ccos Original: 0.7151723504066467\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj7h64hJsFm4"
      },
      "source": [
        "#### Compara as médias da similaridade de cosseno dos embeddings das sentenças do texto original e permutado\n",
        "\n",
        "Características das medidas:\n",
        "- Textos com sentenças iguais resulta uma medida igual a 1.\n",
        "- Textos com sentenças diferenntes resulta uma medida menor que 1.\n",
        "- Texto com sentenças muito diferentes apresentam valores menores que 1.\n",
        "- Textos iguais resultam em medidas iguais. \n",
        "- É uma medida de similaridade.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQLa6sp9sFm4",
        "outputId": "22676c25-1a91-4dc9-bf3e-52aa1b9e2773"
      },
      "source": [
        "print('Ccos Original :', CcosOriginal)\n",
        "print('Ccos Permutado:', CcosPermutado)\n",
        "\n",
        "if (CcosOriginal > CcosPermutado):\n",
        "    print('Texto original tem maior similaridade de cosseno entre as sentenças!')\n",
        "else:\n",
        "    print('Texto Permutado tem menor similaridade de cosseno entre as sentenças!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ccos Original : 0.7745923201243082\n",
            "Ccos Permutado: 0.7151723504066467\n",
            "Texto original tem maior similaridade de cosseno entre as sentenças!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjvPrHXZsFm5"
      },
      "source": [
        "### Distância euclidiana entre os embeddings das sentenças\n",
        "\n",
        "Possui outros nomes como distância L2 ou norma L2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL_xEvs-sFm5"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "def distanciaEuclidiana(sentenca1, sentenca2):\n",
        "  distancia = euclidean(sentenca1, sentenca2)\n",
        "\n",
        "  return distancia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqFVlwDBsFm5"
      },
      "source": [
        "#### Calcula a média aritmética da distância euclidiana entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto original. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3uj0JMvsFm5",
        "outputId": "23b85958-b79c-44bf-b3ab-3b739f80ce26"
      },
      "source": [
        "print('Texto Original  :', str(texto_original))\n",
        "print('Quantidade de sentenças:',len(texto_original))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "n = len(texto_original)\n",
        "\n",
        "somaSeuc = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(n-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_original[i]\n",
        "    Sj = texto_original[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto original    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Si, tokenizer, filtro='CLEAN')        \n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Sj, tokenizer, filtro='CLEAN')\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    # print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "    # Diferença entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Seuc = distanciaEuclidiana(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSeuc = somaSeuc + Seuc\n",
        "\n",
        "CeucOriginal = float(somaSeuc)/float(n-1)\n",
        "print('Ceuc Original:', CeucOriginal)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original  : ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "Quantidade de sentenças: 4\n",
            "Ceuc Original: 11.496900876363119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv5VUtoMsFm5"
      },
      "source": [
        "#### Calcula a média aritmética da distância euclidiana entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto permutado. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QsCz48XsFm6",
        "outputId": "bda2464b-7ba1-4035-fda1-08948deaedff"
      },
      "source": [
        "print('Texto Permutado :', str(texto_permutado))\n",
        "print('Quantidade de sentenças:', len(texto_permutado))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "np = len(texto_permutado)\n",
        "\n",
        "somaSeuc = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(np-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_permutado[i]\n",
        "    Sj = texto_permutado[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto permutado    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Si, tokenizer, filtro='CLEAN')\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Sj, tokenizer, filtro='CLEAN')\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "    # Diferença entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Seuc = distanciaEuclidiana(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSeuc = somaSeuc + Seuc\n",
        "\n",
        "CeucPermutado = float(somaSeuc)/float(np-1)\n",
        "print('Ceuc Original:', CeucPermutado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado : ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "Quantidade de sentenças: 4\n",
            "Ceuc Original: 13.09795061747233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWtkCP0dsFm6"
      },
      "source": [
        "#### Compara as médias da distância euclidiana dos embeddings das sentenças do texto original e permutado\n",
        "\n",
        "Características das medidas:\n",
        "- Textos com sentenças iguais resulta uma medida igual a 0.\n",
        "- Textos com sentenças diferenntes resulta uma medida maior que 0.\n",
        "- Texto com sentenças muito diferentes apresentam valores maiores que 0.\n",
        "- Textos iguais resultam em medidas iguais. \n",
        "- É uma medida de diferença.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SISdwB4RsFm6",
        "outputId": "8668a410-6e13-4fc6-f0cc-d205934dface"
      },
      "source": [
        "print('Ceuc Original :', CeucOriginal)\n",
        "print('Ceuc Permutado:', CeucPermutado)\n",
        "\n",
        "if (CeucOriginal < CeucPermutado):\n",
        "    print('Texto original tem menor distância euclidiana entre as sentenças!')\n",
        "else:\n",
        "    print('Texto Permutado tem maior distância euclidiana entre as sentenças!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ceuc Original : 11.496900876363119\n",
            "Ceuc Permutado: 13.09795061747233\n",
            "Texto original tem menor distância euclidiana entre as sentenças!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln6IuKWfsFm6"
      },
      "source": [
        "### Distância Manhattan entre os embeddings das sentenças\n",
        "\n",
        "Possui outros nomes como distância Cityblock, distância L1, norma L1 e métrica do táxi.\n",
        "\n",
        "Igual subtração absoluta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJSt1k0esFm7"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "from scipy.spatial.distance import cityblock\n",
        "\n",
        "def distanciaManhattan(sentenca1, sentenca2):\n",
        "  distancia = cityblock(sentenca1, sentenca2)\n",
        "\n",
        "  return distancia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBO2UR1IsFm7"
      },
      "source": [
        "#### Calcula a média aritmética da distância de manhattan entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto original. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxrMfVszsFm7",
        "outputId": "5553de91-eb4e-4008-d8af-930b2565a4c5"
      },
      "source": [
        "print('Texto Original  :', str(texto_original))\n",
        "print('Quantidade de sentenças:',len(texto_original))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "n = len(texto_original)\n",
        "\n",
        "somaSman = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(n-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_original[i]\n",
        "    Sj = texto_original[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto original    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Si, tokenizer, filtro='CLEAN')        \n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Sj, tokenizer, filtro='CLEAN')\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    # print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "    # Diferença entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Sman = distanciaManhattan(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSman = somaSman + Sman\n",
        "\n",
        "CmanOriginal = float(somaSman)/float(n-1)\n",
        "print('Cman Original:', CmanOriginal)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original  : ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "Quantidade de sentenças: 4\n",
            "Cman Original: 282.4736073811849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2POGH7msFm7"
      },
      "source": [
        "#### Calcula a média aritmética da distância de manhattan entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto permutado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ji9F1JOsFm7",
        "outputId": "2260bb37-61cf-44cd-ff99-0e25808a3cec"
      },
      "source": [
        "print('Texto Permutado :', str(texto_permutado))\n",
        "print('Quantidade de sentenças:', len(texto_permutado))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "np = len(texto_permutado)\n",
        "\n",
        "somaSman = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(np-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_permutado[i]\n",
        "    Sj = texto_permutado[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto permutado    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Si, tokenizer, filtro='CLEAN')\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Sj, tokenizer, filtro='CLEAN')\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "    # Diferença entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Sman = distanciaManhattan(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSman = somaSman + Sman\n",
        "\n",
        "CmanPermutado = float(somaSman)/float(np-1)\n",
        "print('Ceuc Original:', CmanPermutado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado : ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "Quantidade de sentenças: 4\n",
            "Ceuc Original: 319.1162516276042\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF2QrnIVsFm8"
      },
      "source": [
        "#### Compara as médias da distância de manhattan dos embeddings das sentenças do texto original e permutado\n",
        "\n",
        "Características das medidas:\n",
        "- Textos com sentenças iguais resulta uma medida igual a 0.\n",
        "- Textos com sentenças diferenntes resulta uma medida maior que 0.\n",
        "- Texto com sentenças muito diferentes apresentam valores maiores que 0.\n",
        "- Textos iguais resultam em medidas iguais. \n",
        "- É uma medida de diferença.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gCvmLXqsFm8",
        "outputId": "9055658c-aa3d-4e17-eebd-e6ca34508300"
      },
      "source": [
        "print('Cman Original :', CmanOriginal)\n",
        "print('Cman Permutado:', CmanPermutado)\n",
        "\n",
        "if (CmanOriginal < CmanPermutado):\n",
        "    print('Texto original tem menor distância de manhattan entre as sentenças!')\n",
        "else:\n",
        "    print('Texto Permutado tem maior distância de manhattan entre as sentenças!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cman Original : 282.4736073811849\n",
            "Cman Permutado: 319.1162516276042\n",
            "Texto original tem menor distância de manhattan entre as sentenças!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5rbxNyXsFm8"
      },
      "source": [
        "### Resumo\n",
        "\n",
        "Resultado das medidas utilizando a última camada do BERT.\n",
        "\n",
        "Base(MEAN):\n",
        "- Ccos       :   0.67999101          0.69653825\n",
        "- Ceuc       :   6.34085274          6.15486606\n",
        "- Cman       :   136.53579712          132.14489237\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh4_TmjNsFm8",
        "outputId": "24a10c81-d9fc-446b-f28a-5fe3874dec6a"
      },
      "source": [
        "print('Resultado das medidas utilizando a última camada do BERT')\n",
        "print('Texto  :   Original            Permutado')\n",
        "print('Ccos       :   {:.8f}          {:.8f}'.format(CcosOriginal,CcosPermutado))\n",
        "print('Ceuc       :   {:.8f}          {:.8f}'.format(CeucOriginal,CeucPermutado))\n",
        "print('Cman       :   {:.8f}          {:.8f}'.format(CmanOriginal,CmanPermutado))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resultado das medidas utilizando a última camada do BERT\n",
            "Texto  :   Original            Permutado\n",
            "Ccos       :   0.77459232          0.71517235\n",
            "Ceuc       :   11.49690088          13.09795062\n",
            "Cman       :   282.47360738          319.11625163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQSCarFgl9j5"
      },
      "source": [
        "## 11 - Exemplo sentenças de texto original e permutado utilizando embedding da última camada do BERT usando a estratégia MEAN com palavras relavantes(NOUN-Substantivos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFVHojw1l9j9"
      },
      "source": [
        "### Texto Original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qeR3y4Cl9j9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0725b186-3009-4c78-9274-16cf312c78d5"
      },
      "source": [
        "# Define um texto com 4 sentenças\n",
        "texto_original = ['Bom Dia, professor.',\n",
        "             'Qual o conteúdo da prova?',              \n",
        "             'Vai cair tudo na prova?',\n",
        "             'Aguardo uma resposta, João.']\n",
        "\n",
        "# Concatena as sentenças do texto em uma string\n",
        "textoOriginalConcatenado = ' '.join(texto_original)\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado_original = '[CLS] ' + textoOriginalConcatenado + ' [SEP]'\n",
        "\n",
        "# Divide a sentença em tokens\n",
        "texto_tokenizado_original = tokenizer.tokenize(texto_marcado_original)\n",
        "\n",
        "# Mapeia os tokens em seus índices do vocabulário\n",
        "texto_tokens_indexados_original = tokenizer.convert_tokens_to_ids(texto_tokenizado_original)\n",
        "\n",
        "# Mostra os tokens com seus índices\n",
        "i = 0\n",
        "for tup in zip(texto_tokenizado_original, texto_tokens_indexados_original):\n",
        "    print('{:>3} {:<12} {:>6,}'.format(i, tup[0], tup[1]))\n",
        "    i = i + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0 [CLS]           101\n",
            "  1 Bom           8,399\n",
            "  2 Dia           3,616\n",
            "  3 ,               117\n",
            "  4 professor     2,917\n",
            "  5 .               119\n",
            "  6 Qual         13,082\n",
            "  7 o               146\n",
            "  8 conteúdo      5,015\n",
            "  9 da              180\n",
            " 10 prova         2,310\n",
            " 11 ?               136\n",
            " 12 Vai          20,805\n",
            " 13 cair          9,322\n",
            " 14 tudo          2,745\n",
            " 15 na              229\n",
            " 16 prova         2,310\n",
            " 17 ?               136\n",
            " 18 Agu           8,125\n",
            " 19 ##ardo        2,222\n",
            " 20 uma             230\n",
            " 21 resposta      4,299\n",
            " 22 ,               117\n",
            " 23 João          1,453\n",
            " 24 .               119\n",
            " 25 [SEP]           102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_HEZhCOl9j-"
      },
      "source": [
        "Máscara de atenção das palavras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMvf5JR9l9j-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b76a378e-5049-40f9-97f8-650d04766e02"
      },
      "source": [
        "# Marca cada um dos tokens como pertencentes à sentença '1'.\n",
        "mascara_atencao_original = [1] * len(texto_tokenizado_original)\n",
        "\n",
        "print (mascara_atencao_original)\n",
        "print (len(mascara_atencao_original))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpYRgyDKl9j-"
      },
      "source": [
        "Convertendo as listas em tensores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSkH4nStl9j_"
      },
      "source": [
        "# Importa a biblioteca\n",
        "import torch\n",
        "\n",
        "# Converte as entradas de listas para tensores do torch\n",
        "tokens_tensores_original = torch.as_tensor([texto_tokens_indexados_original])\n",
        "mascara_atencao_tensores_original = torch.as_tensor([mascara_atencao_original])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGIWW2frl9j_"
      },
      "source": [
        "Gera os embeddings para o texto original. Guarda somente a última camada da rede em `outputs`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4UA1jqxl9j_"
      },
      "source": [
        "# Prediz os atributos dos estados ocultos para cada camada\n",
        "with torch.no_grad():\n",
        "    # output[0] contém last_hidden_states\n",
        "    outputs = model(tokens_tensores_original, mascara_atencao_tensores_original)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rpP0syul9j_"
      },
      "source": [
        "Recupera a saída da última camada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EumV200sl9kA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb68efe4-2f17-4908-fdd4-d8909ae336ed"
      },
      "source": [
        "# Recupera a última e única camada da saída\n",
        "last_hidden_states = outputs[0]\n",
        "\n",
        "print ('O vetor da última camada oculta tem o formato:', last_hidden_states.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O vetor da última camada oculta tem o formato: torch.Size([1, 26, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8UQ-CIIl9kA"
      },
      "source": [
        "Vamos nos livrar da dimensão lotes 'batches', pois não precisamos dela."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWdHs89nl9kA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d694e1bc-f044-4348-fc71-d3490f51462f"
      },
      "source": [
        "# Remove a dimensão 1, o lote 'batches'.\n",
        "#O método squeeze remove a primeira dimensão(0) pois possui tamanho 1\n",
        "embeddingTextoOriginal = torch.squeeze(last_hidden_states, dim=0)\n",
        "\n",
        "print ('O vetor de tokens de embedding do texto original tem o formato:', embeddingTextoOriginal.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O vetor de tokens de embedding do texto original tem o formato: torch.Size([26, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4Zflk6Fl9kA"
      },
      "source": [
        "Confirmando vetores dependentes do contexto\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkjJEjmll9kA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86266121-1f6b-4b83-cf81-06facc6e3777"
      },
      "source": [
        "for i, token_str in enumerate(texto_tokenizado_original):\n",
        "  print (i, token_str)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [CLS]\n",
            "1 Bom\n",
            "2 Dia\n",
            "3 ,\n",
            "4 professor\n",
            "5 .\n",
            "6 Qual\n",
            "7 o\n",
            "8 conteúdo\n",
            "9 da\n",
            "10 prova\n",
            "11 ?\n",
            "12 Vai\n",
            "13 cair\n",
            "14 tudo\n",
            "15 na\n",
            "16 prova\n",
            "17 ?\n",
            "18 Agu\n",
            "19 ##ardo\n",
            "20 uma\n",
            "21 resposta\n",
            "22 ,\n",
            "23 João\n",
            "24 .\n",
            "25 [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku6SY2qBl9kB"
      },
      "source": [
        "Exibe os embenddings das sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0X1HZeil9kB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4f628a0-f7da-408d-e07e-3daccbd60611"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Original = texto_original[0]\n",
        "sentenca2Original = texto_original[1]\n",
        "sentenca3Original = texto_original[2]\n",
        "sentenca4Original = texto_original[3]\n",
        "\n",
        "embeddingSentenca1Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca1Original, tokenizer)\n",
        "embeddingSentenca2Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca2Original, tokenizer)\n",
        "embeddingSentenca3Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca3Original, tokenizer)\n",
        "embeddingSentenca4Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca4Original, tokenizer)\n",
        "\n",
        "print('Os primeiros 4 valores de cada sentença do texto original.')\n",
        "\n",
        "print('\\nSentença 1:', sentenca1Original,'-', str(embeddingSentenca1Original[:4]))\n",
        "print('Soma embedding Sentença1:', sentenca1Original,'-', str(torch.sum(embeddingSentenca1Original[:4])))\n",
        "\n",
        "print('\\nSentença 2:', sentenca2Original,'-', str(embeddingSentenca2Original[:4]))\n",
        "print('Soma embedding Sentença2:', sentenca2Original,'-', str(torch.sum(embeddingSentenca2Original[:4])))\n",
        "\n",
        "print('\\nSentença 3:', sentenca3Original,'-', str(embeddingSentenca3Original[:4]))\n",
        "print('Soma embedding Sentença3:', sentenca3Original,'-', str(torch.sum(embeddingSentenca3Original[:4])))\n",
        "\n",
        "print('\\nSentença 4:', sentenca4Original,'-', str(embeddingSentenca4Original[:4]))\n",
        "print('Soma embedding Sentença4:', sentenca4Original,'-', str(torch.sum(embeddingSentenca4Original[:4])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Os primeiros 4 valores de cada sentença do texto original.\n",
            "\n",
            "Sentença 1: Bom Dia, professor. - tensor([[-0.5098, -0.2877,  0.0873,  ...,  0.5436, -0.9302,  0.4668],\n",
            "        [ 0.6078, -0.8869,  0.3736,  ..., -0.3517, -1.2140, -0.3077],\n",
            "        [ 0.9075, -1.1233, -0.0093,  ...,  0.4433, -0.4633, -0.0113],\n",
            "        [ 0.2499, -0.4717, -0.1217,  ...,  0.7079, -0.2300,  0.4911]])\n",
            "Soma embedding Sentença1: Bom Dia, professor. - tensor(-113.4554)\n",
            "\n",
            "Sentença 2: Qual o conteúdo da prova? - tensor([[-0.3987, -0.9450,  0.1785,  ...,  0.7189, -0.6772, -0.1452],\n",
            "        [ 0.2067, -0.2705,  0.7145,  ...,  0.3047, -0.2718,  0.7577],\n",
            "        [ 0.2355,  0.2686,  0.5669,  ...,  1.0817,  0.5614,  0.3750],\n",
            "        [ 0.5264, -0.4600,  0.4810,  ..., -0.5559, -0.2941,  0.0378]])\n",
            "Soma embedding Sentença2: Qual o conteúdo da prova? - tensor(-115.8800)\n",
            "\n",
            "Sentença 3: Vai cair tudo na prova? - tensor([[ 0.5178,  0.0863,  0.7394,  ..., -0.5765, -0.6208, -0.2230],\n",
            "        [ 0.1617,  1.1516, -0.0350,  ...,  0.1730,  0.2104, -0.0207],\n",
            "        [ 0.9252,  0.5806,  0.2491,  ...,  0.1687,  0.0772, -0.1173],\n",
            "        [ 0.5782,  1.3571, -0.5161,  ..., -0.0942,  0.0404, -0.0390]])\n",
            "Soma embedding Sentença3: Vai cair tudo na prova? - tensor(-110.5299)\n",
            "\n",
            "Sentença 4: Aguardo uma resposta, João. - tensor([[ 0.4339, -0.7168,  0.1173,  ...,  0.0768, -1.2036,  0.3863],\n",
            "        [-0.6806, -1.0194, -0.0765,  ..., -0.1768, -0.6326,  0.2895],\n",
            "        [ 1.1384, -0.8541,  0.8992,  ...,  0.2798, -0.0381,  0.5061],\n",
            "        [ 0.9206, -0.9862,  0.1347,  ...,  0.4182, -1.0164,  0.4713]])\n",
            "Soma embedding Sentença4: Aguardo uma resposta, João. - tensor(-116.1903)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uat3GKd1l9kB"
      },
      "source": [
        "Examinando os embeddings do texto original\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w88VPPW8l9kB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90315d1a-3212-492d-efbf-19604ec0b0c0"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Original = texto_original[0]\n",
        "sentenca2Original = texto_original[1]\n",
        "sentenca3Original = texto_original[2]\n",
        "sentenca4Original = texto_original[3]\n",
        "\n",
        "print('Texto Original:', texto_original)\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca1TokenizadaOriginal = tokenizer.tokenize(sentenca1Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca1TokenizadaOriginal)\n",
        "embeddingSentenca1Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca1Original, tokenizer)\n",
        "print('\\nSentença 1 Original=\\'', sentenca1Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca1TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca1Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca1Original))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca2TokenizadaOriginal = tokenizer.tokenize(sentenca2Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca2TokenizadaOriginal)\n",
        "embeddingSentenca2Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca2Original, tokenizer)\n",
        "print('\\nSentença 2 Original=\\'', sentenca2Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca2TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca2Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca2Original))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca3TokenizadaOriginal = tokenizer.tokenize(sentenca3Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca3TokenizadaOriginal)\n",
        "embeddingSentenca3Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca3Original, tokenizer)\n",
        "print('\\nSentença 3 Original=\\'', sentenca3Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca3TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca3Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca3Original))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca4TokenizadaOriginal = tokenizer.tokenize(sentenca4Original)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_original,sentenca4TokenizadaOriginal)\n",
        "embeddingSentenca4Original = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, sentenca4Original, tokenizer)\n",
        "print('\\nSentença 4 Original=\\'', sentenca4Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca4TokenizadaOriginal)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca4Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca4Original))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original: ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "\n",
            "Sentença 1 Original=' Bom Dia, professor. '\n",
            "    Sentença tokenizada: ['Bom', 'Dia', ',', 'professor', '.']\n",
            "    => inicio em 1 e término em 5\n",
            "    Formato modelo : torch.Size([5, 1024])\n",
            "    Soma embeddings:  -141.45\n",
            "\n",
            "Sentença 2 Original=' Qual o conteúdo da prova? '\n",
            "    Sentença tokenizada: ['Qual', 'o', 'conteúdo', 'da', 'prova', '?']\n",
            "    => inicio em 6 e término em 11\n",
            "    Formato modelo : torch.Size([6, 1024])\n",
            "    Soma embeddings:  -173.58\n",
            "\n",
            "Sentença 3 Original=' Vai cair tudo na prova? '\n",
            "    Sentença tokenizada: ['Vai', 'cair', 'tudo', 'na', 'prova', '?']\n",
            "    => inicio em 12 e término em 17\n",
            "    Formato modelo : torch.Size([6, 1024])\n",
            "    Soma embeddings:  -167.58\n",
            "\n",
            "Sentença 4 Original=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    => inicio em 18 e término em 24\n",
            "    Formato modelo : torch.Size([7, 1024])\n",
            "    Soma embeddings:  -200.72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyIawL-gl9kB"
      },
      "source": [
        "### Texto Permutado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m30dkANxl9kB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a83e66-9148-4287-819b-cc7939a3c783"
      },
      "source": [
        "# Define um texto com a permutação das sentenças do texto original\n",
        "texto_permutado = [texto_original[3],   # 'Aguardo uma resposta, João.',\n",
        "             texto_original[1],             # 'Qual o conteúdo da prova?',              \n",
        "             texto_original[0],             # 'Vai cair tudo na prova?',\n",
        "             texto_original[2]]             # 'Bom Dia, professor.']     \n",
        "\n",
        "# Use o texto permutado igual ao original para testar se as medidas estão corretas\n",
        "#texto_permutado = texto_original\n",
        "\n",
        "# Concatena as sentenças do texto em uma string\n",
        "textoPermutadoConcatenado = ' '.join(texto_permutado)\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado_permutado = '[CLS] ' + textoPermutadoConcatenado + ' [SEP]'\n",
        "\n",
        "# Divide a sentença em tokens\n",
        "texto_tokenizado_permutado = tokenizer.tokenize(texto_marcado_permutado)\n",
        "\n",
        "# Mapeia os tokens em seus índices do vocabulário\n",
        "texto_tokens_indexados_permutado = tokenizer.convert_tokens_to_ids(texto_tokenizado_permutado)\n",
        "\n",
        "# Mostra os tokens com seus índices\n",
        "i = 0\n",
        "for tup in zip(texto_tokenizado_permutado, texto_tokens_indexados_permutado):\n",
        "    print('{:>3} {:<12} {:>6,}'.format(i, tup[0], tup[1]))\n",
        "    i = i + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0 [CLS]           101\n",
            "  1 Agu           8,125\n",
            "  2 ##ardo        2,222\n",
            "  3 uma             230\n",
            "  4 resposta      4,299\n",
            "  5 ,               117\n",
            "  6 João          1,453\n",
            "  7 .               119\n",
            "  8 Qual         13,082\n",
            "  9 o               146\n",
            " 10 conteúdo      5,015\n",
            " 11 da              180\n",
            " 12 prova         2,310\n",
            " 13 ?               136\n",
            " 14 Bom           8,399\n",
            " 15 Dia           3,616\n",
            " 16 ,               117\n",
            " 17 professor     2,917\n",
            " 18 .               119\n",
            " 19 Vai          20,805\n",
            " 20 cair          9,322\n",
            " 21 tudo          2,745\n",
            " 22 na              229\n",
            " 23 prova         2,310\n",
            " 24 ?               136\n",
            " 25 [SEP]           102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Muz4w-9ol9kC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1180003c-219e-4b00-ecf5-9daf059b2a8a"
      },
      "source": [
        "# Marca cada um dos tokens como pertencentes à sentença '1'.\n",
        "mascara_atencao_permutado = [1] * len(texto_tokenizado_permutado)\n",
        "\n",
        "print (mascara_atencao_permutado)\n",
        "print (len(mascara_atencao_permutado))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laIJK9b3l9kC"
      },
      "source": [
        "Convertendo as listas em tensores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu5tQwZMl9kC"
      },
      "source": [
        "# Importa a biblioteca\n",
        "import torch\n",
        "\n",
        "# Converte as entradas de listas para tensores do torch\n",
        "tokens_tensores_permutado = torch.as_tensor([texto_tokens_indexados_permutado])\n",
        "mascara_atencao_tensores_permutado = torch.as_tensor([mascara_atencao_permutado])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14LzqtKbl9kC"
      },
      "source": [
        "Gera os embeddings para o texto original. Guarda somente a última camada da rede em `outputs`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhLV2Leel9kC"
      },
      "source": [
        "# Prediz os atributos dos estados ocultos para cada camada\n",
        "with torch.no_grad():\n",
        "    # output[0] contém last_hidden_states\n",
        "    outputs = model(tokens_tensores_permutado, mascara_atencao_tensores_permutado)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwA1d4C6l9kC"
      },
      "source": [
        "Recupera a saída da última camada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjWjud21l9kD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62c63002-aff2-4f67-e042-bedf2a4c09a3"
      },
      "source": [
        "# Recupera a última e única camada da saída\n",
        "last_hidden_states = outputs[0]\n",
        "\n",
        "print ('O vetor da última camada oculta tem o formato:', last_hidden_states.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O vetor da última camada oculta tem o formato: torch.Size([1, 26, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiiNFe8ul9kD"
      },
      "source": [
        "Vamos nos livrar da dimensão lotes 'batches', pois não precisamos dela."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GeLFhGJl9kD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb126b2-70b0-4b5a-835b-ea3781c63b45"
      },
      "source": [
        "# Remove a dimensão 1, o lote 'batches'.\n",
        "#O método squeeze remove a primeira dimensão(0) pois possui tamanho 1\n",
        "embeddingTextoPermutado = torch.squeeze(last_hidden_states, dim=0)\n",
        "\n",
        "print ('O vetor de tokens de embedding do texto permutado tem o formato:', embeddingTextoPermutado.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O vetor de tokens de embedding do texto permutado tem o formato: torch.Size([26, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0d5gJKEl9kD"
      },
      "source": [
        "Exibe os embenddings das sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfdswxTHl9kD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d12e00c7-5f57-4dd8-b576-78b5970d2b5b"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Permutado = texto_permutado[0]\n",
        "sentenca2Permutado = texto_permutado[1]\n",
        "sentenca3Permutado = texto_permutado[2]\n",
        "sentenca4Permutado = texto_permutado[3]\n",
        "\n",
        "embeddingSentenca1Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca1Permutado, tokenizer)\n",
        "embeddingSentenca2Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca2Permutado, tokenizer)\n",
        "embeddingSentenca3Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca3Permutado, tokenizer)\n",
        "embeddingSentenca4Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca4Permutado, tokenizer)\n",
        "\n",
        "print('Os primeiros 4 valores de cada sentença do texto permutado.')\n",
        "\n",
        "print('\\nSentença 1:', sentenca1Permutado,'-', str(embeddingSentenca1Permutado[:4]))\n",
        "print('Soma embedding Sentença1:', sentenca1Original,'-', str(torch.sum(embeddingSentenca1Original[:4])))\n",
        "\n",
        "print('\\nSentença 2:', sentenca2Permutado,'-', str(embeddingSentenca2Permutado[:4]))\n",
        "print('Soma embedding Sentença2:', sentenca2Permutado,'-', str(torch.sum(embeddingSentenca2Permutado[:4])))\n",
        "\n",
        "print('\\nSentença 3:', sentenca3Permutado,'-', str(embeddingSentenca3Permutado[:4]))\n",
        "print('Soma embedding Sentença3:', sentenca3Permutado,'-', str(torch.sum(embeddingSentenca3Original[:4])))\n",
        "\n",
        "print('\\nSentença 4:', sentenca4Permutado,'-', str(embeddingSentenca4Permutado[:4]))\n",
        "print('Soma embedding Sentença4:', sentenca4Permutado,'-', str(torch.sum(embeddingSentenca4Permutado[:4])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Os primeiros 4 valores de cada sentença do texto permutado.\n",
            "\n",
            "Sentença 1: Aguardo uma resposta, João. - tensor([[ 0.4152, -0.7838, -0.0364,  ...,  0.2686, -1.3504,  0.4707],\n",
            "        [-0.6012, -1.1043, -0.2660,  ..., -0.1943, -0.8112,  0.2180],\n",
            "        [ 1.2319, -1.1194,  0.9353,  ...,  0.2953, -0.1973,  0.5069],\n",
            "        [ 0.8861, -0.9666,  0.1831,  ...,  0.4595, -1.1045,  0.5615]])\n",
            "Soma embedding Sentença1: Bom Dia, professor. - tensor(-113.4554)\n",
            "\n",
            "Sentença 2: Qual o conteúdo da prova? - tensor([[-0.2957, -1.0942, -0.0024,  ...,  0.5875, -0.7164,  0.0104],\n",
            "        [ 0.2193, -0.4914,  0.7233,  ...,  0.3551, -0.3698,  0.8577],\n",
            "        [ 0.1377,  0.3856,  0.6060,  ...,  1.2662,  0.4965,  0.5211],\n",
            "        [ 0.5271, -0.4796,  0.4135,  ..., -0.5303, -0.3934,  0.1571]])\n",
            "Soma embedding Sentença2: Qual o conteúdo da prova? - tensor(-115.7949)\n",
            "\n",
            "Sentença 3: Bom Dia, professor. - tensor([[-0.2387, -0.2844,  0.3606,  ...,  0.6976, -0.9028,  0.3216],\n",
            "        [ 0.8188, -0.5643,  0.6965,  ..., -0.1439, -0.7018, -0.1933],\n",
            "        [ 0.9349, -1.0496,  0.1645,  ...,  0.4782, -0.3837, -0.2850],\n",
            "        [ 0.0104, -0.4793,  0.0501,  ...,  0.7341, -0.3687,  0.4562]])\n",
            "Soma embedding Sentença3: Bom Dia, professor. - tensor(-110.5299)\n",
            "\n",
            "Sentença 4: Vai cair tudo na prova? - tensor([[ 7.8763e-01, -1.1689e-01,  7.6317e-01,  ..., -4.3840e-01,\n",
            "         -6.5442e-01, -6.2305e-02],\n",
            "        [ 2.1062e-01,  1.0353e+00,  2.5937e-02,  ...,  7.1820e-02,\n",
            "          1.2368e-01,  1.1584e-03],\n",
            "        [ 7.5943e-01,  7.9969e-01,  2.4871e-01,  ...,  1.8792e-01,\n",
            "          9.4661e-02, -9.1651e-02],\n",
            "        [ 6.7000e-01,  1.3208e+00, -5.6431e-01,  ..., -6.3588e-03,\n",
            "          1.6016e-01, -1.4379e-01]])\n",
            "Soma embedding Sentença4: Vai cair tudo na prova? - tensor(-110.7603)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufyOj-3Ql9kD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a31ae41-77e3-4d8d-fa0d-486efe83d33e"
      },
      "source": [
        "# Índice das sentenças a serem comparadas\n",
        "sentenca1Permutado = texto_permutado[0]\n",
        "sentenca2Permutado = texto_permutado[1]\n",
        "sentenca3Permutado = texto_permutado[2]\n",
        "sentenca4Permutado = texto_permutado[3]\n",
        "\n",
        "print('Texto Permutado:', texto_permutado)\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca1TokenizadaPermutado = tokenizer.tokenize(sentenca1Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca1TokenizadaPermutado)\n",
        "embeddingSentenca1Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca1Permutado, tokenizer)\n",
        "print('\\nSentença 1 Permutada=\\'', sentenca1Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca1TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca1Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca1Permutado))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca2TokenizadaPermutado = tokenizer.tokenize(sentenca2Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca2TokenizadaPermutado)\n",
        "embeddingSentenca2Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca2Permutado, tokenizer)\n",
        "print('\\nSentença 2 Permutada=\\'', sentenca2Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca2TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca2Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca2Permutado))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca3TokenizadaPermutado = tokenizer.tokenize(sentenca3Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca3TokenizadaPermutado)\n",
        "embeddingSentenca3Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca3Permutado, tokenizer)\n",
        "print('\\nSentença 3 Permutada=\\'', sentenca3Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca3TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca3Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca3Permutado))\n",
        "\n",
        "# Localiza os índices dos tokens da sentença no texto\n",
        "sentenca4TokenizadaPermutado = tokenizer.tokenize(sentenca4Permutado)\n",
        "inicio, fim = encontrarIndiceSubLista(texto_tokenizado_permutado,sentenca4TokenizadaPermutado)\n",
        "embeddingSentenca4Permutado = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, sentenca4Permutado, tokenizer)\n",
        "print('\\nSentença 4 Permutada=\\'', sentenca4Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca4TokenizadaPermutado)\n",
        "print('    => inicio em', inicio , 'e término em', fim)\n",
        "print('    Formato modelo :', embeddingSentenca4Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca4Permutado))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado: ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "\n",
            "Sentença 1 Permutada=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    => inicio em 1 e término em 7\n",
            "    Formato modelo : torch.Size([7, 1024])\n",
            "    Soma embeddings:  -199.90\n",
            "\n",
            "Sentença 2 Permutada=' Qual o conteúdo da prova? '\n",
            "    Sentença tokenizada: ['Qual', 'o', 'conteúdo', 'da', 'prova', '?']\n",
            "    => inicio em 8 e término em 13\n",
            "    Formato modelo : torch.Size([6, 1024])\n",
            "    Soma embeddings:  -173.06\n",
            "\n",
            "Sentença 3 Permutada=' Bom Dia, professor. '\n",
            "    Sentença tokenizada: ['Bom', 'Dia', ',', 'professor', '.']\n",
            "    => inicio em 14 e término em 18\n",
            "    Formato modelo : torch.Size([5, 1024])\n",
            "    Soma embeddings:  -141.81\n",
            "\n",
            "Sentença 4 Permutada=' Vai cair tudo na prova? '\n",
            "    Sentença tokenizada: ['Vai', 'cair', 'tudo', 'na', 'prova', '?']\n",
            "    => inicio em 19 e término em 24\n",
            "    Formato modelo : torch.Size([6, 1024])\n",
            "    Soma embeddings:  -167.47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dceUXyTOl9kE"
      },
      "source": [
        "### Examinando as sentenças\n",
        "\n",
        "A mesma sentença apresenta embeddings com valores diferentes, pois se encontram em locais diferentes do texto. A soma de todos os embeddings demonstra isto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL9sCL3vl9kE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6815df65-6c29-4bca-f596-852aef8bb1d2"
      },
      "source": [
        "print('\\nSentença 4 Original=\\'', sentenca4Original, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca4TokenizadaOriginal)\n",
        "print('    Formato modelo :', embeddingSentenca4Original.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca4Original))\n",
        "print('    Os 4 primeiros embeddings:', str(embeddingSentenca4Original[:4]))\n",
        "\n",
        "print('\\nSentença 1 Permutada=\\'', sentenca1Permutado, '\\'')\n",
        "print('    Sentença tokenizada:', sentenca1TokenizadaPermutado)\n",
        "print('    Formato modelo :', embeddingSentenca1Permutado.shape)\n",
        "print('    Soma embeddings:  %.2f' % torch.sum(embeddingSentenca1Permutado))\n",
        "print('    Os 4 primeiros embeddings:', str(embeddingSentenca1Permutado[:4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Sentença 4 Original=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    Formato modelo : torch.Size([7, 1024])\n",
            "    Soma embeddings:  -200.72\n",
            "    Os 4 primeiros embeddings: tensor([[ 0.4339, -0.7168,  0.1173,  ...,  0.0768, -1.2036,  0.3863],\n",
            "        [-0.6806, -1.0194, -0.0765,  ..., -0.1768, -0.6326,  0.2895],\n",
            "        [ 1.1384, -0.8541,  0.8992,  ...,  0.2798, -0.0381,  0.5061],\n",
            "        [ 0.9206, -0.9862,  0.1347,  ...,  0.4182, -1.0164,  0.4713]])\n",
            "\n",
            "Sentença 1 Permutada=' Aguardo uma resposta, João. '\n",
            "    Sentença tokenizada: ['Agu', '##ardo', 'uma', 'resposta', ',', 'João', '.']\n",
            "    Formato modelo : torch.Size([7, 1024])\n",
            "    Soma embeddings:  -199.90\n",
            "    Os 4 primeiros embeddings: tensor([[ 0.4152, -0.7838, -0.0364,  ...,  0.2686, -1.3504,  0.4707],\n",
            "        [-0.6012, -1.1043, -0.2660,  ..., -0.1943, -0.8112,  0.2180],\n",
            "        [ 1.2319, -1.1194,  0.9353,  ...,  0.2953, -0.1973,  0.5069],\n",
            "        [ 0.8861, -0.9666,  0.1831,  ...,  0.4595, -1.1045,  0.5615]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jESgdoQ8l9kM"
      },
      "source": [
        "### Similaridade de cosseno entre os embeddings das sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cf1Y9arl9kM"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "def similaridadeCoseno(sentenca1, sentenca2):\n",
        "  similaridade = 1 - cosine(sentenca1, sentenca2)\n",
        "  return similaridade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NVHFoysl9kM"
      },
      "source": [
        "#### Calcula a média aritmética da similaridade do coseno entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto original. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbUGxtIHl9kM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "398bfba3-d83b-459a-cd0a-dc919aac9d37"
      },
      "source": [
        "print('Texto Original  :', str(texto_original))\n",
        "print('Quantidade de sentenças:',len(texto_original))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "n = len(texto_original)\n",
        "\n",
        "somaScos = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(n-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_original[i]\n",
        "    Sj = texto_original[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto original    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Si, tokenizer, filtro='NOUN')\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Sj, tokenizer, filtro='NOUN')\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "    # Similaridade entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Scos = similaridadeCoseno(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaScos = somaScos + Scos\n",
        "\n",
        "CcosOriginal = float(somaScos)/float(n-1)\n",
        "print('Ccos Original:', CcosOriginal)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original  : ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "Quantidade de sentenças: 4\n",
            "Ccos Original: 0.6610651214917501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh3HGUMIl9kM"
      },
      "source": [
        "#### Calcula a média aritmética da similaridade do coseno entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto permutado. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ7qnwBRl9kM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca8168f1-595f-40c4-ba0b-fa0feac15d5e"
      },
      "source": [
        "print('Texto Permutado :', str(texto_permutado))\n",
        "print('Quantidade de sentenças:', len(texto_permutado))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "np = len(texto_permutado)\n",
        "\n",
        "somaScos = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(np-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_permutado[i]\n",
        "    Sj = texto_permutado[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto permutado    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Si, tokenizer, filtro='NOUN')\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Sj, tokenizer, filtro='NOUN')\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "   # Similaridade entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Scos = similaridadeCoseno(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaScos = somaScos + Scos\n",
        "\n",
        "CcosPermutado = float(somaScos)/float(np-1)\n",
        "print('Ccos Original:', CcosPermutado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado : ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "Quantidade de sentenças: 4\n",
            "Ccos Original: 0.5510792930920919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYHLZrgIl9kN"
      },
      "source": [
        "#### Compara as médias da similaridade de cosseno dos embeddings das sentenças do texto original e permutado\n",
        "\n",
        "Características das medidas:\n",
        "- Textos com sentenças iguais resulta uma medida igual a 1.\n",
        "- Textos com sentenças diferenntes resulta uma medida menor que 1.\n",
        "- Texto com sentenças muito diferentes apresentam valores menores que 1.\n",
        "- Textos iguais resultam em medidas iguais. \n",
        "- É uma medida de similaridade.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeIb45RQl9kN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96a4d252-2104-4379-ff3a-0950670853f8"
      },
      "source": [
        "print('Ccos Original :', CcosOriginal)\n",
        "print('Ccos Permutado:', CcosPermutado)\n",
        "\n",
        "if (CcosOriginal > CcosPermutado):\n",
        "    print('Texto original tem maior similaridade de cosseno entre as sentenças!')\n",
        "else:\n",
        "    print('Texto Permutado tem menor similaridade de cosseno entre as sentenças!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ccos Original : 0.6610651214917501\n",
            "Ccos Permutado: 0.5510792930920919\n",
            "Texto original tem maior similaridade de cosseno entre as sentenças!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RdcWF9Tl9kN"
      },
      "source": [
        "### Distância euclidiana entre os embeddings das sentenças\n",
        "\n",
        "Possui outros nomes como distância L2 ou norma L2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL4gMjoll9kN"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "def distanciaEuclidiana(sentenca1, sentenca2):\n",
        "  distancia = euclidean(sentenca1, sentenca2)\n",
        "\n",
        "  return distancia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHA388-ql9kN"
      },
      "source": [
        "#### Calcula a média aritmética da distância euclidiana entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto original. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr5jWF8Il9kN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ea6230-e8bb-4735-c3a7-5a371ba7e81c"
      },
      "source": [
        "print('Texto Original  :', str(texto_original))\n",
        "print('Quantidade de sentenças:',len(texto_original))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "n = len(texto_original)\n",
        "\n",
        "somaSeuc = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(n-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_original[i]\n",
        "    Sj = texto_original[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto original    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Si, tokenizer, filtro='NOUN')        \n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Sj, tokenizer, filtro='NOUN')\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    # print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "    # Diferença entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Seuc = distanciaEuclidiana(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSeuc = somaSeuc + Seuc\n",
        "\n",
        "CeucOriginal = float(somaSeuc)/float(n-1)\n",
        "print('Ceuc Original:', CeucOriginal)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original  : ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "Quantidade de sentenças: 4\n",
            "Ceuc Original: 17.28178342183431\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpu9QRx4l9kO"
      },
      "source": [
        "#### Calcula a média aritmética da distância euclidiana entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto permutado. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhLznobil9kO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9743084c-c167-4287-9c86-43a078cb10bd"
      },
      "source": [
        "print('Texto Permutado :', str(texto_permutado))\n",
        "print('Quantidade de sentenças:', len(texto_permutado))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "np = len(texto_permutado)\n",
        "\n",
        "somaSeuc = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(np-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_permutado[i]\n",
        "    Sj = texto_permutado[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto permutado    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Si, tokenizer, filtro='NOUN')\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Sj, tokenizer, filtro='NOUN')\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "    # Diferença entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Seuc = distanciaEuclidiana(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSeuc = somaSeuc + Seuc\n",
        "\n",
        "CeucPermutado = float(somaSeuc)/float(np-1)\n",
        "print('Ceuc Original:', CeucPermutado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado : ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "Quantidade de sentenças: 4\n",
            "Ceuc Original: 20.06486447652181\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2G6XKN-l9kO"
      },
      "source": [
        "#### Compara as médias da distância euclidiana dos embeddings das sentenças do texto original e permutado\n",
        "\n",
        "Características das medidas:\n",
        "- Textos com sentenças iguais resulta uma medida igual a 0.\n",
        "- Textos com sentenças diferenntes resulta uma medida maior que 0.\n",
        "- Texto com sentenças muito diferentes apresentam valores maiores que 0.\n",
        "- Textos iguais resultam em medidas iguais. \n",
        "- É uma medida de diferença.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4UFxZsVl9kO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a2547a1-1803-4303-8b3c-e5adc061becc"
      },
      "source": [
        "print('Ceuc Original :', CeucOriginal)\n",
        "print('Ceuc Permutado:', CeucPermutado)\n",
        "\n",
        "if (CeucOriginal < CeucPermutado):\n",
        "    print('Texto original tem menor distância euclidiana entre as sentenças!')\n",
        "else:\n",
        "    print('Texto Permutado tem maior distância euclidiana entre as sentenças!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ceuc Original : 17.28178342183431\n",
            "Ceuc Permutado: 20.06486447652181\n",
            "Texto original tem menor distância euclidiana entre as sentenças!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxAIaJell9kO"
      },
      "source": [
        "### Distância Manhattan entre os embeddings das sentenças\n",
        "\n",
        "Possui outros nomes como distância Cityblock, distância L1, norma L1 e métrica do táxi.\n",
        "\n",
        "Igual subtração absoluta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtUNIARWl9kO"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "from scipy.spatial.distance import cityblock\n",
        "\n",
        "def distanciaManhattan(sentenca1, sentenca2):\n",
        "  distancia = cityblock(sentenca1, sentenca2)\n",
        "\n",
        "  return distancia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKdd7j1wl9kO"
      },
      "source": [
        "#### Calcula a média aritmética da distância de manhattan entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto original. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUjQCxv-l9kP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcbfb124-72e6-4817-bef1-343d3eac69fa"
      },
      "source": [
        "print('Texto Original  :', str(texto_original))\n",
        "print('Quantidade de sentenças:',len(texto_original))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "n = len(texto_original)\n",
        "\n",
        "somaSman = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(n-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_original[i]\n",
        "    Sj = texto_original[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto original    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Si, tokenizer, filtro='NOUN')        \n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Sj, tokenizer, filtro='NOUN')\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    # print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "    # Diferença entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Sman = distanciaManhattan(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSman = somaSman + Sman\n",
        "\n",
        "CmanOriginal = float(somaSman)/float(n-1)\n",
        "print('Cman Original:', CmanOriginal)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Original  : ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "Quantidade de sentenças: 4\n",
            "Cman Original: 425.31744384765625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jz_oV3yl9kP"
      },
      "source": [
        "#### Calcula a média aritmética da distância de manhattan entre os embeddings das sentenças utilizando a média aritmética dos tokens do texto permutado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oUizCe-l9kP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26bd8e0f-cd2e-41b5-d816-1d9050406f7c"
      },
      "source": [
        "print('Texto Permutado :', str(texto_permutado))\n",
        "print('Quantidade de sentenças:', len(texto_permutado))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "np = len(texto_permutado)\n",
        "\n",
        "somaSman = 0\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(np-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_permutado[i]\n",
        "    Sj = texto_permutado[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto permutado    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Si, tokenizer, filtro='NOUN')\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Sj, tokenizer, filtro='NOUN')\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "    # Diferença entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Sman = distanciaManhattan(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaSman = somaSman + Sman\n",
        "\n",
        "CmanPermutado = float(somaSman)/float(np-1)\n",
        "print('Ceuc Original:', CmanPermutado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto Permutado : ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "Quantidade de sentenças: 4\n",
            "Ceuc Original: 490.9454752604167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3WYl6del9kP"
      },
      "source": [
        "#### Compara as médias da distância de manhattan dos embeddings das sentenças do texto original e permutado\n",
        "\n",
        "Características das medidas:\n",
        "- Textos com sentenças iguais resulta uma medida igual a 0.\n",
        "- Textos com sentenças diferenntes resulta uma medida maior que 0.\n",
        "- Texto com sentenças muito diferentes apresentam valores maiores que 0.\n",
        "- Textos iguais resultam em medidas iguais. \n",
        "- É uma medida de diferença.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq5uNunkl9kP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91154fd1-6e04-449d-aae9-075a34b5ea35"
      },
      "source": [
        "print('Cman Original :', CmanOriginal)\n",
        "print('Cman Permutado:', CmanPermutado)\n",
        "\n",
        "if (CmanOriginal < CmanPermutado):\n",
        "    print('Texto original tem menor distância de manhattan entre as sentenças!')\n",
        "else:\n",
        "    print('Texto Permutado tem maior distância de manhattan entre as sentenças!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cman Original : 425.31744384765625\n",
            "Cman Permutado: 490.9454752604167\n",
            "Texto original tem menor distância de manhattan entre as sentenças!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGqyDJIZl9kP"
      },
      "source": [
        "### Resumo\n",
        "\n",
        "Resultado das medidas utilizando a última camada do BERT.\n",
        "\n",
        "Base(MEAN):\n",
        "- Ccos       :   0.67999101          0.69653825\n",
        "- Ceuc       :   6.34085274          6.15486606\n",
        "- Cman       :   136.53579712          132.14489237\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEoyUyoUl9kQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c097a60-e629-49b8-d0a9-4e628a782a3c"
      },
      "source": [
        "print('Resultado das medidas utilizando a última camada do BERT')\n",
        "print('Texto  :   Original            Permutado')\n",
        "print('Ccos       :   {:.8f}          {:.8f}'.format(CcosOriginal,CcosPermutado))\n",
        "print('Ceuc       :   {:.8f}          {:.8f}'.format(CeucOriginal,CeucPermutado))\n",
        "print('Cman       :   {:.8f}          {:.8f}'.format(CmanOriginal,CmanPermutado))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resultado das medidas utilizando a última camada do BERT\n",
            "Texto  :   Original            Permutado\n",
            "Ccos       :   0.66106512          0.55107929\n",
            "Ceuc       :   17.28178342          20.06486448\n",
            "Cman       :   425.31744385          490.94547526\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKVnNNkQ1Fk4"
      },
      "source": [
        "## Comparando textos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVw9sDeX5Gdd"
      },
      "source": [
        "### Função para retornar a medida de coerência entre sentenças de um texto usando similaridade do coseno."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbA0L_PE1SS0"
      },
      "source": [
        "def getMedidaCoerenciaCosseno(texto, concat4=True, filtro='ALL'):\n",
        "\n",
        "  # Concatena as sentenças do texto em uma string\n",
        "  stringTexto = ' '.join(texto)\n",
        "\n",
        "  # Adiciona os tokens especiais\n",
        "  texto_marcado = '[CLS] ' + stringTexto + ' [SEP]'\n",
        "\n",
        "  # Divide a sentença em tokens\n",
        "  texto_tokenizado = tokenizer.tokenize(texto_marcado)\n",
        "\n",
        "  # Mapeia os tokens em seus índices do vocabulário\n",
        "  texto_tokens_indexados = tokenizer.convert_tokens_to_ids(texto_tokenizado)\n",
        "\n",
        "  # Marca cada um dos tokens como pertencentes à sentença '1'.\n",
        "  mascara_atencao = [1] * len(texto_tokenizado)\n",
        "\n",
        "  # Importa a bibliteca\n",
        "  import torch\n",
        "\n",
        "  # Converte as entradas de listas para tensores do torch\n",
        "  tokens_tensores = torch.as_tensor([texto_tokens_indexados])\n",
        "  mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n",
        "\n",
        "  # Prediz os atributos dos estados ocultos para cada camada\n",
        "  with torch.no_grad():\n",
        "    # output[0] contém last_hidden_states\n",
        "    outputs = model(tokens_tensores, mascara_atencao_tensores)\n",
        "\n",
        "  if concat4 == True:\n",
        "    # Cria uma lista com os tensores a serem concatenados\n",
        "    # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "    # Lista com os tensores a serem concatenados\n",
        "    listaConcat = []\n",
        "    # Percorre os 4 últimos\n",
        "    for i in [-1,-2,-3,-4]:\n",
        "        # Concatena da lista\n",
        "        listaConcat.append(outputs[2][i])\n",
        "        # Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "        #print('listaConcat=',len(listaConcat))\n",
        "\n",
        "    # Realiza a concatenação dos embeddings de todos as camadas\n",
        "    # Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "    concat4_hidden_states = torch.cat(listaConcat, dim=-1)\n",
        "    # Saída: Entrada: (<1(lote)> x <qtde_tokens> <3072 ou 4096>)\n",
        "\n",
        "    # Verifica se a primeira dimensão é igual 1 para remover a dimensão de lote 'batches'\n",
        "    if concat4_hidden_states.shape[0] == 1:\n",
        "        # Usa o método 'squeeze' para remover a primeira dimensão(0) pois possui tamanho 1\n",
        "        embeddingTexto = torch.squeeze(concat4_hidden_states, dim=0)   \n",
        "\n",
        "  else:\n",
        "    # Recupera a última e única camada da saída\n",
        "    last_hidden_states = outputs[0]\n",
        "\n",
        "    # Verifica se a primeira dimensão é igual 1 para remover a dimensão de lote 'batches'\n",
        "    if last_hidden_states.shape[0] == 1:\n",
        "        # Usa o método 'squeeze' para remover a primeira dimensão(0) pois possui tamanho 1\n",
        "        embeddingTexto = torch.squeeze(last_hidden_states, dim=0)   \n",
        "\n",
        "  # Quantidade de sentenças no texto\n",
        "  n = len(texto)\n",
        "\n",
        "  somaScos = 0\n",
        "\n",
        "  # Percorre as sentenças do texto\n",
        "  for i in range(n-1):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto[i]\n",
        "    Sj = texto[i+1]\n",
        "\n",
        "    # Recupera os embeddings das sentenças no embeddings do texto original    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTexto, stringTexto, Si, tokenizer, filtro=filtro)\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)\n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Sj (Sentença j), tokenizador\n",
        "    embeddingSj = getEmbeddingSentencaEmbeddingTexto(embeddingTexto, stringTexto, Sj, tokenizer, filtro=filtro)\n",
        "    # Saída: <qtde_tokens_Sj> x <768 ou 1024>\n",
        "    #print('embeddingSj=', embeddingSj.shape)\n",
        "\n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Sj, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSj = torch.mean(embeddingSj, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSj=', mediaEmbeddingSj.shape)\n",
        "  \n",
        "    # Similaridade entre os embeddings Si e Sj\n",
        "    # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n",
        "    Scos = similaridadeCoseno(mediaEmbeddingSi, mediaEmbeddingSj)\n",
        "    # Saída: Um número real\n",
        "    \n",
        "    # Acumula a medida\n",
        "    somaScos = somaScos + Scos\n",
        "\n",
        "  CcosOriginal = float(somaScos)/float(n-1)\n",
        "  return CcosOriginal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCZF2v_H811O"
      },
      "source": [
        "### Exemplo 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp0FIK1V5LV2"
      },
      "source": [
        "### Comparando dois textos distintos usando a medida de similaridade do cosseno de sentenças considerando todas(ALL) as palavras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_sJroEK1Me9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "199d4e92-065f-48a1-a0bc-adc794f8bb0c"
      },
      "source": [
        "# Define um texto\n",
        "texto_1 = ['Fui de carro.',\n",
        "             'O caminhão tombou.',              \n",
        "             'O ônibus atrasou.']\n",
        "\n",
        "# Define um texto com a permutação das sentenças do texto original\n",
        "texto_2 = ['O gato saiu correndo',   \n",
        "             'O cachorro latiu',             \n",
        "             'O passáro está no ninho.']             \n",
        "\n",
        "Ccos1 =  getMedidaCoerenciaCosseno(texto_1)\n",
        "Ccos2 =  getMedidaCoerenciaCosseno(texto_2)\n",
        "print('Ccos1:', Ccos1)\n",
        "print('Ccos2:', Ccos2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ccos1: 0.8908642530441284\n",
            "Ccos2: 0.856334924697876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl4LrTEHcTk0"
      },
      "source": [
        "### Comparando dois textos distintos usando a medida de similaridade do cosseno de sentenças e palavras relevantes (CLEAN - stopwords)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L98YJPQtcTk2",
        "outputId": "957bc612-cedb-4c9c-8734-6b3d1860b644"
      },
      "source": [
        "# Define um texto\n",
        "texto_1 = ['Fui de carro.',\n",
        "             'O caminhão tombou.',              \n",
        "             'O ônibus atrasou.']\n",
        "\n",
        "# Define um texto com a permutação das sentenças do texto original\n",
        "texto_2 = ['O gato saiu correndo',   \n",
        "             'O cachorro latiu',             \n",
        "             'O passáro está no ninho.']             \n",
        "\n",
        "Ccos1 =  getMedidaCoerenciaCosseno(texto_1, filtro='CLEAN')\n",
        "Ccos2 =  getMedidaCoerenciaCosseno(texto_2, filtro='CLEAN')\n",
        "print('Ccos1:', Ccos1)\n",
        "print('Ccos2:', Ccos2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ccos1: 0.8899393975734711\n",
            "Ccos2: 0.8405140340328217\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx1v76PJNQxz"
      },
      "source": [
        "### Comparando dois textos distintos usando a medida de similaridade do cosseno de sentenças considerando palavras relevantes(NOUN - substantivos)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJhdhwZMNQxz",
        "outputId": "5209af10-fe12-42aa-9940-032fb3f457e8"
      },
      "source": [
        "# Define um texto\n",
        "texto_1 = ['Fui de carro.',\n",
        "             'O caminhão tombou.',              \n",
        "             'O ônibus atrasou.']\n",
        "\n",
        "# Define um texto com a permutação das sentenças do texto original\n",
        "texto_2 = ['O gato saiu correndo',   \n",
        "             'O cachorro latiu',             \n",
        "             'O passáro está no ninho.']             \n",
        "\n",
        "Ccos1 =  getMedidaCoerenciaCosseno(texto_1, filtro='NOUN')\n",
        "Ccos2 =  getMedidaCoerenciaCosseno(texto_2, filtro='NOUN')\n",
        "print('Ccos1:', Ccos1)\n",
        "print('Ccos2:', Ccos2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ccos1: 0.7394927144050598\n",
            "Ccos2: 0.6566731631755829\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9FVGMBU5aqK"
      },
      "source": [
        "### Comparando dois textos distintos usando a medida de similaridade do cosseno de sentenças considerando todas(ALL) as palavras relevantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lFQfJmS4uCC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f55f169-6b77-41d3-b652-e888c1d628bb"
      },
      "source": [
        "# Define um texto\n",
        "texto_1 = ['Fui de carro.',\n",
        "             'O caminhão tombou.',              \n",
        "             'O ônibus atrasou.']\n",
        "\n",
        "# Define um texto com a permutação das sentenças do texto original\n",
        "texto_2 = ['O gato saiu correndo',   \n",
        "             'O cachorro latiu',             \n",
        "             'O jogo de futebol atrasou.']                         \n",
        "\n",
        "Ccos1 =  getMedidaCoerenciaCosseno(texto_1)\n",
        "Ccos2 =  getMedidaCoerenciaCosseno(texto_2)\n",
        "print('Ccos1:', Ccos1)\n",
        "print('Ccos2:', Ccos2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ccos1: 0.8908642530441284\n",
            "Ccos2: 0.878132700920105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScpVYF5Kcwqa"
      },
      "source": [
        "### Comparando dois textos distintos usando a medida de similaridade do cosseno de sentenças e palavras relevante (CLEAN-stopwords)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm-g4y8xcwqb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3239c1a9-048c-48a1-8729-75acaeb7dc73"
      },
      "source": [
        "# Define um texto\n",
        "texto_1 = ['Fui de carro.',\n",
        "             'O caminhão tombou.',              \n",
        "             'O ônibus atrasou.']\n",
        "\n",
        "# Define um texto com a permutação das sentenças do texto original\n",
        "texto_2 = ['O gato saiu correndo',   \n",
        "             'O cachorro latiu',             \n",
        "             'O jogo de futebol atrasou.']                         \n",
        "\n",
        "Ccos1 =  getMedidaCoerenciaCosseno(texto_1, filtro='CLEAN')\n",
        "Ccos2 =  getMedidaCoerenciaCosseno(texto_2, filtro='CLEAN')\n",
        "print('Ccos1:', Ccos1)\n",
        "print('Ccos2:', Ccos2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ccos1: 0.8899393975734711\n",
            "Ccos2: 0.8758122622966766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ2kKBHx88SI"
      },
      "source": [
        "### Exemplo 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBKnx0xW6OoR"
      },
      "source": [
        "### Comparando dois textos com um contendo sentenças permutadas usando a medida de similaridade do cosseno de sentenças considerando todas(ALL) as palavras relevantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKooY6Gw5iUZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b785376-ab52-454e-8b64-35426150cb39"
      },
      "source": [
        "# Define um texto com 4 sentenças\n",
        "texto_1 = ['Bom Dia, professor.',\n",
        "             'Qual o conteúdo da prova?',              \n",
        "             'Vai cair tudo na prova?',\n",
        "             'Aguardo uma resposta, João.']\n",
        "\n",
        "# Define um texto com a permutação das sentenças do texto original\n",
        "texto_2 = [texto_1[3],       # 'Aguardo uma resposta, João.',\n",
        "             texto_1[1],     # 'Qual o conteúdo da prova?',              \n",
        "             texto_1[0],     # 'Bom Dia, professor.',\n",
        "             texto_1[2]]     # 'Vai cair tudo na prova?']     \n",
        "\n",
        "Ccos1 =  getMedidaCoerenciaCosseno(texto_1)\n",
        "Ccos2 =  getMedidaCoerenciaCosseno(texto_2)\n",
        "print('Ccos1:', Ccos1)\n",
        "print('Ccos2:', Ccos2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ccos1: 0.8178287744522095\n",
            "Ccos2: 0.7760166923205057\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4sUw9_gc8HM"
      },
      "source": [
        "### Comparando dois textos com um contendo sentenças permutadas usando a medida de similaridade do cosseno de sentenças e palavras relevantes(CLEAN-stopwords)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhXGBZU2c8HN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "599f0ab8-f894-454a-adb0-d261c1320a73"
      },
      "source": [
        "# Define um texto com 4 sentenças\n",
        "texto_1 = ['Bom Dia, professor.',\n",
        "             'Qual o conteúdo da prova?',              \n",
        "             'Vai cair tudo na prova?',\n",
        "             'Aguardo uma resposta, João.']\n",
        "\n",
        "# Define um texto com a permutação das sentenças do texto original\n",
        "texto_2 = [texto_1[3],     # 'Aguardo uma resposta, João.',\n",
        "           texto_1[1],     # 'Qual o conteúdo da prova?',              \n",
        "           texto_1[0],     # 'Bom Dia, professor.',\n",
        "           texto_1[2]]     # 'Vai cair tudo na prova?']     \n",
        "\n",
        "Ccos1 =  getMedidaCoerenciaCosseno(texto_1, filtro='CLEAN')\n",
        "Ccos2 =  getMedidaCoerenciaCosseno(texto_2, filtro='CLEAN')\n",
        "print('Ccos1:', Ccos1)\n",
        "print('Ccos2:', Ccos2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ccos1: 0.810097893079122\n",
            "Ccos2: 0.7615904013315836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRunnvUyM5wn"
      },
      "source": [
        "### Comparando dois textos com um contendo sentenças permutadas usando a medida de similaridade do cosseno de sentenças considerando as palavras relevantes(NOUN-substantivo)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHHszbUfM5wn",
        "outputId": "ef487a56-f949-4306-d465-6452cb93c121"
      },
      "source": [
        "# Define um texto com 4 sentenças\n",
        "texto_1 = ['Bom Dia, professor.',\n",
        "             'Qual o conteúdo da prova?',              \n",
        "             'Vai cair tudo na prova?',\n",
        "             'Aguardo uma resposta, João.']\n",
        "\n",
        "# Define um texto com a permutação das sentenças do texto original\n",
        "texto_2 = [texto_1[3],     # 'Aguardo uma resposta, João.',\n",
        "           texto_1[1],     # 'Qual o conteúdo da prova?',              \n",
        "           texto_1[0],     # 'Bom Dia, professor.',\n",
        "           texto_1[2]]     # 'Vai cair tudo na prova?']   \n",
        "\n",
        "Ccos1 =  getMedidaCoerenciaCosseno(texto_1, filtro='NOUN')\n",
        "Ccos2 =  getMedidaCoerenciaCosseno(texto_2, filtro='NOUN')\n",
        "print('Ccos1:', Ccos1)\n",
        "print('Ccos2:', Ccos2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ccos1: 0.6933325131734213\n",
            "Ccos2: 0.6103532314300537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyLmnlBWZ6c5"
      },
      "source": [
        "## Comparando graficamente os embeddings gerados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDhlpbAajCGO"
      },
      "source": [
        "import matplotlib\n",
        "\n",
        "TAMANHO_FONTE = 28\n",
        "matplotlib.rc('font', size=TAMANHO_FONTE)          # Controla o tamanho do do texto default\n",
        "matplotlib.rc('axes', titlesize=TAMANHO_FONTE)     # Tamanho da fonte do eixo do título\n",
        "matplotlib.rc('axes', labelsize=TAMANHO_FONTE)     # Tamanho da fonte dos rótulos do eixo x e y\n",
        "matplotlib.rc('xtick', labelsize=TAMANHO_FONTE)    # Tamanho da fonte das marcações do eixo y\n",
        "matplotlib.rc('ytick', labelsize=TAMANHO_FONTE)    # Tamanho da fonte dos marcações do eixo x\n",
        "matplotlib.rc('legend', fontsize=TAMANHO_FONTE-2)  # Tamanho da fonte da legenda\n",
        "matplotlib.rc('figure', titlesize=TAMANHO_FONTE + 4)   # Tamanho da fonte do título da figura"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHaf_DQceo3G"
      },
      "source": [
        "### Gerando embeddings das sentenças separadamente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOvAhXTjLXN_"
      },
      "source": [
        "#### Calculando a similaridade com a primeira sentença"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsecc4RhSKPH"
      },
      "source": [
        "# Import das biblioteca\n",
        "import pandas as pd\n",
        "\n",
        "# Define um texto com 4 sentenças\n",
        "texto_1 = ['Bom Dia, professor.',\n",
        "             'Qual o conteúdo da prova?',              \n",
        "             'Vai cair tudo na prova?',\n",
        "             'Aguardo uma resposta, João.']\n",
        "\n",
        "# Define um texto com a permutação das sentenças do texto original\n",
        "texto_2 = [texto_1[3],     # 'Aguardo uma resposta, João.',\n",
        "           texto_1[1],     # 'Qual o conteúdo da prova?',              \n",
        "           texto_1[0],     # 'Bom Dia, professor.',\n",
        "           texto_1[2]]     # 'Vai cair tudo na prova?']   \n",
        "\n",
        "# Converte o texto em um dataframe\n",
        "df1 = pd.DataFrame(texto_1, columns = ['sentenca'])\n",
        "\n",
        "df2 = pd.DataFrame(texto_2, columns = ['sentenca'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0N9Tf0ie4Vg"
      },
      "source": [
        "Gera os embeddings de cada sentença"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5fIzeEzUEOa"
      },
      "source": [
        "# Importa a biblioteca\n",
        "import torch\n",
        "\n",
        "# Calcula o embeddings das sentenças\n",
        "matrix_embedding1 = []\n",
        "\n",
        "for i,sentenca in enumerate(texto_1):\n",
        "    # Gera os embeddings da sentença utiliza a concatenação das 4 últimas camadas\n",
        "    embedding, tokens = getEmbeddingsConcat4UltimasCamadas(sentenca, model, tokenizer)    \n",
        "    # Calcula a média dos embeddings dos tokens da sentença\n",
        "    media_embedding = torch.mean(embedding, dim=0)    \n",
        "    # Converte em um array numpy\n",
        "    media = media_embedding.numpy()\n",
        "    # Adiciona na lista\n",
        "    matrix_embedding1.append(media)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsZ9OIyOe8HJ"
      },
      "source": [
        "Gera os embeddings de cada sentença"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB21PEwz7Ptg"
      },
      "source": [
        "# Importa a biblioteca\n",
        "import torch\n",
        "\n",
        "# Calcula o embeddings das sentenças\n",
        "matrix_embedding2 = []\n",
        "\n",
        "for i,sentenca in enumerate(texto_2):\n",
        "    # Gera os embeddings da sentença utiliza a concatenação das 4 últimas camadas\n",
        "    embedding, tokens = getEmbeddingsConcat4UltimasCamadas(sentenca, model, tokenizer)    \n",
        "    # Calcula a média dos embeddings dos tokens da sentença\n",
        "    media_embedding = torch.mean(embedding, dim=0)    \n",
        "    # Converte em um array numpy\n",
        "    media = media_embedding.numpy()\n",
        "    # Adiciona na lista\n",
        "    matrix_embedding2.append(media)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcQ5yITSfBsG"
      },
      "source": [
        "Calcula a similaridade do cosseno entre os embeddings das sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOitleB8LXYI",
        "outputId": "a5b32239-4a0d-4d8c-9c23-2cbb930b4edf"
      },
      "source": [
        "# Importa a biblioteca\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Coloca todos os embeddings de sentença em uma matriz\n",
        "embed_matrix1 = np.array([x for x in matrix_embedding1])\n",
        "embed_matrix2 = np.array([x for x in matrix_embedding2])\n",
        "\n",
        "# Calcula a similaridade do coseno entre as sentenças\n",
        "cos_matrix = cosine_similarity(embed_matrix1,embed_matrix2)\n",
        "\n",
        "# Coloca a similaridade para a primeira sentença\n",
        "df1['medida'] = cos_matrix[0]\n",
        "\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentenca</th>\n",
              "      <th>medida</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bom Dia, professor.</td>\n",
              "      <td>0.893253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Qual o conteúdo da prova?</td>\n",
              "      <td>0.802693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Vai cair tudo na prova?</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aguardo uma resposta, João.</td>\n",
              "      <td>0.804919</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      sentenca    medida\n",
              "0          Bom Dia, professor.  0.893253\n",
              "1    Qual o conteúdo da prova?  0.802693\n",
              "2      Vai cair tudo na prova?  1.000000\n",
              "3  Aguardo uma resposta, João.  0.804919"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLL7ukdPosEn"
      },
      "source": [
        "#### Mapa de calor calculado com a similaridade cosseno entre todas as sentenças gerados separadamente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "LxUCfzZFs9ls",
        "outputId": "d41e2d2e-816b-4d96-d79e-36e02f5a14f3"
      },
      "source": [
        "# Cria o dataframe da lista com as sentenças como nome das colunas\n",
        "df1 = pd.DataFrame(cos_matrix,columns = texto_2)\n",
        "# Indexa pelas sentença do texto_1\n",
        "df1.index = texto_1\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Aguardo uma resposta, João.</th>\n",
              "      <th>Qual o conteúdo da prova?</th>\n",
              "      <th>Bom Dia, professor.</th>\n",
              "      <th>Vai cair tudo na prova?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Bom Dia, professor.</th>\n",
              "      <td>0.893253</td>\n",
              "      <td>0.802693</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.804919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Qual o conteúdo da prova?</th>\n",
              "      <td>0.802668</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.802693</td>\n",
              "      <td>0.909448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Vai cair tudo na prova?</th>\n",
              "      <td>0.807740</td>\n",
              "      <td>0.909448</td>\n",
              "      <td>0.804919</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aguardo uma resposta, João.</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.802668</td>\n",
              "      <td>0.893253</td>\n",
              "      <td>0.807740</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             Aguardo uma resposta, João.  ...  Vai cair tudo na prova?\n",
              "Bom Dia, professor.                             0.893253  ...                 0.804919\n",
              "Qual o conteúdo da prova?                       0.802668  ...                 0.909448\n",
              "Vai cair tudo na prova?                         0.807740  ...                 1.000000\n",
              "Aguardo uma resposta, João.                     1.000000  ...                 0.807740\n",
              "\n",
              "[4 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "havdK-ZliXAA",
        "outputId": "822c8c7e-50b6-4c41-f1a8-5bde51e774b3"
      },
      "source": [
        "# Importa a biblioteca\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Tamanho da figura\n",
        "fig, ax = plt.subplots(figsize=(18,12))\n",
        "\n",
        "# Cria o gráfico\n",
        "ax = sns.heatmap(cos_matrix, xticklabels=texto_2, yticklabels=texto_1, cbar_kws={'label': 'Medida de similaridade cosseno'}, annot=True)\n",
        "\n",
        "ax.set_yticklabels(ax.get_yticklabels(), rotation=0, horizontalalignment='right')\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, horizontalalignment='right')\n",
        "\n",
        "# Coloca o título da matriz\n",
        "ax.axes.set_title(\"Similaridade do cosseno entre os embeddings das sentenças gerados separadamente\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Similaridade do cosseno entre os embeddings das sentenças gerados separadamente\\n')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x864 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6n3U_D0aE6G"
      },
      "source": [
        "### Gerando embeddings das sentenças simultaneamente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMA19QFtZ4T0"
      },
      "source": [
        "#### Calculando a similaridade com a primeira sentença"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCgWmOn9Z4T7"
      },
      "source": [
        "# Import das biblioteca\n",
        "import pandas as pd\n",
        "\n",
        "# Converte o texto em um dataframe\n",
        "df1 = pd.DataFrame(texto_1, columns = ['sentenca'])\n",
        "\n",
        "# Concatena as sentenças do texto em uma string\n",
        "textoOriginalConcatenado = ' '.join(texto_1)\n",
        "\n",
        "df2 = pd.DataFrame(texto_2, columns = ['sentenca'])\n",
        "\n",
        "# Concatena as sentenças do texto em uma string\n",
        "textoPermutadoConcatenado = ' '.join(texto_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGGGPICufVVm"
      },
      "source": [
        "Gera os embeddings de cada sentença"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlzYvvUrfb-E"
      },
      "source": [
        "# Gerando embeddings dos textos\n",
        "embeddingTextoOriginal, tokensOriginal = getEmbeddingsConcat4UltimasCamadas(textoOriginalConcatenado, model, tokenizer)    \n",
        "\n",
        "embeddingTextoPermutado, tokensPermutado = getEmbeddingsConcat4UltimasCamadas(textoPermutadoConcatenado, model, tokenizer)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ri1po8efht3"
      },
      "source": [
        "Recupera os embeddings de cada sentença"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rsq_U2PFbAl4",
        "outputId": "68818b2f-a8e9-4642-ca81-e603806d67b3"
      },
      "source": [
        "print('Texto 1  :', str(texto_1))\n",
        "print('Quantidade de sentenças:',len(texto_1))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "n = len(texto_1)\n",
        "\n",
        "# Calcula o embeddings das sentenças\n",
        "matrix_embedding1 = []\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(n):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_1[i]\n",
        "  \n",
        "    # Recupera os embeddings das sentenças no embeddings do texto original    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoOriginal, textoOriginalConcatenado, Si, tokenizer, filtro='NOUN')\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)    \n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "\n",
        "    # Adiciona na lista\n",
        "    matrix_embedding1.append(mediaEmbeddingSi.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto 1  : ['Bom Dia, professor.', 'Qual o conteúdo da prova?', 'Vai cair tudo na prova?', 'Aguardo uma resposta, João.']\n",
            "Quantidade de sentenças: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xh_-y4xfo6g"
      },
      "source": [
        "Recupera os embeddings de cada sentença"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xuOtDjGb11-",
        "outputId": "6805975d-2157-49af-f296-23fcc2210606"
      },
      "source": [
        "print('Texto 2  :', str(texto_2))\n",
        "print('Quantidade de sentenças:',len(texto_2))\n",
        "\n",
        "# Quantidade de sentenças no texto\n",
        "n = len(texto_2)\n",
        "\n",
        "# Calcula o embeddings das sentenças\n",
        "matrix_embedding2 = []\n",
        "\n",
        "# Percorre as sentenças do texto\n",
        "for i in range(n):\n",
        "    # Seleciona as sentenças do texto  \n",
        "    Si = texto_2[i]\n",
        "  \n",
        "    # Recupera os embeddings das sentenças no embeddings do texto original    \n",
        "    # Entrada: <qtde_tokens_texto> x <768 ou 1024>, textoConcatenado,  Si (Sentença i), tokenizador\n",
        "    embeddingSi = getEmbeddingSentencaEmbeddingTexto(embeddingTextoPermutado, textoPermutadoConcatenado, Si, tokenizer, filtro='NOUN')\n",
        "    # Saída: <qtde_tokens_Si> x <768 ou 1024>\n",
        "    #print('embeddingSi=', embeddingSi.shape)    \n",
        "  \n",
        "    # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n",
        "    # Entrada: <qtde_tokens> x <768 ou 1024>  \n",
        "    mediaEmbeddingSi = torch.mean(embeddingSi, dim=0)    \n",
        "    # Saída: <768 ou 1024>\n",
        "    #print('mediaEmbeddingSi=', mediaEmbeddingSi.shape)\n",
        "\n",
        "    # Adiciona na lista\n",
        "    matrix_embedding2.append(mediaEmbeddingSi.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto 2  : ['Aguardo uma resposta, João.', 'Qual o conteúdo da prova?', 'Bom Dia, professor.', 'Vai cair tudo na prova?']\n",
            "Quantidade de sentenças: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgrEAtYHfz3i"
      },
      "source": [
        "Calcula a similaridade do cosseno entre os embeddings das sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzNzT7gAZ4T8",
        "outputId": "3b40f463-eacc-43fb-d33f-39a8f17afe43"
      },
      "source": [
        "# Importa a biblioteca\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Coloca todos os embeddings de sentença em uma matriz\n",
        "embed_matrix1 = np.array([x for x in matrix_embedding1])\n",
        "embed_matrix2 = np.array([x for x in matrix_embedding2])\n",
        "\n",
        "# Calcula a similaridade do coseno entre as sentenças\n",
        "cos_matrix = cosine_similarity(embed_matrix1,embed_matrix2)\n",
        "\n",
        "# Coloca a similaridade para a primeira sentença\n",
        "df1['medida'] = cos_matrix[0]\n",
        "\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentenca</th>\n",
              "      <th>medida</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bom Dia, professor.</td>\n",
              "      <td>0.561785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Qual o conteúdo da prova?</td>\n",
              "      <td>0.667567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Vai cair tudo na prova?</td>\n",
              "      <td>0.988495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aguardo uma resposta, João.</td>\n",
              "      <td>0.624757</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      sentenca    medida\n",
              "0          Bom Dia, professor.  0.561785\n",
              "1    Qual o conteúdo da prova?  0.667567\n",
              "2      Vai cair tudo na prova?  0.988495\n",
              "3  Aguardo uma resposta, João.  0.624757"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw_hhpWEZ4T8"
      },
      "source": [
        "#### Mapa de calor calculado com a similaridade cosseno entre todas as sentenças gerados separadamente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUGpvD-8Z4T8",
        "outputId": "64f30c7e-99a0-4ade-c141-56160cf26658"
      },
      "source": [
        "# Cria o dataframe da lista com as sentenças como nome das colunas\n",
        "df1 = pd.DataFrame(cos_matrix,columns = texto_2)\n",
        "# Indexa pela sentença\n",
        "df1.index = texto_1\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Aguardo uma resposta, João.</th>\n",
              "      <th>Qual o conteúdo da prova?</th>\n",
              "      <th>Bom Dia, professor.</th>\n",
              "      <th>Vai cair tudo na prova?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Bom Dia, professor.</th>\n",
              "      <td>0.561785</td>\n",
              "      <td>0.667567</td>\n",
              "      <td>0.988495</td>\n",
              "      <td>0.624757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Qual o conteúdo da prova?</th>\n",
              "      <td>0.563058</td>\n",
              "      <td>0.988942</td>\n",
              "      <td>0.652159</td>\n",
              "      <td>0.865090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Vai cair tudo na prova?</th>\n",
              "      <td>0.537304</td>\n",
              "      <td>0.856462</td>\n",
              "      <td>0.602382</td>\n",
              "      <td>0.989585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aguardo uma resposta, João.</th>\n",
              "      <td>0.948873</td>\n",
              "      <td>0.561365</td>\n",
              "      <td>0.537102</td>\n",
              "      <td>0.542849</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             Aguardo uma resposta, João.  ...  Vai cair tudo na prova?\n",
              "Bom Dia, professor.                             0.561785  ...                 0.624757\n",
              "Qual o conteúdo da prova?                       0.563058  ...                 0.865090\n",
              "Vai cair tudo na prova?                         0.537304  ...                 0.989585\n",
              "Aguardo uma resposta, João.                     0.948873  ...                 0.542849\n",
              "\n",
              "[4 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVqzhgg1Z4T8",
        "outputId": "fef4ce37-bc94-48db-9fa4-93bdd9b724ad"
      },
      "source": [
        "# Importa a biblioteca\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Tamanho da figura\n",
        "fig, ax = plt.subplots(figsize=(18,12))\n",
        "\n",
        "# Cria o gráfico\n",
        "ax = sns.heatmap(cos_matrix, xticklabels=texto_2, yticklabels=texto_1, cbar_kws={'label': 'Medida de similaridade do cosseno'}, annot=True)\n",
        "\n",
        "ax.set_yticklabels(ax.get_yticklabels(), rotation=0, horizontalalignment='right')\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, horizontalalignment='right')\n",
        "\n",
        "# Coloca o título da matriz\n",
        "ax.axes.set_title(\"Similaridade do cosseno entre os embeddings das sentenças gerados simultaneamente\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Similaridade do cosseno entre os embeddings das sentenças gerados simultaneamente\\n')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x864 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}