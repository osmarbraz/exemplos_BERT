{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOjnEG9aiu9QWdZV3W9eNhS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osmarbraz/exemplos_BERT/blob/main/ExemploSentenceBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-BT78wo3RVJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78HE8FLsKN9Q"
      },
      "source": [
        "# Exemplo de Geração de Embeddings de Sentenças com SBERT\n",
        "\n",
        "# **A execução pode ser feita através do menu Ambiente de Execução opção Executar tudo.**\n",
        "\n",
        "\n",
        "**Link artigo SBERT:**\n",
        "https://arxiv.org/abs/1908.10084\n",
        "\n",
        "\n",
        "**Link biblioteca SBERT:**\n",
        "https://www.sbert.net/\n",
        "\n",
        "\n",
        "**Link biblioteca Huggingface:**\n",
        "https://github.com/huggingface/transformers\n",
        "\n",
        "\n",
        "**Artigo original BERT Jacob Devlin:**\n",
        "https://arxiv.org/pdf/1506.06724.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyxb5Px3p1-e"
      },
      "source": [
        "# 0 - Preparação do ambiente\n",
        "Preparação do ambiente para execução do exemplo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAPVtRXQqDim"
      },
      "source": [
        "##Tratamento de logs\n",
        "\n",
        "Método para tratamento dos logs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcopxbGZqDip"
      },
      "source": [
        "# Biblioteca de logging\n",
        "import logging\n",
        "\n",
        "# Formatando a mensagem de logging\n",
        "logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GjYtXcMnSAe"
      },
      "source": [
        "## Identificando o ambiente Colab\n",
        "\n",
        "Cria uma variável para identificar que o notebook está sendo executado no Google Colaboratory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMiH0E3OnRa1"
      },
      "source": [
        "# Se estiver executando no Google Colaboratory\n",
        "import sys\n",
        "\n",
        "# Retorna true ou false se estiver no Google Colaboratory\n",
        "IN_COLAB = \"google.colab\" in sys.modules"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Instalação do BERT Sentence\n",
        "\n",
        "https://www.sbert.net/"
      ],
      "metadata": {
        "id": "R-bV4iFlSpgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJAPt3TOSppy",
        "outputId": "8ffcd808-5e6f-4eda-92f1-16ff6198e3ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.9.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.7.3)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.21.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.64.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.21.6)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.13.1+cu113)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.97)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.1.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carrega o modelo"
      ],
      "metadata": {
        "id": "dT-1zkCRS48A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa das bibliotecas\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Carrega o BERTimbau\n",
        "sentence_model = SentenceTransformer('neuralmind/bert-large-portuguese-cased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snQLwSgNS6ZT",
        "outputId": "815d7d5c-79c9-4e3e-ae69-d66fab0a2da2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/neuralmind_bert-large-portuguese-cased. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/neuralmind_bert-large-portuguese-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RufkKnojlwzu"
      },
      "source": [
        "# 2 - Instalação do spaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0LeiOTx0Dlk"
      },
      "source": [
        "https://spacy.io/\n",
        "\n",
        "Modelos do spaCy para português:\n",
        "https://spacy.io/models/pt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2Fvx0TVRQUw",
        "outputId": "0de36e5e-143c-4f0c-f62b-28b5d8494afa"
      },
      "source": [
        "# Instala o spacy\n",
        "!pip install -U spacy==2.3.5"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy==2.3.5 in /usr/local/lib/python3.7/dist-packages (2.3.5)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (7.4.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (0.10.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (2.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (1.21.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (4.64.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (57.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (3.0.7)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (0.7.8)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (1.0.8)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.3.5) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.5) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.5) (4.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35GwcgkOlWi3"
      },
      "source": [
        "Realiza o download e carrega os modelos necessários a biblioteca\n",
        "\n",
        "https://spacy.io/models/pt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4LqE5kTwDYm"
      },
      "source": [
        "# Definição do nome do arquivo do modelo\n",
        "#ARQUIVOMODELO = \"pt_core_news_sm\"\n",
        "#ARQUIVOMODELO = \"pt_core_news_md\"\n",
        "ARQUIVOMODELO = \"pt_core_news_lg\"\n",
        "\n",
        "# Definição da versão da spaCy\n",
        "#VERSAOSPACY = \"-3.0.0a0\"\n",
        "VERSAOSPACY = \"-2.3.0\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ2KB3UCp-ws"
      },
      "source": [
        "#Baixa automaticamente o arquivo do modelo.\n",
        "#!python -m spacy download {ARQUIVOMODELO}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASk5iFeUp9LE",
        "outputId": "c56a0ffb-2c22-4ba1-e92d-481d71dbbd1e"
      },
      "source": [
        "# Realiza o download do arquivo do modelo para o diretório corrente\n",
        "!wget https://github.com/explosion/spacy-models/releases/download/{ARQUIVOMODELO}{VERSAOSPACY}/{ARQUIVOMODELO}{VERSAOSPACY}.tar.gz"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-11 19:10:06--  https://github.com/explosion/spacy-models/releases/download/pt_core_news_lg-2.3.0/pt_core_news_lg-2.3.0.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/84940268/a899e480-ab07-11ea-831b-b5aa9cc04510?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220911%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220911T191006Z&X-Amz-Expires=300&X-Amz-Signature=320f6eb8b2bc3fb8c5cd5bbd01675a3a990787ee28d7b72c9903ec69c124a27d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=84940268&response-content-disposition=attachment%3B%20filename%3Dpt_core_news_lg-2.3.0.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-09-11 19:10:06--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/84940268/a899e480-ab07-11ea-831b-b5aa9cc04510?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220911%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220911T191006Z&X-Amz-Expires=300&X-Amz-Signature=320f6eb8b2bc3fb8c5cd5bbd01675a3a990787ee28d7b72c9903ec69c124a27d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=84940268&response-content-disposition=attachment%3B%20filename%3Dpt_core_news_lg-2.3.0.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 576599832 (550M) [application/octet-stream]\n",
            "Saving to: ‘pt_core_news_lg-2.3.0.tar.gz.1’\n",
            "\n",
            "pt_core_news_lg-2.3 100%[===================>] 549.89M   179MB/s    in 3.1s    \n",
            "\n",
            "2022-09-11 19:10:09 (179 MB/s) - ‘pt_core_news_lg-2.3.0.tar.gz.1’ saved [576599832/576599832]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu_LkF7Nfm8_"
      },
      "source": [
        "Descompacta o arquivo do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9fCQQJGeVEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0948903-4528-4522-99e9-cb474c25f388"
      },
      "source": [
        "# Descompacta o arquivo do modelo\n",
        "!tar -xvf  /content/{ARQUIVOMODELO}{VERSAOSPACY}.tar.gz"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pt_core_news_lg-2.3.0/\n",
            "pt_core_news_lg-2.3.0/PKG-INFO\n",
            "pt_core_news_lg-2.3.0/setup.py\n",
            "pt_core_news_lg-2.3.0/setup.cfg\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/dependency_links.txt\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/PKG-INFO\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/SOURCES.txt\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/requires.txt\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/top_level.txt\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/not-zip-safe\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/__init__.py\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/parser/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/parser/cfg\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/parser/moves\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/parser/model\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/ner/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/ner/cfg\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/ner/moves\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/ner/model\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tokenizer\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/lookups.bin\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/vectors\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/key2row\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/lookups_extra.bin\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/strings.json\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/accuracy.json\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tagger/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tagger/cfg\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tagger/tag_map\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tagger/model\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/meta.json\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/meta.json\n",
            "pt_core_news_lg-2.3.0/MANIFEST.in\n",
            "pt_core_news_lg-2.3.0/meta.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovOx-3Wb-JJW"
      },
      "source": [
        "# Coloca a pasta do modelo descompactado em uma pasta de nome mais simples\n",
        "!mv /content/{ARQUIVOMODELO}{VERSAOSPACY}/{ARQUIVOMODELO}/{ARQUIVOMODELO}{VERSAOSPACY} /content/{ARQUIVOMODELO}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STHT2c89qvwK"
      },
      "source": [
        "Carrega o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbELnrpgA4T1"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "import spacy\n",
        "\n",
        "CAMINHOMODELO = \"/content/\" + ARQUIVOMODELO\n",
        "\n",
        "nlp = spacy.load(CAMINHOMODELO)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFTTdqxKQ1Ay"
      },
      "source": [
        "Recupera os stopwords do spaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBInu7ayQ31J"
      },
      "source": [
        "# Recupera as stop words\n",
        "spacy_stopwords = nlp.Defaults.stop_words"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_EYNu-_RX7k"
      },
      "source": [
        "Lista dos stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUSaUJEWRbnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a827c75-4457-4d4b-a025-2e70bdc8de6a"
      },
      "source": [
        "print(\"Quantidade de stopwords:\", len(spacy_stopwords))\n",
        "\n",
        "print(spacy_stopwords)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade de stopwords: 413\n",
            "{'quanto', 'tens', 'após', 'segundo', 'tais', 'tanto', 'dão', 'grupo', 'mês', 'desse', 'assim', 'vós', 'ao', 'eventual', 'comprido', 'vinda', 'primeira', 'as', 'ora', 'sétimo', 'minha', 'teve', 'puderam', 'minhas', 'me', 'pode', 'máximo', 'foi', 'não', 'tentei', 'próxima', 'apoio', 'nossa', 'direita', 'além', 'tivestes', 'vindo', 'cuja', 'apoia', 'treze', 'parece', 'ponto', 'três', 'demais', 'quinze', 'só', 'ir', 'onde', 'ela', 'vêm', 'terceiro', 'disso', 'ainda', 'terceira', 'como', 'podem', 'estes', 'diante', 'está', 'lugar', 'põe', 'deste', 'cujo', 'final', 'isto', 'zero', 'próximo', 'sétima', 'daquele', 'seis', 'entre', 'quarta', 'esteve', 'dizem', 'era', 'onze', 'essa', 'vens', 'é', 'dois', 'apontar', 'obrigado', 'então', 'dá', 'vai', 'ambos', 'conhecido', 'antes', 'baixo', 'poder', 'quieta', 'tem', 'ambas', 'vão', 'lá', 'tarde', 'aquele', 'esses', 'nunca', 'boa', 'dezoito', 'um', 'pôde', 'isso', 'à', 'põem', 'for', 'vem', 'tu', 'usar', 'coisa', 'estará', 'faz', 'tivemos', 'certamente', 'meus', 'pois', 'grandes', 'sob', 'dizer', 'todo', 'neste', 'apenas', 'área', 'dezanove', 'duas', 'muito', 'obrigada', 'fazer', 'tiveram', 'têm', 'tenho', 'vosso', 'vocês', 'também', 'são', 'com', 'doze', 'estiveram', 'aqui', 'momento', 'da', 'numa', 'na', 'pelo', 'fostes', 'somente', 'possível', 'ser', 'seria', 'sete', 'contudo', 'tuas', 'tua', 'ele', 'breve', 'alguns', 'posição', 'num', 'iniciar', 'saber', 'aquela', 'mesmo', 'és', 'perto', 'das', 'conselho', 'números', 'dez', 'quatro', 'porquanto', 'pouca', 'ontem', 'acerca', 'quer', 'partir', 'poderá', 'uma', 'oitava', 'conhecida', 'uns', 'sobre', 'qual', 'bom', 'corrente', 'nossas', 'maioria', 'dessa', 'sim', 'fazemos', 'porque', 'até', 'ver', 'pouco', 'comprida', 'nesse', 'outras', 'atrás', 'grande', 'novos', 'pegar', 'fazem', 'fará', 'aos', 'sem', 'inclusive', 'tentar', 'daquela', 'do', 'vossa', 'algo', 'tudo', 'nosso', 'favor', 'fez', 'em', 'ligado', 'cento', 'questão', 'ali', 'se', 'nossos', 'aquilo', 'às', 'ter', 'estive', 'tente', 'primeiro', 'essas', 'este', 'os', 'bastante', 'vossas', 'mal', 'nessa', 'falta', 'lado', 'foste', 'de', 'dentro', 'quarto', 'caminho', 'veja', 'você', 'por', 'qualquer', 'oitavo', 'algumas', 'nuns', 'querem', 'oito', 'muitos', 'suas', 'cedo', 'que', 'nada', 'faço', 'nova', 'sistema', 'estás', 'esse', 'contra', 'fomos', 'fim', 'pela', 'estão', 'sabe', 'nesta', 'pontos', 'debaixo', 'meio', 'estivemos', 'meses', 'eu', 'dos', 'naquela', 'nas', 'enquanto', 'fazes', 'quero', 'teus', 'sexta', 'tiveste', 'estar', 'sois', 'vez', 'cada', 'parte', 'seu', 'maiorias', 'mil', 'portanto', 'aí', 'cima', 'nem', 'toda', 'tendes', 'fora', 'temos', 'fazeis', 'devem', 'cá', 'agora', 'depois', 'pelos', 'já', 'des', 'nos', 'cinco', 'diz', 'sei', 'geral', 'tentaram', 'irá', 'umas', 'porquê', 'menos', 'tal', 'forma', 'nove', 'estava', 'relação', 'menor', 'todos', 'foram', 'nível', 'embora', 'estado', 'vossos', 'lhe', 'fazia', 'no', 'mais', 'exemplo', 'tempo', 'quê', 'novo', 'nenhuma', 'sou', 'maior', 'adeus', 'estou', 'vezes', 'ou', 'quais', 'catorze', 'desde', 'eles', 'sua', 'custa', 'inicio', 'local', 'dar', 'segunda', 'elas', 'te', 'aquelas', 'vários', 'podia', 'ademais', 'esta', 'vais', 'vos', 'tão', 'outra', 'aqueles', 'quieto', 'possivelmente', 'somos', 'bem', 'usa', 'pelas', 'logo', 'longe', 'povo', 'tive', 'fui', 'sempre', 'vinte', 'estivestes', 'estas', 'dezasseis', 'novas', 'próprio', 'tipo', 'mas', 'teu', 'posso', 'através', 'quem', 'dezassete', 'porém', 'nós', 'outros', 'deverá', 'último', 'meu', 'quando', 'naquele', 'todas', 'seus', 'sexto', 'quinta', 'estiveste', 'número', 'quinto', 'deve', 'tanta', 'talvez', 'desta', 'valor', 'certeza', 'para'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getTextoSemStopword(lista_tokens, spacy_stopwords):\n",
        "    \"\"\"\n",
        "      Retira os tokens que estão na lista de stopword\n",
        "    \n",
        "      Parâmetros:\n",
        "        `lista_tokens` - Uma lista com os tokens.\n",
        "        `spacy_stopwords` - Uma lista com as stopword. \n",
        "    \"\"\"\n",
        "    \n",
        "    spacy_stopwords = nlp.Defaults.stop_words\n",
        "    \n",
        "    lista_tokens_semstopwords = []\n",
        "    \n",
        "    # Percorre os tokens    \n",
        "    for token in lista_tokens:\n",
        "      # Verifica se o toke não está na lista de stopwords para adicionar a nova lista\n",
        "      if token not in spacy_stopwords:\n",
        "        lista_tokens_semstopwords.append(token)\n",
        "\n",
        "\n",
        "    return lista_tokens_semstopwords "
      ],
      "metadata": {
        "id": "pbUf_V_1axS2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Exemplo embeddings de sentenças\n",
        "\n",
        "Usando o BERTimbau e Sentence BERT\n"
      ],
      "metadata": {
        "id": "NCrHYsdpTPRE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Sentenças"
      ],
      "metadata": {
        "id": "On28CoRfd0IA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentos = [\n",
        "# 20 Perguntas do Cohebert\n",
        "\"Como enfileirar elementos em uma fila?\",      \n",
        "\"Como desenfileirar elementos em uma fila?\",\n",
        "\"Como empilhar elementos em uma pilha?\",\n",
        "\"Como empilhar e desempilhar elementos em uma pilha?\",\n",
        "\"Como empilhar elementos em uma estrutura de dados pilha?\",\n",
        "\"Como empilhar e desempilhar elementos em uma estrutura de dados pilha?\",\n",
        "\"Como desempilhar elementos em uma pilha?\",\n",
        "\"Como desempilhar elementos em uma estrutura de dados pilha?\",\n",
        "\"O que é uma pilha e como empilhar seu elemento?\",\n",
        "\"O que é uma fila e como enfileirar seu elemento?\",\n",
        "\"O que é uma fila e como desenfileirar um elemento nela?\",\n",
        "\"O que é uma pilha e como desempilhar um elemento nela?\",\n",
        "\"O que é uma fila e como enfileirar um elemento nela?\",\n",
        "\"O que é uma pilha e como empilhar um elemento nela?\",\n",
        "\"O que é uma pilha e como empilhar e desempilhar seus elementos?\",\n",
        "\"O que é uma fila e como enfileirar e desenfileirar seus elementos?\",\n",
        "\"Como são implementadas as operações de empilhar e desempilhar elementos em uma pilha?\",\n",
        "\"Como são implementadas as operações de enfileirar e desenfileirar elementos em uma fila?\",\n",
        "\"Em uma pilha a operação de empilhar ocorre em qual extremidade?\",\n",
        "\"Em uma fila a operação de enfileirar ocorre em qual extremidade?\"\n",
        "]\n",
        "\n",
        "print(\"Quantidade de documentos:\", len(documentos))"
      ],
      "metadata": {
        "id": "FFRHakyFTQsF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "912e1701-a754-4818-e86f-bfd7f8b98820"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade de documentos: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Executa o SBERT"
      ],
      "metadata": {
        "id": "azVrZBtfd32b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carrega o SBERT"
      ],
      "metadata": {
        "id": "1FOcOxyjeFKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa das bibliotecas\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Carrega o BERTimbau\n",
        "sentence_model = SentenceTransformer('neuralmind/bert-large-portuguese-cased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa9e0fc0-40fe-4e55-da69-5fcb04ba1739",
        "id": "8d_Wj9if4NSe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/neuralmind_bert-large-portuguese-cased. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/neuralmind_bert-large-portuguese-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gera os embeddings dos documentos"
      ],
      "metadata": {
        "id": "FYMxlj7K4z0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#As sentenças são codificadas chamando model.encode()\n",
        "embeddings = sentence_model.encode(documentos)"
      ],
      "metadata": {
        "id": "K76U53XS4I69"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostra as sentenças, o tamanho dos embeddings e os embeddings"
      ],
      "metadata": {
        "id": "W79SeaGt439G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print the embeddings\n",
        "for sentenca, embedding in zip(documentos, embeddings):\n",
        "    print(\"Sentença:\", sentenca)\n",
        "    print(\"Embedding:\", embedding.shape, embedding)\n",
        "    print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMSyUEO24skY",
        "outputId": "a44f97fa-8a3c-4dfd-9a80-17f7dcab0cea"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentença: Como enfileirar elementos em uma fila?\n",
            "Embedding: (1024,) [ 0.68154013  0.57252467  0.17376563 ...  0.18361737 -0.3099475\n",
            " -0.42516118]\n",
            "\n",
            "Sentença: Como desenfileirar elementos em uma fila?\n",
            "Embedding: (1024,) [ 0.67173254  0.6271159   0.14545439 ...  0.35041693 -0.22504759\n",
            " -0.11911644]\n",
            "\n",
            "Sentença: Como empilhar elementos em uma pilha?\n",
            "Embedding: (1024,) [ 0.43170884  0.41206315  0.32280293 ...  0.38283882 -0.23511854\n",
            " -0.3312927 ]\n",
            "\n",
            "Sentença: Como empilhar e desempilhar elementos em uma pilha?\n",
            "Embedding: (1024,) [ 0.47373885  0.4825631   0.36223608 ...  0.28731996 -0.1441043\n",
            " -0.2465222 ]\n",
            "\n",
            "Sentença: Como empilhar elementos em uma estrutura de dados pilha?\n",
            "Embedding: (1024,) [ 0.35204166  0.56649333 -0.12389781 ...  0.1032858  -0.33934513\n",
            " -0.24827304]\n",
            "\n",
            "Sentença: Como empilhar e desempilhar elementos em uma estrutura de dados pilha?\n",
            "Embedding: (1024,) [ 0.37628603  0.7487235   0.00377593 ... -0.01976712 -0.28557017\n",
            " -0.22509223]\n",
            "\n",
            "Sentença: Como desempilhar elementos em uma pilha?\n",
            "Embedding: (1024,) [ 0.4665278   0.525781    0.30706453 ...  0.42121133 -0.2948343\n",
            " -0.10329586]\n",
            "\n",
            "Sentença: Como desempilhar elementos em uma estrutura de dados pilha?\n",
            "Embedding: (1024,) [ 0.41583115  0.6668957  -0.1729607  ...  0.15619312 -0.38597763\n",
            " -0.11396559]\n",
            "\n",
            "Sentença: O que é uma pilha e como empilhar seu elemento?\n",
            "Embedding: (1024,) [ 0.39195886  0.21071132  0.44871768 ...  0.3330358  -0.08837064\n",
            " -0.3092327 ]\n",
            "\n",
            "Sentença: O que é uma fila e como enfileirar seu elemento?\n",
            "Embedding: (1024,) [ 0.4750756   0.36347565  0.24592184 ...  0.1991866  -0.21712746\n",
            " -0.4062442 ]\n",
            "\n",
            "Sentença: O que é uma fila e como desenfileirar um elemento nela?\n",
            "Embedding: (1024,) [ 0.6419499   0.61356753  0.13164194 ...  0.25011605 -0.34615317\n",
            " -0.16096303]\n",
            "\n",
            "Sentença: O que é uma pilha e como desempilhar um elemento nela?\n",
            "Embedding: (1024,) [ 0.537576    0.3342377   0.37865925 ...  0.43253154 -0.26428506\n",
            " -0.09656272]\n",
            "\n",
            "Sentença: O que é uma fila e como enfileirar um elemento nela?\n",
            "Embedding: (1024,) [ 0.56896454  0.5261136   0.11494985 ...  0.13027951 -0.32381016\n",
            " -0.3700452 ]\n",
            "\n",
            "Sentença: O que é uma pilha e como empilhar um elemento nela?\n",
            "Embedding: (1024,) [ 0.51487726  0.29830727  0.41925713 ...  0.29253638 -0.19900523\n",
            " -0.3009544 ]\n",
            "\n",
            "Sentença: O que é uma pilha e como empilhar e desempilhar seus elementos?\n",
            "Embedding: (1024,) [ 0.4797213   0.63025934  0.5538956  ...  0.43015584 -0.12912461\n",
            " -0.24301276]\n",
            "\n",
            "Sentença: O que é uma fila e como enfileirar e desenfileirar seus elementos?\n",
            "Embedding: (1024,) [ 0.5694164   0.4978731   0.18403439 ...  0.163859   -0.4045861\n",
            " -0.21184288]\n",
            "\n",
            "Sentença: Como são implementadas as operações de empilhar e desempilhar elementos em uma pilha?\n",
            "Embedding: (1024,) [ 0.6918652   0.46835986  0.05262977 ...  0.07693674 -0.30703068\n",
            " -0.15055026]\n",
            "\n",
            "Sentença: Como são implementadas as operações de enfileirar e desenfileirar elementos em uma fila?\n",
            "Embedding: (1024,) [ 0.77500653  0.5045202   0.02065889 ...  0.11268724 -0.34587574\n",
            " -0.08574677]\n",
            "\n",
            "Sentença: Em uma pilha a operação de empilhar ocorre em qual extremidade?\n",
            "Embedding: (1024,) [ 0.31079796  0.17884348  0.03336012 ...  0.44252    -0.17639422\n",
            "  0.10577226]\n",
            "\n",
            "Sentença: Em uma fila a operação de enfileirar ocorre em qual extremidade?\n",
            "Embedding: (1024,) [ 0.39443296  0.41913876 -0.13131982 ...  0.15884383 -0.09168692\n",
            "  0.02846449]\n",
            "\n",
            "Sentença: Qual era o precursor do MEC ?\n",
            "Embedding: (1024,) [ 0.5276158  -0.06891616 -0.12237298 ...  0.42874736 -0.13461499\n",
            " -0.00373845]\n",
            "\n",
            "Sentença: O que é monografia ?\n",
            "Embedding: (1024,) [-0.08402362 -0.13689382  0.14108732 ...  0.5317525   0.1254245\n",
            " -0.31471118]\n",
            "\n",
            "Sentença: Onde é sediada a UFMS ?\n",
            "Embedding: (1024,) [ 0.350389   -0.08857426 -0.08754631 ...  0.28932545 -0.11236349\n",
            "  0.37224331]\n",
            "\n",
            "Sentença: O que o desenvolvimento cada vez mais rápido de novas tecnologias reduziu ?\n",
            "Embedding: (1024,) [ 0.37431946  0.42035115 -0.03982641 ...  0.15306346 -0.31480545\n",
            " -0.24966355]\n",
            "\n",
            "Sentença: O regime de exercícios domiciliares substitui o quê ?\n",
            "Embedding: (1024,) [ 0.03488822  0.35798824  0.23738718 ...  0.5952858  -0.6752684\n",
            "  0.470212  ]\n",
            "\n",
            "Sentença: Como pode ser definido um sistema de informação ?\n",
            "Embedding: (1024,) [ 0.30753297  0.25058335  0.14300857 ...  0.20736256  0.11982183\n",
            " -0.23533873]\n",
            "\n",
            "Sentença: Por que a preocupação com a coleta , armazenamento , processamento e transmissão da informação cresce ?\n",
            "Embedding: (1024,) [ 0.4915936   0.29230052 -0.11644835 ...  0.11262629 -0.26704317\n",
            "  0.14460567]\n",
            "\n",
            "Sentença: Em que se concentram as responsabilidades do analista de sistemas ?\n",
            "Embedding: (1024,) [ 0.282043   -0.3165895  -0.09735922 ...  0.22401075 -0.23128133\n",
            " -0.0202709 ]\n",
            "\n",
            "Sentença: O que é análise de sistemas ?\n",
            "Embedding: (1024,) [ 0.44231603 -0.08888508 -0.120378   ...  0.34533113  0.08871482\n",
            "  0.0086041 ]\n",
            "\n",
            "Sentença: Por que o analista de sistemas deve traduzir a necessidade do usuário ?\n",
            "Embedding: (1024,) [ 0.01042408  0.03663076  0.21829508 ...  0.12514724 -0.5210811\n",
            "  0.32217255]\n",
            "\n",
            "Sentença: O que é necessário apresentar para comprovar a participação em um evento ?\n",
            "Embedding: (1024,) [ 0.12017049  0.19094254  0.38246804 ...  0.14798439 -0.00172999\n",
            "  0.33481818]\n",
            "\n",
            "Sentença: Qual o valor de um crédito na maioria das universidades ?\n",
            "Embedding: (1024,) [ 0.09514724 -0.10009266  0.06724457 ...  0.646936    0.15849426\n",
            " -0.16006574]\n",
            "\n",
            "Sentença: Como o aluno pode adquirir conhecimento sem o acompanhamento de um professor ?\n",
            "Embedding: (1024,) [ 0.14379244  0.12004978  0.1331819  ...  0.28125495 -0.2798257\n",
            "  0.37184402]\n",
            "\n",
            "Sentença: Como são utilizadas as versões mais modernas do ábaco ?\n",
            "Embedding: (1024,) [ 0.31505188  0.01717153 -0.11500113 ...  0.23787597 -0.18251714\n",
            " -0.39923173]\n",
            "\n",
            "Sentença: Por quem eram produzidas as tabelas logarítmicas ?\n",
            "Embedding: (1024,) [ 0.40937102  0.24094619 -0.42362463 ...  0.23535337 -0.51443756\n",
            " -0.09643508]\n",
            "\n",
            "Sentença: Qual foi a primeira ferramenta conhecida para a computação ?\n",
            "Embedding: (1024,) [ 0.3746835   0.19128682 -0.45534673 ...  0.08295891 -0.07231649\n",
            " -0.1133726 ]\n",
            "\n",
            "Sentença: Como é conhecido Alan Turing ?\n",
            "Embedding: (1024,) [ 0.551234    0.00859318 -0.34122527 ...  0.12511456 -0.25271264\n",
            " -0.02374995]\n",
            "\n",
            "Sentença: Para que engenheiros eletricistas contruiam circuitos eletrônicos ?\n",
            "Embedding: (1024,) [ 0.5482449   0.32036912 -0.40156516 ...  0.24259584 -0.26486695\n",
            "  0.6274471 ]\n",
            "\n",
            "Sentença: Quais órgãos centrais são comuns em universidades?\n",
            "Embedding: (1024,) [ 0.47969654 -0.01596161 -0.11594047 ...  0.19287755  0.16844058\n",
            " -0.21110478]\n",
            "\n",
            "Sentença: Quando Turing cometeu suicídio ?\n",
            "Embedding: (1024,) [ 0.6674965  -0.18487456  0.5170461  ...  0.5718618  -0.4253085\n",
            "  0.8308119 ]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 - Exemplo comparando sentenças"
      ],
      "metadata": {
        "id": "fwyGMedL5SR_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Sentenças "
      ],
      "metadata": {
        "id": "px5fvL3_6GmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentenca1 = \"Como enfileirar elementos em uma fila?\"\n",
        "sentenca2 = \"Como desenfileirar elementos em uma fila?\"\n",
        "sentenca3 = \"Como empilhar elementos em uma pilha?\""
      ],
      "metadata": {
        "id": "Sb56L9li6E3A"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Executa o SBERT"
      ],
      "metadata": {
        "id": "7YD-w3oh6tPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carrega o modelo"
      ],
      "metadata": {
        "id": "AecNGD8X5fP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa das bibliotecas\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Carrega o BERTimbau\n",
        "sentence_model = SentenceTransformer('neuralmind/bert-large-portuguese-cased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QCfJCw35Uc2",
        "outputId": "c5847fa4-6cb0-42c4-e46a-ebd2be2a4a38"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/neuralmind_bert-large-portuguese-cased. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/neuralmind_bert-large-portuguese-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforma as sentenças"
      ],
      "metadata": {
        "id": "umhpNQD25c_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#As sentenças são codificadas chamando model.encode()\n",
        "emb1 = sentence_model.encode(sentenca1)\n",
        "emb2 = sentence_model.encode(sentenca2)\n",
        "emb3 = sentence_model.encode(sentenca3)"
      ],
      "metadata": {
        "id": "r9ZrWgdp5dG_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparando embeddings de sentenças "
      ],
      "metadata": {
        "id": "zd6nG5d75zNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa das bibliotecas\n",
        "from sentence_transformers import util\n",
        "\n",
        "print(\"Sentença 1: \", sentenca1)\n",
        "print(\"Sentença 2: \", sentenca2)\n",
        "print(\"Sentença 3: \", sentenca3)\n",
        "print()\n",
        "\n",
        "cos_sim12 = util.cos_sim(emb1, emb2)\n",
        "print(\"cos(Sentença 1, Sentença2):\", cos_sim12)\n",
        "\n",
        "cos_sim13 = util.cos_sim(emb1, emb3)\n",
        "print(\"cos(Sentença 1, Sentença3):\", cos_sim13)\n",
        "\n",
        "cos_sim23 = util.cos_sim(emb2, emb3)\n",
        "print(\"cos(Sentença 2, Sentença3):\", cos_sim23)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q6lFyYP51H1",
        "outputId": "60267b94-4c8c-42d2-e713-59b663dddff0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentença 1:  Como enfileirar elementos em uma fila?\n",
            "Sentença 2:  Como desenfileirar elementos em uma fila?\n",
            "Sentença 3:  Como empilhar elementos em uma pilha?\n",
            "\n",
            "cos(Sentença 1, Sentença2): tensor([[0.9515]])\n",
            "cos(Sentença 1, Sentença3): tensor([[0.9423]])\n",
            "cos(Sentença 2, Sentença3): tensor([[0.9143]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 - Exemplo comparando duas lista de sentenças"
      ],
      "metadata": {
        "id": "EurHC28G67Jv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Sentenças "
      ],
      "metadata": {
        "id": "OavpklFB67Jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentencas1 = [\n",
        "\"Como enfileirar elementos em uma fila?\",      \n",
        "\"Como desenfileirar elementos em uma fila?\",\n",
        "\"Como empilhar elementos em uma pilha?\",\n",
        "\"Como empilhar e desempilhar elementos em uma pilha?\",\n",
        "\"Como empilhar elementos em uma estrutura de dados pilha?\",\n",
        "\"Como empilhar e desempilhar elementos em uma estrutura de dados pilha?\",\n",
        "\"Como desempilhar elementos em uma pilha?\",\n",
        "\"Como desempilhar elementos em uma estrutura de dados pilha?\",\n",
        "\"O que é uma pilha e como empilhar seu elemento?\",\n",
        "\"O que é uma fila e como enfileirar seu elemento?\"]\n",
        "\n",
        "sentencas2 = [\n",
        "\"O que é uma fila e como desenfileirar um elemento nela?\",\n",
        "\"O que é uma pilha e como desempilhar um elemento nela?\",\n",
        "\"O que é uma fila e como enfileirar um elemento nela?\",\n",
        "\"O que é uma pilha e como empilhar um elemento nela?\",\n",
        "\"O que é uma pilha e como empilhar e desempilhar seus elementos?\",\n",
        "\"O que é uma fila e como enfileirar e desenfileirar seus elementos?\",\n",
        "\"Como são implementadas as operações de empilhar e desempilhar elementos em uma pilha?\",\n",
        "\"Como são implementadas as operações de enfileirar e desenfileirar elementos em uma fila?\",\n",
        "\"Em uma pilha a operação de empilhar ocorre em qual extremidade?\",\n",
        "\"Em uma fila a operação de enfileirar ocorre em qual extremidade?\"]"
      ],
      "metadata": {
        "id": "pxt8dgA067Jw"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Executa o SBERT"
      ],
      "metadata": {
        "id": "YIaqpf-w67Jw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carrega o modelo"
      ],
      "metadata": {
        "id": "Y23rd9RC67Jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa das bibliotecas\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Carrega o BERTimbau\n",
        "sentence_model = SentenceTransformer('neuralmind/bert-large-portuguese-cased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca85e871-f514-4d16-81cd-ff99c8635d47",
        "id": "2Ej0pbJh67Jw"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/neuralmind_bert-large-portuguese-cased. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/neuralmind_bert-large-portuguese-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforma as listas de sentenças em embeddings"
      ],
      "metadata": {
        "id": "_qw0yeeS67Jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#As sentenças são codificadas chamando model.encode()\n",
        "embeddings1 = sentence_model.encode(sentencas1, convert_to_tensor=True)\n",
        "embeddings2 = sentence_model.encode(sentencas2, convert_to_tensor=True)"
      ],
      "metadata": {
        "id": "fYMghQIN67Jx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparando embeddings de sentenças "
      ],
      "metadata": {
        "id": "hlt4Sf9i67Jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calcula da similaridade do cosseno entre as sentenças\n",
        "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
        "\n",
        "# Mostra os resultados das comparações\n",
        "for i in range(len(sentencas1)):\n",
        "  print(\"{:.4f} => {} \\t\\t\\t {} \\t\\t \".format(cosine_scores[i][i], sentencas1[i], sentencas2[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46f953fe-84d9-4797-d299-148f6c8ab32d",
        "id": "8F9djMOv67Jx"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9292 => Como enfileirar elementos em uma fila? \t\t\t O que é uma fila e como desenfileirar um elemento nela? \t\t \n",
            "0.8959 => Como desenfileirar elementos em uma fila? \t\t\t O que é uma pilha e como desempilhar um elemento nela? \t\t \n",
            "0.9224 => Como empilhar elementos em uma pilha? \t\t\t O que é uma fila e como enfileirar um elemento nela? \t\t \n",
            "0.9482 => Como empilhar e desempilhar elementos em uma pilha? \t\t\t O que é uma pilha e como empilhar um elemento nela? \t\t \n",
            "0.8257 => Como empilhar elementos em uma estrutura de dados pilha? \t\t\t O que é uma pilha e como empilhar e desempilhar seus elementos? \t\t \n",
            "0.8664 => Como empilhar e desempilhar elementos em uma estrutura de dados pilha? \t\t\t O que é uma fila e como enfileirar e desenfileirar seus elementos? \t\t \n",
            "0.9362 => Como desempilhar elementos em uma pilha? \t\t\t Como são implementadas as operações de empilhar e desempilhar elementos em uma pilha? \t\t \n",
            "0.8769 => Como desempilhar elementos em uma estrutura de dados pilha? \t\t\t Como são implementadas as operações de enfileirar e desenfileirar elementos em uma fila? \t\t \n",
            "0.9019 => O que é uma pilha e como empilhar seu elemento? \t\t\t Em uma pilha a operação de empilhar ocorre em qual extremidade? \t\t \n",
            "0.9085 => O que é uma fila e como enfileirar seu elemento? \t\t\t Em uma fila a operação de enfileirar ocorre em qual extremidade? \t\t \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 - Encontrando sentenças similares"
      ],
      "metadata": {
        "id": "qrdb21My8EPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1 Sentenças "
      ],
      "metadata": {
        "id": "IUlUQQec8LNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentencas = [\n",
        "\"Como enfileirar elementos em uma fila?\",      \n",
        "\"Como desenfileirar elementos em uma fila?\",\n",
        "\"Como empilhar elementos em uma pilha?\",\n",
        "\"Como empilhar e desempilhar elementos em uma pilha?\",\n",
        "\"Como empilhar elementos em uma estrutura de dados pilha?\",\n",
        "\"Como empilhar e desempilhar elementos em uma estrutura de dados pilha?\",\n",
        "\"Como desempilhar elementos em uma pilha?\",\n",
        "\"Como desempilhar elementos em uma estrutura de dados pilha?\",\n",
        "\"O que é uma pilha e como empilhar seu elemento?\",\n",
        "\"O que é uma fila e como enfileirar seu elemento?\",\n",
        "\"O que é uma fila e como desenfileirar um elemento nela?\",\n",
        "\"O que é uma pilha e como desempilhar um elemento nela?\",\n",
        "\"O que é uma fila e como enfileirar um elemento nela?\",\n",
        "\"O que é uma pilha e como empilhar um elemento nela?\",\n",
        "\"O que é uma pilha e como empilhar e desempilhar seus elementos?\",\n",
        "\"O que é uma fila e como enfileirar e desenfileirar seus elementos?\",\n",
        "\"Como são implementadas as operações de empilhar e desempilhar elementos em uma pilha?\",\n",
        "\"Como são implementadas as operações de enfileirar e desenfileirar elementos em uma fila?\",\n",
        "\"Em uma pilha a operação de empilhar ocorre em qual extremidade?\",\n",
        "\"Em uma fila a operação de enfileirar ocorre em qual extremidade?\"]"
      ],
      "metadata": {
        "id": "OqpjzIYI8LNK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2 Executa o SBERT"
      ],
      "metadata": {
        "id": "VZhZFNn78LNK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carrega o modelo"
      ],
      "metadata": {
        "id": "3l70sm8Q8LNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa das bibliotecas\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Carrega o BERTimbau\n",
        "sentence_model = SentenceTransformer('neuralmind/bert-large-portuguese-cased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78649a99-77ca-41f7-bba6-85a5a64c4186",
        "id": "Yon59Bjp8LNK"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/neuralmind_bert-large-portuguese-cased. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/neuralmind_bert-large-portuguese-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforma as listas de sentenças em embeddings"
      ],
      "metadata": {
        "id": "Oe8uuiFB8LNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#As sentenças são codificadas chamando model.encode()\n",
        "embeddings1 = sentence_model.encode(sentencas1, convert_to_tensor=True)"
      ],
      "metadata": {
        "id": "r95bNWz88LNK"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparando embeddings de sentenças entre si"
      ],
      "metadata": {
        "id": "m2IG-TtG8LNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa das bibliotecas\n",
        "from sentence_transformers import util\n",
        "\n",
        "#Calcula da similaridade do cosseno entre as sentenças\n",
        "cosine_scores = util.cos_sim(embeddings1, embeddings1)"
      ],
      "metadata": {
        "id": "nhx34AuA8LNL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Procura os pares de sentenças com as maiores similaridades"
      ],
      "metadata": {
        "id": "AgX0OmYE8nvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Encontra os pares de sentenças com as maiores similaridades\n",
        "pairs = []\n",
        "for i in range(len(cosine_scores)-1):\n",
        "    for j in range(i+1, len(cosine_scores)):\n",
        "        pairs.append({'index': [i, j], 'score': cosine_scores[i][j]})\n",
        "\n",
        "#Ordena os resultados da similaridades em ordem descrente\n",
        "pairs = sorted(pairs, key=lambda x: x['score'], reverse=True)"
      ],
      "metadata": {
        "id": "gtgrX5MX8W9n"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostra os pares de sentença"
      ],
      "metadata": {
        "id": "2BUfdkKX9Dml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for pair in pairs[0:20]:\n",
        "    i, j = pair['index']\n",
        "    print(\"{:.4f} => {} \\t\\t {} \\t\\t\".format(pair['score'], sentencas[i], sentencas[j]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcD_Tha-9EzL",
        "outputId": "9732db5d-7e2e-409e-cad0-67c4f783d1fe"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9841 => Como empilhar e desempilhar elementos em uma estrutura de dados pilha? \t\t Como desempilhar elementos em uma estrutura de dados pilha? \t\t\n",
            "0.9836 => Como empilhar elementos em uma estrutura de dados pilha? \t\t Como desempilhar elementos em uma estrutura de dados pilha? \t\t\n",
            "0.9828 => Como empilhar elementos em uma estrutura de dados pilha? \t\t Como empilhar e desempilhar elementos em uma estrutura de dados pilha? \t\t\n",
            "0.9765 => Como empilhar elementos em uma pilha? \t\t Como empilhar e desempilhar elementos em uma pilha? \t\t\n",
            "0.9744 => Como empilhar e desempilhar elementos em uma pilha? \t\t Como desempilhar elementos em uma pilha? \t\t\n",
            "0.9574 => Como empilhar elementos em uma pilha? \t\t Como desempilhar elementos em uma pilha? \t\t\n",
            "0.9563 => Como enfileirar elementos em uma fila? \t\t O que é uma fila e como enfileirar seu elemento? \t\t\n",
            "0.9515 => Como enfileirar elementos em uma fila? \t\t Como desenfileirar elementos em uma fila? \t\t\n",
            "0.9498 => Como empilhar elementos em uma pilha? \t\t O que é uma pilha e como empilhar seu elemento? \t\t\n",
            "0.9451 => O que é uma pilha e como empilhar seu elemento? \t\t O que é uma fila e como enfileirar seu elemento? \t\t\n",
            "0.9423 => Como empilhar e desempilhar elementos em uma pilha? \t\t O que é uma pilha e como empilhar seu elemento? \t\t\n",
            "0.9423 => Como enfileirar elementos em uma fila? \t\t Como empilhar elementos em uma pilha? \t\t\n",
            "0.9289 => Como desenfileirar elementos em uma fila? \t\t Como desempilhar elementos em uma pilha? \t\t\n",
            "0.9287 => Como enfileirar elementos em uma fila? \t\t Como empilhar e desempilhar elementos em uma pilha? \t\t\n",
            "0.9243 => Como desempilhar elementos em uma pilha? \t\t O que é uma pilha e como empilhar seu elemento? \t\t\n",
            "0.9209 => Como empilhar e desempilhar elementos em uma pilha? \t\t Como empilhar e desempilhar elementos em uma estrutura de dados pilha? \t\t\n",
            "0.9160 => Como desenfileirar elementos em uma fila? \t\t Como empilhar e desempilhar elementos em uma pilha? \t\t\n",
            "0.9143 => Como desenfileirar elementos em uma fila? \t\t Como empilhar elementos em uma pilha? \t\t\n",
            "0.9116 => Como enfileirar elementos em uma fila? \t\t Como desempilhar elementos em uma pilha? \t\t\n",
            "0.9101 => Como desenfileirar elementos em uma fila? \t\t O que é uma fila e como enfileirar seu elemento? \t\t\n"
          ]
        }
      ]
    }
  ]
}