{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExemplosPythonBERTTransformers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMZoDI3NX9otZ+9mBaeIc0g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "81c698d967c24a6f9d580eebfc7de638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d388f78aa40f4515bc86f620975716bb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f4cc03f3c80849b0af8ccf46d0b257fb",
              "IPY_MODEL_19f8fb95cf1f448396ae164e3aecafdd"
            ]
          }
        },
        "d388f78aa40f4515bc86f620975716bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4cc03f3c80849b0af8ccf46d0b257fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6038ab40ea0c458981aed4ab13cd9a1d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 434,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 434,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f5a110167104e17b64cd243b08b05e9"
          }
        },
        "19f8fb95cf1f448396ae164e3aecafdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2f186ae4671a41149169db8ce2fece09",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 434/434 [00:00&lt;00:00, 462B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_449e38653aca469eb69b20b34fc7214f"
          }
        },
        "6038ab40ea0c458981aed4ab13cd9a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f5a110167104e17b64cd243b08b05e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f186ae4671a41149169db8ce2fece09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "449e38653aca469eb69b20b34fc7214f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4eaa30cdf7c458aab34002d7bdd1a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7159165567f448e9b107a935f7afd5ff",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_755bdc7472b34440a08ff41d28cad5a1",
              "IPY_MODEL_d95b47461b0e48709a890f50dc59a335"
            ]
          }
        },
        "7159165567f448e9b107a935f7afd5ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "755bdc7472b34440a08ff41d28cad5a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9c8d8430c03f4031b85c76e3c161abfc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1344997306,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1344997306,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7a34a262af1402385bc16c00817a10d"
          }
        },
        "d95b47461b0e48709a890f50dc59a335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_39f7e95889714ca3a4c5fc81fda4cbca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.34G/1.34G [00:51&lt;00:00, 26.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61329cb6348b4fb998b8138613b1284d"
          }
        },
        "9c8d8430c03f4031b85c76e3c161abfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e7a34a262af1402385bc16c00817a10d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "39f7e95889714ca3a4c5fc81fda4cbca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61329cb6348b4fb998b8138613b1284d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "30441d93f6c44417a925ffa21a550916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9960aafc77504cacbf68d6679bc4f647",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1f2f965ef7a849b4a4de3580f582f40d",
              "IPY_MODEL_ad50e43c77b5447c95a739b39a0c3e97"
            ]
          }
        },
        "9960aafc77504cacbf68d6679bc4f647": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f2f965ef7a849b4a4de3580f582f40d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_343ae9c6e0ac4eb2a04e94299cc5f4b8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_581e9d25ead74321ba543e27ccf9c7b9"
          }
        },
        "ad50e43c77b5447c95a739b39a0c3e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_34714666a2024876aa34f542d140a1b6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:08&lt;00:00, 50.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22376b5b307144fb9f42618f2c21bb5a"
          }
        },
        "343ae9c6e0ac4eb2a04e94299cc5f4b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "581e9d25ead74321ba543e27ccf9c7b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34714666a2024876aa34f542d140a1b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22376b5b307144fb9f42618f2c21bb5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8bef9fa2f78b4da98a4945fafbbcd3c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fdeab3a1c1c34b93812ed9bd08b055f9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2fd487fddb214cc8a373686d3b3c9c15",
              "IPY_MODEL_17163beee8784f67ba7ae5ab3b18e3de"
            ]
          }
        },
        "fdeab3a1c1c34b93812ed9bd08b055f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2fd487fddb214cc8a373686d3b3c9c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_85edd1cce82c465ea20ac93bdcc0d783",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1631e89f390247759f1f998242c558e3"
          }
        },
        "17163beee8784f67ba7ae5ab3b18e3de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9f6d7459ba7e47cdb17381a36e9d032b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:07&lt;00:00, 57.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33b0bcc7b5724cafbe2c3a418ea418d0"
          }
        },
        "85edd1cce82c465ea20ac93bdcc0d783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1631e89f390247759f1f998242c558e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f6d7459ba7e47cdb17381a36e9d032b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33b0bcc7b5724cafbe2c3a418ea418d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osmarbraz/exemplos_BERT/blob/main/ExemplosPythonBERTTransformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VTUgBXSzaGh"
      },
      "source": [
        "# Exemplos de uso do BERT in Transformers by Huggingface\n",
        "\n",
        "Funções e exemplos de uso BERT através da biblioteca `Transformer` da [Huggingface](https://huggingface.co/transformers/).\n",
        "\n",
        "- Exemplo de carregamento do tokenizador e modelo através de diretório e da comunidade\n",
        "  - Download do arquivos do modelo \n",
        "  \n",
        "- Função de retorno do tokenizador. \n",
        "- Função de retorno do modelo. \n",
        "- Função de retorno do tokenizador e do modelo. \n",
        "\n",
        "Artigo base do [BERT](https://arxiv.org/pdf/1810.04805.pdf).\n",
        "\n",
        "O tokenizador da BERT utiliza WordPiece, veja em [artigo original](https://arxiv.org/pdf/1609.08144.pdf).\n",
        "\n",
        "-----------------------------------------\n",
        "**Guia Colab Iniciante:**\n",
        "\n",
        "https://medium.com/machina-sapiens/google-colab-guia-do-iniciante-334d70aad531\n",
        "\n",
        "**Documentação oficial:**\n",
        "\n",
        "https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/01.01-Help-And-Documentation.ipynb\n",
        "\n",
        "**Características :**\n",
        "\n",
        "https://colab.research.google.com/notebooks/basic_features_overview.ipynb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOwhoI1lzi-s"
      },
      "source": [
        "# 1 Instalação dos pacotes das biblioteca Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNn1DGlMzNDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d8de4e-2a94-46e1-f0ae-7269c0b489cd"
      },
      "source": [
        "# Instala a última versão da biblioteca\n",
        "!pip install transformers\n",
        "\n",
        "# Instala uma versão específica da biblioteca\n",
        "# !pip install -U transformers==4.5.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsX_7pxMzvhS"
      },
      "source": [
        "# 2 Carregamento do modelo e tokenizador do BERT do Transfomer by Huggingface\n",
        "\n",
        "Os tokenizadores e os modelos PyTorch podem ser carregados diretamente da comunidade ou através do download de arquivos.\n",
        "\n",
        "Independente de onde foi carregado o tokenizador ou o modelo Pytorch existe a dpendência da instalação da biblioteca."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URuijJq7z7Kv"
      },
      "source": [
        "### Carregando BERT da comunidade\n",
        "\n",
        "Lista de **modelos da comunidade** podem ser consultadas em \n",
        "https://huggingface.co/models.\n",
        "\n",
        "Lista dos nomes dos modelos em **português** disponíveis na comunidade (https://github.com/neuralmind-ai/portuguese-bert):  \n",
        "* **'neuralmind/bert-base-portuguese-cased'**\n",
        "* **'neuralmind/bert-large-portuguese-cased'**\n",
        "\n",
        "Lista dos nomes dos modelos em **inglês** disponíveis na comunidade:\n",
        "* **'bert-base-uncased'**\n",
        "* **'bert-large-uncased'**\n",
        "\n",
        "O modelo do tokenizador pode ser acessado de duas formas, ou utilizando as AutoClasses ou Classes Específicas. A seguir as duas formas de carregar o modelo BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XwUuIioozUj"
      },
      "source": [
        "#### AutoClasses\n",
        "\n",
        "As `AutoClasses` recuperam automaticamente o modelo mais relevante, dado o nome/caminho para os pesos/configuração /vocabulário pré-treinados. A API destas classes podem ser consultadas [aqui](https://huggingface.co/transformers/model_doc/auto.html).\n",
        "\n",
        "A classe `AutoTokenizer` identifica a arquitetura a partir do nome ou do caminho do modelo pré-treinado que você está fornecendo ao método from_pretrained.\n",
        "\n",
        "Ao instanciar um  `AutoModel`, `AutoConfig` ou `AutoTokenizer` criará diretamente uma classe da arquitetura relevante, por exemplo:\n",
        "- `tokenizador = AutoTokenizer.from_pretrained('bert-base-cased')` \n",
        "  - criará uma instância de `BertTokenizerr`.\n",
        "- `model = AutoModel.from_pretrained('bert-base-cased')` \n",
        "  - criará uma instância de `BertModel`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jec62Nah0iQI"
      },
      "source": [
        "# Importando as bibliotecas do Modelo e do Tokenizador\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "# Carregando o modelo do tokenizador o modelo do PyTorch da comunidade utilizando AutoClasses\n",
        "\n",
        "# Tokenizador do modelo utilizando as AutoClasses\n",
        "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "\n",
        "# Modelo pré-treinado utilizando as AutoClasses\n",
        "model = AutoModel.from_pretrained('neuralmind/bert-base-portuguese-cased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-gJlnkBo2U5"
      },
      "source": [
        "#### Classes específicas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oi8ez_FNWkR"
      },
      "source": [
        "# Importando as bibliotecas do Modelo e do Tokenizador\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "# Carregando o modelo do tokenizador o modelo do PyTorch da comunidade utilizando classes específicas\n",
        "\n",
        "# Tokenizador do modelo utilizando classe específica\n",
        "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "\n",
        "# Modelo pré-treinado utilizando classe específica\n",
        "model = BertModel.from_pretrained('neuralmind/bert-base-portuguese-cased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wrp2wwYytLDW"
      },
      "source": [
        "### Carregando BERT de diretório(arquivo)\n",
        "\n",
        "O carregamento do BERT a partir de um diretório com os arquivos do tokenizador e do modelo. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c161Lh80z8T2"
      },
      "source": [
        "Os arquivo do modelo devem deve ser colocados na pasta '/content/modelo'.\n",
        "\n",
        "Este arquivo pode ser utilizado tanto pelas classes especificas ou pelas AutoClasses, conforme apresentado na seção 'AutoTokenizer'.\n",
        "\n",
        "Link dos arquivos do modelo BERT pré-treinado em português(pt-br) da neuralmind-ai chamado de [BERTTimbau](https://github.com/neuralmind-ai/portuguese-bert).\n",
        "\n",
        "O BERT em português édisponibilizado em dois tamanhos: **BASE** e **LARGE** e em dois formatos: checkpoint do **TensorFlow** ou do **Pytorch**.\n",
        "\n",
        "O arquivo do **Pytorch** é manipulado pela implementação da biblioteca torch disponível [aqui](https://pytorch.org/docs/stable/torch.html)\n",
        "\n",
        "**BERT Base: 1.1 Gbytes**\n",
        "* **Pytorch Checkpoint(Usado no exemplo)** - https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\n",
        "\n",
        "* **Tensor Flow Checkpoint** - https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_tensorflow_checkpoint.zip\n",
        "\n",
        "* **Vocabulário(Usado no exemplo)** - https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/vocab.txt\n",
        "\n",
        "\n",
        "**BERT Large: 3.2 Gbytes**\n",
        "* **Pytorch Checkpoint** - https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\n",
        "\n",
        "* **Tensor Checkpoint** - https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_tensorflow_checkpoint.zip\n",
        "\n",
        "* **Vocabulário** - https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/vocab.txt\n",
        "\n",
        "-----------------\n",
        "**Correção dos nomes dos arquivos para usar com o BERT as Service:**\n",
        "* 'large'\n",
        "    * model.ckpt-1000000.data-00000-of-00001 > bert_model.ckpt.data-00000-of-00001\n",
        "    * model.ckpt-1000000.index bert_model.ckpt.index\n",
        "    * model.ckpt-1000000.meta > bert_model.ckpt.meta\n",
        "\n",
        "* 'base'\n",
        "    * model.ckpt.data-00000-of-00001> bert_model.ckpt.data-00000-of-00001\n",
        "    * model.ckpt.index > bert_model.ckpt.index\n",
        "    * model.ckpt.meta > bert_model.ckpt.meta\n",
        "-------------------------\n",
        "O modelo foi treinado com dados de **BrWaC** (Brazilian Web as Corpus):\n",
        "\n",
        "https://www.researchgate.net/publication/326303825_The_brWaC_Corpus_A_New_Open_Resource_for_Brazilian_Portuguese\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZGdOSC_lLBh"
      },
      "source": [
        "#### Usando o BERT do diretório"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyhoaQKNaNY7"
      },
      "source": [
        "##### Download do arquivo do Pytorch Checkpoint\n",
        "\n",
        "É necessário realizar o download do arquivo de checkpoint e do vocabulário.\n",
        "\n",
        "O arquivo do checkpoint precisa ser descompactado.\n",
        "\n",
        "Os arquivos do modelo e do vocabulário são movidos para o diretório `modelo`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYTujSE9aNY_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4520711d-21f2-44ea-dbe6-a51824d3d549"
      },
      "source": [
        "# Importando as bibliotecas\n",
        "import os\n",
        "\n",
        "# Comente uma das urls para carregar modelo do BERT de tamanhos diferentes(base/large)\n",
        "# url do arquivo do modelo do Pytorch checkpoint\n",
        "\n",
        "# arquivo menor(base) 1.1 Gbytes\n",
        "# url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "# arquivo grande(large) 3.5 Gbytes\n",
        "url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "      \n",
        "# Recupera o nome do arquivo do modelo da url anterior\n",
        "arquivo = url.split(\"/\")[-1]\n",
        "\n",
        "# Nome do arquivo do vocabulário\n",
        "arquivo_vocab = \"vocab.txt\"\n",
        "\n",
        "# Caminho do arquivo na url\n",
        "caminho = url[0:len(url)-len(arquivo)]\n",
        "\n",
        "# Diretório descompactação do modelo\n",
        "diretorio = '/content/modelo'\n",
        "\n",
        "# Verifica se o diretório do modelo existe a partir do diretório corrente\n",
        "if not os.path.exists(diretorio):\n",
        "   \n",
        "    # Realiza o download do arquivo do tokenizador\n",
        "    !wget $url\n",
        "    \n",
        "    # Descompacta o arquivo no diretório do modelo\n",
        "    !unzip -o $arquivo -d $diretorio\n",
        "\n",
        "    # Realiza o download do arquivo do vocabulário\n",
        "    # O vocabulário não está no arquivo compactado acima\n",
        "    # Concatena o caminho do modelo mais o nome do arquivo do vocabulário\n",
        "    url_vocab = caminho + arquivo_vocab\n",
        "\n",
        "    # Realiza o download do arquivo do vocabulário\n",
        "    !wget $url_vocab\n",
        "    \n",
        "    # Move o arquivo do vocabulário para o diretório do modelo\n",
        "    !mv $arquivo_vocab $diretorio\n",
        "            \n",
        "    # Apaga o arquivo baixado\n",
        "    #!rm $arquivo\n",
        "    \n",
        "    # Move o arquivo do modelo para o diretório do modelo\n",
        "    !mv $arquivo $diretorio\n",
        "    \n",
        "    print('Diretório do modelo:\\'' + diretorio + '\\' pronta!')\n",
        "else:\n",
        "    print('Diretório do modelo:\\'' + diretorio + '\\' já existe!')\n",
        "\n",
        "# Lista o diretório corrente\n",
        "!ls -la"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Diretório do modelo:'/content/modelo' já existe!\n",
            "total 28\n",
            "drwxr-xr-x 1 root root 4096 Feb  2 15:35 .\n",
            "drwxr-xr-x 1 root root 4096 Feb  2 15:08 ..\n",
            "drwxr-xr-x 1 root root 4096 Jan 28 17:15 .config\n",
            "drwxr-xr-x 2 root root 4096 Feb  2 15:13 modelo\n",
            "drwxr-xr-x 2 root root 4096 Feb  2 15:34 modelobase\n",
            "drwxr-xr-x 2 root root 4096 Feb  2 15:35 modelolarge\n",
            "drwxr-xr-x 1 root root 4096 Jan 20 17:27 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gZ7lZaVaEk5"
      },
      "source": [
        "##### Carregando o BERT do diretório\n",
        "\n",
        "Carregando o **tokenizador** e **modelo** BERT do diretório '/content/modelo/' do diretório padrão.\n",
        "\n",
        "A implementação do huggingface pytorch inclui um conjunto de interfaces projetadas para uma variedade de tarefas de PNL. Embora essas interfaces sejam todas construídas sobre um modelo treinado de BERT, cada uma possui diferentes camadas superiores e tipos de saída projetados para acomodar suas tarefas específicas de PNL.\n",
        "\n",
        "Aqui está a lista atual de classes fornecidas para o ajuste fino:\n",
        "* BertModel\n",
        "* BertForPreTraining\n",
        "* BertForMaskedLM\n",
        "* BertForNextSentencePrediction\n",
        "* BertForSequenceClassification\n",
        "* BertForTokenClassification\n",
        "* BertForQuestionAnswering\n",
        "\n",
        "A documentação para estas pode ser encontrada em [aqui](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyA4PFN6aNZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb340569-c3ce-4fa1-d5fd-71da42433688"
      },
      "source": [
        "# Importando as bibliotecas do Modelo e do Tokenizador\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "# Carregando o modelo do tokenizador o modelo do PyTorch do diretório  utilizando classes específicas\n",
        "\n",
        "print('Carregando o tokenizador BERT do diretório \\'' + diretorio + '\\'...')\n",
        "\n",
        "# Tokenizador do modelo utilizando classe específica\n",
        "tokenizer = BertTokenizer.from_pretrained('/content/modelo/', \n",
        "                                          do_lower_case=False)\n",
        "\n",
        "print('Carregando o modelo BERT do diretório \\'' + diretorio + '\\'...')\n",
        "\n",
        "# Modelo pré-treinado utilizando classe específica\n",
        "model = BertModel.from_pretrained('/content/modelo/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT do diretório '/content/modelo'...\n",
            "Carregando o modelo BERT do diretório '/content/modelo'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAm-Or2D0M0k"
      },
      "source": [
        "## Exemplos de formas de carregamento do BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udxdl4qklY--"
      },
      "source": [
        "#### Usando o BERT da comunidade ou diretório v1\n",
        "\n",
        "Permite configurar a **fonte do modelo**.\n",
        "\n",
        "A variável `url` setada especifica que o BERT deve ser carregado de um diretório, caso contrário da comunidade."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXm3x84klfRN"
      },
      "source": [
        "##### Download do arquivo do Pytorch Checkpoint\n",
        "\n",
        "É necessário realizar o download do arquivo de checkpoint e do vocabulário.\n",
        "\n",
        "O arquivo do checkpoint precisa ser descompactado.\n",
        "\n",
        "Os arquivos do modelo e do vocabulário são movidos para o diretório `modelo`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtzDkSAYlfs1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab4a5a39-3275-46db-f441-50bea2b4bb0e"
      },
      "source": [
        "# Importando as bibliotecas\n",
        "import os\n",
        "\n",
        "# Variável para setar o tamanho do arquivo do BERT(base ou large)\n",
        "url = None\n",
        "\n",
        "# Comente uma das urls para carregar modelo do BERT de tamanhos diferentes(base/large)\n",
        "# url do arquivo do modelo do Pytorch checkpoint\n",
        "\n",
        "# arquivo menor(base) 1.1 Gbytes\n",
        "# url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "# arquivo grande(large) 3.5 Gbytes\n",
        "# url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "# Se a variável foi setada\n",
        "if url:\n",
        "\n",
        "    # Diretório descompactação do modelo\n",
        "    diretorio = '/content/modelo'\n",
        "\n",
        "    # Recupera o nome do arquivo do modelo da url anterior\n",
        "    arquivo = url.split(\"/\")[-1]\n",
        "\n",
        "    # Nome do arquivo do vocabulário\n",
        "    arquivo_vocab = \"vocab.txt\"\n",
        "\n",
        "    # Caminho do arquivo na url\n",
        "    caminho = url[0:len(url)-len(arquivo)]\n",
        "\n",
        "    # Verifica se a pasta de descompactação existe no pasta corrente\n",
        "    if not os.path.exists(diretorio):\n",
        "   \n",
        "        # Realiza o download do arquivo do modelo\n",
        "        !wget $url\n",
        "    \n",
        "        # Descompacta o arquivo na pasta de destino\n",
        "        !unzip -o $arquivo -d $diretorio\n",
        "\n",
        "        # Realiza o download do arquivo do vocabulário\n",
        "        # O vocabulário não está no arquivo compactado acima\n",
        "        # Concatena o caminho do modelo mais o nome do arquivo do vocabulário\n",
        "        url_vocab = caminho + arquivo_vocab\n",
        "\n",
        "        # Realiza o download do arquivo do vocabulário\n",
        "        !wget $url_vocab\n",
        "    \n",
        "        # Move o arquivo do vocabulário para o diretório do modelo\n",
        "        !mv $arquivo_vocab $diretorio\n",
        "            \n",
        "        # Move o arquivo do modelo para o diretório do modelo\n",
        "        !mv $arquivo $diretorio\n",
        "        \n",
        "        print('Diretório do modelo:\\'' + diretorio + '\\' pronta!')\n",
        "    else:      \n",
        "      print('Diretório do modelo:\\'' + diretorio + '\\' já existe!')\n",
        "\n",
        "    #lista a pasta corrente\n",
        "    !ls -la $diretorio\n",
        "else:\n",
        "    print('Variável url não setada!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Variável url não setada!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2VmlSXMgUiU"
      },
      "source": [
        "##### Carregando o BERT\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR3LKinp7GiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bf739e2-f07e-4130-8c29-334b97a27551"
      },
      "source": [
        "# Importando as bibliotecas do Modelo e do Tokenizador\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "# Se a variável url foi setada\n",
        "if url:\n",
        "    # Carregando o Tokenizador do diretório\n",
        "    print('Carregando o tokenizador BERT do diretório \\'' + diretorio + '\\'...')\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(diretorio)\n",
        "\n",
        "    # Carregano o Modelo do diretório\n",
        "    print('Carregando o modelo BERT do diretório \\'' + diretorio + '\\'...')\n",
        "\n",
        "    model = BertModel.from_pretrained(diretorio, \n",
        "                                      do_lower_case=False)\n",
        "\n",
        "else:\n",
        "    # Carregando o Tokenizador da comunidade\n",
        "    print('Carregando o tokenizador BERT da comunidade...')\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', \n",
        "                                              do_lower_case=False)\n",
        "\n",
        "    # Carregando o Modelo da comunidade\n",
        "    print('Carregando o modelo BERT da comunidade...')\n",
        "\n",
        "    model = BertModel.from_pretrained('neuralmind/bert-base-portuguese-cased')  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT da comunidade...\n",
            "Carregando o modelo BERT da comunidade...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snDFb_WBpItd"
      },
      "source": [
        "#### Usando o BERT da comunidade ou diretório v2\n",
        "\n",
        "Permite configurar o **tamanho do modelo** e a **fonte do modelo**.\n",
        "\n",
        "A variável `fonteBERT` com os valores `comunidade` ou `diretório` especifica se deve ser carregado o BERT de um diretório ou da comunidade.\n",
        "\n",
        "A variável `tamanhoBERT` com os valores `base` ou `large` especifica se o tamanho do modelo BERT a ser utilizado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nj1KS8xCpIte"
      },
      "source": [
        "##### Download do arquivo do Pytorch Checkpoint\n",
        "\n",
        "É necessário realizar o download do arquivo de checkpoint e do vocabulário.\n",
        "\n",
        "O arquivo do checkpoint precisa ser descompactado.\n",
        "\n",
        "Os arquivos do modelo e do vocabulário são movidos para o diretório `modelo`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gab02A0pIte",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57a877a5-b362-4f78-c5c5-6448d09c8171"
      },
      "source": [
        "# Importando as bibliotecas\n",
        "import os\n",
        "\n",
        "# Variável fonte especifica a origem do modelo(comunidade ou diretório)\n",
        "#fonteBERT = 'comunidade'\n",
        "fonteBERT = 'diretorio'\n",
        "\n",
        "# Especifica o tamanho do modelo a ser carregado(base ou large)\n",
        "tamanhoBERT = 'large'\n",
        "#tamanhoBERT = 'base'\n",
        "\n",
        "# Se a variável 'fonteBERT' foi setada para 'diretorio' faz o download dos arquivos modelo\n",
        "if fonteBERT == 'diretorio':\n",
        "    \n",
        "    # Se a variável 'tamanhoBERT' foi setada para 'base' faz o download do arquivo do tamanho base do BERT, caso contrário do large.\n",
        "    if tamanhoBERT == 'base':\n",
        "        # url do arquivo do modelo do Pytorch checkpoint\n",
        "        # arquivo menor(base) 1.1 Gbytes\n",
        "        url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "    else:\n",
        "        # url do arquivo do modelo do Pytorch checkpoint\n",
        "        # arquivo grande(large) 3.5 Gbytes\n",
        "        url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "    # Diretório descompactação do modelo\n",
        "    diretorio = '/content/modelo'\n",
        "\n",
        "    # Recupera o nome do arquivo do modelo da url anterior\n",
        "    arquivo = url.split(\"/\")[-1]\n",
        "\n",
        "    # Nome do arquivo do vocabulário\n",
        "    arquivo_vocab = \"vocab.txt\"\n",
        "\n",
        "    # Caminho do arquivo na url\n",
        "    caminho = url[0:len(url)-len(arquivo)]\n",
        "\n",
        "    # Verifica se a pasta de descompactação existe no pasta corrente\n",
        "    if not os.path.exists(diretorio):\n",
        "   \n",
        "        # Realiza o download do arquivo do modelo\n",
        "        !wget $url\n",
        "    \n",
        "        # Descompacta o arquivo na pasta de destino\n",
        "        !unzip -o $arquivo -d $diretorio\n",
        "\n",
        "        # Realiza o download do arquivo do vocabulário\n",
        "        # O vocabulário não está no arquivo compactado acima\n",
        "        # Concatena o caminho do modelo mais o nome do arquivo do vocabulário\n",
        "        url_vocab = caminho + arquivo_vocab\n",
        "\n",
        "        # Realiza o download do arquivo do vocabulário\n",
        "        !wget $url_vocab\n",
        "    \n",
        "        # Move o arquivo do vocabulário para o diretório do modelo\n",
        "        !mv $arquivo_vocab $diretorio\n",
        "            \n",
        "        # Move o arquivo do modelo para o diretório do modelo\n",
        "        !mv $arquivo $diretorio      \n",
        "                \n",
        "        print('Diretório do modelo:\\'' + diretorio + '\\' pronta!')\n",
        "    else:      \n",
        "      print('Diretório do modelo:\\'' + diretorio + '\\' já existe!')\n",
        "\n",
        "    #lista a pasta corrente\n",
        "    !ls -la $diretorio\n",
        "else:\n",
        "    print('Será carregado o BERT da comunidade')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Diretório do modelo:'/content/modelo' já existe!\n",
            "total 2525908\n",
            "drwxr-xr-x 2 root root       4096 Feb  2 15:13 .\n",
            "drwxr-xr-x 1 root root       4096 Feb  2 15:35 ..\n",
            "-rw-r--r-- 1 root root 1244275810 Jan 22  2020 bert-large-portuguese-cased_pytorch_checkpoint.zip\n",
            "-rw-rw-r-- 1 root root        874 Jan 12  2020 config.json\n",
            "-rw-rw-r-- 1 root root 1342014951 Jan 12  2020 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root     209528 Jan 21  2020 vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stZE-KdbpIti"
      },
      "source": [
        "##### Carregando o BERT\n",
        "\n",
        "Carregando o **tokenizador** e **modelo** BERT do diretório '/content/modelo/' do diretório padrão.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbdpa5IzpItj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af5878c2-9bac-476e-867d-a6606736ff3f"
      },
      "source": [
        "# Importando as bibliotecas do Modelo e do Tokenizador\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "# Se a variável 'fonteBERT' foi setada para 'diretorio' faz o download dos arquivos modelo\n",
        "if fonteBERT == 'diretorio':\n",
        "\n",
        "    # Carregando o Tokenizador do diretório\n",
        "    print('Carregando o tokenizador BERT_' + tamanhoBERT + ' do diretório ' + diretorio + '...')\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(diretorio,\n",
        "                                              do_lower_case=False)   \n",
        "\n",
        "    # Carregando o Modelo do diretório\n",
        "    print('Carregando o modelo BERT_' + tamanhoBERT + ' do diretório ' + diretorio + '...')\n",
        "\n",
        "    model = BertModel.from_pretrained(diretorio)\n",
        "\n",
        "else:\n",
        "    # Se a variável 'tamanhoBERT' foi setada para 'base' faz o carregamento do tamanho base do BERT, caso contrário do large.\n",
        "    if tamanhoBERT == 'base':\n",
        "        # Carregando o Tokenizador da comunidade\n",
        "        print('Carregando o tokenizador BERT_base da comunidade...')\n",
        "\n",
        "        tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', \n",
        "                                                  do_lower_case=False)\n",
        "\n",
        "        # Carregando o Modelo da comunidade\n",
        "        print('Carregando o modelo BERT_base da comunidade...')\n",
        "\n",
        "        model = BertModel.from_pretrained('neuralmind/bert-base-portuguese-cased')  \n",
        "    else:\n",
        "        # Carregando o Tokenizador da comunidade  \n",
        "        print('Carregando o tokenizador BERT_large da comunidade...')\n",
        "\n",
        "        tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-large-portuguese-cased',\n",
        "                                                  do_lower_case=False)\n",
        "\n",
        "        # Carregando o Modelo da comunidade\n",
        "        print('Carregando o modelo BERT_large da comunidade...')\n",
        "\n",
        "        model = BertModel.from_pretrained('neuralmind/bert-large-portuguese-cased')  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT_large do diretório /content/modelo...\n",
            "Carregando o modelo BERT_large do diretório /content/modelo...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaBm0YHY4lsf"
      },
      "source": [
        "#### \\>>> Usando o BERT da comunidade ou diretório v3 <<<\n",
        "\n",
        "Permite configurar o **tamanho do modelo**, **fonte do modelo** e **se deve retornar os pesos das camadas ocultas**.\n",
        "\n",
        "A variável `fonteBERT` com os valores `comunidade` ou `diretório` especifica se deve ser carregado o BERT de um diretório ou da comunidade.\n",
        "\n",
        "A variável `tamanhoBERT` com os valores `base` ou `large` especifica se o tamanho do modelo BERT a ser utilizado.\n",
        "\n",
        "A variável `pesosCamadasOcultas` com os valores `True` ou `False` especifica se é para gerar e retornar os pesos das camadas ocultas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiZcK9JU4lsj"
      },
      "source": [
        "##### Download do arquivo do Pytorch Checkpoint\n",
        "\n",
        "É necessário realizar o download do arquivo de checkpoint e do vocabulário.\n",
        "\n",
        "O arquivo do checkpoint precisa ser descompactado.\n",
        "\n",
        "Os arquivos do modelo e do vocabulário são movidos para o diretório `modelo`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k4sP3yZ4lsm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d55dc28d-4175-491b-d10f-5180eb58a300"
      },
      "source": [
        "# Importando as bibliotecas\n",
        "import os\n",
        "\n",
        "# Variável fonte especifica a origem do modelo(comunidade ou diretório)\n",
        "#fonteBERT = 'comunidade'\n",
        "fonteBERT = 'diretorio'\n",
        "\n",
        "# Especifica o tamanho do modelo a ser carregado(base ou large)\n",
        "tamanhoBERT = 'large'\n",
        "#tamanhoBERT = 'base'\n",
        "\n",
        "# Especifica se o modelo deve ser carregado com os pesos das camadas ocultas(True ou False)\n",
        "pesosCamadasOcultas = False\n",
        "\n",
        "# Se a variável 'fonteBERT' foi setada para 'diretorio' faz o download dos arquivos modelo\n",
        "if fonteBERT == 'diretorio':\n",
        "    \n",
        "    # Se a variável 'tamanhoBERT' foi setada para 'base' faz o download do arquivo do tamanho base do BERT, caso contrário do large.\n",
        "    if tamanhoBERT == 'base':\n",
        "        # url do arquivo do modelo do Pytorch checkpoint\n",
        "        # arquivo menor(base) 1.1 Gbytes\n",
        "        url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "    else:\n",
        "        # url do arquivo do modelo do Pytorch checkpoint\n",
        "        # arquivo grande(large) 3.5 Gbytes\n",
        "        url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "    # Diretório descompactação do modelo\n",
        "    diretorio = '/content/modelo'\n",
        "\n",
        "    # Recupera o nome do arquivo do modelo da url anterior\n",
        "    arquivo = url.split(\"/\")[-1]\n",
        "\n",
        "    # Nome do arquivo do vocabulário\n",
        "    arquivo_vocab = \"vocab.txt\"\n",
        "\n",
        "    # Caminho do arquivo na url\n",
        "    caminho = url[0:len(url)-len(arquivo)]\n",
        "\n",
        "    # Verifica se a pasta de descompactação existe no pasta corrente\n",
        "    if not os.path.exists(diretorio):\n",
        "   \n",
        "        # Realiza o download do arquivo do modelo\n",
        "        !wget $url\n",
        "    \n",
        "        # Descompacta o arquivo na pasta de destino\n",
        "        !unzip -o $arquivo -d $diretorio\n",
        "\n",
        "        # Realiza o download do arquivo do vocabulário\n",
        "        # O vocabulário não está no arquivo compactado acima\n",
        "        # Concatena o caminho do modelo mais o nome do arquivo do vocabulário\n",
        "        url_vocab = caminho + arquivo_vocab\n",
        "\n",
        "        # Realiza o download do arquivo do vocabulário\n",
        "        !wget $url_vocab\n",
        "    \n",
        "        # Move o arquivo do vocabulário para o diretório do modelo\n",
        "        !mv $arquivo_vocab $diretorio\n",
        "            \n",
        "        # Move o arquivo do modelo para o diretório do modelo\n",
        "        !mv $arquivo $diretorio      \n",
        "                \n",
        "        print('Diretório do modelo:\\'' + diretorio + '\\' pronta!')\n",
        "    else:      \n",
        "      print('Diretório do modelo:\\'' + diretorio + '\\' já existe!')\n",
        "\n",
        "    #lista a pasta corrente\n",
        "    !ls -la $diretorio\n",
        "else:\n",
        "    print('Será carregado o BERT da comunidade')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Diretório do modelo:'/content/modelo' já existe!\n",
            "total 2525908\n",
            "drwxr-xr-x 2 root root       4096 Feb  2 15:13 .\n",
            "drwxr-xr-x 1 root root       4096 Feb  2 15:35 ..\n",
            "-rw-r--r-- 1 root root 1244275810 Jan 22  2020 bert-large-portuguese-cased_pytorch_checkpoint.zip\n",
            "-rw-rw-r-- 1 root root        874 Jan 12  2020 config.json\n",
            "-rw-rw-r-- 1 root root 1342014951 Jan 12  2020 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root     209528 Jan 21  2020 vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu-MjBcD4ls3"
      },
      "source": [
        "##### Carregando o BERT\n",
        "\n",
        "Carregando o **tokenizador** e **modelo** BERT do diretório '/content/modelo/' do diretório padrão.\n",
        "\n",
        "O tokenizador utiliza WordPiece, veja em [artigo original](https://arxiv.org/pdf/1609.08144.pdf).\n",
        "\n",
        "Carregando o tokenizador da pasta '/content/modelo/' do diretório padrão se variável `url` setada.\n",
        "\n",
        "**Caso contrário carrega da comunidade**\n",
        "\n",
        "Por default(`do_lower_case=True`) todas as letras são colocadas para minúsculas. Para ignorar a conversão para minúsculo use o parâmetro `do_lower_case=False`. Esta opção também considera as letras acentuadas(ãçéí...), que são necessárias a língua portuguesa.\n",
        "\n",
        "O parâmetro `do_lower_case` interfere na quantidade tokens a ser gerado apartir de um texto. Quando igual a `False` reduz a quantidade de tokens gerados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMivq-Lk4ls5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a3c2175-b635-47ad-c4a1-3087509cdc43"
      },
      "source": [
        "# Importando as bibliotecas do Modelo e do Tokenizador\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "# Se a variável 'fonteBERT' foi setada para 'diretorio' faz o download dos arquivos modelo\n",
        "if fonteBERT == 'diretorio':\n",
        "\n",
        "    # Carregando o Tokenizador do diretório\n",
        "    print('Carregando o tokenizador BERT_' + tamanhoBERT + ' do diretório ' + diretorio + '...')\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(diretorio,\n",
        "                                               do_lower_case=False)   \n",
        "\n",
        "    # Carregando o Modelo do diretório\n",
        "    print('Carregando o modelo BERT_' + tamanhoBERT + ' do diretório ' + diretorio + '...')\n",
        "\n",
        "    model = BertModel.from_pretrained(diretorio,\n",
        "                                      output_hidden_states = pesosCamadasOcultas) # Se o modelo retorna todos os estados ocultos)\n",
        "\n",
        "else:\n",
        "    # Se a variável 'tamanhoBERT' foi setada para 'base' faz o carregamento do tamanho base do BERT, caso contrário do large.\n",
        "    if tamanhoBERT == 'base':\n",
        "        # Carregando o Tokenizador da comunidade\n",
        "        print('Carregando o tokenizador BERT_base da comunidade...')\n",
        "\n",
        "        tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased',\n",
        "                                                   do_lower_case=False)     \n",
        "\n",
        "        # Carregando o Modelo da comunidade\n",
        "        print('Carregando o modelo BERT_base da comunidade...')\n",
        "\n",
        "        model = BertModel.from_pretrained('neuralmind/bert-base-portuguese-cased', \n",
        "                                          output_hidden_states = pesosCamadasOcultas) # Se o modelo retorna todos os estados ocultos)  \n",
        "    else:\n",
        "        # Carregando o Tokenizador da comunidade  \n",
        "        print('Carregando o tokenizador BERT_large da comunidade...')\n",
        "\n",
        "        tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-large-portuguese-cased',\n",
        "                                                   do_lower_case=False)     \n",
        "\n",
        "        # Carregando o Modelo da comunidade\n",
        "        print('Carregando o modelo BERT_large da comunidade...')\n",
        "\n",
        "        model = BertModel.from_pretrained('neuralmind/bert-large-portuguese-cased', \n",
        "                                          output_hidden_states = pesosCamadasOcultas) # Se o modelo retorna todos os estados ocultos)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT_large do diretório /content/modelo...\n",
            "Carregando o modelo BERT_large do diretório /content/modelo...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7NXsoTTC9rf"
      },
      "source": [
        "#### Usando o BERT da comunidade ou diretório  com uma função que retorna o tokenizador v4\n",
        "\n",
        "Função que retorna o tokenizador do BERT. permite configurar o tamanho do modelo e a fonte do modelo. \n",
        "\n",
        "A linguagem do modelo é especificada internamente na função.\n",
        "\n",
        "O parâmetro  `fonteBERT` com os valores `comunidade` ou `diretório` especifica se deve ser carregado o BERT de um diretório ou da comunidade.\n",
        "\n",
        "O parâmetro `tamanhoBERT` com os valores `base` ou `large` especifica se o tamanho do modelo BERT a ser utilizado.\n",
        "\n",
        "O parâmetro `lingua` com os valores `portugues` ou `ingles` especifica a lingua do modelo BERT a ser utilizado.\n",
        "\n",
        "O parâmetro `do_lower_case` específica para colocar as letras em maiúsculo ou minísculo e a remoção das letras acentuadas. Nesta função o default `False` pois a língua portugues possui letras acentuadas(ãçéí...), que são necessárias a língua portuguesa. No método `from_treina from_pretrained` o default é `True` quando o parämetro não é especificado.\n",
        "\n",
        "A função retorna o **tokenizador** para os parâmetros especificado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCyv5sfgC9rg"
      },
      "source": [
        "##### Declarando uma função que retorna o tokenizador."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1siflk0C9rh"
      },
      "source": [
        "# Valores default para os parâmetros da função\n",
        "def getTokenizadorBERT(fonteBERT = 'comunidade', \n",
        "                       tamanhoBERT = 'base', \n",
        "                       linguaBERT = 'portugues',\n",
        "                       do_lower_case = False):\n",
        "\n",
        "    \"\"\"Retorna o tokenizador BERT carregado.\n",
        "    De acordo com os parâmetros especificados ou carrega o BERT da comunidade \n",
        "    ou realiza o download dos arquivos do modelo.\n",
        "\n",
        "    Args:\n",
        "        fonteBERT: Especifica a origem do modelo do BERT 'comunidade' ou 'diretorio'.\n",
        "        tamanhoBERT: Especifica o tamanho do modelo do BERT 'large' ou 'base'.\n",
        "        linguaBERT: Especifica a língua do modelo do BERT 'portugues' ou 'ingles'.\n",
        "\n",
        "    Returns:\n",
        "        `tokenizador` com o tokenizador do modelo BERT carregado.       \n",
        "    \"\"\"\n",
        "    #======================================================================\n",
        "    # Verificação do idioma e tamanho do modelo\n",
        "    #======================================================================\n",
        "    # Verifica se a língua é português e o tamanho do modelo\n",
        "    if linguaBERT == 'portugues' and tamanhoBERT == 'base':\n",
        "        nome_modelo_bert = 'neuralmind/bert-base-portuguese-cased'\n",
        "    else:\n",
        "        if linguaBERT == 'portugues' and tamanhoBERT == 'large':\n",
        "            nome_modelo_bert = 'neuralmind/bert-large-portuguese-cased'\n",
        "        else:\n",
        "            # Verifica se a língua é inglés e o tamanho do modelo\n",
        "            if linguaBERT == 'ingles' and tamanhoBERT == 'base':\n",
        "                nome_modelo_bert = 'bert-base-uncased'\n",
        "            else:\n",
        "                if linguaBERT == 'ingles' and tamanhoBERT == 'large':\n",
        "                    nome_modelo_bert = 'bert-large-uncased'\n",
        "                else:\n",
        "                    print(\"Parâmetros \\'língua\\' e \\'tamanhoBERT\\' especificados incorretamente!\")\n",
        "                    return None, None\n",
        "\n",
        "    #======================================================================\n",
        "    # Download do arquivo do modelo\n",
        "    #======================================================================\n",
        "    #Se a variável 'fonteBERT' foi setada para 'diretorio' faz o download dos arquivos modelo\n",
        "    if fonteBERT == 'diretorio' and linguaBERT == 'portugues':\n",
        "    \n",
        "      # Se a variável 'tamanhoBERT' foi setada para 'base' faz o download do arquivo do tamanho base do BERT, caso contrário do large.\n",
        "      if tamanhoBERT == 'base':\n",
        "          # url do arquivo do modelo do Pytorch checkpoint\n",
        "          # arquivo menor(base) 1.1 Gbytes\n",
        "          url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "      else:\n",
        "          # url do arquivo do modelo do Pytorch checkpoint\n",
        "          # arquivo grande(large) 3.5 Gbytes\n",
        "          url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "      # Diretório descompactação do modelo\n",
        "      diretorio = '/content/modelo' + tamanhoBERT\n",
        "\n",
        "      # Recupera o nome do arquivo do modelo da url anterior\n",
        "      arquivo = url.split(\"/\")[-1]\n",
        "\n",
        "      # Nome do arquivo do vocabulário\n",
        "      arquivo_vocab = \"vocab.txt\"\n",
        "\n",
        "      # Caminho do arquivo na url\n",
        "      caminho = url[0:len(url)-len(arquivo)]\n",
        "\n",
        "      # Verifica se a pasta de descompactação existe no pasta corrente\n",
        "      if not os.path.exists(diretorio):\n",
        "   \n",
        "          # Realiza o download do arquivo do modelo\n",
        "          !wget $url\n",
        "    \n",
        "          # Descompacta o arquivo na pasta de destino\n",
        "          !unzip -o $arquivo -d $diretorio\n",
        "\n",
        "          # Realiza o download do arquivo do vocabulário\n",
        "          # O vocabulário não está no arquivo compactado acima\n",
        "          # Concatena o caminho do modelo mais o nome do arquivo do vocabulário\n",
        "          url_vocab = caminho + arquivo_vocab\n",
        "\n",
        "          # Realiza o download do arquivo do vocabulário\n",
        "          !wget $url_vocab\n",
        "    \n",
        "          # Move o arquivo do vocabulário para o diretório do modelo\n",
        "          !mv $arquivo_vocab $diretorio\n",
        "            \n",
        "          # Move o arquivo do modelo para o diretório do modelo\n",
        "          !mv $arquivo $diretorio      \n",
        "                \n",
        "          print('Diretório do modelo:\\'' + diretorio + '\\' pronta!')\n",
        "      else:      \n",
        "          print('Diretório do modelo:\\'' + diretorio + '\\' já existe!')\n",
        "      \n",
        "    else:\n",
        "        if linguaBERT == 'ingles':\n",
        "            print('O modelo BERT na língua inglesa deve ser carregado somente da comunidade.')\n",
        "       \n",
        "    #======================================================================\n",
        "    # Carregamento do tokenizador\n",
        "    #======================================================================\n",
        "\n",
        "    # Importando as bibliotecas do Tokenizador\n",
        "    from transformers import BertTokenizer\n",
        "\n",
        "    # Se a variável 'fonteBERT' foi setada para 'diretorio' faz o download dos arquivos modelo\n",
        "    # Carregamento de diretório somente para a língua portuguesa\n",
        "    if fonteBERT == 'diretorio' and linguaBERT == 'portugues':\n",
        "\n",
        "        # Carregando o Tokenizador do diretório\n",
        "        print('Carregando o tokenizador BERT_' + tamanhoBERT \n",
        "              + ' do diretório \\'' + diretorio \n",
        "              + '\\' em língua \\''+ linguaBERT + '\\'...')\n",
        "\n",
        "        tokenizer = BertTokenizer.from_pretrained(diretorio,\n",
        "                                                  do_lower_case=do_lower_case)\n",
        "    else:\n",
        "        # Carregando o Tokenizador da comunidade\n",
        "        print('Carregando o tokenizador BERT \\'' + nome_modelo_bert \n",
        "              + '\\' da comunidade em língua \\''+ linguaBERT + '\\'...')\n",
        "\n",
        "        tokenizer = BertTokenizer.from_pretrained(nome_modelo_bert,\n",
        "                                                  do_lower_case=do_lower_case)\n",
        "\n",
        "    # Retorna o tokenizador BERT carregado           \n",
        "    return tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MemXlw5fC9rl"
      },
      "source": [
        "##### Usando a função **getTokenizadorBERT()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2dSJJQsC9rl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd7cfdab-2c42-462e-9d7c-8089abeca773"
      },
      "source": [
        "tokenizador = getTokenizadorBERT()\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK9EVQjTC9ro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a11dc0f3-8d59-420c-f20a-7de45262d17c"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(tamanhoBERT='large')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-large-portuguese-cased' da comunidade em língua 'portugues'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pylw2QuC9rr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c442611-792f-4198-e7f3-b8f792e2680b"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(tamanhoBERT='base')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JZqO28VC9rt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "321a3372-b5c2-4a97-b446-aa254983e117"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(fonteBERT='diretorio', \n",
        "                      tamanhoBERT='base')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Diretório do modelo:'/content/modelobase' já existe!\n",
            "Carregando o tokenizador BERT_base do diretório '/content/modelobase' em língua 'portugues'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxPhkiHgC9rw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6feb3e09-9c90-4ed4-d404-fb92d131ebb9"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(fonteBERT='diretorio', \n",
        "                      tamanhoBERT='large', \n",
        "                      linguaBERT='portugues')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Diretório do modelo:'/content/modelolarge' já existe!\n",
            "Carregando o tokenizador BERT_large do diretório '/content/modelolarge' em língua 'portugues'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch9g2K7JC9ry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c61767c2-bbc5-494d-92d2-ecb81f8f1bfe"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(fonteBERT='diretorio', \n",
        "                                 tamanhoBERT='base', \n",
        "                                 linguaBERT='portugues')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Diretório do modelo:'/content/modelobase' já existe!\n",
            "Carregando o tokenizador BERT_base do diretório '/content/modelobase' em língua 'portugues'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqAOEy4KC9r1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53296b3f-0f52-4ac2-c349-6ea5eb455b9e"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(fonteBERT='comunidade', \n",
        "                      tamanhoBERT='large', \n",
        "                      linguaBERT='portugues')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-large-portuguese-cased' da comunidade em língua 'portugues'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yZilzc7C9r3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d996ad3a-af5f-4048-9a21-9c41a145ff8c"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(fonteBERT='comunidade', \n",
        "                                 tamanhoBERT='base', \n",
        "                                 linguaBERT='portugues')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmcpd7bgC9r7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94963224-4e91-4080-e34f-de069cb45bbf"
      },
      "source": [
        "tokenizador  = getTokenizadorBERT(tamanhoBERT='large', \n",
        "                                  linguaBERT='ingles')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na língua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-large-uncased' da comunidade em língua 'ingles'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtLgJEEGC9r-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68a27fa8-59ce-4918-e627-693a2bb720b9"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(tamanhoBERT='base', \n",
        "                                 linguaBERT='ingles')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na língua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-base-uncased' da comunidade em língua 'ingles'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IxywOwUC9sA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8310546-69c3-42ca-db9a-8fd98643bc42"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(fonteBERT='diretorio', \n",
        "                                tamanhoBERT='large', \n",
        "                                linguaBERT='ingles')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na língua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-large-uncased' da comunidade em língua 'ingles'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoH_mQBaC9sC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c896ed11-9c2f-4a79-8bcb-a4ebf0283715"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(fonteBERT='diretorio', \n",
        "                                 tamanhoBERT='base', \n",
        "                                 linguaBERT='ingles')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na língua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-base-uncased' da comunidade em língua 'ingles'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsVXks6PC9sE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2681c1e8-ce71-4875-9ba1-739f647c02e2"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(fonteBERT='comunidade', \n",
        "                                 tamanhoBERT='large', \n",
        "                                 linguaBERT='ingles')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na língua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-large-uncased' da comunidade em língua 'ingles'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ1NiUxgC9sH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5a74f02-265e-44bb-a39e-5163377bb740"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(fonteBERT='comunidade', \n",
        "                                 tamanhoBERT='base', \n",
        "                                 linguaBERT='ingles') \n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na língua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-base-uncased' da comunidade em língua 'ingles'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiwRA1m9C9sQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cf9652b-67e5-4f2b-923b-ce8568729f14"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3381"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnCNWElNFi49"
      },
      "source": [
        "#### Usando o BERT da comunidade ou diretório com uma função que retorna o modelo v5\n",
        "\n",
        "Função que retorna modelo do BERT. permite configurar o tamanho do modelo e a fonte do modelo. \n",
        "\n",
        "A linguagem do modelo é especificada internamente na função.\n",
        "\n",
        "O parâmetro  `fonteBERT` com os valores `comunidade` ou `diretório` especifica se deve ser carregado o BERT de um diretório ou da comunidade.\n",
        "\n",
        "O parâmetro `tamanhoBERT` com os valores `base` ou `large` especifica se o tamanho do modelo BERT a ser utilizado.\n",
        "\n",
        "O parâmetro `lingua` com os valores `portugues` ou `ingles` especifica a lingua do modelo BERT a ser utilizado.\n",
        "\n",
        "O parâmetro `pesosCamadasOcultas` com os valores `True` ou `False` especifica se é para gerar e retornar os pesos das camadas ocultas.\n",
        "\n",
        "A função retorna o **modelo** para os parâmetros especificado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_HNay2hFi49"
      },
      "source": [
        "##### Declarando uma função que retorna o modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEu7UM89Fi4-"
      },
      "source": [
        "# Valores default para os parâmetros da função\n",
        "def getModeloBERT(fonteBERT = 'comunidade', \n",
        "                  tamanhoBERT = 'base', \n",
        "                  linguaBERT = 'portugues', \n",
        "                  pesosCamadasOcultas = False):\n",
        "\n",
        "    \"\"\"Retorna o modelo BERT carregado.\n",
        "    De acordo com os parâmetros especificados ou carrega o BERT da comunidade \n",
        "    ou realiza o download dos arquivos do modelo.\n",
        "\n",
        "    Args:\n",
        "        fonteBERT: Especifica a origem do modelo do BERT 'comunidade' ou 'diretorio'.\n",
        "        tamanhoBERT: Especifica o tamanho do modelo do BERT 'large' ou 'base'.\n",
        "        linguaBERT: Especifica a língua do modelo do BERT 'portugues' ou 'ingles'.\n",
        "        pesosCamadasOcultas: Especifica ao modelo para manter os pesos de todas as camadas \n",
        "            ocultas, caso contrário mantém somente a última. A avaliação do modelo retorna\n",
        "            um número de diferentes objetos com base em como é configurado na chamada do\n",
        "            método `from_pretrained`. O retorno de model quando output_hidden_states=True´ é:  \n",
        "                #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states            \n",
        "            Veja a documentação para mais detalhes:\n",
        "            https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "\n",
        "    Returns:        \n",
        "        `modelo` com o modelo BERT carregado.\n",
        "    \"\"\"\n",
        "    #======================================================================\n",
        "    # Verificação do idioma e tamanho do modelo\n",
        "    #======================================================================\n",
        "    # Verifica se a língua é português e o tamanho do modelo\n",
        "    if linguaBERT == 'portugues' and tamanhoBERT == 'base':\n",
        "        nome_modelo_bert = 'neuralmind/bert-base-portuguese-cased'\n",
        "    else:\n",
        "        if linguaBERT == 'portugues' and tamanhoBERT == 'large':\n",
        "            nome_modelo_bert = 'neuralmind/bert-large-portuguese-cased'\n",
        "        else:\n",
        "            # Verifica se a língua é inglés e o tamanho do modelo\n",
        "            if linguaBERT == 'ingles' and tamanhoBERT == 'base':\n",
        "                nome_modelo_bert = 'bert-base-uncased'\n",
        "            else:\n",
        "                if linguaBERT == 'ingles' and tamanhoBERT == 'large':\n",
        "                    nome_modelo_bert = 'bert-large-uncased'\n",
        "                else:\n",
        "                    print(\"Parâmetros \\'língua\\' e \\'tamanhoBERT\\' especificados incorretamente!\")\n",
        "                    return None, None\n",
        "\n",
        "    #======================================================================\n",
        "    # Download do arquivo do modelo\n",
        "    #======================================================================\n",
        "    #Se a variável 'fonteBERT' foi setada para 'diretorio' faz o download dos arquivos modelo\n",
        "    if fonteBERT == 'diretorio' and linguaBERT == 'portugues':\n",
        "    \n",
        "      # Se a variável 'tamanhoBERT' foi setada para 'base' faz o download do arquivo do tamanho base do BERT, caso contrário do large.\n",
        "      if tamanhoBERT == 'base':\n",
        "          # url do arquivo do modelo do Pytorch checkpoint\n",
        "          # arquivo menor(base) 1.1 Gbytes\n",
        "          url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "      else:\n",
        "          # url do arquivo do modelo do Pytorch checkpoint\n",
        "          # arquivo grande(large) 3.5 Gbytes\n",
        "          url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "      # Diretório descompactação do modelo\n",
        "      diretorio = '/content/modelo' + tamanhoBERT\n",
        "\n",
        "      # Recupera o nome do arquivo do modelo da url anterior\n",
        "      arquivo = url.split(\"/\")[-1]\n",
        "\n",
        "      # Nome do arquivo do vocabulário\n",
        "      arquivo_vocab = \"vocab.txt\"\n",
        "\n",
        "      # Caminho do arquivo na url\n",
        "      caminho = url[0:len(url)-len(arquivo)]\n",
        "\n",
        "      # Verifica se a pasta de descompactação existe no pasta corrente\n",
        "      if not os.path.exists(diretorio):\n",
        "   \n",
        "          # Realiza o download do arquivo do modelo\n",
        "          !wget $url\n",
        "    \n",
        "          # Descompacta o arquivo na pasta de destino\n",
        "          !unzip -o $arquivo -d $diretorio\n",
        "\n",
        "          # Realiza o download do arquivo do vocabulário\n",
        "          # O vocabulário não está no arquivo compactado acima\n",
        "          # Concatena o caminho do modelo mais o nome do arquivo do vocabulário\n",
        "          url_vocab = caminho + arquivo_vocab\n",
        "\n",
        "          # Realiza o download do arquivo do vocabulário\n",
        "          !wget $url_vocab\n",
        "    \n",
        "          # Move o arquivo do vocabulário para o diretório do modelo\n",
        "          !mv $arquivo_vocab $diretorio\n",
        "            \n",
        "          # Move o arquivo do modelo para o diretório do modelo\n",
        "          !mv $arquivo $diretorio      \n",
        "                \n",
        "          print('Diretório do modelo:\\'' + diretorio + '\\' pronta!')\n",
        "      else:      \n",
        "          print('Diretório do modelo:\\'' + diretorio + '\\' já existe!')\n",
        "      \n",
        "    else:\n",
        "        if linguaBERT == 'ingles':\n",
        "            print('O modelo BERT na língua inglesa deve ser carregado somente da comunidade.')\n",
        "       \n",
        "    #======================================================================\n",
        "    # Carregamento do modelo\n",
        "    #======================================================================\n",
        "\n",
        "    # Importando as bibliotecas do Modelo\n",
        "    from transformers import BertModel\n",
        "\n",
        "    # Se a variável 'fonteBERT' foi setada para 'diretorio' faz o download dos arquivos modelo\n",
        "    # Carregamento de diretório somente para a língua portuguesa\n",
        "    if fonteBERT == 'diretorio' and linguaBERT == 'portugues':\n",
        "\n",
        "        # Carregando o Modelo do diretório\n",
        "        print('Carregando o modelo BERT_' + tamanhoBERT \n",
        "              + ' do diretório \\'' + diretorio \n",
        "              + '\\' em língua \\''+ linguaBERT \n",
        "              + '\\' com os pesos das camadas ocultas=' + str(pesosCamadasOcultas) + '...')\n",
        "\n",
        "        model = BertModel.from_pretrained(diretorio, \n",
        "                                          output_hidden_states = pesosCamadasOcultas) # Se o modelo retorna todos os estados ocultos\n",
        "\n",
        "    else:\n",
        "\n",
        "        # Carregando o Modelo da comunidade\n",
        "        print('Carregando o modelo BERT \\'' + nome_modelo_bert \n",
        "              + '\\' da comunidade em língua \\''+ linguaBERT \n",
        "              + '\\' com os pesos das camadas ocultas=' + str(pesosCamadasOcultas) + '...')\n",
        "\n",
        "        model = BertModel.from_pretrained(nome_modelo_bert, \n",
        "                                          output_hidden_states = pesosCamadasOcultas) # Se o modelo retorna todos os estados ocultos \n",
        "    \n",
        "    # Retorna o modelo BERT carregado           \n",
        "    return  model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQsZoz_0Fi5B"
      },
      "source": [
        "##### Usando a função getModeloBERT()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Shpi5zYrFi5C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f817dac-6d7d-4ef6-8a65-7e2c26201fda"
      },
      "source": [
        "model = getModeloBERT()\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o modelo BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vgrczx9Fi5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e73e89e1-4daf-4571-cb85-94126f4ca093"
      },
      "source": [
        "model = getModeloBERT(tamanhoBERT='large')\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o modelo BERT 'neuralmind/bert-large-portuguese-cased' da comunidade em língua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee7F6aJZFi5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04cb1216-8f8d-4011-905b-950ac3ed5c41"
      },
      "source": [
        "model = getModeloBERT(tamanhoBERT='base')\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o modelo BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ouj7SbLFi5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc979a1a-efbd-409a-d361-7d0b49fd1432"
      },
      "source": [
        "model = getModeloBERT(fonteBERT='diretorio', \n",
        "                      tamanhoBERT='base')\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Diretório do modelo:'/content/modelobase' já existe!\n",
            "Carregando o modelo BERT_base do diretório '/content/modelobase' em língua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re0JeBNIFi5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05bc5cdf-d4f8-462d-da3b-8d771506733e"
      },
      "source": [
        "model = getModeloBERT(fonteBERT='diretorio', \n",
        "                      tamanhoBERT='large', \n",
        "                      linguaBERT='portugues')\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Diretório do modelo:'/content/modelolarge' já existe!\n",
            "Carregando o modelo BERT_large do diretório '/content/modelolarge' em língua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D84OnvHPFi5R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ff1908c-dfe2-4ee3-b467-6bd8d5a8c4d9"
      },
      "source": [
        "model = getModeloBERT(fonteBERT='diretorio', \n",
        "                      tamanhoBERT='base', \n",
        "                      linguaBERT='portugues')\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Diretório do modelo:'/content/modelobase' já existe!\n",
            "Carregando o modelo BERT_base do diretório '/content/modelobase' em língua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x7bJqb4Fi5U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a313c8aa-3c71-4846-bd90-050bc732330f"
      },
      "source": [
        "model = getModeloBERT(fonteBERT='comunidade', \n",
        "                      tamanhoBERT='large', \n",
        "                      linguaBERT='portugues')\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o modelo BERT 'neuralmind/bert-large-portuguese-cased' da comunidade em língua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QRBdDKMFi5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e13847f2-01df-458c-b49a-1017e26a53e3"
      },
      "source": [
        "model = getModeloBERT(fonteBERT='comunidade', \n",
        "                      tamanhoBERT='base', \n",
        "                      linguaBERT='portugues')\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o modelo BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsoRCNwLFi5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8200759c-5176-4cbc-b227-c2a199e6c733"
      },
      "source": [
        "model =getModeloBERT(fonteBERT='comunidade', \n",
        "                     tamanhoBERT='base', \n",
        "                     linguaBERT='portugues',\n",
        "                     pesosCamadasOcultas = False)\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o modelo BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkLHJXiUFi5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169,
          "referenced_widgets": [
            "81c698d967c24a6f9d580eebfc7de638",
            "d388f78aa40f4515bc86f620975716bb",
            "f4cc03f3c80849b0af8ccf46d0b257fb",
            "19f8fb95cf1f448396ae164e3aecafdd",
            "6038ab40ea0c458981aed4ab13cd9a1d",
            "4f5a110167104e17b64cd243b08b05e9",
            "2f186ae4671a41149169db8ce2fece09",
            "449e38653aca469eb69b20b34fc7214f",
            "a4eaa30cdf7c458aab34002d7bdd1a99",
            "7159165567f448e9b107a935f7afd5ff",
            "755bdc7472b34440a08ff41d28cad5a1",
            "d95b47461b0e48709a890f50dc59a335",
            "9c8d8430c03f4031b85c76e3c161abfc",
            "e7a34a262af1402385bc16c00817a10d",
            "39f7e95889714ca3a4c5fc81fda4cbca",
            "61329cb6348b4fb998b8138613b1284d"
          ]
        },
        "outputId": "a901adf3-0b1b-41ea-ccb3-2bec9d7011e5"
      },
      "source": [
        "model = getModeloBERT(tamanhoBERT='large', \n",
        "                      linguaBERT='ingles')\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na língua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o modelo BERT 'bert-large-uncased' da comunidade em língua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81c698d967c24a6f9d580eebfc7de638",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=434.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4eaa30cdf7c458aab34002d7bdd1a99",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1344997306.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DWDVehwFi5g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169,
          "referenced_widgets": [
            "30441d93f6c44417a925ffa21a550916",
            "9960aafc77504cacbf68d6679bc4f647",
            "1f2f965ef7a849b4a4de3580f582f40d",
            "ad50e43c77b5447c95a739b39a0c3e97",
            "343ae9c6e0ac4eb2a04e94299cc5f4b8",
            "581e9d25ead74321ba543e27ccf9c7b9",
            "34714666a2024876aa34f542d140a1b6",
            "22376b5b307144fb9f42618f2c21bb5a",
            "8bef9fa2f78b4da98a4945fafbbcd3c5",
            "fdeab3a1c1c34b93812ed9bd08b055f9",
            "2fd487fddb214cc8a373686d3b3c9c15",
            "17163beee8784f67ba7ae5ab3b18e3de",
            "85edd1cce82c465ea20ac93bdcc0d783",
            "1631e89f390247759f1f998242c558e3",
            "9f6d7459ba7e47cdb17381a36e9d032b",
            "33b0bcc7b5724cafbe2c3a418ea418d0"
          ]
        },
        "outputId": "d21b881a-f364-42fe-be86-e157cfd41726"
      },
      "source": [
        "model = getModeloBERT(tamanhoBERT='base', \n",
        "                     linguaBERT='ingles')\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na língua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o modelo BERT 'bert-base-uncased' da comunidade em língua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30441d93f6c44417a925ffa21a550916",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bef9fa2f78b4da98a4945fafbbcd3c5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaf7ha23Fi5j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "688505ef-7a3a-4596-958a-e7b321d24cf5"
      },
      "source": [
        "model = getModeloBERT(fonteBERT='diretorio', \n",
        "                      tamanhoBERT='large', \n",
        "                      linguaBERT='ingles')\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na língua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o modelo BERT 'bert-large-uncased' da comunidade em língua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhpOpsNcFi5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36936cb1-d935-48e2-9c39-2bda3853764b"
      },
      "source": [
        "model = getModeloBERT(fonteBERT='diretorio', \n",
        "                      tamanhoBERT='base', \n",
        "                      linguaBERT='ingles')\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na língua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o modelo BERT 'bert-base-uncased' da comunidade em língua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzLsTc5CFi5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c83ccaa-8d67-4cfd-d0e0-60aaca0a1340"
      },
      "source": [
        "model = getModeloBERT(fonteBERT='comunidade', \n",
        "                      tamanhoBERT='large', \n",
        "                      linguaBERT='ingles')\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na língua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o modelo BERT 'bert-large-uncased' da comunidade em língua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGpA4qAWFi5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec99fd97-0d3a-4377-d7b9-6eec1669e771"
      },
      "source": [
        "model = getModeloBERT(fonteBERT='comunidade', \n",
        "                      tamanhoBERT='base', \n",
        "                      linguaBERT='ingles') \n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na língua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o modelo BERT 'bert-base-uncased' da comunidade em língua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccq15D00Fi5t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b52ed2db-29f8-4e07-ac24-5bd74a3e4424"
      },
      "source": [
        "model = getModeloBERT(fonteBERT='comunidade', \n",
        "                      tamanhoBERT='base', \n",
        "                      linguaBERT='ingles', \n",
        "                      pesosCamadasOcultas = False)\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na língua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o modelo BERT 'bert-base-uncased' da comunidade em língua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAmRY-IEFi5x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a108013-fe93-44ea-8523-9cd027d440b4"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4761"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxolJHbqz83c"
      },
      "source": [
        "#### Usando o BERT da comunidade ou diretório com uma função que retorna o tokenizador e o modelo v6\n",
        "\n",
        "Função que retorna o tokenizador e modelo do BERT. permite configurar o tamanho do modelo e a fonte do modelo. \n",
        "\n",
        "A linguagem do modelo é especificada internamente na função.\n",
        "\n",
        "O parâmetro  `fonteBERT` com os valores `comunidade` ou `diretório` especifica se deve ser carregado o BERT de um diretório ou da comunidade.\n",
        "\n",
        "O parâmetro `tamanhoBERT` com os valores `base` ou `large` especifica se o tamanho do modelo BERT a ser utilizado.\n",
        "\n",
        "O parâmetro `lingua` com os valores `portugues` ou `ingles` especifica a lingua do modelo BERT a ser utilizado.\n",
        "\n",
        "O parâmetro `pesosCamadasOcultas` com os valores `True` ou `False` especifica se é para gerar e retornar os pesos das camadas ocultas.\n",
        "\n",
        "O parâmetro `do_lower_case` específica para colocar as letras em maiúsculo ou minísculo e a remoção das letras acentuadas. Nesta função o default `False` pois a língua portugues possui letras acentuadas(ãçéí...), que são necessárias a língua portuguesa. No método `from_treina from_pretrained` o default é `True` quando o parämetro não é especificado.\n",
        "\n",
        "\n",
        "\n",
        "A função retorna o **tokenizador** e o **modelo** para os parâmetros especificado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWC2y9At7PJo"
      },
      "source": [
        "##### Declarando uma função que retorna o tokenizador e o modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snXme4uU1M7F"
      },
      "source": [
        "# Valores default para os parâmetros da função\n",
        "def getBERT(fonteBERT = 'comunidade', \n",
        "            tamanhoBERT = 'base', \n",
        "            linguaBERT = 'portugues', \n",
        "            pesosCamadasOcultas = False,\n",
        "            do_lower_case = False):\n",
        "\n",
        "    \"\"\"Retorna o tokenizador e modelo BERT carregado.\n",
        "    De acordo com os parâmetros especificados ou carrega o BERT da comunidade \n",
        "    ou realiza o download dos arquivos do modelo.\n",
        "\n",
        "    Args:\n",
        "        fonteBERT: Especifica a origem do modelo do BERT 'comunidade' ou 'diretorio'.\n",
        "        tamanhoBERT: Especifica o tamanho do modelo do BERT 'large' ou 'base'.\n",
        "        linguaBERT: Especifica a língua do modelo do BERT 'portugues' ou 'ingles'.\n",
        "        pesosCamadasOcultas: Especifica ao modelo para manter os pesos de todas as camadas \n",
        "            ocultas, caso contrário mantém somente a última. A avaliação do modelo retorna\n",
        "            um número de diferentes objetos com base em como é configurado na chamada do\n",
        "            método `from_pretrained`. O retorno de model quando output_hidden_states=True´ é:  \n",
        "                #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states            \n",
        "            Veja a documentação para mais detalhes:\n",
        "            https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "\n",
        "    Returns:\n",
        "        `tokenizador` com o tokenizador do modelo BERT carregado.\n",
        "        `modelo` com o modelo BERT carregado.\n",
        "    \"\"\"\n",
        "    #======================================================================\n",
        "    # Verificação do idioma e tamanho do modelo\n",
        "    #======================================================================\n",
        "    # Verifica se a língua é português e o tamanho do modelo\n",
        "    if linguaBERT == 'portugues' and tamanhoBERT == 'base':\n",
        "        nome_modelo_bert = 'neuralmind/bert-base-portuguese-cased'\n",
        "    else:\n",
        "        if linguaBERT == 'portugues' and tamanhoBERT == 'large':\n",
        "            nome_modelo_bert = 'neuralmind/bert-large-portuguese-cased'\n",
        "        else:\n",
        "            # Verifica se a língua é inglés e o tamanho do modelo\n",
        "            if linguaBERT == 'ingles' and tamanhoBERT == 'base':\n",
        "                nome_modelo_bert = 'bert-base-uncased'\n",
        "            else:\n",
        "                if linguaBERT == 'ingles' and tamanhoBERT == 'large':\n",
        "                    nome_modelo_bert = 'bert-large-uncased'\n",
        "                else:\n",
        "                    print(\"Parâmetros \\'língua\\' e \\'tamanhoBERT\\' especificados incorretamente!\")\n",
        "                    return None, None\n",
        "\n",
        "    #======================================================================\n",
        "    # Download do arquivo do modelo\n",
        "    #======================================================================\n",
        "    #Se a variável 'fonteBERT' foi setada para 'diretorio' faz o download dos arquivos modelo\n",
        "    if fonteBERT == 'diretorio' and linguaBERT == 'portugues':\n",
        "    \n",
        "      # Se a variável 'tamanhoBERT' foi setada para 'base' faz o download do arquivo do tamanho base do BERT, caso contrário do large.\n",
        "      if tamanhoBERT == 'base':\n",
        "          # url do arquivo do modelo do Pytorch checkpoint\n",
        "          # arquivo menor(base) 1.1 Gbytes\n",
        "          url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "      else:\n",
        "          # url do arquivo do modelo do Pytorch checkpoint\n",
        "          # arquivo grande(large) 3.5 Gbytes\n",
        "          url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "      # Diretório descompactação do modelo\n",
        "      diretorio = '/content/modelo' + tamanhoBERT\n",
        "\n",
        "      # Recupera o nome do arquivo do modelo da url anterior\n",
        "      arquivo = url.split(\"/\")[-1]\n",
        "\n",
        "      # Nome do arquivo do vocabulário\n",
        "      arquivo_vocab = \"vocab.txt\"\n",
        "\n",
        "      # Caminho do arquivo na url\n",
        "      caminho = url[0:len(url)-len(arquivo)]\n",
        "\n",
        "      # Verifica se a pasta de descompactação existe no pasta corrente\n",
        "      if not os.path.exists(diretorio):\n",
        "   \n",
        "          # Realiza o download do arquivo do modelo\n",
        "          !wget $url\n",
        "    \n",
        "          # Descompacta o arquivo na pasta de destino\n",
        "          !unzip -o $arquivo -d $diretorio\n",
        "\n",
        "          # Realiza o download do arquivo do vocabulário\n",
        "          # O vocabulário não está no arquivo compactado acima\n",
        "          # Concatena o caminho do modelo mais o nome do arquivo do vocabulário\n",
        "          url_vocab = caminho + arquivo_vocab\n",
        "\n",
        "          # Realiza o download do arquivo do vocabulário\n",
        "          !wget $url_vocab\n",
        "    \n",
        "          # Move o arquivo do vocabulário para o diretório do modelo\n",
        "          !mv $arquivo_vocab $diretorio\n",
        "            \n",
        "          # Move o arquivo do modelo para o diretório do modelo\n",
        "          !mv $arquivo $diretorio      \n",
        "                \n",
        "          print('Diretório do modelo:\\'' + diretorio + '\\' pronta!')\n",
        "      else:      \n",
        "          print('Diretório do modelo:\\'' + diretorio + '\\' já existe!')\n",
        "      \n",
        "    else:\n",
        "        if linguaBERT == 'ingles':\n",
        "            print('O modelo BERT na língua inglesa deve ser carregado somente da comunidade.')\n",
        "       \n",
        "    #======================================================================\n",
        "    # Carregamento do tokenizador e do modelo \n",
        "    #======================================================================\n",
        "\n",
        "    # Importando as bibliotecas do Modelo e do Tokenizador\n",
        "    from transformers import BertModel, BertTokenizer\n",
        "\n",
        "    # Se a variável 'fonteBERT' foi setada para 'diretorio' faz o download dos arquivos modelo\n",
        "    # Carregamento de diretório somente para a língua portuguesa\n",
        "    if fonteBERT == 'diretorio' and linguaBERT == 'portugues':\n",
        "\n",
        "        # Carregando o Tokenizador do diretório\n",
        "        print('Carregando o tokenizador BERT_' + tamanhoBERT \n",
        "              + ' do diretório \\'' + diretorio \n",
        "              + '\\' em língua \\''+ linguaBERT + '\\'...')\n",
        "\n",
        "        tokenizer = BertTokenizer.from_pretrained(diretorio,\n",
        "                                                  do_lower_case = do_lower_case)\n",
        "\n",
        "        # Carregando o Modelo do diretório\n",
        "        print('Carregando o modelo BERT_' + tamanhoBERT \n",
        "              + ' do diretório \\'' + diretorio \n",
        "              + '\\' em língua \\''+ linguaBERT \n",
        "              + '\\' com os pesos das camadas ocultas=' + str(pesosCamadasOcultas) + '...')\n",
        "\n",
        "        model = BertModel.from_pretrained(diretorio, \n",
        "                                          output_hidden_states = pesosCamadasOcultas) # Se o modelo retorna todos os estados ocultos\n",
        "\n",
        "    else:\n",
        "        # Carregando o Tokenizador da comunidade\n",
        "        print('Carregando o tokenizador BERT \\'' + nome_modelo_bert \n",
        "              + '\\' da comunidade em língua \\''+ linguaBERT + '\\'...')\n",
        "\n",
        "        tokenizer = BertTokenizer.from_pretrained(nome_modelo_bert,\n",
        "                                                  do_lower_case = do_lower_case)  \n",
        "\n",
        "        # Carregando o Modelo da comunidade\n",
        "        print('Carregando o modelo BERT \\'' + nome_modelo_bert \n",
        "              + '\\' da comunidade em língua \\''+ linguaBERT \n",
        "              + '\\' com os pesos das camadas ocultas=' + str(pesosCamadasOcultas) + '...')\n",
        "\n",
        "        model = BertModel.from_pretrained(nome_modelo_bert, \n",
        "                                          output_hidden_states = pesosCamadasOcultas)  # Se o modelo retorna todos os estados ocultos\n",
        "    \n",
        "    # Retorna o tokenizador e o modelo BERT carregado           \n",
        "    return tokenizer, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2CgB02_2wJQ"
      },
      "source": [
        "##### Usando a função getBERT()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8ol9ckB9QPY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dea223f3-958d-498d-b04c-af87b2c9fdce"
      },
      "source": [
        "tokenizador, model = getBERT()\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues'...\n",
            "Carregando o modelo BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDkdnWDp9SI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1688a754-8f42-4d71-d488-85c257023938"
      },
      "source": [
        "tokenizador, model = getBERT(tamanhoBERT='large')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-large-portuguese-cased' da comunidade em língua 'portugues'...\n",
            "Carregando o modelo BERT 'neuralmind/bert-large-portuguese-cased' da comunidade em língua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib-_gNFj9WIu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca73c484-5752-4866-85f9-333f4e41b489"
      },
      "source": [
        "tokenizador, model = getBERT(tamanhoBERT='base')\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues'...\n",
            "Carregando o modelo BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-QtCuOf9aOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a83c38d9-6db0-466a-f533-19b9958af04c"
      },
      "source": [
        "tokenizador, model = getBERT(fonteBERT='diretorio', \n",
        "                             tamanhoBERT='base')\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Diretório do modelo:'/content/modelobase' já existe!\n",
            "Carregando o tokenizador BERT_base do diretório '/content/modelobase' em língua 'portugues'...\n",
            "Carregando o modelo BERT_base do diretório '/content/modelobase' em língua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAtFJaBS9eE-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c456517e-a4a4-4820-c44d-785ada54fffd"
      },
      "source": [
        "tokenizador, model = getBERT(fonteBERT='diretorio', \n",
        "                             tamanhoBERT='large', \n",
        "                             linguaBERT='portugues')\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Diretório do modelo:'/content/modelolarge' já existe!\n",
            "Carregando o tokenizador BERT_large do diretório '/content/modelolarge' em língua 'portugues'...\n",
            "Carregando o modelo BERT_large do diretório '/content/modelolarge' em língua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_jYbPyr9hal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7b60d09-b0f3-4a13-fe49-8ad361d81202"
      },
      "source": [
        "tokenizador, model = getBERT(fonteBERT='diretorio', \n",
        "                             tamanhoBERT='base', \n",
        "                             linguaBERT='portugues')\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Diretório do modelo:'/content/modelobase' já existe!\n",
            "Carregando o tokenizador BERT_base do diretório '/content/modelobase' em língua 'portugues'...\n",
            "Carregando o modelo BERT_base do diretório '/content/modelobase' em língua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ty684uT9kmi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78048ed3-f5f6-47c7-965a-8c00a297e819"
      },
      "source": [
        "tokenizador, model = getBERT(fonteBERT='comunidade', \n",
        "                             tamanhoBERT='large', \n",
        "                             linguaBERT='portugues')\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-large-portuguese-cased' da comunidade em língua 'portugues'...\n",
            "Carregando o modelo BERT 'neuralmind/bert-large-portuguese-cased' da comunidade em língua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddnIW3qs9nEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a3e37c3-696d-487f-ceea-b2bc30317259"
      },
      "source": [
        "tokenizador, model = getBERT(fonteBERT='comunidade', \n",
        "                             tamanhoBERT='base', \n",
        "                             linguaBERT='portugues')\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues'...\n",
            "Carregando o modelo BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxRMvyCeY0Qi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21a6d4a3-3e4b-4c92-d3fe-154ce65e1dd1"
      },
      "source": [
        "tokenizador, model = getBERT(fonteBERT='comunidade', \n",
        "                             tamanhoBERT='base', \n",
        "                             linguaBERT='portugues',\n",
        "                             pesosCamadasOcultas = False)\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues'...\n",
            "Carregando o modelo BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGtEwUsz9bqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bcb74ca-2cf9-4c77-f36d-5cf3fbd3405a"
      },
      "source": [
        "tokenizador, model = getBERT(tamanhoBERT='large', \n",
        "                             linguaBERT='ingles')\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na língua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-large-uncased' da comunidade em língua 'ingles'...\n",
            "Carregando o modelo BERT 'bert-large-uncased' da comunidade em língua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7RmGEJh2yVt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87b4bef6-b5c4-4985-e830-54ff75c6a954"
      },
      "source": [
        "tokenizador, model = getBERT(tamanhoBERT='base', \n",
        "                             linguaBERT='ingles')\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na língua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-base-uncased' da comunidade em língua 'ingles'...\n",
            "Carregando o modelo BERT 'bert-base-uncased' da comunidade em língua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvCaohAg9spJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2803697c-63a2-41a9-ee25-5be228e8cdad"
      },
      "source": [
        "tokenizador, model = getBERT(fonteBERT='diretorio', \n",
        "                             tamanhoBERT='large', \n",
        "                             linguaBERT='ingles')\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na língua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-large-uncased' da comunidade em língua 'ingles'...\n",
            "Carregando o modelo BERT 'bert-large-uncased' da comunidade em língua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GmVk2Vs91vf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34445708-3e02-47d9-dcc8-126b518b0e48"
      },
      "source": [
        "tokenizador, model = getBERT(fonteBERT='diretorio', \n",
        "                             tamanhoBERT='base', \n",
        "                             linguaBERT='ingles')\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na língua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-base-uncased' da comunidade em língua 'ingles'...\n",
            "Carregando o modelo BERT 'bert-base-uncased' da comunidade em língua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTlXm1iV9r6u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7002e56-1085-46cf-949b-3f560df19ae4"
      },
      "source": [
        "tokenizador, model = getBERT(fonteBERT='comunidade', \n",
        "                             tamanhoBERT='large', \n",
        "                             linguaBERT='ingles')\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na língua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-large-uncased' da comunidade em língua 'ingles'...\n",
            "Carregando o modelo BERT 'bert-large-uncased' da comunidade em língua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1LrfoJR93JA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0868a8d-8dea-45a3-ba0d-516546608f8f"
      },
      "source": [
        "tokenizador, model = getBERT(fonteBERT='comunidade', \n",
        "                             tamanhoBERT='base', \n",
        "                             linguaBERT='ingles') \n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na língua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-base-uncased' da comunidade em língua 'ingles'...\n",
            "Carregando o modelo BERT 'bert-base-uncased' da comunidade em língua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE-nPaejYgZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccbabf8f-ace7-43ae-a645-165643d94126"
      },
      "source": [
        "tokenizador, model = getBERT(fonteBERT='comunidade', \n",
        "                             tamanhoBERT='base', \n",
        "                             linguaBERT='ingles', \n",
        "                             pesosCamadasOcultas = False)\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na língua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-base-uncased' da comunidade em língua 'ingles'...\n",
            "Carregando o modelo BERT 'bert-base-uncased' da comunidade em língua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJKkYninAk-j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2259d995-af38-4c3f-d290-d9b7ca2c4b1b"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5062"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gci3FLLlLUJE"
      },
      "source": [
        "## Declarando uma função que recupera embeddings de frase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeaDaUvaLoC4"
      },
      "source": [
        "def getEmbedding(texto, tokenizadorBERT, modeloBERT):\n",
        "\n",
        "    \"\"\"\n",
        "    Retorna os embeddings de uma frase utilizando um tokenizador e modelo BERT carregado.\n",
        "    \n",
        "    Args:\n",
        "        texto: Texto a ser convertindo em embeddings utilizando o BERT.\n",
        "        tokenizadorBERT: Tokenizador BERT carregado.\n",
        "        modelBERT: Modelo BERT carregado.\n",
        "        \n",
        "    Returns:\n",
        "          0-texto_tokenizado, \n",
        "          1-input_ids, \n",
        "          2-attention_mask, \n",
        "          3-token_type_ids, \n",
        "          4-outputs \n",
        "              0-last_hidden_state,\n",
        "              1-pooler_output,\n",
        "              2-hidden_states\n",
        "    \"\"\"\n",
        "    # Importando a biblioteca\n",
        "    import torch\n",
        "\n",
        "    # Adiciona os tokens especiais\n",
        "    texto_marcado = \"[CLS] \" + texto + \" [SEP]\"\n",
        "\n",
        "    # Tokeniza o texto marcado\n",
        "    texto_tokenizado = tokenizer.tokenize(texto_marcado)\n",
        "    \n",
        "    # Recupera a quantidade tokens do texto tokenizado\n",
        "    qtdeTokens = len(texto_tokenizado)\n",
        "\n",
        "    #tokeniza o texto e retorna os tensores\n",
        "    dic_codificado = tokenizadorBERT.encode_plus(\n",
        "                        text=texto,                     # texto a ser codificado.\n",
        "                        add_special_tokens = True,      # Adiciona os tokens especiais '[CLS]' e '[SEP]'\n",
        "                        max_length = qtdeTokens,        # Define o tamanho máximo para preencheer ou truncar.\n",
        "                        truncation = True,              # Trunca o texto por max_length\n",
        "                        padding = 'max_length',         # Preenche o texto até max_length\n",
        "                        return_attention_mask = True,   # Constrói a máscara de atenção.\n",
        "                        return_tensors = 'pt'           # Retorna os dados como tensores pytorch.\n",
        "                   )                   \n",
        "\n",
        "    # Ids dos tokens de entrada mapeados em seus índices do vocabuário    \n",
        "    input_ids =  dic_codificado['input_ids']\n",
        "\n",
        "    # Máscara de atenção de cada um dos tokens como pertencentes à frase \"1\".\n",
        "    attention_mask = dic_codificado['attention_mask']\n",
        "\n",
        "    # Recupera os tensores dos segmentos\n",
        "    token_type_ids = dic_codificado['token_type_ids']\n",
        "\n",
        "    # Roda o texto através do BERT, e coleta todos os estados ocultos produzidos\n",
        "    # das 12 camadas. \n",
        "    with torch.no_grad():\n",
        "\n",
        "        # Passe para a frente, calcule as previsões outputs\n",
        "        outputs = modeloBERT(input_ids=input_ids, \n",
        "                             attention_mask=attention_mask)\n",
        "\n",
        "        # A avaliação do modelo retorna um número de diferentes objetos com base em\n",
        "        # como é configurado na chamada do método `from_pretrained` anterior. Nesse caso,\n",
        "        # porque definimos `output_hidden_states = True`, o terceiro item será o\n",
        "        # estados ocultos(hidden_states) de todas as camadas. Veja a documentação para mais detalhes:\n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "\n",
        "        # Retorno de model quando ´output_hidden_states=True´ é setado:    \n",
        "        #last_hidden_state = outputs[0], pooler_output = outputs[1], hidden_states = outputs[2]\n",
        "\n",
        "    # 0-texto_tokenizado, 1-input_ids, 2-attention_mask, 3-token_type_ids, 4-outputs(0=last_hidden_state,1=pooler_output,2=hidden_states)    \n",
        "    return texto_tokenizado, input_ids, attention_mask, token_type_ids, outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV8B1VdVxF4l"
      },
      "source": [
        "# 4 Preparando a entrada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PieeR7bQxKO2"
      },
      "source": [
        "## Tokenizador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dedf1fOJyYkR"
      },
      "source": [
        "### Exemplo do tokenizador com método 'tokenize'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl7-DgNpxTkd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a4d50c-0538-4bff-c00f-daa9934c7806"
      },
      "source": [
        "# Recupera o tokenizador BERT\n",
        "tokenizer = getTokenizadorBERT()\n",
        "\n",
        "# Texto de exemplo\n",
        "texto = \"O que é embedding?\"\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado = \"[CLS] \" + texto + \" [SEP]\"\n",
        "\n",
        "# Tokeniza o texto em tokens\n",
        "texto_tokenizado = tokenizer.tokenize(texto_marcado)\n",
        "\n",
        "# Mostra o texto exemplo\n",
        "print(\"Texto exemplo      :\", texto)\n",
        "\n",
        "# Mostra o texto marcado\n",
        "print(\"Texto marcado      :\", texto_marcado)\n",
        "\n",
        "# Mostra o texto tokenizado\n",
        "print(\"Texto tokenizado   :\", texto_tokenizado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues'...\n",
            "Texto exemplo      : O que é embedding?\n",
            "Texto marcado      : [CLS] O que é embedding? [SEP]\n",
            "Texto tokenizado   : ['[CLS]', 'O', 'que', 'é', 'em', '##be', '##dd', '##ing', '?', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVhPYQg_yMl0"
      },
      "source": [
        "## Codificador (input_ids)\n",
        "\n",
        "Converte cada token do texto tokenizado para um id presente no vocabulário do modelo do Tokenizador. Se houver um token que não está presente no vocabulário, o tokenizador usará o id token especial [UNK].\n",
        "\n",
        "- encode\n",
        "- convert_tokens_to_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ezUjHyRMIuQ"
      },
      "source": [
        "### Exemplo de gerador do id do token com o método 'encode'\n",
        "\n",
        "Método encode tokeniza e converte os tokens para os ids do vocabulário."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlXtmkcjMNu0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f70479f-cb83-4ab2-e59d-edcc15d952dd"
      },
      "source": [
        "# Recupera o tokenizador BERT\n",
        "tokenizer = getTokenizadorBERT()\n",
        "\n",
        "# Texto de exemplo\n",
        "texto = \"O que é embedding?\"\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado = \"[CLS] \" + texto + \" [SEP]\"\n",
        "\n",
        "# Tokeniza o texto em tokens\n",
        "texto_tokenizado = tokenizer.tokenize(texto_marcado)\n",
        "\n",
        "# Converte os tokens para os ids do vocabulário, por default(add_special_tokens=True) \n",
        "# já adiciona os tokens especiais.\n",
        "texto_token_ids = tokenizer.encode(text=texto_tokenizado, \n",
        "                                   add_special_tokens=False)\n",
        "\n",
        "# Mostra o texto exemplo\n",
        "print(\"Texto exemplo      :\", texto)\n",
        "\n",
        "# Mostra o texto marcado\n",
        "print(\"Texto marcado      :\", texto_marcado)\n",
        "\n",
        "# Mostra o texto tokenizado\n",
        "print(\"Texto tokenizado   :\", texto_tokenizado)\n",
        "\n",
        "# Mostra o id do texto tokenizado\n",
        "print(\"Texto id token     :\", texto_token_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues'...\n",
            "Texto exemplo      : O que é embedding?\n",
            "Texto marcado      : [CLS] O que é embedding? [SEP]\n",
            "Texto tokenizado   : ['[CLS]', 'O', 'que', 'é', 'em', '##be', '##dd', '##ing', '?', '[SEP]']\n",
            "Texto id token     : [101, 231, 179, 253, 173, 483, 14852, 446, 136, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5T9g55j57_k"
      },
      "source": [
        "### Exemplo de gerador do id do token com o método 'convert_tokens_to_ids'\n",
        "\n",
        "Método convert_tokens_to_ids tokeniza e converte os tokens para os ids do vocabulário.\n",
        "\n",
        "Função semenlhante ao método `enconde`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL_qJ-nh0Cq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a0db835-afec-4287-a9fd-cc64639c9d1c"
      },
      "source": [
        "# Recupera o tokenizador BERT\n",
        "tokenizer = getTokenizadorBERT()\n",
        "\n",
        "# Texto de exemplo\n",
        "texto = \"O que é embedding?\"\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado = \"[CLS] \" + texto + \" [SEP]\"\n",
        "\n",
        "# Tokeniza o texto em tokens\n",
        "texto_tokenizado = tokenizer.tokenize(texto_marcado)\n",
        "\n",
        "# Converte os tokens para os ids do vocabulário\n",
        "texto_token_ids = tokenizer.convert_tokens_to_ids(texto_tokenizado)\n",
        "\n",
        "# Mostra o texto exemplo\n",
        "print(\"Texto exemplo      :\", texto)\n",
        "\n",
        "# Mostra o texto marcado\n",
        "print(\"Texto marcado      :\", texto_marcado)\n",
        "\n",
        "# Mostra o texto tokenizado\n",
        "print(\"Texto tokenizado   :\", texto_tokenizado)\n",
        "\n",
        "# Mostra o id do texto tokenizado\n",
        "print(\"Texto id token     :\", texto_token_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues'...\n",
            "Texto exemplo      : O que é embedding?\n",
            "Texto marcado      : [CLS] O que é embedding? [SEP]\n",
            "Texto tokenizado   : ['[CLS]', 'O', 'que', 'é', 'em', '##be', '##dd', '##ing', '?', '[SEP]']\n",
            "Texto id token     : [101, 231, 179, 253, 173, 483, 14852, 446, 136, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbYZGyvGIg2q"
      },
      "source": [
        "### Exemplo de decodificação dos id dos tokens com o método 'decode'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2-DNVvBIzrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b61377d-225b-48f6-db8b-bb7eefae5a45"
      },
      "source": [
        "# Recupera o tokenizador BERT\n",
        "tokenizer = getTokenizadorBERT()\n",
        "\n",
        "# Texto de exemplo\n",
        "texto = \"O que é embedding?\"\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado = \"[CLS] \" + texto + \" [SEP]\"\n",
        "\n",
        "# Tokeniza o texto em tokens\n",
        "texto_tokenizado = tokenizer.tokenize(texto_marcado)\n",
        "\n",
        "# Converte os tokens para os ids do vocabulário\n",
        "texto_token_ids = tokenizer.convert_tokens_to_ids(texto_tokenizado)\n",
        "\n",
        "# Decodifica o id texto tokenizado\n",
        "# skip_special_tokens: bool = False retira os tokens especiais\n",
        "texto_decodificado = tokenizer.decode(texto_token_ids)\n",
        "\n",
        "print(\"Texto exemplo      :\", texto)\n",
        "\n",
        "# Mostra o texto marcado\n",
        "print(\"Texto marcado      :\", texto_marcado)\n",
        "\n",
        "# Mostra o texto tokenizado\n",
        "print(\"Texto tokenizado   :\", texto_tokenizado)\n",
        "\n",
        "# Mostra o id do texto tokenizado\n",
        "print(\"Texto id token     :\", texto_token_ids)\n",
        "\n",
        "# Mostra texto decodificado\n",
        "print(\"Texto decodificado :\", texto_decodificado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues'...\n",
            "Texto exemplo      : O que é embedding?\n",
            "Texto marcado      : [CLS] O que é embedding? [SEP]\n",
            "Texto tokenizado   : ['[CLS]', 'O', 'que', 'é', 'em', '##be', '##dd', '##ing', '?', '[SEP]']\n",
            "Texto id token     : [101, 231, 179, 253, 173, 483, 14852, 446, 136, 102]\n",
            "Texto decodificado : [CLS] O que é embedding? [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6IhqAYe0U6f"
      },
      "source": [
        "## Gerador da máscara de atenção (attention_mask)\n",
        "\n",
        "O BERT é treinado e espera pares de frases, usando 1s e 0s para distinguir entre as duas frases. Ou seja, para cada token em \"texto_tokenizado\", devemos especificar a qual frase pertence: sentença 0 (uma série de 0s) ou sentença 1 (uma série de 1s). \n",
        "\n",
        "Para casos onde as entradas de texto é **única** requerem apenas uma série de 1s; portanto, criaremos um vetor de 1s para cada token em input_ids.\n",
        "\n",
        "Se desejar processar **duas frases**, atribua cada palavra na primeira frase mais o token '[SEP]' a 0 e todos os tokens da segunda frase a 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB1NizSQ6y9O"
      },
      "source": [
        "### Exemplo de gerador de máscara para frase única com lista"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oOSCtd00W2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38398bc5-e35f-4515-bc99-f510616c4e7f"
      },
      "source": [
        "# Recupera o tokenizador BERT\n",
        "tokenizer = getTokenizadorBERT()\n",
        "\n",
        "# Texto de exemplo\n",
        "texto = \"O que é embedding?\"\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado = \"[CLS] \" + texto + \" [SEP]\"\n",
        "\n",
        "# Tokeniza o texto em tokens\n",
        "texto_tokenizado = tokenizer.tokenize(texto_marcado)\n",
        "\n",
        "# Converte os tokens para os ids do vocabulário\n",
        "texto_token_ids = tokenizer.convert_tokens_to_ids(texto_tokenizado)\n",
        "\n",
        "# Cria um vetor com o tamanho da quantidade de tokens do texto preenchidos com 1.\n",
        "mascara_atencao = [1] * len(texto_token_ids)\n",
        "\n",
        "print(\"Texto exemplo      :\", texto)\n",
        "\n",
        "# Mostra o texto marcado\n",
        "print(\"Texto marcado      :\", texto_marcado)\n",
        "\n",
        "# Mostra o texto tokenizado\n",
        "print(\"Texto tokenizado   :\", texto_tokenizado)\n",
        "\n",
        "# Mostra o id do texto tokenizado\n",
        "print(\"Texto id token     :\", texto_token_ids)\n",
        "\n",
        "# Mostra a máscara de atenção\n",
        "print(\"Máscara de atenção :\", mascara_atencao)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues'...\n",
            "Texto exemplo      : O que é embedding?\n",
            "Texto marcado      : [CLS] O que é embedding? [SEP]\n",
            "Texto tokenizado   : ['[CLS]', 'O', 'que', 'é', 'em', '##be', '##dd', '##ing', '?', '[SEP]']\n",
            "Texto id token     : [101, 231, 179, 253, 173, 483, 14852, 446, 136, 102]\n",
            "Máscara de atenção : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKdO4ZDi8O8Q"
      },
      "source": [
        "## Gerando toda a entrada com o encode_plus(input_ids, attention_mask, token_type_ids)\n",
        "\n",
        "O método `enconde_plus` gera todas as entradas necessárias a partir do texto. O método retorna um dicionário com as chaves:\n",
        "\n",
        "- 'input_ids' - O id do texto tokenizado\n",
        "- 'attention_mask' - A máscara de atenção truncada ou preenchida até `max_length`\n",
        "- 'token_type_ids' - A máscara de atenção de pares de frase. Quando o texto é tokenizado com duas frases, a primeira recebe 0 a segunda frase recebe 1.\n",
        "\n",
        "https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWM3U6wF8PNw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fac225d9-b7fa-4e8d-d9ee-04611c6df826"
      },
      "source": [
        "# Recupera o tokenizador BERT\n",
        "tokenizer = getTokenizadorBERT()\n",
        "\n",
        "# Texto de exemplo\n",
        "texto = \"O que é embedding?\"\n",
        "\n",
        "# `encode_plus` irá:\n",
        "#   (1) Tokenize a frase sentence.\n",
        "#   (2) Adicionar o token `[CLS]` no início.\n",
        "#   (3) Adicionar o token `[SEP]` no fim.\n",
        "#   (4) Mapear tokens para os seus IDS.\n",
        "#   (5) Preencher ou truncar as frases para `max_length`\n",
        "#   (6) Criar máscara de atenção para os tokens [PAD].    \n",
        "#   (7) Retorna os dados com tensores\n",
        "dic_codificado = tokenizer.encode_plus(\n",
        "                        text=texto,                     # Texto a ser codificado.\n",
        "                        add_special_tokens = True,      # Adiciona os tokens especiais '[CLS]' e '[SEP]'\n",
        "                        max_length = 10,                # Define o tamanho máximo para preencheer ou truncar.\n",
        "                        truncation = True,              # Trunca o texto por max_length\n",
        "                        padding = 'max_length',         # Preenche o texto até max_length\n",
        "                        return_attention_mask = True,   # Constrói a máscara de atenção.\n",
        "                        return_tensors = 'pt'           # Retorna os dados como tensores pytorch.\n",
        "                   )\n",
        "\n",
        "# Recupera os dados do dicionário\n",
        "texto_token_ids = dic_codificado['input_ids']\n",
        "mascara_atencao = dic_codificado['attention_mask']\n",
        "token_type_ids = dic_codificado['token_type_ids']\n",
        "\n",
        "print(\"Texto exemplo      :\", texto)\n",
        "\n",
        "# Mostra o texto marcado\n",
        "print(\"Texto marcado      :\", texto_marcado)\n",
        "\n",
        "# Mostra o texto tokenizado\n",
        "print(\"Texto tokenizado   :\", texto_tokenizado)\n",
        "\n",
        "# Mostra o id do texto tokenizado\n",
        "print(\"Texto id token     :\", texto_token_ids)\n",
        "\n",
        "# Mostra a máscara de atenção\n",
        "print(\"Máscara de atenção :\", mascara_atencao)\n",
        "\n",
        "# Mostra a máscara de atenção de pares de frase (0 primeira frase e 1 para a segunda frase)\n",
        "print(\"Token types ids    :\", token_type_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues'...\n",
            "Texto exemplo      : O que é embedding?\n",
            "Texto marcado      : [CLS] O que é embedding? [SEP]\n",
            "Texto tokenizado   : ['[CLS]', 'O', 'que', 'é', 'em', '##be', '##dd', '##ing', '?', '[SEP]']\n",
            "Texto id token     : tensor([[  101,   231,   179,   253,   173,   483, 14852,   446,   136,   102]])\n",
            "Máscara de atenção : tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "Token types ids    : tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjHaBG4U8z04"
      },
      "source": [
        "# 5 Usando o modelo Pré-treinado\n",
        "\n",
        "Uso do modell pré-treinado sem ajuste fino."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riR4jz8W-qk3"
      },
      "source": [
        "# 6 Teste Completo do Tokenizador e Modelo BERT\n",
        "\n",
        "Testa o tokenizador e modelo de vretorno da função getBERT.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QP-2tC8YOFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eea17364-165f-4a5d-8523-70d9545de98f"
      },
      "source": [
        "# Utiliza a função para retornar o tokenizador e o modelo\n",
        "tokenizer, model = getBERT(tamanhoBERT='base')\n",
        "\n",
        "# Define um sentença de exemplo com diversos siginificados da palavra  \"banco\"\n",
        "texto = \"Depois de roubar o cofre do banco,\"\\\n",
        "        \" o ladrão de banco foi visto \" \\\n",
        "        \"sentado no banco da praça central.\"\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado = \"[CLS] \" + texto + \" [SEP]\"\n",
        "\n",
        "# Divide a sentença em tokens\n",
        "texto_tokenizado = tokenizer.tokenize(texto_marcado)\n",
        "\n",
        "# Mapeia os tokens em seus índices do vocabuário\n",
        "tokens_indexados = tokenizer.convert_tokens_to_ids(texto_tokenizado)\n",
        "\n",
        "# Mostra os tokens com seus índices\n",
        "i = 0\n",
        "for tup in zip(texto_tokenizado, tokens_indexados):\n",
        "    print('{:>3} {:<12} {:>6,}'.format(i, tup[0], tup[1]))\n",
        "    i= i + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues'...\n",
            "Carregando o modelo BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues' com os pesos das camadas ocultas=False...\n",
            "  0 [CLS]           101\n",
            "  1 Depois        1,603\n",
            "  2 de              125\n",
            "  3 roubar       16,150\n",
            "  4 o               146\n",
            "  5 co              144\n",
            "  6 ##fre         1,198\n",
            "  7 do              171\n",
            "  8 banco         6,465\n",
            "  9 ,               117\n",
            " 10 o               146\n",
            " 11 lad          13,503\n",
            " 12 ##rão         1,759\n",
            " 13 de              125\n",
            " 14 banco         6,465\n",
            " 15 foi             262\n",
            " 16 visto         3,382\n",
            " 17 sentado      21,541\n",
            " 18 no              202\n",
            " 19 banco         6,465\n",
            " 20 da              180\n",
            " 21 praça         6,357\n",
            " 22 central       2,692\n",
            " 23 .               119\n",
            " 24 [SEP]           102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUU1BIGiYs58"
      },
      "source": [
        "# Importa a bibliteca\n",
        "import torch\n",
        "\n",
        "# Marca cada um dos tokens como pertencentes à frase \"1\", pois só iremos analisar uma.\n",
        "segmentos_ids = [1] * len(texto_tokenizado)\n",
        "\n",
        "# Converte as entradas de listas para tensores do torch\n",
        "input_ids = torch.as_tensor([tokens_indexados])\n",
        "attention_mask = torch.as_tensor([segmentos_ids])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-hYiWnRYs6B"
      },
      "source": [
        "# Prediz os atributos dos estados ocultos para cada camada\n",
        "with torch.no_grad():    \n",
        "  \n",
        "    # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states    \n",
        "    outputs = model(input_ids=input_ids, \n",
        "                    attention_mask=attention_mask)\n",
        "    \n",
        "    # Recupera a última camada oculta da saída\n",
        "    last_hidden_states = outputs[0]\n",
        "\n",
        "# Remove a dimensão 1, o lote \"batches\".\n",
        "# O método ´squeeze´ remove a primeira dimensão(0) pois possui tamanho 1\n",
        "token_embeddings = torch.squeeze(last_hidden_states, dim=0)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tnv1g2qIWKD"
      },
      "source": [
        "BASE em português:\n",
        "* banco tensor([ 0.2817, -0.2229,  0.4058, -0.1698,  0.4350])\n",
        "* banco tensor([ 0.3844, -0.2985,  0.1629, -0.2853,  0.4661])\n",
        "* banco tensor([ 0.0382, -0.1985,  0.0825,  0.1369,  0.6871])\n",
        "\n",
        "\n",
        "LARGE em português:\n",
        "* banco tensor([ 0.4261, -0.1251, -0.4406,  0.0736, -1.4059])\n",
        "* banco tensor([ 0.4835,  0.1447, -0.4306,  0.3436, -1.4682])\n",
        "* banco tensor([ 0.3631,  0.9212,  0.1919, -0.2493, -0.9418])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hrWa-RzZIFl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62f892e6-7b3d-4b5e-9a85-1bf17d8399d0"
      },
      "source": [
        "palavra1 = 8\n",
        "palavra2 = 14\n",
        "palavra3 = 19\n",
        "\n",
        "print('Os primeiros 5 valores de cada instância de \"banco\".')\n",
        "print('')\n",
        "print(texto_tokenizado[palavra1], str(token_embeddings[palavra1][:5]))\n",
        "print(texto_tokenizado[palavra2], str(token_embeddings[palavra2][:5]))\n",
        "print(texto_tokenizado[palavra3], str(token_embeddings[palavra3][:5]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Os primeiros 5 valores de cada instância de \"banco\".\n",
            "\n",
            "banco tensor([ 0.2817, -0.2229,  0.4058, -0.1698,  0.4350])\n",
            "banco tensor([ 0.3844, -0.2985,  0.1629, -0.2853,  0.4661])\n",
            "banco tensor([ 0.0382, -0.1985,  0.0825,  0.1369,  0.6871])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neHWoJlxLe2z"
      },
      "source": [
        "BASE em português:\n",
        "* Vetor de similaridade  para diferentes significados( 14 , 19 ):  0.71\n",
        "* Vetor de similaridade  para mesmo significado( 14 , 8 ):  0.88\n",
        "* Vetor de similaridade  para diferentes significados( 19 , 8 ):  0.76\n",
        "\n",
        "LARGE em português:\n",
        "* Vetor de similaridade  para diferentes significados( 14 , 19 ):  0.78\n",
        "* Vetor de similaridade  para mesmo significado( 14 , 8 ):  0.92\n",
        "* Vetor de similaridade  para diferentes significados( 19 , 8 ):  0.77"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0Wz7anjZIFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1af45ba6-a70b-4045-8f82-a221fbb9109f"
      },
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "print(\"Período:\", texto)\n",
        "print(\"Palavra1= \", palavra1, \"=\", texto_tokenizado[palavra1], \"(instituição financeira)\")\n",
        "print(\"Palavra2=\", palavra2, \"=\", texto_tokenizado[palavra2], \"(instituição financeira)\")\n",
        "print(\"Palavra3=\", palavra3, \"=\", texto_tokenizado[palavra3], \"(assento)\")\n",
        "\n",
        "# Calcula a similaridade de coseno entre as palavras banco\n",
        "# Em \"ladrão de banco\" versus \"banco da praça\" (diferentes significados).\n",
        "banco_diferente = 1 - cosine(token_embeddings[palavra2], token_embeddings[palavra3])\n",
        "\n",
        "print('Vetor de similaridade  para diferentes significados(',palavra2,',',palavra3,'):  %.2f' % banco_diferente)\n",
        "\n",
        "# Calcula a similaridade de coseno entre as palavras banco\n",
        "# Em \"ladrão de banco\" versus \"cofre do banco\" (mesmo significado).\n",
        "mesmo_banco = 1 - cosine(token_embeddings[palavra2], token_embeddings[palavra1])\n",
        "\n",
        "print('Vetor de similaridade  para mesmo significado      (',palavra2,', ',palavra1,'):  %.2f' % mesmo_banco)\n",
        "\n",
        "# Calcula a similaridade de coseno entre as palavras banco\n",
        "# Em \"cofre do banco\" versus \"banco da praça\" (diferente significados).\n",
        "banco_diferente2 = 1 - cosine(token_embeddings[palavra3], token_embeddings[palavra1])\n",
        "\n",
        "print('Vetor de similaridade  para diferentes significados(',palavra3,', ',palavra1,'):  %.2f' % banco_diferente2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Período: Depois de roubar o cofre do banco, o ladrão de banco foi visto sentado no banco da praça central.\n",
            "Palavra1=  8 = banco (instituição financeira)\n",
            "Palavra2= 14 = banco (instituição financeira)\n",
            "Palavra3= 19 = banco (assento)\n",
            "Vetor de similaridade  para diferentes significados( 14 , 19 ):  0.71\n",
            "Vetor de similaridade  para mesmo significado      ( 14 ,  8 ):  0.88\n",
            "Vetor de similaridade  para diferentes significados( 19 ,  8 ):  0.76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JAFCSVopfFb"
      },
      "source": [
        "# 7 Teste completo da função de recuperação de embeddings de frase\n",
        "\n",
        "Testa os embeddings de retorno da função getEmbedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmjHFQUttUtF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae8cec2e-b5cd-4efd-cdfc-509beb44872a"
      },
      "source": [
        "# Utiliza a função para retornar o tokenizador e o modelo\n",
        "tokenizer, model = getBERT(tamanhoBERT='base')\n",
        "\n",
        "# Define um sentença de exemplo com diversos siginificados da palavra  \"banco\"\n",
        "texto = \"Depois de roubar o cofre do banco,\"\\\n",
        "        \" o ladrão de banco foi visto \" \\\n",
        "        \"sentado no banco da praça central.\"\n",
        "\n",
        "# 0-texto_tokenizado, 1-input_ids, 2-attention_mask, 3-token_type_ids, 4-outputs(0=last_hidden_state,1=pooler_output,2=hidden_states)\n",
        "outputs = getEmbedding(texto, tokenizer, model)        \n",
        "\n",
        "# Recupera a última camada oculta da saída\n",
        "# 4-outputs 0=last_hidden_state\n",
        "last_hidden_states = outputs[4][0]\n",
        "\n",
        "# Remove a dimensão 1, o lote \"batches\".\n",
        "# O método ´squeeze´ remove a primeira dimensão(0) pois possui tamanho 1\n",
        "token_embeddings = torch.squeeze(last_hidden_states, dim=0)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues'...\n",
            "Carregando o modelo BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em língua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd84LqC5tUtI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fd834d7-8078-49a9-e880-76bf9dabe9e5"
      },
      "source": [
        "# Divide a sentença em tokens\n",
        "texto_tokenizado = outputs[0]\n",
        "\n",
        "# Mapeia os tokens em seus índices do vocabuário\n",
        "tokens_indexados = outputs[1]\n",
        "\n",
        "# Mostra os tokens com seus índices\n",
        "for i, token in enumerate(texto_tokenizado):\n",
        "    print(i, token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [CLS]\n",
            "1 Depois\n",
            "2 de\n",
            "3 roubar\n",
            "4 o\n",
            "5 co\n",
            "6 ##fre\n",
            "7 do\n",
            "8 banco\n",
            "9 ,\n",
            "10 o\n",
            "11 lad\n",
            "12 ##rão\n",
            "13 de\n",
            "14 banco\n",
            "15 foi\n",
            "16 visto\n",
            "17 sentado\n",
            "18 no\n",
            "19 banco\n",
            "20 da\n",
            "21 praça\n",
            "22 central\n",
            "23 .\n",
            "24 [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDB9bYPpI-Oq"
      },
      "source": [
        "BASE em português:\n",
        "* banco tensor([ 0.2817, -0.2229,  0.4058, -0.1698,  0.4350])\n",
        "* banco tensor([ 0.3844, -0.2985,  0.1629, -0.2853,  0.4661])\n",
        "* banco tensor([ 0.0382, -0.1985,  0.0825,  0.1369,  0.6871])\n",
        "\n",
        "\n",
        "LARGE em português:\n",
        "* banco tensor([ 0.4261, -0.1251, -0.4406,  0.0736, -1.4059])\n",
        "* banco tensor([ 0.4835,  0.1447, -0.4306,  0.3436, -1.4682])\n",
        "* banco tensor([ 0.3631,  0.9212,  0.1919, -0.2493, -0.9418])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhKpFWRrECOo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c692ea98-0e41-466b-f3d1-a38ba34012bd"
      },
      "source": [
        "palavra1 = 8\n",
        "palavra2 = 14\n",
        "palavra3 = 19\n",
        "\n",
        "print('Os primeiros 5 valores de cada instância de \"banco\".')\n",
        "print('')\n",
        "print(texto_tokenizado[palavra1], str(token_embeddings[palavra1][:5]))\n",
        "print(texto_tokenizado[palavra2], str(token_embeddings[palavra2][:5]))\n",
        "print(texto_tokenizado[palavra3], str(token_embeddings[palavra3][:5]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Os primeiros 5 valores de cada instância de \"banco\".\n",
            "\n",
            "banco tensor([ 0.2817, -0.2229,  0.4058, -0.1698,  0.4350])\n",
            "banco tensor([ 0.3844, -0.2985,  0.1629, -0.2853,  0.4661])\n",
            "banco tensor([ 0.0382, -0.1985,  0.0825,  0.1369,  0.6871])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgv05eUcECOs"
      },
      "source": [
        "BASE em português:\n",
        "* Vetor de similaridade  para diferentes significados( 14 , 19 ):  0.71\n",
        "* Vetor de similaridade  para mesmo significado( 14 , 8 ):  0.88\n",
        "* Vetor de similaridade  para diferentes significados( 19 , 8 ):  0.76\n",
        "\n",
        "LARGE em português:\n",
        "* Vetor de similaridade  para diferentes significados( 14 , 19 ):  0.78\n",
        "* Vetor de similaridade  para mesmo significado( 14 , 8 ):  0.92\n",
        "* Vetor de similaridade  para diferentes significados( 19 , 8 ):  0.77"
      ]
    }
  ]
}