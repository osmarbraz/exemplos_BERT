{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExemplosPythonBERTTransformers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMZoDI3NX9otZ+9mBaeIc0g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "81c698d967c24a6f9d580eebfc7de638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d388f78aa40f4515bc86f620975716bb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f4cc03f3c80849b0af8ccf46d0b257fb",
              "IPY_MODEL_19f8fb95cf1f448396ae164e3aecafdd"
            ]
          }
        },
        "d388f78aa40f4515bc86f620975716bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4cc03f3c80849b0af8ccf46d0b257fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6038ab40ea0c458981aed4ab13cd9a1d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 434,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 434,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f5a110167104e17b64cd243b08b05e9"
          }
        },
        "19f8fb95cf1f448396ae164e3aecafdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2f186ae4671a41149169db8ce2fece09",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 434/434 [00:00&lt;00:00, 462B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_449e38653aca469eb69b20b34fc7214f"
          }
        },
        "6038ab40ea0c458981aed4ab13cd9a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f5a110167104e17b64cd243b08b05e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f186ae4671a41149169db8ce2fece09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "449e38653aca469eb69b20b34fc7214f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4eaa30cdf7c458aab34002d7bdd1a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7159165567f448e9b107a935f7afd5ff",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_755bdc7472b34440a08ff41d28cad5a1",
              "IPY_MODEL_d95b47461b0e48709a890f50dc59a335"
            ]
          }
        },
        "7159165567f448e9b107a935f7afd5ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "755bdc7472b34440a08ff41d28cad5a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9c8d8430c03f4031b85c76e3c161abfc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1344997306,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1344997306,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7a34a262af1402385bc16c00817a10d"
          }
        },
        "d95b47461b0e48709a890f50dc59a335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_39f7e95889714ca3a4c5fc81fda4cbca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.34G/1.34G [00:51&lt;00:00, 26.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61329cb6348b4fb998b8138613b1284d"
          }
        },
        "9c8d8430c03f4031b85c76e3c161abfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e7a34a262af1402385bc16c00817a10d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "39f7e95889714ca3a4c5fc81fda4cbca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61329cb6348b4fb998b8138613b1284d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "30441d93f6c44417a925ffa21a550916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9960aafc77504cacbf68d6679bc4f647",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1f2f965ef7a849b4a4de3580f582f40d",
              "IPY_MODEL_ad50e43c77b5447c95a739b39a0c3e97"
            ]
          }
        },
        "9960aafc77504cacbf68d6679bc4f647": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f2f965ef7a849b4a4de3580f582f40d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_343ae9c6e0ac4eb2a04e94299cc5f4b8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_581e9d25ead74321ba543e27ccf9c7b9"
          }
        },
        "ad50e43c77b5447c95a739b39a0c3e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_34714666a2024876aa34f542d140a1b6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:08&lt;00:00, 50.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22376b5b307144fb9f42618f2c21bb5a"
          }
        },
        "343ae9c6e0ac4eb2a04e94299cc5f4b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "581e9d25ead74321ba543e27ccf9c7b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34714666a2024876aa34f542d140a1b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22376b5b307144fb9f42618f2c21bb5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8bef9fa2f78b4da98a4945fafbbcd3c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fdeab3a1c1c34b93812ed9bd08b055f9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2fd487fddb214cc8a373686d3b3c9c15",
              "IPY_MODEL_17163beee8784f67ba7ae5ab3b18e3de"
            ]
          }
        },
        "fdeab3a1c1c34b93812ed9bd08b055f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2fd487fddb214cc8a373686d3b3c9c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_85edd1cce82c465ea20ac93bdcc0d783",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1631e89f390247759f1f998242c558e3"
          }
        },
        "17163beee8784f67ba7ae5ab3b18e3de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9f6d7459ba7e47cdb17381a36e9d032b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:07&lt;00:00, 57.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33b0bcc7b5724cafbe2c3a418ea418d0"
          }
        },
        "85edd1cce82c465ea20ac93bdcc0d783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1631e89f390247759f1f998242c558e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f6d7459ba7e47cdb17381a36e9d032b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33b0bcc7b5724cafbe2c3a418ea418d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osmarbraz/exemplos_BERT/blob/main/ExemplosPythonBERTTransformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VTUgBXSzaGh"
      },
      "source": [
        "# Exemplos de uso do BERT in Transformers by Huggingface\n",
        "\n",
        "FunÃ§Ãµes e exemplos de uso BERT atravÃ©s da biblioteca `Transformer` da [Huggingface](https://huggingface.co/transformers/).\n",
        "\n",
        "- Exemplo de carregamento do tokenizador e modelo atravÃ©s de diretÃ³rio e da comunidade\n",
        "  - Download do arquivos do modelo \n",
        "  \n",
        "- FunÃ§Ã£o de retorno do tokenizador. \n",
        "- FunÃ§Ã£o de retorno do modelo. \n",
        "- FunÃ§Ã£o de retorno do tokenizador e do modelo. \n",
        "\n",
        "Artigo base do [BERT](https://arxiv.org/pdf/1810.04805.pdf).\n",
        "\n",
        "O tokenizador da BERT utiliza WordPiece, veja em [artigo original](https://arxiv.org/pdf/1609.08144.pdf).\n",
        "\n",
        "-----------------------------------------\n",
        "**Guia Colab Iniciante:**\n",
        "\n",
        "https://medium.com/machina-sapiens/google-colab-guia-do-iniciante-334d70aad531\n",
        "\n",
        "**DocumentaÃ§Ã£o oficial:**\n",
        "\n",
        "https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/01.01-Help-And-Documentation.ipynb\n",
        "\n",
        "**CaracterÃ­sticas :**\n",
        "\n",
        "https://colab.research.google.com/notebooks/basic_features_overview.ipynb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOwhoI1lzi-s"
      },
      "source": [
        "# 1 InstalaÃ§Ã£o dos pacotes das biblioteca Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNn1DGlMzNDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d8de4e-2a94-46e1-f0ae-7269c0b489cd"
      },
      "source": [
        "# Instala a Ãºltima versÃ£o da biblioteca\n",
        "!pip install transformers\n",
        "\n",
        "# Instala uma versÃ£o especÃ­fica da biblioteca\n",
        "# !pip install -U transformers==4.5.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsX_7pxMzvhS"
      },
      "source": [
        "# 2 Carregamento do modelo e tokenizador do BERT do Transfomer by Huggingface\n",
        "\n",
        "Os tokenizadores e os modelos PyTorch podem ser carregados diretamente da comunidade ou atravÃ©s do download de arquivos.\n",
        "\n",
        "Independente de onde foi carregado o tokenizador ou o modelo Pytorch existe a dpendÃªncia da instalaÃ§Ã£o da biblioteca."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URuijJq7z7Kv"
      },
      "source": [
        "### Carregando BERT da comunidade\n",
        "\n",
        "Lista de **modelos da comunidade** podem ser consultadas em \n",
        "https://huggingface.co/models.\n",
        "\n",
        "Lista dos nomes dos modelos em **portuguÃªs** disponÃ­veis na comunidade (https://github.com/neuralmind-ai/portuguese-bert):  \n",
        "* **'neuralmind/bert-base-portuguese-cased'**\n",
        "* **'neuralmind/bert-large-portuguese-cased'**\n",
        "\n",
        "Lista dos nomes dos modelos em **inglÃªs** disponÃ­veis na comunidade:\n",
        "* **'bert-base-uncased'**\n",
        "* **'bert-large-uncased'**\n",
        "\n",
        "O modelo do tokenizador pode ser acessado de duas formas, ou utilizando as AutoClasses ou Classes EspecÃ­ficas. A seguir as duas formas de carregar o modelo BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XwUuIioozUj"
      },
      "source": [
        "#### AutoClasses\n",
        "\n",
        "As `AutoClasses` recuperam automaticamente o modelo mais relevante, dado o nome/caminho para os pesos/configuraÃ§Ã£o /vocabulÃ¡rio prÃ©-treinados. A API destas classes podem ser consultadas [aqui](https://huggingface.co/transformers/model_doc/auto.html).\n",
        "\n",
        "A classe `AutoTokenizer` identifica a arquitetura a partir do nome ou do caminho do modelo prÃ©-treinado que vocÃª estÃ¡ fornecendo ao mÃ©todo from_pretrained.\n",
        "\n",
        "Ao instanciar um  `AutoModel`, `AutoConfig` ou `AutoTokenizer` criarÃ¡ diretamente uma classe da arquitetura relevante, por exemplo:\n",
        "- `tokenizador = AutoTokenizer.from_pretrained('bert-base-cased')` \n",
        "  - criarÃ¡ uma instÃ¢ncia de `BertTokenizerr`.\n",
        "- `model = AutoModel.from_pretrained('bert-base-cased')` \n",
        "  - criarÃ¡ uma instÃ¢ncia de `BertModel`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jec62Nah0iQI"
      },
      "source": [
        "# Importando as bibliotecas do Modelo e do Tokenizador\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "# Carregando o modelo do tokenizador o modelo do PyTorch da comunidade utilizando AutoClasses\n",
        "\n",
        "# Tokenizador do modelo utilizando as AutoClasses\n",
        "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "\n",
        "# Modelo prÃ©-treinado utilizando as AutoClasses\n",
        "model = AutoModel.from_pretrained('neuralmind/bert-base-portuguese-cased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-gJlnkBo2U5"
      },
      "source": [
        "#### Classes especÃ­ficas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oi8ez_FNWkR"
      },
      "source": [
        "# Importando as bibliotecas do Modelo e do Tokenizador\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "# Carregando o modelo do tokenizador o modelo do PyTorch da comunidade utilizando classes especÃ­ficas\n",
        "\n",
        "# Tokenizador do modelo utilizando classe especÃ­fica\n",
        "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "\n",
        "# Modelo prÃ©-treinado utilizando classe especÃ­fica\n",
        "model = BertModel.from_pretrained('neuralmind/bert-base-portuguese-cased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wrp2wwYytLDW"
      },
      "source": [
        "### Carregando BERT de diretÃ³rio(arquivo)\n",
        "\n",
        "O carregamento do BERT a partir de um diretÃ³rio com os arquivos do tokenizador e do modelo. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c161Lh80z8T2"
      },
      "source": [
        "Os arquivo do modelo devem deve ser colocados na pasta '/content/modelo'.\n",
        "\n",
        "Este arquivo pode ser utilizado tanto pelas classes especificas ou pelas AutoClasses, conforme apresentado na seÃ§Ã£o 'AutoTokenizer'.\n",
        "\n",
        "Link dos arquivos do modelo BERT prÃ©-treinado em portuguÃªs(pt-br) da neuralmind-ai chamado de [BERTTimbau](https://github.com/neuralmind-ai/portuguese-bert).\n",
        "\n",
        "O BERT em portuguÃªs Ã©disponibilizado em dois tamanhos: **BASE** e **LARGE** e em dois formatos: checkpoint do **TensorFlow** ou do **Pytorch**.\n",
        "\n",
        "O arquivo do **Pytorch** Ã© manipulado pela implementaÃ§Ã£o da biblioteca torch disponÃ­vel [aqui](https://pytorch.org/docs/stable/torch.html)\n",
        "\n",
        "**BERT Base: 1.1 Gbytes**\n",
        "* **Pytorch Checkpoint(Usado no exemplo)** - https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\n",
        "\n",
        "* **Tensor Flow Checkpoint** - https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_tensorflow_checkpoint.zip\n",
        "\n",
        "* **VocabulÃ¡rio(Usado no exemplo)** - https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/vocab.txt\n",
        "\n",
        "\n",
        "**BERT Large: 3.2 Gbytes**\n",
        "* **Pytorch Checkpoint** - https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\n",
        "\n",
        "* **Tensor Checkpoint** - https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_tensorflow_checkpoint.zip\n",
        "\n",
        "* **VocabulÃ¡rio** - https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/vocab.txt\n",
        "\n",
        "-----------------\n",
        "**CorreÃ§Ã£o dos nomes dos arquivos para usar com o BERT as Service:**\n",
        "* 'large'\n",
        "    * model.ckpt-1000000.data-00000-of-00001 > bert_model.ckpt.data-00000-of-00001\n",
        "    * model.ckpt-1000000.index bert_model.ckpt.index\n",
        "    * model.ckpt-1000000.meta > bert_model.ckpt.meta\n",
        "\n",
        "* 'base'\n",
        "    * model.ckpt.data-00000-of-00001> bert_model.ckpt.data-00000-of-00001\n",
        "    * model.ckpt.index > bert_model.ckpt.index\n",
        "    * model.ckpt.meta > bert_model.ckpt.meta\n",
        "-------------------------\n",
        "O modelo foi treinado com dados de **BrWaC** (Brazilian Web as Corpus):\n",
        "\n",
        "https://www.researchgate.net/publication/326303825_The_brWaC_Corpus_A_New_Open_Resource_for_Brazilian_Portuguese\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZGdOSC_lLBh"
      },
      "source": [
        "#### Usando o BERT do diretÃ³rio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyhoaQKNaNY7"
      },
      "source": [
        "##### Download do arquivo do Pytorch Checkpoint\n",
        "\n",
        "Ã‰ necessÃ¡rio realizar o download do arquivo de checkpoint e do vocabulÃ¡rio.\n",
        "\n",
        "O arquivo do checkpoint precisa ser descompactado.\n",
        "\n",
        "Os arquivos do modelo e do vocabulÃ¡rio sÃ£o movidos para o diretÃ³rio `modelo`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYTujSE9aNY_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4520711d-21f2-44ea-dbe6-a51824d3d549"
      },
      "source": [
        "# Importando as bibliotecas\n",
        "import os\n",
        "\n",
        "# Comente uma das urls para carregar modelo do BERT de tamanhos diferentes(base/large)\n",
        "# url do arquivo do modelo do Pytorch checkpoint\n",
        "\n",
        "# arquivo menor(base) 1.1 Gbytes\n",
        "# url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "# arquivo grande(large) 3.5 Gbytes\n",
        "url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "      \n",
        "# Recupera o nome do arquivo do modelo da url anterior\n",
        "arquivo = url.split(\"/\")[-1]\n",
        "\n",
        "# Nome do arquivo do vocabulÃ¡rio\n",
        "arquivo_vocab = \"vocab.txt\"\n",
        "\n",
        "# Caminho do arquivo na url\n",
        "caminho = url[0:len(url)-len(arquivo)]\n",
        "\n",
        "# DiretÃ³rio descompactaÃ§Ã£o do modelo\n",
        "diretorio = '/content/modelo'\n",
        "\n",
        "# Verifica se o diretÃ³rio do modelo existe a partir do diretÃ³rio corrente\n",
        "if not os.path.exists(diretorio):\n",
        "   \n",
        "    # Realiza o download do arquivo do tokenizador\n",
        "    !wget $url\n",
        "    \n",
        "    # Descompacta o arquivo no diretÃ³rio do modelo\n",
        "    !unzip -o $arquivo -d $diretorio\n",
        "\n",
        "    # Realiza o download do arquivo do vocabulÃ¡rio\n",
        "    # O vocabulÃ¡rio nÃ£o estÃ¡ no arquivo compactado acima\n",
        "    # Concatena o caminho do modelo mais o nome do arquivo do vocabulÃ¡rio\n",
        "    url_vocab = caminho + arquivo_vocab\n",
        "\n",
        "    # Realiza o download do arquivo do vocabulÃ¡rio\n",
        "    !wget $url_vocab\n",
        "    \n",
        "    # Move o arquivo do vocabulÃ¡rio para o diretÃ³rio do modelo\n",
        "    !mv $arquivo_vocab $diretorio\n",
        "            \n",
        "    # Apaga o arquivo baixado\n",
        "    #!rm $arquivo\n",
        "    \n",
        "    # Move o arquivo do modelo para o diretÃ³rio do modelo\n",
        "    !mv $arquivo $diretorio\n",
        "    \n",
        "    print('DiretÃ³rio do modelo:\\'' + diretorio + '\\' pronta!')\n",
        "else:\n",
        "    print('DiretÃ³rio do modelo:\\'' + diretorio + '\\' jÃ¡ existe!')\n",
        "\n",
        "# Lista o diretÃ³rio corrente\n",
        "!ls -la"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DiretÃ³rio do modelo:'/content/modelo' jÃ¡ existe!\n",
            "total 28\n",
            "drwxr-xr-x 1 root root 4096 Feb  2 15:35 .\n",
            "drwxr-xr-x 1 root root 4096 Feb  2 15:08 ..\n",
            "drwxr-xr-x 1 root root 4096 Jan 28 17:15 .config\n",
            "drwxr-xr-x 2 root root 4096 Feb  2 15:13 modelo\n",
            "drwxr-xr-x 2 root root 4096 Feb  2 15:34 modelobase\n",
            "drwxr-xr-x 2 root root 4096 Feb  2 15:35 modelolarge\n",
            "drwxr-xr-x 1 root root 4096 Jan 20 17:27 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gZ7lZaVaEk5"
      },
      "source": [
        "##### Carregando o BERT do diretÃ³rio\n",
        "\n",
        "Carregando o **tokenizador** e **modelo** BERT do diretÃ³rio '/content/modelo/' do diretÃ³rio padrÃ£o.\n",
        "\n",
        "A implementaÃ§Ã£o do huggingface pytorch inclui um conjunto de interfaces projetadas para uma variedade de tarefas de PNL. Embora essas interfaces sejam todas construÃ­das sobre um modelo treinado de BERT, cada uma possui diferentes camadas superiores e tipos de saÃ­da projetados para acomodar suas tarefas especÃ­ficas de PNL.\n",
        "\n",
        "Aqui estÃ¡ a lista atual de classes fornecidas para o ajuste fino:\n",
        "* BertModel\n",
        "* BertForPreTraining\n",
        "* BertForMaskedLM\n",
        "* BertForNextSentencePrediction\n",
        "* BertForSequenceClassification\n",
        "* BertForTokenClassification\n",
        "* BertForQuestionAnswering\n",
        "\n",
        "A documentaÃ§Ã£o para estas pode ser encontrada em [aqui](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyA4PFN6aNZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb340569-c3ce-4fa1-d5fd-71da42433688"
      },
      "source": [
        "# Importando as bibliotecas do Modelo e do Tokenizador\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "# Carregando o modelo do tokenizador o modelo do PyTorch do diretÃ³rio  utilizando classes especÃ­ficas\n",
        "\n",
        "print('Carregando o tokenizador BERT do diretÃ³rio \\'' + diretorio + '\\'...')\n",
        "\n",
        "# Tokenizador do modelo utilizando classe especÃ­fica\n",
        "tokenizer = BertTokenizer.from_pretrained('/content/modelo/', \n",
        "                                          do_lower_case=False)\n",
        "\n",
        "print('Carregando o modelo BERT do diretÃ³rio \\'' + diretorio + '\\'...')\n",
        "\n",
        "# Modelo prÃ©-treinado utilizando classe especÃ­fica\n",
        "model = BertModel.from_pretrained('/content/modelo/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT do diretÃ³rio '/content/modelo'...\n",
            "Carregando o modelo BERT do diretÃ³rio '/content/modelo'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAm-Or2D0M0k"
      },
      "source": [
        "## Exemplos de formas de carregamento do BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udxdl4qklY--"
      },
      "source": [
        "#### Usando o BERT da comunidade ou diretÃ³rio v1\n",
        "\n",
        "Permite configurar a **fonte do modelo**.\n",
        "\n",
        "A variÃ¡vel `url` setada especifica que o BERT deve ser carregado de um diretÃ³rio, caso contrÃ¡rio da comunidade."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXm3x84klfRN"
      },
      "source": [
        "##### Download do arquivo do Pytorch Checkpoint\n",
        "\n",
        "Ã‰ necessÃ¡rio realizar o download do arquivo de checkpoint e do vocabulÃ¡rio.\n",
        "\n",
        "O arquivo do checkpoint precisa ser descompactado.\n",
        "\n",
        "Os arquivos do modelo e do vocabulÃ¡rio sÃ£o movidos para o diretÃ³rio `modelo`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtzDkSAYlfs1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab4a5a39-3275-46db-f441-50bea2b4bb0e"
      },
      "source": [
        "# Importando as bibliotecas\n",
        "import os\n",
        "\n",
        "# VariÃ¡vel para setar o tamanho do arquivo do BERT(base ou large)\n",
        "url = None\n",
        "\n",
        "# Comente uma das urls para carregar modelo do BERT de tamanhos diferentes(base/large)\n",
        "# url do arquivo do modelo do Pytorch checkpoint\n",
        "\n",
        "# arquivo menor(base) 1.1 Gbytes\n",
        "# url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "# arquivo grande(large) 3.5 Gbytes\n",
        "# url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "# Se a variÃ¡vel foi setada\n",
        "if url:\n",
        "\n",
        "    # DiretÃ³rio descompactaÃ§Ã£o do modelo\n",
        "    diretorio = '/content/modelo'\n",
        "\n",
        "    # Recupera o nome do arquivo do modelo da url anterior\n",
        "    arquivo = url.split(\"/\")[-1]\n",
        "\n",
        "    # Nome do arquivo do vocabulÃ¡rio\n",
        "    arquivo_vocab = \"vocab.txt\"\n",
        "\n",
        "    # Caminho do arquivo na url\n",
        "    caminho = url[0:len(url)-len(arquivo)]\n",
        "\n",
        "    # Verifica se a pasta de descompactaÃ§Ã£o existe no pasta corrente\n",
        "    if not os.path.exists(diretorio):\n",
        "   \n",
        "        # Realiza o download do arquivo do modelo\n",
        "        !wget $url\n",
        "    \n",
        "        # Descompacta o arquivo na pasta de destino\n",
        "        !unzip -o $arquivo -d $diretorio\n",
        "\n",
        "        # Realiza o download do arquivo do vocabulÃ¡rio\n",
        "        # O vocabulÃ¡rio nÃ£o estÃ¡ no arquivo compactado acima\n",
        "        # Concatena o caminho do modelo mais o nome do arquivo do vocabulÃ¡rio\n",
        "        url_vocab = caminho + arquivo_vocab\n",
        "\n",
        "        # Realiza o download do arquivo do vocabulÃ¡rio\n",
        "        !wget $url_vocab\n",
        "    \n",
        "        # Move o arquivo do vocabulÃ¡rio para o diretÃ³rio do modelo\n",
        "        !mv $arquivo_vocab $diretorio\n",
        "            \n",
        "        # Move o arquivo do modelo para o diretÃ³rio do modelo\n",
        "        !mv $arquivo $diretorio\n",
        "        \n",
        "        print('DiretÃ³rio do modelo:\\'' + diretorio + '\\' pronta!')\n",
        "    else:      \n",
        "      print('DiretÃ³rio do modelo:\\'' + diretorio + '\\' jÃ¡ existe!')\n",
        "\n",
        "    #lista a pasta corrente\n",
        "    !ls -la $diretorio\n",
        "else:\n",
        "    print('VariÃ¡vel url nÃ£o setada!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VariÃ¡vel url nÃ£o setada!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2VmlSXMgUiU"
      },
      "source": [
        "##### Carregando o BERT\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR3LKinp7GiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bf739e2-f07e-4130-8c29-334b97a27551"
      },
      "source": [
        "# Importando as bibliotecas do Modelo e do Tokenizador\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "# Se a variÃ¡vel url foi setada\n",
        "if url:\n",
        "    # Carregando o Tokenizador do diretÃ³rio\n",
        "    print('Carregando o tokenizador BERT do diretÃ³rio \\'' + diretorio + '\\'...')\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(diretorio)\n",
        "\n",
        "    # Carregano o Modelo do diretÃ³rio\n",
        "    print('Carregando o modelo BERT do diretÃ³rio \\'' + diretorio + '\\'...')\n",
        "\n",
        "    model = BertModel.from_pretrained(diretorio, \n",
        "                                      do_lower_case=False)\n",
        "\n",
        "else:\n",
        "    # Carregando o Tokenizador da comunidade\n",
        "    print('Carregando o tokenizador BERT da comunidade...')\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', \n",
        "                                              do_lower_case=False)\n",
        "\n",
        "    # Carregando o Modelo da comunidade\n",
        "    print('Carregando o modelo BERT da comunidade...')\n",
        "\n",
        "    model = BertModel.from_pretrained('neuralmind/bert-base-portuguese-cased')  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT da comunidade...\n",
            "Carregando o modelo BERT da comunidade...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snDFb_WBpItd"
      },
      "source": [
        "#### Usando o BERT da comunidade ou diretÃ³rio v2\n",
        "\n",
        "Permite configurar o **tamanho do modelo** e a **fonte do modelo**.\n",
        "\n",
        "A variÃ¡vel `fonteBERT` com os valores `comunidade` ou `diretÃ³rio` especifica se deve ser carregado o BERT de um diretÃ³rio ou da comunidade.\n",
        "\n",
        "A variÃ¡vel `tamanhoBERT` com os valores `base` ou `large` especifica se o tamanho do modelo BERT a ser utilizado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nj1KS8xCpIte"
      },
      "source": [
        "##### Download do arquivo do Pytorch Checkpoint\n",
        "\n",
        "Ã‰ necessÃ¡rio realizar o download do arquivo de checkpoint e do vocabulÃ¡rio.\n",
        "\n",
        "O arquivo do checkpoint precisa ser descompactado.\n",
        "\n",
        "Os arquivos do modelo e do vocabulÃ¡rio sÃ£o movidos para o diretÃ³rio `modelo`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gab02A0pIte",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57a877a5-b362-4f78-c5c5-6448d09c8171"
      },
      "source": [
        "# Importando as bibliotecas\n",
        "import os\n",
        "\n",
        "# VariÃ¡vel fonte especifica a origem do modelo(comunidade ou diretÃ³rio)\n",
        "#fonteBERT = 'comunidade'\n",
        "fonteBERT = 'diretorio'\n",
        "\n",
        "# Especifica o tamanho do modelo a ser carregado(base ou large)\n",
        "tamanhoBERT = 'large'\n",
        "#tamanhoBERT = 'base'\n",
        "\n",
        "# Se a variÃ¡vel 'fonteBERT' foi setada para 'diretorio' faz o download dos arquivos modelo\n",
        "if fonteBERT == 'diretorio':\n",
        "    \n",
        "    # Se a variÃ¡vel 'tamanhoBERT' foi setada para 'base' faz o download do arquivo do tamanho base do BERT, caso contrÃ¡rio do large.\n",
        "    if tamanhoBERT == 'base':\n",
        "        # url do arquivo do modelo do Pytorch checkpoint\n",
        "        # arquivo menor(base) 1.1 Gbytes\n",
        "        url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "    else:\n",
        "        # url do arquivo do modelo do Pytorch checkpoint\n",
        "        # arquivo grande(large) 3.5 Gbytes\n",
        "        url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "    # DiretÃ³rio descompactaÃ§Ã£o do modelo\n",
        "    diretorio = '/content/modelo'\n",
        "\n",
        "    # Recupera o nome do arquivo do modelo da url anterior\n",
        "    arquivo = url.split(\"/\")[-1]\n",
        "\n",
        "    # Nome do arquivo do vocabulÃ¡rio\n",
        "    arquivo_vocab = \"vocab.txt\"\n",
        "\n",
        "    # Caminho do arquivo na url\n",
        "    caminho = url[0:len(url)-len(arquivo)]\n",
        "\n",
        "    # Verifica se a pasta de descompactaÃ§Ã£o existe no pasta corrente\n",
        "    if not os.path.exists(diretorio):\n",
        "   \n",
        "        # Realiza o download do arquivo do modelo\n",
        "        !wget $url\n",
        "    \n",
        "        # Descompacta o arquivo na pasta de destino\n",
        "        !unzip -o $arquivo -d $diretorio\n",
        "\n",
        "        # Realiza o download do arquivo do vocabulÃ¡rio\n",
        "        # O vocabulÃ¡rio nÃ£o estÃ¡ no arquivo compactado acima\n",
        "        # Concatena o caminho do modelo mais o nome do arquivo do vocabulÃ¡rio\n",
        "        url_vocab = caminho + arquivo_vocab\n",
        "\n",
        "        # Realiza o download do arquivo do vocabulÃ¡rio\n",
        "        !wget $url_vocab\n",
        "    \n",
        "        # Move o arquivo do vocabulÃ¡rio para o diretÃ³rio do modelo\n",
        "        !mv $arquivo_vocab $diretorio\n",
        "            \n",
        "        # Move o arquivo do modelo para o diretÃ³rio do modelo\n",
        "        !mv $arquivo $diretorio      \n",
        "                \n",
        "        print('DiretÃ³rio do modelo:\\'' + diretorio + '\\' pronta!')\n",
        "    else:      \n",
        "      print('DiretÃ³rio do modelo:\\'' + diretorio + '\\' jÃ¡ existe!')\n",
        "\n",
        "    #lista a pasta corrente\n",
        "    !ls -la $diretorio\n",
        "else:\n",
        "    print('SerÃ¡ carregado o BERT da comunidade')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DiretÃ³rio do modelo:'/content/modelo' jÃ¡ existe!\n",
            "total 2525908\n",
            "drwxr-xr-x 2 root root       4096 Feb  2 15:13 .\n",
            "drwxr-xr-x 1 root root       4096 Feb  2 15:35 ..\n",
            "-rw-r--r-- 1 root root 1244275810 Jan 22  2020 bert-large-portuguese-cased_pytorch_checkpoint.zip\n",
            "-rw-rw-r-- 1 root root        874 Jan 12  2020 config.json\n",
            "-rw-rw-r-- 1 root root 1342014951 Jan 12  2020 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root     209528 Jan 21  2020 vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stZE-KdbpIti"
      },
      "source": [
        "##### Carregando o BERT\n",
        "\n",
        "Carregando o **tokenizador** e **modelo** BERT do diretÃ³rio '/content/modelo/' do diretÃ³rio padrÃ£o.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbdpa5IzpItj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af5878c2-9bac-476e-867d-a6606736ff3f"
      },
      "source": [
        "# Importando as bibliotecas do Modelo e do Tokenizador\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "# Se a variÃ¡vel 'fonteBERT' foi setada para 'diretorio' faz o download dos arquivos modelo\n",
        "if fonteBERT == 'diretorio':\n",
        "\n",
        "    # Carregando o Tokenizador do diretÃ³rio\n",
        "    print('Carregando o tokenizador BERT_' + tamanhoBERT + ' do diretÃ³rio ' + diretorio + '...')\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(diretorio,\n",
        "                                              do_lower_case=False)   \n",
        "\n",
        "    # Carregando o Modelo do diretÃ³rio\n",
        "    print('Carregando o modelo BERT_' + tamanhoBERT + ' do diretÃ³rio ' + diretorio + '...')\n",
        "\n",
        "    model = BertModel.from_pretrained(diretorio)\n",
        "\n",
        "else:\n",
        "    # Se a variÃ¡vel 'tamanhoBERT' foi setada para 'base' faz o carregamento do tamanho base do BERT, caso contrÃ¡rio do large.\n",
        "    if tamanhoBERT == 'base':\n",
        "        # Carregando o Tokenizador da comunidade\n",
        "        print('Carregando o tokenizador BERT_base da comunidade...')\n",
        "\n",
        "        tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', \n",
        "                                                  do_lower_case=False)\n",
        "\n",
        "        # Carregando o Modelo da comunidade\n",
        "        print('Carregando o modelo BERT_base da comunidade...')\n",
        "\n",
        "        model = BertModel.from_pretrained('neuralmind/bert-base-portuguese-cased')  \n",
        "    else:\n",
        "        # Carregando o Tokenizador da comunidade  \n",
        "        print('Carregando o tokenizador BERT_large da comunidade...')\n",
        "\n",
        "        tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-large-portuguese-cased',\n",
        "                                                  do_lower_case=False)\n",
        "\n",
        "        # Carregando o Modelo da comunidade\n",
        "        print('Carregando o modelo BERT_large da comunidade...')\n",
        "\n",
        "        model = BertModel.from_pretrained('neuralmind/bert-large-portuguese-cased')  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT_large do diretÃ³rio /content/modelo...\n",
            "Carregando o modelo BERT_large do diretÃ³rio /content/modelo...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaBm0YHY4lsf"
      },
      "source": [
        "#### \\>>> Usando o BERT da comunidade ou diretÃ³rio v3 <<<\n",
        "\n",
        "Permite configurar o **tamanho do modelo**, **fonte do modelo** e **se deve retornar os pesos das camadas ocultas**.\n",
        "\n",
        "A variÃ¡vel `fonteBERT` com os valores `comunidade` ou `diretÃ³rio` especifica se deve ser carregado o BERT de um diretÃ³rio ou da comunidade.\n",
        "\n",
        "A variÃ¡vel `tamanhoBERT` com os valores `base` ou `large` especifica se o tamanho do modelo BERT a ser utilizado.\n",
        "\n",
        "A variÃ¡vel `pesosCamadasOcultas` com os valores `True` ou `False` especifica se Ã© para gerar e retornar os pesos das camadas ocultas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiZcK9JU4lsj"
      },
      "source": [
        "##### Download do arquivo do Pytorch Checkpoint\n",
        "\n",
        "Ã‰ necessÃ¡rio realizar o download do arquivo de checkpoint e do vocabulÃ¡rio.\n",
        "\n",
        "O arquivo do checkpoint precisa ser descompactado.\n",
        "\n",
        "Os arquivos do modelo e do vocabulÃ¡rio sÃ£o movidos para o diretÃ³rio `modelo`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k4sP3yZ4lsm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d55dc28d-4175-491b-d10f-5180eb58a300"
      },
      "source": [
        "# Importando as bibliotecas\n",
        "import os\n",
        "\n",
        "# VariÃ¡vel fonte especifica a origem do modelo(comunidade ou diretÃ³rio)\n",
        "#fonteBERT = 'comunidade'\n",
        "fonteBERT = 'diretorio'\n",
        "\n",
        "# Especifica o tamanho do modelo a ser carregado(base ou large)\n",
        "tamanhoBERT = 'large'\n",
        "#tamanhoBERT = 'base'\n",
        "\n",
        "# Especifica se o modelo deve ser carregado com os pesos das camadas ocultas(True ou False)\n",
        "pesosCamadasOcultas = False\n",
        "\n",
        "# Se a variÃ¡vel 'fonteBERT' foi setada para 'diretorio' faz o download dos arquivos modelo\n",
        "if fonteBERT == 'diretorio':\n",
        "    \n",
        "    # Se a variÃ¡vel 'tamanhoBERT' foi setada para 'base' faz o download do arquivo do tamanho base do BERT, caso contrÃ¡rio do large.\n",
        "    if tamanhoBERT == 'base':\n",
        "        # url do arquivo do modelo do Pytorch checkpoint\n",
        "        # arquivo menor(base) 1.1 Gbytes\n",
        "        url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "    else:\n",
        "        # url do arquivo do modelo do Pytorch checkpoint\n",
        "        # arquivo grande(large) 3.5 Gbytes\n",
        "        url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "    # DiretÃ³rio descompactaÃ§Ã£o do modelo\n",
        "    diretorio = '/content/modelo'\n",
        "\n",
        "    # Recupera o nome do arquivo do modelo da url anterior\n",
        "    arquivo = url.split(\"/\")[-1]\n",
        "\n",
        "    # Nome do arquivo do vocabulÃ¡rio\n",
        "    arquivo_vocab = \"vocab.txt\"\n",
        "\n",
        "    # Caminho do arquivo na url\n",
        "    caminho = url[0:len(url)-len(arquivo)]\n",
        "\n",
        "    # Verifica se a pasta de descompactaÃ§Ã£o existe no pasta corrente\n",
        "    if not os.path.exists(diretorio):\n",
        "   \n",
        "        # Realiza o download do arquivo do modelo\n",
        "        !wget $url\n",
        "    \n",
        "        # Descompacta o arquivo na pasta de destino\n",
        "        !unzip -o $arquivo -d $diretorio\n",
        "\n",
        "        # Realiza o download do arquivo do vocabulÃ¡rio\n",
        "        # O vocabulÃ¡rio nÃ£o estÃ¡ no arquivo compactado acima\n",
        "        # Concatena o caminho do modelo mais o nome do arquivo do vocabulÃ¡rio\n",
        "        url_vocab = caminho + arquivo_vocab\n",
        "\n",
        "        # Realiza o download do arquivo do vocabulÃ¡rio\n",
        "        !wget $url_vocab\n",
        "    \n",
        "        # Move o arquivo do vocabulÃ¡rio para o diretÃ³rio do modelo\n",
        "        !mv $arquivo_vocab $diretorio\n",
        "            \n",
        "        # Move o arquivo do modelo para o diretÃ³rio do modelo\n",
        "        !mv $arquivo $diretorio      \n",
        "                \n",
        "        print('DiretÃ³rio do modelo:\\'' + diretorio + '\\' pronta!')\n",
        "    else:      \n",
        "      print('DiretÃ³rio do modelo:\\'' + diretorio + '\\' jÃ¡ existe!')\n",
        "\n",
        "    #lista a pasta corrente\n",
        "    !ls -la $diretorio\n",
        "else:\n",
        "    print('SerÃ¡ carregado o BERT da comunidade')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DiretÃ³rio do modelo:'/content/modelo' jÃ¡ existe!\n",
            "total 2525908\n",
            "drwxr-xr-x 2 root root       4096 Feb  2 15:13 .\n",
            "drwxr-xr-x 1 root root       4096 Feb  2 15:35 ..\n",
            "-rw-r--r-- 1 root root 1244275810 Jan 22  2020 bert-large-portuguese-cased_pytorch_checkpoint.zip\n",
            "-rw-rw-r-- 1 root root        874 Jan 12  2020 config.json\n",
            "-rw-rw-r-- 1 root root 1342014951 Jan 12  2020 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root     209528 Jan 21  2020 vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu-MjBcD4ls3"
      },
      "source": [
        "##### Carregando o BERT\n",
        "\n",
        "Carregando o **tokenizador** e **modelo** BERT do diretÃ³rio '/content/modelo/' do diretÃ³rio padrÃ£o.\n",
        "\n",
        "O tokenizador utiliza WordPiece, veja em [artigo original](https://arxiv.org/pdf/1609.08144.pdf).\n",
        "\n",
        "Carregando o tokenizador da pasta '/content/modelo/' do diretÃ³rio padrÃ£o se variÃ¡vel `url` setada.\n",
        "\n",
        "**Caso contrÃ¡rio carrega da comunidade**\n",
        "\n",
        "Por default(`do_lower_case=True`) todas as letras sÃ£o colocadas para minÃºsculas. Para ignorar a conversÃ£o para minÃºsculo use o parÃ¢metro `do_lower_case=False`. Esta opÃ§Ã£o tambÃ©m considera as letras acentuadas(Ã£Ã§Ã©Ã­...), que sÃ£o necessÃ¡rias a lÃ­ngua portuguesa.\n",
        "\n",
        "O parÃ¢metro `do_lower_case` interfere na quantidade tokens a ser gerado apartir de um texto. Quando igual a `False` reduz a quantidade de tokens gerados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMivq-Lk4ls5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a3c2175-b635-47ad-c4a1-3087509cdc43"
      },
      "source": [
        "# Importando as bibliotecas do Modelo e do Tokenizador\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "# Se a variÃ¡vel 'fonteBERT' foi setada para 'diretorio' faz o download dos arquivos modelo\n",
        "if fonteBERT == 'diretorio':\n",
        "\n",
        "    # Carregando o Tokenizador do diretÃ³rio\n",
        "    print('Carregando o tokenizador BERT_' + tamanhoBERT + ' do diretÃ³rio ' + diretorio + '...')\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(diretorio,\n",
        "                                               do_lower_case=False)   \n",
        "\n",
        "    # Carregando o Modelo do diretÃ³rio\n",
        "    print('Carregando o modelo BERT_' + tamanhoBERT + ' do diretÃ³rio ' + diretorio + '...')\n",
        "\n",
        "    model = BertModel.from_pretrained(diretorio,\n",
        "                                      output_hidden_states = pesosCamadasOcultas) # Se o modelo retorna todos os estados ocultos)\n",
        "\n",
        "else:\n",
        "    # Se a variÃ¡vel 'tamanhoBERT' foi setada para 'base' faz o carregamento do tamanho base do BERT, caso contrÃ¡rio do large.\n",
        "    if tamanhoBERT == 'base':\n",
        "        # Carregando o Tokenizador da comunidade\n",
        "        print('Carregando o tokenizador BERT_base da comunidade...')\n",
        "\n",
        "        tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased',\n",
        "                                                   do_lower_case=False)     \n",
        "\n",
        "        # Carregando o Modelo da comunidade\n",
        "        print('Carregando o modelo BERT_base da comunidade...')\n",
        "\n",
        "        model = BertModel.from_pretrained('neuralmind/bert-base-portuguese-cased', \n",
        "                                          output_hidden_states = pesosCamadasOcultas) # Se o modelo retorna todos os estados ocultos)  \n",
        "    else:\n",
        "        # Carregando o Tokenizador da comunidade  \n",
        "        print('Carregando o tokenizador BERT_large da comunidade...')\n",
        "\n",
        "        tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-large-portuguese-cased',\n",
        "                                                   do_lower_case=False)     \n",
        "\n",
        "        # Carregando o Modelo da comunidade\n",
        "        print('Carregando o modelo BERT_large da comunidade...')\n",
        "\n",
        "        model = BertModel.from_pretrained('neuralmind/bert-large-portuguese-cased', \n",
        "                                          output_hidden_states = pesosCamadasOcultas) # Se o modelo retorna todos os estados ocultos)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT_large do diretÃ³rio /content/modelo...\n",
            "Carregando o modelo BERT_large do diretÃ³rio /content/modelo...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7NXsoTTC9rf"
      },
      "source": [
        "#### Usando o BERT da comunidade ou diretÃ³rio  com uma funÃ§Ã£o que retorna o tokenizador v4\n",
        "\n",
        "FunÃ§Ã£o que retorna o tokenizador do BERT. permite configurar o tamanho do modelo e a fonte do modelo. \n",
        "\n",
        "A linguagem do modelo Ã© especificada internamente na funÃ§Ã£o.\n",
        "\n",
        "O parÃ¢metro  `fonteBERT` com os valores `comunidade` ou `diretÃ³rio` especifica se deve ser carregado o BERT de um diretÃ³rio ou da comunidade.\n",
        "\n",
        "O parÃ¢metro `tamanhoBERT` com os valores `base` ou `large` especifica se o tamanho do modelo BERT a ser utilizado.\n",
        "\n",
        "O parÃ¢metro `lingua` com os valores `portugues` ou `ingles` especifica a lingua do modelo BERT a ser utilizado.\n",
        "\n",
        "O parÃ¢metro `do_lower_case` especÃ­fica para colocar as letras em maiÃºsculo ou minÃ­sculo e a remoÃ§Ã£o das letras acentuadas. Nesta funÃ§Ã£o o default `False` pois a lÃ­ngua portugues possui letras acentuadas(Ã£Ã§Ã©Ã­...), que sÃ£o necessÃ¡rias a lÃ­ngua portuguesa. No mÃ©todo `from_treina from_pretrained` o default Ã© `True` quando o parÃ¤metro nÃ£o Ã© especificado.\n",
        "\n",
        "A funÃ§Ã£o retorna o **tokenizador** para os parÃ¢metros especificado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCyv5sfgC9rg"
      },
      "source": [
        "##### Declarando uma funÃ§Ã£o que retorna o tokenizador."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1siflk0C9rh"
      },
      "source": [
        "# Valores default para os parÃ¢metros da funÃ§Ã£o\n",
        "def getTokenizadorBERT(fonteBERT = 'comunidade', \n",
        "                       tamanhoBERT = 'base', \n",
        "                       linguaBERT = 'portugues',\n",
        "                       do_lower_case = False):\n",
        "\n",
        "    \"\"\"Retorna o tokenizador BERT carregado.\n",
        "    De acordo com os parÃ¢metros especificados ou carrega o BERT da comunidade \n",
        "    ou realiza o download dos arquivos do modelo.\n",
        "\n",
        "    Args:\n",
        "        fonteBERT: Especifica a origem do modelo do BERT 'comunidade' ou 'diretorio'.\n",
        "        tamanhoBERT: Especifica o tamanho do modelo do BERT 'large' ou 'base'.\n",
        "        linguaBERT: Especifica a lÃ­ngua do modelo do BERT 'portugues' ou 'ingles'.\n",
        "\n",
        "    Returns:\n",
        "        `tokenizador` com o tokenizador do modelo BERT carregado.       \n",
        "    \"\"\"\n",
        "    #======================================================================\n",
        "    # VerificaÃ§Ã£o do idioma e tamanho do modelo\n",
        "    #======================================================================\n",
        "    # Verifica se a lÃ­ngua Ã© portuguÃªs e o tamanho do modelo\n",
        "    if linguaBERT == 'portugues' and tamanhoBERT == 'base':\n",
        "        nome_modelo_bert = 'neuralmind/bert-base-portuguese-cased'\n",
        "    else:\n",
        "        if linguaBERT == 'portugues' and tamanhoBERT == 'large':\n",
        "            nome_modelo_bert = 'neuralmind/bert-large-portuguese-cased'\n",
        "        else:\n",
        "            # Verifica se a lÃ­ngua Ã© inglÃ©s e o tamanho do modelo\n",
        "            if linguaBERT == 'ingles' and tamanhoBERT == 'base':\n",
        "                nome_modelo_bert = 'bert-base-uncased'\n",
        "            else:\n",
        "                if linguaBERT == 'ingles' and tamanhoBERT == 'large':\n",
        "                    nome_modelo_bert = 'bert-large-uncased'\n",
        "                else:\n",
        "                    print(\"ParÃ¢metros \\'lÃ­ngua\\' e \\'tamanhoBERT\\' especificados incorretamente!\")\n",
        "                    return None, None\n",
        "\n",
        "    #======================================================================\n",
        "    # Download do arquivo do modelo\n",
        "    #======================================================================\n",
        "    #Se a variÃ¡vel 'fonteBERT' foi setada para 'diretorio' faz o download dos arquivos modelo\n",
        "    if fonteBERT == 'diretorio' and linguaBERT == 'portugues':\n",
        "    \n",
        "      # Se a variÃ¡vel 'tamanhoBERT' foi setada para 'base' faz o download do arquivo do tamanho base do BERT, caso contrÃ¡rio do large.\n",
        "      if tamanhoBERT == 'base':\n",
        "          # url do arquivo do modelo do Pytorch checkpoint\n",
        "          # arquivo menor(base) 1.1 Gbytes\n",
        "          url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "      else:\n",
        "          # url do arquivo do modelo do Pytorch checkpoint\n",
        "          # arquivo grande(large) 3.5 Gbytes\n",
        "          url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "      # DiretÃ³rio descompactaÃ§Ã£o do modelo\n",
        "      diretorio = '/content/modelo' + tamanhoBERT\n",
        "\n",
        "      # Recupera o nome do arquivo do modelo da url anterior\n",
        "      arquivo = url.split(\"/\")[-1]\n",
        "\n",
        "      # Nome do arquivo do vocabulÃ¡rio\n",
        "      arquivo_vocab = \"vocab.txt\"\n",
        "\n",
        "      # Caminho do arquivo na url\n",
        "      caminho = url[0:len(url)-len(arquivo)]\n",
        "\n",
        "      # Verifica se a pasta de descompactaÃ§Ã£o existe no pasta corrente\n",
        "      if not os.path.exists(diretorio):\n",
        "   \n",
        "          # Realiza o download do arquivo do modelo\n",
        "          !wget $url\n",
        "    \n",
        "          # Descompacta o arquivo na pasta de destino\n",
        "          !unzip -o $arquivo -d $diretorio\n",
        "\n",
        "          # Realiza o download do arquivo do vocabulÃ¡rio\n",
        "          # O vocabulÃ¡rio nÃ£o estÃ¡ no arquivo compactado acima\n",
        "          # Concatena o caminho do modelo mais o nome do arquivo do vocabulÃ¡rio\n",
        "          url_vocab = caminho + arquivo_vocab\n",
        "\n",
        "          # Realiza o download do arquivo do vocabulÃ¡rio\n",
        "          !wget $url_vocab\n",
        "    \n",
        "          # Move o arquivo do vocabulÃ¡rio para o diretÃ³rio do modelo\n",
        "          !mv $arquivo_vocab $diretorio\n",
        "            \n",
        "          # Move o arquivo do modelo para o diretÃ³rio do modelo\n",
        "          !mv $arquivo $diretorio      \n",
        "                \n",
        "          print('DiretÃ³rio do modelo:\\'' + diretorio + '\\' pronta!')\n",
        "      else:      \n",
        "          print('DiretÃ³rio do modelo:\\'' + diretorio + '\\' jÃ¡ existe!')\n",
        "      \n",
        "    else:\n",
        "        if linguaBERT == 'ingles':\n",
        "            print('O modelo BERT na lÃ­ngua inglesa deve ser carregado somente da comunidade.')\n",
        "       \n",
        "    #======================================================================\n",
        "    # Carregamento do tokenizador\n",
        "    #======================================================================\n",
        "\n",
        "    # Importando as bibliotecas do Tokenizador\n",
        "    from transformers import BertTokenizer\n",
        "\n",
        "    # Se a variÃ¡vel 'fonteBERT' foi setada para 'diretorio' faz o download dos arquivos modelo\n",
        "    # Carregamento de diretÃ³rio somente para a lÃ­ngua portuguesa\n",
        "    if fonteBERT == 'diretorio' and linguaBERT == 'portugues':\n",
        "\n",
        "        # Carregando o Tokenizador do diretÃ³rio\n",
        "        print('Carregando o tokenizador BERT_' + tamanhoBERT \n",
        "              + ' do diretÃ³rio \\'' + diretorio \n",
        "              + '\\' em lÃ­ngua \\''+ linguaBERT + '\\'...')\n",
        "\n",
        "        tokenizer = BertTokenizer.from_pretrained(diretorio,\n",
        "                                                  do_lower_case=do_lower_case)\n",
        "    else:\n",
        "        # Carregando o Tokenizador da comunidade\n",
        "        print('Carregando o tokenizador BERT \\'' + nome_modelo_bert \n",
        "              + '\\' da comunidade em lÃ­ngua \\''+ linguaBERT + '\\'...')\n",
        "\n",
        "        tokenizer = BertTokenizer.from_pretrained(nome_modelo_bert,\n",
        "                                                  do_lower_case=do_lower_case)\n",
        "\n",
        "    # Retorna o tokenizador BERT carregado           \n",
        "    return tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MemXlw5fC9rl"
      },
      "source": [
        "##### Usando a funÃ§Ã£o **getTokenizadorBERT()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2dSJJQsC9rl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd7cfdab-2c42-462e-9d7c-8089abeca773"
      },
      "source": [
        "tokenizador = getTokenizadorBERT()\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK9EVQjTC9ro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a11dc0f3-8d59-420c-f20a-7de45262d17c"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(tamanhoBERT='large')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-large-portuguese-cased' da comunidade em lÃ­ngua 'portugues'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pylw2QuC9rr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c442611-792f-4198-e7f3-b8f792e2680b"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(tamanhoBERT='base')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JZqO28VC9rt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "321a3372-b5c2-4a97-b446-aa254983e117"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(fonteBERT='diretorio', \n",
        "                      tamanhoBERT='base')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DiretÃ³rio do modelo:'/content/modelobase' jÃ¡ existe!\n",
            "Carregando o tokenizador BERT_base do diretÃ³rio '/content/modelobase' em lÃ­ngua 'portugues'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxPhkiHgC9rw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6feb3e09-9c90-4ed4-d404-fb92d131ebb9"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(fonteBERT='diretorio', \n",
        "                      tamanhoBERT='large', \n",
        "                      linguaBERT='portugues')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DiretÃ³rio do modelo:'/content/modelolarge' jÃ¡ existe!\n",
            "Carregando o tokenizador BERT_large do diretÃ³rio '/content/modelolarge' em lÃ­ngua 'portugues'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch9g2K7JC9ry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c61767c2-bbc5-494d-92d2-ecb81f8f1bfe"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(fonteBERT='diretorio', \n",
        "                                 tamanhoBERT='base', \n",
        "                                 linguaBERT='portugues')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DiretÃ³rio do modelo:'/content/modelobase' jÃ¡ existe!\n",
            "Carregando o tokenizador BERT_base do diretÃ³rio '/content/modelobase' em lÃ­ngua 'portugues'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqAOEy4KC9r1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53296b3f-0f52-4ac2-c349-6ea5eb455b9e"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(fonteBERT='comunidade', \n",
        "                      tamanhoBERT='large', \n",
        "                      linguaBERT='portugues')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-large-portuguese-cased' da comunidade em lÃ­ngua 'portugues'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yZilzc7C9r3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d996ad3a-af5f-4048-9a21-9c41a145ff8c"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(fonteBERT='comunidade', \n",
        "                                 tamanhoBERT='base', \n",
        "                                 linguaBERT='portugues')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmcpd7bgC9r7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94963224-4e91-4080-e34f-de069cb45bbf"
      },
      "source": [
        "tokenizador  = getTokenizadorBERT(tamanhoBERT='large', \n",
        "                                  linguaBERT='ingles')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na lÃ­ngua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-large-uncased' da comunidade em lÃ­ngua 'ingles'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtLgJEEGC9r-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68a27fa8-59ce-4918-e627-693a2bb720b9"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(tamanhoBERT='base', \n",
        "                                 linguaBERT='ingles')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na lÃ­ngua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-base-uncased' da comunidade em lÃ­ngua 'ingles'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IxywOwUC9sA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8310546-69c3-42ca-db9a-8fd98643bc42"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(fonteBERT='diretorio', \n",
        "                                tamanhoBERT='large', \n",
        "                                linguaBERT='ingles')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na lÃ­ngua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-large-uncased' da comunidade em lÃ­ngua 'ingles'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoH_mQBaC9sC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c896ed11-9c2f-4a79-8bcb-a4ebf0283715"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(fonteBERT='diretorio', \n",
        "                                 tamanhoBERT='base', \n",
        "                                 linguaBERT='ingles')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na lÃ­ngua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-base-uncased' da comunidade em lÃ­ngua 'ingles'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsVXks6PC9sE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2681c1e8-ce71-4875-9ba1-739f647c02e2"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(fonteBERT='comunidade', \n",
        "                                 tamanhoBERT='large', \n",
        "                                 linguaBERT='ingles')\n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na lÃ­ngua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-large-uncased' da comunidade em lÃ­ngua 'ingles'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ1NiUxgC9sH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5a74f02-265e-44bb-a39e-5163377bb740"
      },
      "source": [
        "tokenizador = getTokenizadorBERT(fonteBERT='comunidade', \n",
        "                                 tamanhoBERT='base', \n",
        "                                 linguaBERT='ingles') \n",
        "\n",
        "del tokenizador"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na lÃ­ngua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-base-uncased' da comunidade em lÃ­ngua 'ingles'...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiwRA1m9C9sQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cf9652b-67e5-4f2b-923b-ce8568729f14"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3381"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnCNWElNFi49"
      },
      "source": [
        "#### Usando o BERT da comunidade ou diretÃ³rio com uma funÃ§Ã£o que retorna o modelo v5\n",
        "\n",
        "FunÃ§Ã£o que retorna modelo do BERT. permite configurar o tamanho do modelo e a fonte do modelo. \n",
        "\n",
        "A linguagem do modelo Ã© especificada internamente na funÃ§Ã£o.\n",
        "\n",
        "O parÃ¢metro  `fonteBERT` com os valores `comunidade` ou `diretÃ³rio` especifica se deve ser carregado o BERT de um diretÃ³rio ou da comunidade.\n",
        "\n",
        "O parÃ¢metro `tamanhoBERT` com os valores `base` ou `large` especifica se o tamanho do modelo BERT a ser utilizado.\n",
        "\n",
        "O parÃ¢metro `lingua` com os valores `portugues` ou `ingles` especifica a lingua do modelo BERT a ser utilizado.\n",
        "\n",
        "O parÃ¢metro `pesosCamadasOcultas` com os valores `True` ou `False` especifica se Ã© para gerar e retornar os pesos das camadas ocultas.\n",
        "\n",
        "A funÃ§Ã£o retorna o **modelo** para os parÃ¢metros especificado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_HNay2hFi49"
      },
      "source": [
        "##### Declarando uma funÃ§Ã£o que retorna o modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEu7UM89Fi4-"
      },
      "source": [
        "# Valores default para os parÃ¢metros da funÃ§Ã£o\n",
        "def getModeloBERT(fonteBERT = 'comunidade', \n",
        "                  tamanhoBERT = 'base', \n",
        "                  linguaBERT = 'portugues', \n",
        "                  pesosCamadasOcultas = False):\n",
        "\n",
        "    \"\"\"Retorna o modelo BERT carregado.\n",
        "    De acordo com os parÃ¢metros especificados ou carrega o BERT da comunidade \n",
        "    ou realiza o download dos arquivos do modelo.\n",
        "\n",
        "    Args:\n",
        "        fonteBERT: Especifica a origem do modelo do BERT 'comunidade' ou 'diretorio'.\n",
        "        tamanhoBERT: Especifica o tamanho do modelo do BERT 'large' ou 'base'.\n",
        "        linguaBERT: Especifica a lÃ­ngua do modelo do BERT 'portugues' ou 'ingles'.\n",
        "        pesosCamadasOcultas: Especifica ao modelo para manter os pesos de todas as camadas \n",
        "            ocultas, caso contrÃ¡rio mantÃ©m somente a Ãºltima. A avaliaÃ§Ã£o do modelo retorna\n",
        "            um nÃºmero de diferentes objetos com base em como Ã© configurado na chamada do\n",
        "            mÃ©todo `from_pretrained`. O retorno de model quando output_hidden_states=TrueÂ´ Ã©:  \n",
        "                #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states            \n",
        "            Veja a documentaÃ§Ã£o para mais detalhes:\n",
        "            https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "\n",
        "    Returns:        \n",
        "        `modelo` com o modelo BERT carregado.\n",
        "    \"\"\"\n",
        "    #======================================================================\n",
        "    # VerificaÃ§Ã£o do idioma e tamanho do modelo\n",
        "    #======================================================================\n",
        "    # Verifica se a lÃ­ngua Ã© portuguÃªs e o tamanho do modelo\n",
        "    if linguaBERT == 'portugues' and tamanhoBERT == 'base':\n",
        "        nome_modelo_bert = 'neuralmind/bert-base-portuguese-cased'\n",
        "    else:\n",
        "        if linguaBERT == 'portugues' and tamanhoBERT == 'large':\n",
        "            nome_modelo_bert = 'neuralmind/bert-large-portuguese-cased'\n",
        "        else:\n",
        "            # Verifica se a lÃ­ngua Ã© inglÃ©s e o tamanho do modelo\n",
        "            if linguaBERT == 'ingles' and tamanhoBERT == 'base':\n",
        "                nome_modelo_bert = 'bert-base-uncased'\n",
        "            else:\n",
        "                if linguaBERT == 'ingles' and tamanhoBERT == 'large':\n",
        "                    nome_modelo_bert = 'bert-large-uncased'\n",
        "                else:\n",
        "                    print(\"ParÃ¢metros \\'lÃ­ngua\\' e \\'tamanhoBERT\\' especificados incorretamente!\")\n",
        "                    return None, None\n",
        "\n",
        "    #======================================================================\n",
        "    # Download do arquivo do modelo\n",
        "    #======================================================================\n",
        "    #Se a variÃ¡vel 'fonteBERT' foi setada para 'diretorio' faz o download dos arquivos modelo\n",
        "    if fonteBERT == 'diretorio' and linguaBERT == 'portugues':\n",
        "    \n",
        "      # Se a variÃ¡vel 'tamanhoBERT' foi setada para 'base' faz o download do arquivo do tamanho base do BERT, caso contrÃ¡rio do large.\n",
        "      if tamanhoBERT == 'base':\n",
        "          # url do arquivo do modelo do Pytorch checkpoint\n",
        "          # arquivo menor(base) 1.1 Gbytes\n",
        "          url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "      else:\n",
        "          # url do arquivo do modelo do Pytorch checkpoint\n",
        "          # arquivo grande(large) 3.5 Gbytes\n",
        "          url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "      # DiretÃ³rio descompactaÃ§Ã£o do modelo\n",
        "      diretorio = '/content/modelo' + tamanhoBERT\n",
        "\n",
        "      # Recupera o nome do arquivo do modelo da url anterior\n",
        "      arquivo = url.split(\"/\")[-1]\n",
        "\n",
        "      # Nome do arquivo do vocabulÃ¡rio\n",
        "      arquivo_vocab = \"vocab.txt\"\n",
        "\n",
        "      # Caminho do arquivo na url\n",
        "      caminho = url[0:len(url)-len(arquivo)]\n",
        "\n",
        "      # Verifica se a pasta de descompactaÃ§Ã£o existe no pasta corrente\n",
        "      if not os.path.exists(diretorio):\n",
        "   \n",
        "          # Realiza o download do arquivo do modelo\n",
        "          !wget $url\n",
        "    \n",
        "          # Descompacta o arquivo na pasta de destino\n",
        "          !unzip -o $arquivo -d $diretorio\n",
        "\n",
        "          # Realiza o download do arquivo do vocabulÃ¡rio\n",
        "          # O vocabulÃ¡rio nÃ£o estÃ¡ no arquivo compactado acima\n",
        "          # Concatena o caminho do modelo mais o nome do arquivo do vocabulÃ¡rio\n",
        "          url_vocab = caminho + arquivo_vocab\n",
        "\n",
        "          # Realiza o download do arquivo do vocabulÃ¡rio\n",
        "          !wget $url_vocab\n",
        "    \n",
        "          # Move o arquivo do vocabulÃ¡rio para o diretÃ³rio do modelo\n",
        "          !mv $arquivo_vocab $diretorio\n",
        "            \n",
        "          # Move o arquivo do modelo para o diretÃ³rio do modelo\n",
        "          !mv $arquivo $diretorio      \n",
        "                \n",
        "          print('DiretÃ³rio do modelo:\\'' + diretorio + '\\' pronta!')\n",
        "      else:      \n",
        "          print('DiretÃ³rio do modelo:\\'' + diretorio + '\\' jÃ¡ existe!')\n",
        "      \n",
        "    else:\n",
        "        if linguaBERT == 'ingles':\n",
        "            print('O modelo BERT na lÃ­ngua inglesa deve ser carregado somente da comunidade.')\n",
        "       \n",
        "    #======================================================================\n",
        "    # Carregamento do modelo\n",
        "    #======================================================================\n",
        "\n",
        "    # Importando as bibliotecas do Modelo\n",
        "    from transformers import BertModel\n",
        "\n",
        "    # Se a variÃ¡vel 'fonteBERT' foi setada para 'diretorio' faz o download dos arquivos modelo\n",
        "    # Carregamento de diretÃ³rio somente para a lÃ­ngua portuguesa\n",
        "    if fonteBERT == 'diretorio' and linguaBERT == 'portugues':\n",
        "\n",
        "        # Carregando o Modelo do diretÃ³rio\n",
        "        print('Carregando o modelo BERT_' + tamanhoBERT \n",
        "              + ' do diretÃ³rio \\'' + diretorio \n",
        "              + '\\' em lÃ­ngua \\''+ linguaBERT \n",
        "              + '\\' com os pesos das camadas ocultas=' + str(pesosCamadasOcultas) + '...')\n",
        "\n",
        "        model = BertModel.from_pretrained(diretorio, \n",
        "                                          output_hidden_states = pesosCamadasOcultas) # Se o modelo retorna todos os estados ocultos\n",
        "\n",
        "    else:\n",
        "\n",
        "        # Carregando o Modelo da comunidade\n",
        "        print('Carregando o modelo BERT \\'' + nome_modelo_bert \n",
        "              + '\\' da comunidade em lÃ­ngua \\''+ linguaBERT \n",
        "              + '\\' com os pesos das camadas ocultas=' + str(pesosCamadasOcultas) + '...')\n",
        "\n",
        "        model = BertModel.from_pretrained(nome_modelo_bert, \n",
        "                                          output_hidden_states = pesosCamadasOcultas) # Se o modelo retorna todos os estados ocultos \n",
        "    \n",
        "    # Retorna o modelo BERT carregado           \n",
        "    return  model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQsZoz_0Fi5B"
      },
      "source": [
        "##### Usando a funÃ§Ã£o getModeloBERT()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Shpi5zYrFi5C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f817dac-6d7d-4ef6-8a65-7e2c26201fda"
      },
      "source": [
        "model = getModeloBERT()\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o modelo BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vgrczx9Fi5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e73e89e1-4daf-4571-cb85-94126f4ca093"
      },
      "source": [
        "model = getModeloBERT(tamanhoBERT='large')\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o modelo BERT 'neuralmind/bert-large-portuguese-cased' da comunidade em lÃ­ngua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee7F6aJZFi5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04cb1216-8f8d-4011-905b-950ac3ed5c41"
      },
      "source": [
        "model = getModeloBERT(tamanhoBERT='base')\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o modelo BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ouj7SbLFi5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc979a1a-efbd-409a-d361-7d0b49fd1432"
      },
      "source": [
        "model = getModeloBERT(fonteBERT='diretorio', \n",
        "                      tamanhoBERT='base')\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DiretÃ³rio do modelo:'/content/modelobase' jÃ¡ existe!\n",
            "Carregando o modelo BERT_base do diretÃ³rio '/content/modelobase' em lÃ­ngua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re0JeBNIFi5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05bc5cdf-d4f8-462d-da3b-8d771506733e"
      },
      "source": [
        "model = getModeloBERT(fonteBERT='diretorio', \n",
        "                      tamanhoBERT='large', \n",
        "                      linguaBERT='portugues')\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DiretÃ³rio do modelo:'/content/modelolarge' jÃ¡ existe!\n",
            "Carregando o modelo BERT_large do diretÃ³rio '/content/modelolarge' em lÃ­ngua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D84OnvHPFi5R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ff1908c-dfe2-4ee3-b467-6bd8d5a8c4d9"
      },
      "source": [
        "model = getModeloBERT(fonteBERT='diretorio', \n",
        "                      tamanhoBERT='base', \n",
        "                      linguaBERT='portugues')\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DiretÃ³rio do modelo:'/content/modelobase' jÃ¡ existe!\n",
            "Carregando o modelo BERT_base do diretÃ³rio '/content/modelobase' em lÃ­ngua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x7bJqb4Fi5U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a313c8aa-3c71-4846-bd90-050bc732330f"
      },
      "source": [
        "model = getModeloBERT(fonteBERT='comunidade', \n",
        "                      tamanhoBERT='large', \n",
        "                      linguaBERT='portugues')\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o modelo BERT 'neuralmind/bert-large-portuguese-cased' da comunidade em lÃ­ngua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QRBdDKMFi5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e13847f2-01df-458c-b49a-1017e26a53e3"
      },
      "source": [
        "model = getModeloBERT(fonteBERT='comunidade', \n",
        "                      tamanhoBERT='base', \n",
        "                      linguaBERT='portugues')\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o modelo BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsoRCNwLFi5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8200759c-5176-4cbc-b227-c2a199e6c733"
      },
      "source": [
        "model =getModeloBERT(fonteBERT='comunidade', \n",
        "                     tamanhoBERT='base', \n",
        "                     linguaBERT='portugues',\n",
        "                     pesosCamadasOcultas = False)\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o modelo BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkLHJXiUFi5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169,
          "referenced_widgets": [
            "81c698d967c24a6f9d580eebfc7de638",
            "d388f78aa40f4515bc86f620975716bb",
            "f4cc03f3c80849b0af8ccf46d0b257fb",
            "19f8fb95cf1f448396ae164e3aecafdd",
            "6038ab40ea0c458981aed4ab13cd9a1d",
            "4f5a110167104e17b64cd243b08b05e9",
            "2f186ae4671a41149169db8ce2fece09",
            "449e38653aca469eb69b20b34fc7214f",
            "a4eaa30cdf7c458aab34002d7bdd1a99",
            "7159165567f448e9b107a935f7afd5ff",
            "755bdc7472b34440a08ff41d28cad5a1",
            "d95b47461b0e48709a890f50dc59a335",
            "9c8d8430c03f4031b85c76e3c161abfc",
            "e7a34a262af1402385bc16c00817a10d",
            "39f7e95889714ca3a4c5fc81fda4cbca",
            "61329cb6348b4fb998b8138613b1284d"
          ]
        },
        "outputId": "a901adf3-0b1b-41ea-ccb3-2bec9d7011e5"
      },
      "source": [
        "model = getModeloBERT(tamanhoBERT='large', \n",
        "                      linguaBERT='ingles')\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na lÃ­ngua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o modelo BERT 'bert-large-uncased' da comunidade em lÃ­ngua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81c698d967c24a6f9d580eebfc7de638",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=434.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4eaa30cdf7c458aab34002d7bdd1a99",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1344997306.0, style=ProgressStyle(descrâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DWDVehwFi5g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169,
          "referenced_widgets": [
            "30441d93f6c44417a925ffa21a550916",
            "9960aafc77504cacbf68d6679bc4f647",
            "1f2f965ef7a849b4a4de3580f582f40d",
            "ad50e43c77b5447c95a739b39a0c3e97",
            "343ae9c6e0ac4eb2a04e94299cc5f4b8",
            "581e9d25ead74321ba543e27ccf9c7b9",
            "34714666a2024876aa34f542d140a1b6",
            "22376b5b307144fb9f42618f2c21bb5a",
            "8bef9fa2f78b4da98a4945fafbbcd3c5",
            "fdeab3a1c1c34b93812ed9bd08b055f9",
            "2fd487fddb214cc8a373686d3b3c9c15",
            "17163beee8784f67ba7ae5ab3b18e3de",
            "85edd1cce82c465ea20ac93bdcc0d783",
            "1631e89f390247759f1f998242c558e3",
            "9f6d7459ba7e47cdb17381a36e9d032b",
            "33b0bcc7b5724cafbe2c3a418ea418d0"
          ]
        },
        "outputId": "d21b881a-f364-42fe-be86-e157cfd41726"
      },
      "source": [
        "model = getModeloBERT(tamanhoBERT='base', \n",
        "                     linguaBERT='ingles')\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na lÃ­ngua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o modelo BERT 'bert-base-uncased' da comunidade em lÃ­ngua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30441d93f6c44417a925ffa21a550916",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bef9fa2f78b4da98a4945fafbbcd3c5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaf7ha23Fi5j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "688505ef-7a3a-4596-958a-e7b321d24cf5"
      },
      "source": [
        "model = getModeloBERT(fonteBERT='diretorio', \n",
        "                      tamanhoBERT='large', \n",
        "                      linguaBERT='ingles')\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na lÃ­ngua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o modelo BERT 'bert-large-uncased' da comunidade em lÃ­ngua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhpOpsNcFi5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36936cb1-d935-48e2-9c39-2bda3853764b"
      },
      "source": [
        "model = getModeloBERT(fonteBERT='diretorio', \n",
        "                      tamanhoBERT='base', \n",
        "                      linguaBERT='ingles')\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na lÃ­ngua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o modelo BERT 'bert-base-uncased' da comunidade em lÃ­ngua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzLsTc5CFi5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c83ccaa-8d67-4cfd-d0e0-60aaca0a1340"
      },
      "source": [
        "model = getModeloBERT(fonteBERT='comunidade', \n",
        "                      tamanhoBERT='large', \n",
        "                      linguaBERT='ingles')\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na lÃ­ngua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o modelo BERT 'bert-large-uncased' da comunidade em lÃ­ngua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGpA4qAWFi5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec99fd97-0d3a-4377-d7b9-6eec1669e771"
      },
      "source": [
        "model = getModeloBERT(fonteBERT='comunidade', \n",
        "                      tamanhoBERT='base', \n",
        "                      linguaBERT='ingles') \n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na lÃ­ngua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o modelo BERT 'bert-base-uncased' da comunidade em lÃ­ngua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccq15D00Fi5t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b52ed2db-29f8-4e07-ac24-5bd74a3e4424"
      },
      "source": [
        "model = getModeloBERT(fonteBERT='comunidade', \n",
        "                      tamanhoBERT='base', \n",
        "                      linguaBERT='ingles', \n",
        "                      pesosCamadasOcultas = False)\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na lÃ­ngua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o modelo BERT 'bert-base-uncased' da comunidade em lÃ­ngua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAmRY-IEFi5x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a108013-fe93-44ea-8523-9cd027d440b4"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4761"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxolJHbqz83c"
      },
      "source": [
        "#### Usando o BERT da comunidade ou diretÃ³rio com uma funÃ§Ã£o que retorna o tokenizador e o modelo v6\n",
        "\n",
        "FunÃ§Ã£o que retorna o tokenizador e modelo do BERT. permite configurar o tamanho do modelo e a fonte do modelo. \n",
        "\n",
        "A linguagem do modelo Ã© especificada internamente na funÃ§Ã£o.\n",
        "\n",
        "O parÃ¢metro  `fonteBERT` com os valores `comunidade` ou `diretÃ³rio` especifica se deve ser carregado o BERT de um diretÃ³rio ou da comunidade.\n",
        "\n",
        "O parÃ¢metro `tamanhoBERT` com os valores `base` ou `large` especifica se o tamanho do modelo BERT a ser utilizado.\n",
        "\n",
        "O parÃ¢metro `lingua` com os valores `portugues` ou `ingles` especifica a lingua do modelo BERT a ser utilizado.\n",
        "\n",
        "O parÃ¢metro `pesosCamadasOcultas` com os valores `True` ou `False` especifica se Ã© para gerar e retornar os pesos das camadas ocultas.\n",
        "\n",
        "O parÃ¢metro `do_lower_case` especÃ­fica para colocar as letras em maiÃºsculo ou minÃ­sculo e a remoÃ§Ã£o das letras acentuadas. Nesta funÃ§Ã£o o default `False` pois a lÃ­ngua portugues possui letras acentuadas(Ã£Ã§Ã©Ã­...), que sÃ£o necessÃ¡rias a lÃ­ngua portuguesa. No mÃ©todo `from_treina from_pretrained` o default Ã© `True` quando o parÃ¤metro nÃ£o Ã© especificado.\n",
        "\n",
        "\n",
        "\n",
        "A funÃ§Ã£o retorna o **tokenizador** e o **modelo** para os parÃ¢metros especificado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWC2y9At7PJo"
      },
      "source": [
        "##### Declarando uma funÃ§Ã£o que retorna o tokenizador e o modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snXme4uU1M7F"
      },
      "source": [
        "# Valores default para os parÃ¢metros da funÃ§Ã£o\n",
        "def getBERT(fonteBERT = 'comunidade', \n",
        "            tamanhoBERT = 'base', \n",
        "            linguaBERT = 'portugues', \n",
        "            pesosCamadasOcultas = False,\n",
        "            do_lower_case = False):\n",
        "\n",
        "    \"\"\"Retorna o tokenizador e modelo BERT carregado.\n",
        "    De acordo com os parÃ¢metros especificados ou carrega o BERT da comunidade \n",
        "    ou realiza o download dos arquivos do modelo.\n",
        "\n",
        "    Args:\n",
        "        fonteBERT: Especifica a origem do modelo do BERT 'comunidade' ou 'diretorio'.\n",
        "        tamanhoBERT: Especifica o tamanho do modelo do BERT 'large' ou 'base'.\n",
        "        linguaBERT: Especifica a lÃ­ngua do modelo do BERT 'portugues' ou 'ingles'.\n",
        "        pesosCamadasOcultas: Especifica ao modelo para manter os pesos de todas as camadas \n",
        "            ocultas, caso contrÃ¡rio mantÃ©m somente a Ãºltima. A avaliaÃ§Ã£o do modelo retorna\n",
        "            um nÃºmero de diferentes objetos com base em como Ã© configurado na chamada do\n",
        "            mÃ©todo `from_pretrained`. O retorno de model quando output_hidden_states=TrueÂ´ Ã©:  \n",
        "                #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states            \n",
        "            Veja a documentaÃ§Ã£o para mais detalhes:\n",
        "            https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "\n",
        "    Returns:\n",
        "        `tokenizador` com o tokenizador do modelo BERT carregado.\n",
        "        `modelo` com o modelo BERT carregado.\n",
        "    \"\"\"\n",
        "    #======================================================================\n",
        "    # VerificaÃ§Ã£o do idioma e tamanho do modelo\n",
        "    #======================================================================\n",
        "    # Verifica se a lÃ­ngua Ã© portuguÃªs e o tamanho do modelo\n",
        "    if linguaBERT == 'portugues' and tamanhoBERT == 'base':\n",
        "        nome_modelo_bert = 'neuralmind/bert-base-portuguese-cased'\n",
        "    else:\n",
        "        if linguaBERT == 'portugues' and tamanhoBERT == 'large':\n",
        "            nome_modelo_bert = 'neuralmind/bert-large-portuguese-cased'\n",
        "        else:\n",
        "            # Verifica se a lÃ­ngua Ã© inglÃ©s e o tamanho do modelo\n",
        "            if linguaBERT == 'ingles' and tamanhoBERT == 'base':\n",
        "                nome_modelo_bert = 'bert-base-uncased'\n",
        "            else:\n",
        "                if linguaBERT == 'ingles' and tamanhoBERT == 'large':\n",
        "                    nome_modelo_bert = 'bert-large-uncased'\n",
        "                else:\n",
        "                    print(\"ParÃ¢metros \\'lÃ­ngua\\' e \\'tamanhoBERT\\' especificados incorretamente!\")\n",
        "                    return None, None\n",
        "\n",
        "    #======================================================================\n",
        "    # Download do arquivo do modelo\n",
        "    #======================================================================\n",
        "    #Se a variÃ¡vel 'fonteBERT' foi setada para 'diretorio' faz o download dos arquivos modelo\n",
        "    if fonteBERT == 'diretorio' and linguaBERT == 'portugues':\n",
        "    \n",
        "      # Se a variÃ¡vel 'tamanhoBERT' foi setada para 'base' faz o download do arquivo do tamanho base do BERT, caso contrÃ¡rio do large.\n",
        "      if tamanhoBERT == 'base':\n",
        "          # url do arquivo do modelo do Pytorch checkpoint\n",
        "          # arquivo menor(base) 1.1 Gbytes\n",
        "          url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "      else:\n",
        "          # url do arquivo do modelo do Pytorch checkpoint\n",
        "          # arquivo grande(large) 3.5 Gbytes\n",
        "          url = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "      # DiretÃ³rio descompactaÃ§Ã£o do modelo\n",
        "      diretorio = '/content/modelo' + tamanhoBERT\n",
        "\n",
        "      # Recupera o nome do arquivo do modelo da url anterior\n",
        "      arquivo = url.split(\"/\")[-1]\n",
        "\n",
        "      # Nome do arquivo do vocabulÃ¡rio\n",
        "      arquivo_vocab = \"vocab.txt\"\n",
        "\n",
        "      # Caminho do arquivo na url\n",
        "      caminho = url[0:len(url)-len(arquivo)]\n",
        "\n",
        "      # Verifica se a pasta de descompactaÃ§Ã£o existe no pasta corrente\n",
        "      if not os.path.exists(diretorio):\n",
        "   \n",
        "          # Realiza o download do arquivo do modelo\n",
        "          !wget $url\n",
        "    \n",
        "          # Descompacta o arquivo na pasta de destino\n",
        "          !unzip -o $arquivo -d $diretorio\n",
        "\n",
        "          # Realiza o download do arquivo do vocabulÃ¡rio\n",
        "          # O vocabulÃ¡rio nÃ£o estÃ¡ no arquivo compactado acima\n",
        "          # Concatena o caminho do modelo mais o nome do arquivo do vocabulÃ¡rio\n",
        "          url_vocab = caminho + arquivo_vocab\n",
        "\n",
        "          # Realiza o download do arquivo do vocabulÃ¡rio\n",
        "          !wget $url_vocab\n",
        "    \n",
        "          # Move o arquivo do vocabulÃ¡rio para o diretÃ³rio do modelo\n",
        "          !mv $arquivo_vocab $diretorio\n",
        "            \n",
        "          # Move o arquivo do modelo para o diretÃ³rio do modelo\n",
        "          !mv $arquivo $diretorio      \n",
        "                \n",
        "          print('DiretÃ³rio do modelo:\\'' + diretorio + '\\' pronta!')\n",
        "      else:      \n",
        "          print('DiretÃ³rio do modelo:\\'' + diretorio + '\\' jÃ¡ existe!')\n",
        "      \n",
        "    else:\n",
        "        if linguaBERT == 'ingles':\n",
        "            print('O modelo BERT na lÃ­ngua inglesa deve ser carregado somente da comunidade.')\n",
        "       \n",
        "    #======================================================================\n",
        "    # Carregamento do tokenizador e do modelo \n",
        "    #======================================================================\n",
        "\n",
        "    # Importando as bibliotecas do Modelo e do Tokenizador\n",
        "    from transformers import BertModel, BertTokenizer\n",
        "\n",
        "    # Se a variÃ¡vel 'fonteBERT' foi setada para 'diretorio' faz o download dos arquivos modelo\n",
        "    # Carregamento de diretÃ³rio somente para a lÃ­ngua portuguesa\n",
        "    if fonteBERT == 'diretorio' and linguaBERT == 'portugues':\n",
        "\n",
        "        # Carregando o Tokenizador do diretÃ³rio\n",
        "        print('Carregando o tokenizador BERT_' + tamanhoBERT \n",
        "              + ' do diretÃ³rio \\'' + diretorio \n",
        "              + '\\' em lÃ­ngua \\''+ linguaBERT + '\\'...')\n",
        "\n",
        "        tokenizer = BertTokenizer.from_pretrained(diretorio,\n",
        "                                                  do_lower_case = do_lower_case)\n",
        "\n",
        "        # Carregando o Modelo do diretÃ³rio\n",
        "        print('Carregando o modelo BERT_' + tamanhoBERT \n",
        "              + ' do diretÃ³rio \\'' + diretorio \n",
        "              + '\\' em lÃ­ngua \\''+ linguaBERT \n",
        "              + '\\' com os pesos das camadas ocultas=' + str(pesosCamadasOcultas) + '...')\n",
        "\n",
        "        model = BertModel.from_pretrained(diretorio, \n",
        "                                          output_hidden_states = pesosCamadasOcultas) # Se o modelo retorna todos os estados ocultos\n",
        "\n",
        "    else:\n",
        "        # Carregando o Tokenizador da comunidade\n",
        "        print('Carregando o tokenizador BERT \\'' + nome_modelo_bert \n",
        "              + '\\' da comunidade em lÃ­ngua \\''+ linguaBERT + '\\'...')\n",
        "\n",
        "        tokenizer = BertTokenizer.from_pretrained(nome_modelo_bert,\n",
        "                                                  do_lower_case = do_lower_case)  \n",
        "\n",
        "        # Carregando o Modelo da comunidade\n",
        "        print('Carregando o modelo BERT \\'' + nome_modelo_bert \n",
        "              + '\\' da comunidade em lÃ­ngua \\''+ linguaBERT \n",
        "              + '\\' com os pesos das camadas ocultas=' + str(pesosCamadasOcultas) + '...')\n",
        "\n",
        "        model = BertModel.from_pretrained(nome_modelo_bert, \n",
        "                                          output_hidden_states = pesosCamadasOcultas)  # Se o modelo retorna todos os estados ocultos\n",
        "    \n",
        "    # Retorna o tokenizador e o modelo BERT carregado           \n",
        "    return tokenizer, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2CgB02_2wJQ"
      },
      "source": [
        "##### Usando a funÃ§Ã£o getBERT()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8ol9ckB9QPY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dea223f3-958d-498d-b04c-af87b2c9fdce"
      },
      "source": [
        "tokenizador, model = getBERT()\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues'...\n",
            "Carregando o modelo BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDkdnWDp9SI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1688a754-8f42-4d71-d488-85c257023938"
      },
      "source": [
        "tokenizador, model = getBERT(tamanhoBERT='large')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-large-portuguese-cased' da comunidade em lÃ­ngua 'portugues'...\n",
            "Carregando o modelo BERT 'neuralmind/bert-large-portuguese-cased' da comunidade em lÃ­ngua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib-_gNFj9WIu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca73c484-5752-4866-85f9-333f4e41b489"
      },
      "source": [
        "tokenizador, model = getBERT(tamanhoBERT='base')\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues'...\n",
            "Carregando o modelo BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-QtCuOf9aOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a83c38d9-6db0-466a-f533-19b9958af04c"
      },
      "source": [
        "tokenizador, model = getBERT(fonteBERT='diretorio', \n",
        "                             tamanhoBERT='base')\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DiretÃ³rio do modelo:'/content/modelobase' jÃ¡ existe!\n",
            "Carregando o tokenizador BERT_base do diretÃ³rio '/content/modelobase' em lÃ­ngua 'portugues'...\n",
            "Carregando o modelo BERT_base do diretÃ³rio '/content/modelobase' em lÃ­ngua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAtFJaBS9eE-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c456517e-a4a4-4820-c44d-785ada54fffd"
      },
      "source": [
        "tokenizador, model = getBERT(fonteBERT='diretorio', \n",
        "                             tamanhoBERT='large', \n",
        "                             linguaBERT='portugues')\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DiretÃ³rio do modelo:'/content/modelolarge' jÃ¡ existe!\n",
            "Carregando o tokenizador BERT_large do diretÃ³rio '/content/modelolarge' em lÃ­ngua 'portugues'...\n",
            "Carregando o modelo BERT_large do diretÃ³rio '/content/modelolarge' em lÃ­ngua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_jYbPyr9hal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7b60d09-b0f3-4a13-fe49-8ad361d81202"
      },
      "source": [
        "tokenizador, model = getBERT(fonteBERT='diretorio', \n",
        "                             tamanhoBERT='base', \n",
        "                             linguaBERT='portugues')\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DiretÃ³rio do modelo:'/content/modelobase' jÃ¡ existe!\n",
            "Carregando o tokenizador BERT_base do diretÃ³rio '/content/modelobase' em lÃ­ngua 'portugues'...\n",
            "Carregando o modelo BERT_base do diretÃ³rio '/content/modelobase' em lÃ­ngua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ty684uT9kmi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78048ed3-f5f6-47c7-965a-8c00a297e819"
      },
      "source": [
        "tokenizador, model = getBERT(fonteBERT='comunidade', \n",
        "                             tamanhoBERT='large', \n",
        "                             linguaBERT='portugues')\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-large-portuguese-cased' da comunidade em lÃ­ngua 'portugues'...\n",
            "Carregando o modelo BERT 'neuralmind/bert-large-portuguese-cased' da comunidade em lÃ­ngua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddnIW3qs9nEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a3e37c3-696d-487f-ceea-b2bc30317259"
      },
      "source": [
        "tokenizador, model = getBERT(fonteBERT='comunidade', \n",
        "                             tamanhoBERT='base', \n",
        "                             linguaBERT='portugues')\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues'...\n",
            "Carregando o modelo BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxRMvyCeY0Qi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21a6d4a3-3e4b-4c92-d3fe-154ce65e1dd1"
      },
      "source": [
        "tokenizador, model = getBERT(fonteBERT='comunidade', \n",
        "                             tamanhoBERT='base', \n",
        "                             linguaBERT='portugues',\n",
        "                             pesosCamadasOcultas = False)\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues'...\n",
            "Carregando o modelo BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGtEwUsz9bqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bcb74ca-2cf9-4c77-f36d-5cf3fbd3405a"
      },
      "source": [
        "tokenizador, model = getBERT(tamanhoBERT='large', \n",
        "                             linguaBERT='ingles')\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na lÃ­ngua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-large-uncased' da comunidade em lÃ­ngua 'ingles'...\n",
            "Carregando o modelo BERT 'bert-large-uncased' da comunidade em lÃ­ngua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7RmGEJh2yVt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87b4bef6-b5c4-4985-e830-54ff75c6a954"
      },
      "source": [
        "tokenizador, model = getBERT(tamanhoBERT='base', \n",
        "                             linguaBERT='ingles')\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na lÃ­ngua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-base-uncased' da comunidade em lÃ­ngua 'ingles'...\n",
            "Carregando o modelo BERT 'bert-base-uncased' da comunidade em lÃ­ngua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvCaohAg9spJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2803697c-63a2-41a9-ee25-5be228e8cdad"
      },
      "source": [
        "tokenizador, model = getBERT(fonteBERT='diretorio', \n",
        "                             tamanhoBERT='large', \n",
        "                             linguaBERT='ingles')\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na lÃ­ngua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-large-uncased' da comunidade em lÃ­ngua 'ingles'...\n",
            "Carregando o modelo BERT 'bert-large-uncased' da comunidade em lÃ­ngua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GmVk2Vs91vf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34445708-3e02-47d9-dcc8-126b518b0e48"
      },
      "source": [
        "tokenizador, model = getBERT(fonteBERT='diretorio', \n",
        "                             tamanhoBERT='base', \n",
        "                             linguaBERT='ingles')\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na lÃ­ngua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-base-uncased' da comunidade em lÃ­ngua 'ingles'...\n",
            "Carregando o modelo BERT 'bert-base-uncased' da comunidade em lÃ­ngua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTlXm1iV9r6u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7002e56-1085-46cf-949b-3f560df19ae4"
      },
      "source": [
        "tokenizador, model = getBERT(fonteBERT='comunidade', \n",
        "                             tamanhoBERT='large', \n",
        "                             linguaBERT='ingles')\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na lÃ­ngua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-large-uncased' da comunidade em lÃ­ngua 'ingles'...\n",
            "Carregando o modelo BERT 'bert-large-uncased' da comunidade em lÃ­ngua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1LrfoJR93JA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0868a8d-8dea-45a3-ba0d-516546608f8f"
      },
      "source": [
        "tokenizador, model = getBERT(fonteBERT='comunidade', \n",
        "                             tamanhoBERT='base', \n",
        "                             linguaBERT='ingles') \n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na lÃ­ngua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-base-uncased' da comunidade em lÃ­ngua 'ingles'...\n",
            "Carregando o modelo BERT 'bert-base-uncased' da comunidade em lÃ­ngua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE-nPaejYgZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccbabf8f-ace7-43ae-a645-165643d94126"
      },
      "source": [
        "tokenizador, model = getBERT(fonteBERT='comunidade', \n",
        "                             tamanhoBERT='base', \n",
        "                             linguaBERT='ingles', \n",
        "                             pesosCamadasOcultas = False)\n",
        "\n",
        "del tokenizador\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT na lÃ­ngua inglesa deve ser carregado somente da comunidade.\n",
            "Carregando o tokenizador BERT 'bert-base-uncased' da comunidade em lÃ­ngua 'ingles'...\n",
            "Carregando o modelo BERT 'bert-base-uncased' da comunidade em lÃ­ngua 'ingles' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJKkYninAk-j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2259d995-af38-4c3f-d290-d9b7ca2c4b1b"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5062"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gci3FLLlLUJE"
      },
      "source": [
        "## Declarando uma funÃ§Ã£o que recupera embeddings de frase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeaDaUvaLoC4"
      },
      "source": [
        "def getEmbedding(texto, tokenizadorBERT, modeloBERT):\n",
        "\n",
        "    \"\"\"\n",
        "    Retorna os embeddings de uma frase utilizando um tokenizador e modelo BERT carregado.\n",
        "    \n",
        "    Args:\n",
        "        texto: Texto a ser convertindo em embeddings utilizando o BERT.\n",
        "        tokenizadorBERT: Tokenizador BERT carregado.\n",
        "        modelBERT: Modelo BERT carregado.\n",
        "        \n",
        "    Returns:\n",
        "          0-texto_tokenizado, \n",
        "          1-input_ids, \n",
        "          2-attention_mask, \n",
        "          3-token_type_ids, \n",
        "          4-outputs \n",
        "              0-last_hidden_state,\n",
        "              1-pooler_output,\n",
        "              2-hidden_states\n",
        "    \"\"\"\n",
        "    # Importando a biblioteca\n",
        "    import torch\n",
        "\n",
        "    # Adiciona os tokens especiais\n",
        "    texto_marcado = \"[CLS] \" + texto + \" [SEP]\"\n",
        "\n",
        "    # Tokeniza o texto marcado\n",
        "    texto_tokenizado = tokenizer.tokenize(texto_marcado)\n",
        "    \n",
        "    # Recupera a quantidade tokens do texto tokenizado\n",
        "    qtdeTokens = len(texto_tokenizado)\n",
        "\n",
        "    #tokeniza o texto e retorna os tensores\n",
        "    dic_codificado = tokenizadorBERT.encode_plus(\n",
        "                        text=texto,                     # texto a ser codificado.\n",
        "                        add_special_tokens = True,      # Adiciona os tokens especiais '[CLS]' e '[SEP]'\n",
        "                        max_length = qtdeTokens,        # Define o tamanho mÃ¡ximo para preencheer ou truncar.\n",
        "                        truncation = True,              # Trunca o texto por max_length\n",
        "                        padding = 'max_length',         # Preenche o texto atÃ© max_length\n",
        "                        return_attention_mask = True,   # ConstrÃ³i a mÃ¡scara de atenÃ§Ã£o.\n",
        "                        return_tensors = 'pt'           # Retorna os dados como tensores pytorch.\n",
        "                   )                   \n",
        "\n",
        "    # Ids dos tokens de entrada mapeados em seus Ã­ndices do vocabuÃ¡rio    \n",
        "    input_ids =  dic_codificado['input_ids']\n",
        "\n",
        "    # MÃ¡scara de atenÃ§Ã£o de cada um dos tokens como pertencentes Ã  frase \"1\".\n",
        "    attention_mask = dic_codificado['attention_mask']\n",
        "\n",
        "    # Recupera os tensores dos segmentos\n",
        "    token_type_ids = dic_codificado['token_type_ids']\n",
        "\n",
        "    # Roda o texto atravÃ©s do BERT, e coleta todos os estados ocultos produzidos\n",
        "    # das 12 camadas. \n",
        "    with torch.no_grad():\n",
        "\n",
        "        # Passe para a frente, calcule as previsÃµes outputs\n",
        "        outputs = modeloBERT(input_ids=input_ids, \n",
        "                             attention_mask=attention_mask)\n",
        "\n",
        "        # A avaliaÃ§Ã£o do modelo retorna um nÃºmero de diferentes objetos com base em\n",
        "        # como Ã© configurado na chamada do mÃ©todo `from_pretrained` anterior. Nesse caso,\n",
        "        # porque definimos `output_hidden_states = True`, o terceiro item serÃ¡ o\n",
        "        # estados ocultos(hidden_states) de todas as camadas. Veja a documentaÃ§Ã£o para mais detalhes:\n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "\n",
        "        # Retorno de model quando Â´output_hidden_states=TrueÂ´ Ã© setado:    \n",
        "        #last_hidden_state = outputs[0], pooler_output = outputs[1], hidden_states = outputs[2]\n",
        "\n",
        "    # 0-texto_tokenizado, 1-input_ids, 2-attention_mask, 3-token_type_ids, 4-outputs(0=last_hidden_state,1=pooler_output,2=hidden_states)    \n",
        "    return texto_tokenizado, input_ids, attention_mask, token_type_ids, outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV8B1VdVxF4l"
      },
      "source": [
        "# 4 Preparando a entrada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PieeR7bQxKO2"
      },
      "source": [
        "## Tokenizador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dedf1fOJyYkR"
      },
      "source": [
        "### Exemplo do tokenizador com mÃ©todo 'tokenize'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl7-DgNpxTkd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a4d50c-0538-4bff-c00f-daa9934c7806"
      },
      "source": [
        "# Recupera o tokenizador BERT\n",
        "tokenizer = getTokenizadorBERT()\n",
        "\n",
        "# Texto de exemplo\n",
        "texto = \"O que Ã© embedding?\"\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado = \"[CLS] \" + texto + \" [SEP]\"\n",
        "\n",
        "# Tokeniza o texto em tokens\n",
        "texto_tokenizado = tokenizer.tokenize(texto_marcado)\n",
        "\n",
        "# Mostra o texto exemplo\n",
        "print(\"Texto exemplo      :\", texto)\n",
        "\n",
        "# Mostra o texto marcado\n",
        "print(\"Texto marcado      :\", texto_marcado)\n",
        "\n",
        "# Mostra o texto tokenizado\n",
        "print(\"Texto tokenizado   :\", texto_tokenizado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues'...\n",
            "Texto exemplo      : O que Ã© embedding?\n",
            "Texto marcado      : [CLS] O que Ã© embedding? [SEP]\n",
            "Texto tokenizado   : ['[CLS]', 'O', 'que', 'Ã©', 'em', '##be', '##dd', '##ing', '?', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVhPYQg_yMl0"
      },
      "source": [
        "## Codificador (input_ids)\n",
        "\n",
        "Converte cada token do texto tokenizado para um id presente no vocabulÃ¡rio do modelo do Tokenizador. Se houver um token que nÃ£o estÃ¡ presente no vocabulÃ¡rio, o tokenizador usarÃ¡ o id token especial [UNK].\n",
        "\n",
        "- encode\n",
        "- convert_tokens_to_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ezUjHyRMIuQ"
      },
      "source": [
        "### Exemplo de gerador do id do token com o mÃ©todo 'encode'\n",
        "\n",
        "MÃ©todo encode tokeniza e converte os tokens para os ids do vocabulÃ¡rio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlXtmkcjMNu0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f70479f-cb83-4ab2-e59d-edcc15d952dd"
      },
      "source": [
        "# Recupera o tokenizador BERT\n",
        "tokenizer = getTokenizadorBERT()\n",
        "\n",
        "# Texto de exemplo\n",
        "texto = \"O que Ã© embedding?\"\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado = \"[CLS] \" + texto + \" [SEP]\"\n",
        "\n",
        "# Tokeniza o texto em tokens\n",
        "texto_tokenizado = tokenizer.tokenize(texto_marcado)\n",
        "\n",
        "# Converte os tokens para os ids do vocabulÃ¡rio, por default(add_special_tokens=True) \n",
        "# jÃ¡ adiciona os tokens especiais.\n",
        "texto_token_ids = tokenizer.encode(text=texto_tokenizado, \n",
        "                                   add_special_tokens=False)\n",
        "\n",
        "# Mostra o texto exemplo\n",
        "print(\"Texto exemplo      :\", texto)\n",
        "\n",
        "# Mostra o texto marcado\n",
        "print(\"Texto marcado      :\", texto_marcado)\n",
        "\n",
        "# Mostra o texto tokenizado\n",
        "print(\"Texto tokenizado   :\", texto_tokenizado)\n",
        "\n",
        "# Mostra o id do texto tokenizado\n",
        "print(\"Texto id token     :\", texto_token_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues'...\n",
            "Texto exemplo      : O que Ã© embedding?\n",
            "Texto marcado      : [CLS] O que Ã© embedding? [SEP]\n",
            "Texto tokenizado   : ['[CLS]', 'O', 'que', 'Ã©', 'em', '##be', '##dd', '##ing', '?', '[SEP]']\n",
            "Texto id token     : [101, 231, 179, 253, 173, 483, 14852, 446, 136, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5T9g55j57_k"
      },
      "source": [
        "### Exemplo de gerador do id do token com o mÃ©todo 'convert_tokens_to_ids'\n",
        "\n",
        "MÃ©todo convert_tokens_to_ids tokeniza e converte os tokens para os ids do vocabulÃ¡rio.\n",
        "\n",
        "FunÃ§Ã£o semenlhante ao mÃ©todo `enconde`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL_qJ-nh0Cq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a0db835-afec-4287-a9fd-cc64639c9d1c"
      },
      "source": [
        "# Recupera o tokenizador BERT\n",
        "tokenizer = getTokenizadorBERT()\n",
        "\n",
        "# Texto de exemplo\n",
        "texto = \"O que Ã© embedding?\"\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado = \"[CLS] \" + texto + \" [SEP]\"\n",
        "\n",
        "# Tokeniza o texto em tokens\n",
        "texto_tokenizado = tokenizer.tokenize(texto_marcado)\n",
        "\n",
        "# Converte os tokens para os ids do vocabulÃ¡rio\n",
        "texto_token_ids = tokenizer.convert_tokens_to_ids(texto_tokenizado)\n",
        "\n",
        "# Mostra o texto exemplo\n",
        "print(\"Texto exemplo      :\", texto)\n",
        "\n",
        "# Mostra o texto marcado\n",
        "print(\"Texto marcado      :\", texto_marcado)\n",
        "\n",
        "# Mostra o texto tokenizado\n",
        "print(\"Texto tokenizado   :\", texto_tokenizado)\n",
        "\n",
        "# Mostra o id do texto tokenizado\n",
        "print(\"Texto id token     :\", texto_token_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues'...\n",
            "Texto exemplo      : O que Ã© embedding?\n",
            "Texto marcado      : [CLS] O que Ã© embedding? [SEP]\n",
            "Texto tokenizado   : ['[CLS]', 'O', 'que', 'Ã©', 'em', '##be', '##dd', '##ing', '?', '[SEP]']\n",
            "Texto id token     : [101, 231, 179, 253, 173, 483, 14852, 446, 136, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbYZGyvGIg2q"
      },
      "source": [
        "### Exemplo de decodificaÃ§Ã£o dos id dos tokens com o mÃ©todo 'decode'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2-DNVvBIzrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b61377d-225b-48f6-db8b-bb7eefae5a45"
      },
      "source": [
        "# Recupera o tokenizador BERT\n",
        "tokenizer = getTokenizadorBERT()\n",
        "\n",
        "# Texto de exemplo\n",
        "texto = \"O que Ã© embedding?\"\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado = \"[CLS] \" + texto + \" [SEP]\"\n",
        "\n",
        "# Tokeniza o texto em tokens\n",
        "texto_tokenizado = tokenizer.tokenize(texto_marcado)\n",
        "\n",
        "# Converte os tokens para os ids do vocabulÃ¡rio\n",
        "texto_token_ids = tokenizer.convert_tokens_to_ids(texto_tokenizado)\n",
        "\n",
        "# Decodifica o id texto tokenizado\n",
        "# skip_special_tokens: bool = False retira os tokens especiais\n",
        "texto_decodificado = tokenizer.decode(texto_token_ids)\n",
        "\n",
        "print(\"Texto exemplo      :\", texto)\n",
        "\n",
        "# Mostra o texto marcado\n",
        "print(\"Texto marcado      :\", texto_marcado)\n",
        "\n",
        "# Mostra o texto tokenizado\n",
        "print(\"Texto tokenizado   :\", texto_tokenizado)\n",
        "\n",
        "# Mostra o id do texto tokenizado\n",
        "print(\"Texto id token     :\", texto_token_ids)\n",
        "\n",
        "# Mostra texto decodificado\n",
        "print(\"Texto decodificado :\", texto_decodificado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues'...\n",
            "Texto exemplo      : O que Ã© embedding?\n",
            "Texto marcado      : [CLS] O que Ã© embedding? [SEP]\n",
            "Texto tokenizado   : ['[CLS]', 'O', 'que', 'Ã©', 'em', '##be', '##dd', '##ing', '?', '[SEP]']\n",
            "Texto id token     : [101, 231, 179, 253, 173, 483, 14852, 446, 136, 102]\n",
            "Texto decodificado : [CLS] O que Ã© embedding? [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6IhqAYe0U6f"
      },
      "source": [
        "## Gerador da mÃ¡scara de atenÃ§Ã£o (attention_mask)\n",
        "\n",
        "O BERT Ã© treinado e espera pares de frases, usando 1s e 0s para distinguir entre as duas frases. Ou seja, para cada token em \"texto_tokenizado\", devemos especificar a qual frase pertence: sentenÃ§a 0 (uma sÃ©rie de 0s) ou sentenÃ§a 1 (uma sÃ©rie de 1s). \n",
        "\n",
        "Para casos onde as entradas de texto Ã© **Ãºnica** requerem apenas uma sÃ©rie de 1s; portanto, criaremos um vetor de 1s para cada token em input_ids.\n",
        "\n",
        "Se desejar processar **duas frases**, atribua cada palavra na primeira frase mais o token '[SEP]' a 0 e todos os tokens da segunda frase a 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB1NizSQ6y9O"
      },
      "source": [
        "### Exemplo de gerador de mÃ¡scara para frase Ãºnica com lista"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oOSCtd00W2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38398bc5-e35f-4515-bc99-f510616c4e7f"
      },
      "source": [
        "# Recupera o tokenizador BERT\n",
        "tokenizer = getTokenizadorBERT()\n",
        "\n",
        "# Texto de exemplo\n",
        "texto = \"O que Ã© embedding?\"\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado = \"[CLS] \" + texto + \" [SEP]\"\n",
        "\n",
        "# Tokeniza o texto em tokens\n",
        "texto_tokenizado = tokenizer.tokenize(texto_marcado)\n",
        "\n",
        "# Converte os tokens para os ids do vocabulÃ¡rio\n",
        "texto_token_ids = tokenizer.convert_tokens_to_ids(texto_tokenizado)\n",
        "\n",
        "# Cria um vetor com o tamanho da quantidade de tokens do texto preenchidos com 1.\n",
        "mascara_atencao = [1] * len(texto_token_ids)\n",
        "\n",
        "print(\"Texto exemplo      :\", texto)\n",
        "\n",
        "# Mostra o texto marcado\n",
        "print(\"Texto marcado      :\", texto_marcado)\n",
        "\n",
        "# Mostra o texto tokenizado\n",
        "print(\"Texto tokenizado   :\", texto_tokenizado)\n",
        "\n",
        "# Mostra o id do texto tokenizado\n",
        "print(\"Texto id token     :\", texto_token_ids)\n",
        "\n",
        "# Mostra a mÃ¡scara de atenÃ§Ã£o\n",
        "print(\"MÃ¡scara de atenÃ§Ã£o :\", mascara_atencao)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues'...\n",
            "Texto exemplo      : O que Ã© embedding?\n",
            "Texto marcado      : [CLS] O que Ã© embedding? [SEP]\n",
            "Texto tokenizado   : ['[CLS]', 'O', 'que', 'Ã©', 'em', '##be', '##dd', '##ing', '?', '[SEP]']\n",
            "Texto id token     : [101, 231, 179, 253, 173, 483, 14852, 446, 136, 102]\n",
            "MÃ¡scara de atenÃ§Ã£o : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKdO4ZDi8O8Q"
      },
      "source": [
        "## Gerando toda a entrada com o encode_plus(input_ids, attention_mask, token_type_ids)\n",
        "\n",
        "O mÃ©todo `enconde_plus` gera todas as entradas necessÃ¡rias a partir do texto. O mÃ©todo retorna um dicionÃ¡rio com as chaves:\n",
        "\n",
        "- 'input_ids' - O id do texto tokenizado\n",
        "- 'attention_mask' - A mÃ¡scara de atenÃ§Ã£o truncada ou preenchida atÃ© `max_length`\n",
        "- 'token_type_ids' - A mÃ¡scara de atenÃ§Ã£o de pares de frase. Quando o texto Ã© tokenizado com duas frases, a primeira recebe 0 a segunda frase recebe 1.\n",
        "\n",
        "https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWM3U6wF8PNw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fac225d9-b7fa-4e8d-d9ee-04611c6df826"
      },
      "source": [
        "# Recupera o tokenizador BERT\n",
        "tokenizer = getTokenizadorBERT()\n",
        "\n",
        "# Texto de exemplo\n",
        "texto = \"O que Ã© embedding?\"\n",
        "\n",
        "# `encode_plus` irÃ¡:\n",
        "#   (1) Tokenize a frase sentence.\n",
        "#   (2) Adicionar o token `[CLS]` no inÃ­cio.\n",
        "#   (3) Adicionar o token `[SEP]` no fim.\n",
        "#   (4) Mapear tokens para os seus IDS.\n",
        "#   (5) Preencher ou truncar as frases para `max_length`\n",
        "#   (6) Criar mÃ¡scara de atenÃ§Ã£o para os tokens [PAD].    \n",
        "#   (7) Retorna os dados com tensores\n",
        "dic_codificado = tokenizer.encode_plus(\n",
        "                        text=texto,                     # Texto a ser codificado.\n",
        "                        add_special_tokens = True,      # Adiciona os tokens especiais '[CLS]' e '[SEP]'\n",
        "                        max_length = 10,                # Define o tamanho mÃ¡ximo para preencheer ou truncar.\n",
        "                        truncation = True,              # Trunca o texto por max_length\n",
        "                        padding = 'max_length',         # Preenche o texto atÃ© max_length\n",
        "                        return_attention_mask = True,   # ConstrÃ³i a mÃ¡scara de atenÃ§Ã£o.\n",
        "                        return_tensors = 'pt'           # Retorna os dados como tensores pytorch.\n",
        "                   )\n",
        "\n",
        "# Recupera os dados do dicionÃ¡rio\n",
        "texto_token_ids = dic_codificado['input_ids']\n",
        "mascara_atencao = dic_codificado['attention_mask']\n",
        "token_type_ids = dic_codificado['token_type_ids']\n",
        "\n",
        "print(\"Texto exemplo      :\", texto)\n",
        "\n",
        "# Mostra o texto marcado\n",
        "print(\"Texto marcado      :\", texto_marcado)\n",
        "\n",
        "# Mostra o texto tokenizado\n",
        "print(\"Texto tokenizado   :\", texto_tokenizado)\n",
        "\n",
        "# Mostra o id do texto tokenizado\n",
        "print(\"Texto id token     :\", texto_token_ids)\n",
        "\n",
        "# Mostra a mÃ¡scara de atenÃ§Ã£o\n",
        "print(\"MÃ¡scara de atenÃ§Ã£o :\", mascara_atencao)\n",
        "\n",
        "# Mostra a mÃ¡scara de atenÃ§Ã£o de pares de frase (0 primeira frase e 1 para a segunda frase)\n",
        "print(\"Token types ids    :\", token_type_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues'...\n",
            "Texto exemplo      : O que Ã© embedding?\n",
            "Texto marcado      : [CLS] O que Ã© embedding? [SEP]\n",
            "Texto tokenizado   : ['[CLS]', 'O', 'que', 'Ã©', 'em', '##be', '##dd', '##ing', '?', '[SEP]']\n",
            "Texto id token     : tensor([[  101,   231,   179,   253,   173,   483, 14852,   446,   136,   102]])\n",
            "MÃ¡scara de atenÃ§Ã£o : tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "Token types ids    : tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjHaBG4U8z04"
      },
      "source": [
        "# 5 Usando o modelo PrÃ©-treinado\n",
        "\n",
        "Uso do modell prÃ©-treinado sem ajuste fino."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riR4jz8W-qk3"
      },
      "source": [
        "# 6 Teste Completo do Tokenizador e Modelo BERT\n",
        "\n",
        "Testa o tokenizador e modelo de vretorno da funÃ§Ã£o getBERT.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QP-2tC8YOFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eea17364-165f-4a5d-8523-70d9545de98f"
      },
      "source": [
        "# Utiliza a funÃ§Ã£o para retornar o tokenizador e o modelo\n",
        "tokenizer, model = getBERT(tamanhoBERT='base')\n",
        "\n",
        "# Define um sentenÃ§a de exemplo com diversos siginificados da palavra  \"banco\"\n",
        "texto = \"Depois de roubar o cofre do banco,\"\\\n",
        "        \" o ladrÃ£o de banco foi visto \" \\\n",
        "        \"sentado no banco da praÃ§a central.\"\n",
        "\n",
        "# Adiciona os tokens especiais\n",
        "texto_marcado = \"[CLS] \" + texto + \" [SEP]\"\n",
        "\n",
        "# Divide a sentenÃ§a em tokens\n",
        "texto_tokenizado = tokenizer.tokenize(texto_marcado)\n",
        "\n",
        "# Mapeia os tokens em seus Ã­ndices do vocabuÃ¡rio\n",
        "tokens_indexados = tokenizer.convert_tokens_to_ids(texto_tokenizado)\n",
        "\n",
        "# Mostra os tokens com seus Ã­ndices\n",
        "i = 0\n",
        "for tup in zip(texto_tokenizado, tokens_indexados):\n",
        "    print('{:>3} {:<12} {:>6,}'.format(i, tup[0], tup[1]))\n",
        "    i= i + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues'...\n",
            "Carregando o modelo BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues' com os pesos das camadas ocultas=False...\n",
            "  0 [CLS]           101\n",
            "  1 Depois        1,603\n",
            "  2 de              125\n",
            "  3 roubar       16,150\n",
            "  4 o               146\n",
            "  5 co              144\n",
            "  6 ##fre         1,198\n",
            "  7 do              171\n",
            "  8 banco         6,465\n",
            "  9 ,               117\n",
            " 10 o               146\n",
            " 11 lad          13,503\n",
            " 12 ##rÃ£o         1,759\n",
            " 13 de              125\n",
            " 14 banco         6,465\n",
            " 15 foi             262\n",
            " 16 visto         3,382\n",
            " 17 sentado      21,541\n",
            " 18 no              202\n",
            " 19 banco         6,465\n",
            " 20 da              180\n",
            " 21 praÃ§a         6,357\n",
            " 22 central       2,692\n",
            " 23 .               119\n",
            " 24 [SEP]           102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUU1BIGiYs58"
      },
      "source": [
        "# Importa a bibliteca\n",
        "import torch\n",
        "\n",
        "# Marca cada um dos tokens como pertencentes Ã  frase \"1\", pois sÃ³ iremos analisar uma.\n",
        "segmentos_ids = [1] * len(texto_tokenizado)\n",
        "\n",
        "# Converte as entradas de listas para tensores do torch\n",
        "input_ids = torch.as_tensor([tokens_indexados])\n",
        "attention_mask = torch.as_tensor([segmentos_ids])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-hYiWnRYs6B"
      },
      "source": [
        "# Prediz os atributos dos estados ocultos para cada camada\n",
        "with torch.no_grad():    \n",
        "  \n",
        "    # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states    \n",
        "    outputs = model(input_ids=input_ids, \n",
        "                    attention_mask=attention_mask)\n",
        "    \n",
        "    # Recupera a Ãºltima camada oculta da saÃ­da\n",
        "    last_hidden_states = outputs[0]\n",
        "\n",
        "# Remove a dimensÃ£o 1, o lote \"batches\".\n",
        "# O mÃ©todo Â´squeezeÂ´ remove a primeira dimensÃ£o(0) pois possui tamanho 1\n",
        "token_embeddings = torch.squeeze(last_hidden_states, dim=0)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tnv1g2qIWKD"
      },
      "source": [
        "BASE em portuguÃªs:\n",
        "* banco tensor([ 0.2817, -0.2229,  0.4058, -0.1698,  0.4350])\n",
        "* banco tensor([ 0.3844, -0.2985,  0.1629, -0.2853,  0.4661])\n",
        "* banco tensor([ 0.0382, -0.1985,  0.0825,  0.1369,  0.6871])\n",
        "\n",
        "\n",
        "LARGE em portuguÃªs:\n",
        "* banco tensor([ 0.4261, -0.1251, -0.4406,  0.0736, -1.4059])\n",
        "* banco tensor([ 0.4835,  0.1447, -0.4306,  0.3436, -1.4682])\n",
        "* banco tensor([ 0.3631,  0.9212,  0.1919, -0.2493, -0.9418])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hrWa-RzZIFl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62f892e6-7b3d-4b5e-9a85-1bf17d8399d0"
      },
      "source": [
        "palavra1 = 8\n",
        "palavra2 = 14\n",
        "palavra3 = 19\n",
        "\n",
        "print('Os primeiros 5 valores de cada instÃ¢ncia de \"banco\".')\n",
        "print('')\n",
        "print(texto_tokenizado[palavra1], str(token_embeddings[palavra1][:5]))\n",
        "print(texto_tokenizado[palavra2], str(token_embeddings[palavra2][:5]))\n",
        "print(texto_tokenizado[palavra3], str(token_embeddings[palavra3][:5]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Os primeiros 5 valores de cada instÃ¢ncia de \"banco\".\n",
            "\n",
            "banco tensor([ 0.2817, -0.2229,  0.4058, -0.1698,  0.4350])\n",
            "banco tensor([ 0.3844, -0.2985,  0.1629, -0.2853,  0.4661])\n",
            "banco tensor([ 0.0382, -0.1985,  0.0825,  0.1369,  0.6871])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neHWoJlxLe2z"
      },
      "source": [
        "BASE em portuguÃªs:\n",
        "* Vetor de similaridade  para diferentes significados( 14 , 19 ):  0.71\n",
        "* Vetor de similaridade  para mesmo significado( 14 , 8 ):  0.88\n",
        "* Vetor de similaridade  para diferentes significados( 19 , 8 ):  0.76\n",
        "\n",
        "LARGE em portuguÃªs:\n",
        "* Vetor de similaridade  para diferentes significados( 14 , 19 ):  0.78\n",
        "* Vetor de similaridade  para mesmo significado( 14 , 8 ):  0.92\n",
        "* Vetor de similaridade  para diferentes significados( 19 , 8 ):  0.77"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0Wz7anjZIFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1af45ba6-a70b-4045-8f82-a221fbb9109f"
      },
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "print(\"PerÃ­odo:\", texto)\n",
        "print(\"Palavra1= \", palavra1, \"=\", texto_tokenizado[palavra1], \"(instituiÃ§Ã£o financeira)\")\n",
        "print(\"Palavra2=\", palavra2, \"=\", texto_tokenizado[palavra2], \"(instituiÃ§Ã£o financeira)\")\n",
        "print(\"Palavra3=\", palavra3, \"=\", texto_tokenizado[palavra3], \"(assento)\")\n",
        "\n",
        "# Calcula a similaridade de coseno entre as palavras banco\n",
        "# Em \"ladrÃ£o de banco\" versus \"banco da praÃ§a\" (diferentes significados).\n",
        "banco_diferente = 1 - cosine(token_embeddings[palavra2], token_embeddings[palavra3])\n",
        "\n",
        "print('Vetor de similaridade  para diferentes significados(',palavra2,',',palavra3,'):  %.2f' % banco_diferente)\n",
        "\n",
        "# Calcula a similaridade de coseno entre as palavras banco\n",
        "# Em \"ladrÃ£o de banco\" versus \"cofre do banco\" (mesmo significado).\n",
        "mesmo_banco = 1 - cosine(token_embeddings[palavra2], token_embeddings[palavra1])\n",
        "\n",
        "print('Vetor de similaridade  para mesmo significado      (',palavra2,', ',palavra1,'):  %.2f' % mesmo_banco)\n",
        "\n",
        "# Calcula a similaridade de coseno entre as palavras banco\n",
        "# Em \"cofre do banco\" versus \"banco da praÃ§a\" (diferente significados).\n",
        "banco_diferente2 = 1 - cosine(token_embeddings[palavra3], token_embeddings[palavra1])\n",
        "\n",
        "print('Vetor de similaridade  para diferentes significados(',palavra3,', ',palavra1,'):  %.2f' % banco_diferente2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PerÃ­odo: Depois de roubar o cofre do banco, o ladrÃ£o de banco foi visto sentado no banco da praÃ§a central.\n",
            "Palavra1=  8 = banco (instituiÃ§Ã£o financeira)\n",
            "Palavra2= 14 = banco (instituiÃ§Ã£o financeira)\n",
            "Palavra3= 19 = banco (assento)\n",
            "Vetor de similaridade  para diferentes significados( 14 , 19 ):  0.71\n",
            "Vetor de similaridade  para mesmo significado      ( 14 ,  8 ):  0.88\n",
            "Vetor de similaridade  para diferentes significados( 19 ,  8 ):  0.76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JAFCSVopfFb"
      },
      "source": [
        "# 7 Teste completo da funÃ§Ã£o de recuperaÃ§Ã£o de embeddings de frase\n",
        "\n",
        "Testa os embeddings de retorno da funÃ§Ã£o getEmbedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmjHFQUttUtF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae8cec2e-b5cd-4efd-cdfc-509beb44872a"
      },
      "source": [
        "# Utiliza a funÃ§Ã£o para retornar o tokenizador e o modelo\n",
        "tokenizer, model = getBERT(tamanhoBERT='base')\n",
        "\n",
        "# Define um sentenÃ§a de exemplo com diversos siginificados da palavra  \"banco\"\n",
        "texto = \"Depois de roubar o cofre do banco,\"\\\n",
        "        \" o ladrÃ£o de banco foi visto \" \\\n",
        "        \"sentado no banco da praÃ§a central.\"\n",
        "\n",
        "# 0-texto_tokenizado, 1-input_ids, 2-attention_mask, 3-token_type_ids, 4-outputs(0=last_hidden_state,1=pooler_output,2=hidden_states)\n",
        "outputs = getEmbedding(texto, tokenizer, model)        \n",
        "\n",
        "# Recupera a Ãºltima camada oculta da saÃ­da\n",
        "# 4-outputs 0=last_hidden_state\n",
        "last_hidden_states = outputs[4][0]\n",
        "\n",
        "# Remove a dimensÃ£o 1, o lote \"batches\".\n",
        "# O mÃ©todo Â´squeezeÂ´ remove a primeira dimensÃ£o(0) pois possui tamanho 1\n",
        "token_embeddings = torch.squeeze(last_hidden_states, dim=0)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues'...\n",
            "Carregando o modelo BERT 'neuralmind/bert-base-portuguese-cased' da comunidade em lÃ­ngua 'portugues' com os pesos das camadas ocultas=False...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd84LqC5tUtI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fd834d7-8078-49a9-e880-76bf9dabe9e5"
      },
      "source": [
        "# Divide a sentenÃ§a em tokens\n",
        "texto_tokenizado = outputs[0]\n",
        "\n",
        "# Mapeia os tokens em seus Ã­ndices do vocabuÃ¡rio\n",
        "tokens_indexados = outputs[1]\n",
        "\n",
        "# Mostra os tokens com seus Ã­ndices\n",
        "for i, token in enumerate(texto_tokenizado):\n",
        "    print(i, token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [CLS]\n",
            "1 Depois\n",
            "2 de\n",
            "3 roubar\n",
            "4 o\n",
            "5 co\n",
            "6 ##fre\n",
            "7 do\n",
            "8 banco\n",
            "9 ,\n",
            "10 o\n",
            "11 lad\n",
            "12 ##rÃ£o\n",
            "13 de\n",
            "14 banco\n",
            "15 foi\n",
            "16 visto\n",
            "17 sentado\n",
            "18 no\n",
            "19 banco\n",
            "20 da\n",
            "21 praÃ§a\n",
            "22 central\n",
            "23 .\n",
            "24 [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDB9bYPpI-Oq"
      },
      "source": [
        "BASE em portuguÃªs:\n",
        "* banco tensor([ 0.2817, -0.2229,  0.4058, -0.1698,  0.4350])\n",
        "* banco tensor([ 0.3844, -0.2985,  0.1629, -0.2853,  0.4661])\n",
        "* banco tensor([ 0.0382, -0.1985,  0.0825,  0.1369,  0.6871])\n",
        "\n",
        "\n",
        "LARGE em portuguÃªs:\n",
        "* banco tensor([ 0.4261, -0.1251, -0.4406,  0.0736, -1.4059])\n",
        "* banco tensor([ 0.4835,  0.1447, -0.4306,  0.3436, -1.4682])\n",
        "* banco tensor([ 0.3631,  0.9212,  0.1919, -0.2493, -0.9418])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhKpFWRrECOo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c692ea98-0e41-466b-f3d1-a38ba34012bd"
      },
      "source": [
        "palavra1 = 8\n",
        "palavra2 = 14\n",
        "palavra3 = 19\n",
        "\n",
        "print('Os primeiros 5 valores de cada instÃ¢ncia de \"banco\".')\n",
        "print('')\n",
        "print(texto_tokenizado[palavra1], str(token_embeddings[palavra1][:5]))\n",
        "print(texto_tokenizado[palavra2], str(token_embeddings[palavra2][:5]))\n",
        "print(texto_tokenizado[palavra3], str(token_embeddings[palavra3][:5]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Os primeiros 5 valores de cada instÃ¢ncia de \"banco\".\n",
            "\n",
            "banco tensor([ 0.2817, -0.2229,  0.4058, -0.1698,  0.4350])\n",
            "banco tensor([ 0.3844, -0.2985,  0.1629, -0.2853,  0.4661])\n",
            "banco tensor([ 0.0382, -0.1985,  0.0825,  0.1369,  0.6871])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgv05eUcECOs"
      },
      "source": [
        "BASE em portuguÃªs:\n",
        "* Vetor de similaridade  para diferentes significados( 14 , 19 ):  0.71\n",
        "* Vetor de similaridade  para mesmo significado( 14 , 8 ):  0.88\n",
        "* Vetor de similaridade  para diferentes significados( 19 , 8 ):  0.76\n",
        "\n",
        "LARGE em portuguÃªs:\n",
        "* Vetor de similaridade  para diferentes significados( 14 , 19 ):  0.78\n",
        "* Vetor de similaridade  para mesmo significado( 14 , 8 ):  0.92\n",
        "* Vetor de similaridade  para diferentes significados( 19 , 8 ):  0.77"
      ]
    }
  ]
}