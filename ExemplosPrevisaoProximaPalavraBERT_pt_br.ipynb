{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExemplosPrevisaoProximaPalavraBERT_pt_br.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osmarbraz/exemplos_BERT/blob/main/ExemplosPrevisaoProximaPalavraBERT_pt_br.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78HE8FLsKN9Q"
      },
      "source": [
        "#Exemplo de Previsão da Próxima Palavra(pt-br) usando BERT Transformers by HuggingFace\n",
        "\n",
        "## **A execução pode ser feita através do menu Ambiente de Execução opção Executar tudo.**\n",
        "\n",
        "Exemplos de **Previsão da Próxima Palavra(pt-br)** usando **BERT** em uma sentença pelo mascaramento(\"[MASK]\") de palavras.\n",
        "\n",
        "**Link biblioteca Huggingface:**\n",
        "https://github.com/huggingface/transformers\n",
        "\n",
        "\n",
        "**Artigo original BERT Jacob Devlin:**\n",
        "https://arxiv.org/pdf/1506.06724.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyxb5Px3p1-e"
      },
      "source": [
        "## 0 - Preparação do ambiente\n",
        "Preparação do ambiente para execução do exemplo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAPVtRXQqDim"
      },
      "source": [
        "###Tratamento de logs\n",
        "\n",
        "Método para tratamento dos logs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcopxbGZqDip"
      },
      "source": [
        "# Biblioteca de logging\n",
        "import logging\n",
        "\n",
        "# Formatando a mensagem de logging\n",
        "logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GjYtXcMnSAe"
      },
      "source": [
        "### Identificando o ambiente Colab\n",
        "\n",
        "Cria uma variável para identificar que o notebook está sendo executado no Google Colaboratory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMiH0E3OnRa1"
      },
      "source": [
        "# Se estiver executando no Google Colaboratory\n",
        "import sys\n",
        "\n",
        "# Retorna true ou false se estiver no Google Colaboratory\n",
        "IN_COLAB = \"google.colab\" in sys.modules"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RufkKnojlwzu"
      },
      "source": [
        "### Instalação do spaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0LeiOTx0Dlk"
      },
      "source": [
        "https://spacy.io/\n",
        "\n",
        "Modelos do spaCy para português:\n",
        "https://spacy.io/models/pt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2Fvx0TVRQUw",
        "outputId": "ed05cfdc-2a77-4fc5-a271-07f4678de6d6"
      },
      "source": [
        "# Instala o spacy\n",
        "!pip install -U spacy==2.3.5"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spacy==2.3.5\n",
            "  Downloading spacy-2.3.5-cp37-cp37m-manylinux2014_x86_64.whl (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (0.4.1)\n",
            "Collecting thinc<7.5.0,>=7.4.1\n",
            "  Downloading thinc-7.4.5-cp37-cp37m-manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 48.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (4.62.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (2.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (57.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (1.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (3.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.3.5) (4.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.5) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.5) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (2021.10.8)\n",
            "Installing collected packages: thinc, spacy\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed spacy-2.3.5 thinc-7.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35GwcgkOlWi3"
      },
      "source": [
        "Realiza o download e carrega os modelos necessários a biblioteca\n",
        "\n",
        "https://spacy.io/models/pt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4LqE5kTwDYm"
      },
      "source": [
        "# Definição do nome do arquivo do modelo\n",
        "#ARQUIVOMODELO = \"pt_core_news_sm\"\n",
        "#ARQUIVOMODELO = \"pt_core_news_md\"\n",
        "ARQUIVOMODELO = \"pt_core_news_lg\"\n",
        "\n",
        "# Definição da versão da spaCy\n",
        "#VERSAOSPACY = \"-3.0.0a0\"\n",
        "VERSAOSPACY = \"-2.3.0\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ2KB3UCp-ws"
      },
      "source": [
        "#Baixa automaticamente o arquivo do modelo.\n",
        "#!python -m spacy download {ARQUIVOMODELO}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASk5iFeUp9LE",
        "outputId": "1b9534d1-2a41-4da0-8ca3-5da1a054f63a"
      },
      "source": [
        "# Realiza o download do arquivo do modelo para o diretório corrente\n",
        "!wget https://github.com/explosion/spacy-models/releases/download/{ARQUIVOMODELO}{VERSAOSPACY}/{ARQUIVOMODELO}{VERSAOSPACY}.tar.gz"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-29 13:35:22--  https://github.com/explosion/spacy-models/releases/download/pt_core_news_lg-2.3.0/pt_core_news_lg-2.3.0.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/84940268/a899e480-ab07-11ea-831b-b5aa9cc04510?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220129%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220129T133522Z&X-Amz-Expires=300&X-Amz-Signature=b42a1de6e9a0aa5cb5815cf3d3ea2e38ef2ddd7ec78937aa51800e4175124684&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=84940268&response-content-disposition=attachment%3B%20filename%3Dpt_core_news_lg-2.3.0.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-01-29 13:35:22--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/84940268/a899e480-ab07-11ea-831b-b5aa9cc04510?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220129%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220129T133522Z&X-Amz-Expires=300&X-Amz-Signature=b42a1de6e9a0aa5cb5815cf3d3ea2e38ef2ddd7ec78937aa51800e4175124684&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=84940268&response-content-disposition=attachment%3B%20filename%3Dpt_core_news_lg-2.3.0.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 576599832 (550M) [application/octet-stream]\n",
            "Saving to: ‘pt_core_news_lg-2.3.0.tar.gz’\n",
            "\n",
            "pt_core_news_lg-2.3 100%[===================>] 549.89M   118MB/s    in 4.6s    \n",
            "\n",
            "2022-01-29 13:35:27 (120 MB/s) - ‘pt_core_news_lg-2.3.0.tar.gz’ saved [576599832/576599832]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu_LkF7Nfm8_"
      },
      "source": [
        "Descompacta o arquivo do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9fCQQJGeVEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d46ba9ad-0791-4ab6-c2aa-8fe8e89ea8f9"
      },
      "source": [
        "# Descompacta o arquivo do modelo\n",
        "!tar -xvf  /content/{ARQUIVOMODELO}{VERSAOSPACY}.tar.gz"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pt_core_news_lg-2.3.0/\n",
            "pt_core_news_lg-2.3.0/PKG-INFO\n",
            "pt_core_news_lg-2.3.0/setup.py\n",
            "pt_core_news_lg-2.3.0/setup.cfg\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/dependency_links.txt\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/PKG-INFO\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/SOURCES.txt\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/requires.txt\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/top_level.txt\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/not-zip-safe\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/__init__.py\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/parser/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/parser/cfg\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/parser/moves\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/parser/model\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/ner/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/ner/cfg\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/ner/moves\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/ner/model\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tokenizer\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/lookups.bin\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/vectors\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/key2row\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/lookups_extra.bin\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/strings.json\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/accuracy.json\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tagger/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tagger/cfg\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tagger/tag_map\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tagger/model\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/meta.json\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/meta.json\n",
            "pt_core_news_lg-2.3.0/MANIFEST.in\n",
            "pt_core_news_lg-2.3.0/meta.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovOx-3Wb-JJW"
      },
      "source": [
        "# Coloca a pasta do modelo descompactado em uma pasta de nome mais simples\n",
        "!mv /content/{ARQUIVOMODELO}{VERSAOSPACY}/{ARQUIVOMODELO}/{ARQUIVOMODELO}{VERSAOSPACY} /content/{ARQUIVOMODELO}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STHT2c89qvwK"
      },
      "source": [
        "Carrega o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbELnrpgA4T1"
      },
      "source": [
        "# Importando as bibliotecas\n",
        "import spacy\n",
        "\n",
        "CAMINHOMODELO = \"/content/\" + ARQUIVOMODELO\n",
        "\n",
        "#nlp = spacy.load(CAMINHOMODELO)\n",
        "# Necessário \"tagger\" para encontrar os substantivos\n",
        "nlp = spacy.load(CAMINHOMODELO, disable=[\"tokenizer\", \"lemmatizer\", \"ner\", \"parser\", \"textcat\", \"custom\"])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFTTdqxKQ1Ay"
      },
      "source": [
        "Recupera os stopwords do spaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBInu7ayQ31J"
      },
      "source": [
        "# Recupera as stop words\n",
        "spacy_stopwords = nlp.Defaults.stop_words"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_EYNu-_RX7k"
      },
      "source": [
        "Lista dos stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUSaUJEWRbnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d50ac8df-ce60-410d-a90e-661d5d4904a0"
      },
      "source": [
        "print(\"Quantidade de stopwords:\", len(spacy_stopwords))\n",
        "\n",
        "print(spacy_stopwords)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade de stopwords: 413\n",
            "{'alguns', 'estás', 'já', 'agora', 'ou', 'dezanove', 'cinco', 'custa', 'quero', 'sei', 'têm', 'fazemos', 'terceiro', 'sob', 'pelo', 'conhecida', 'assim', 'ser', 'tem', 'teve', 'essas', 'valor', 'se', 'esse', 'inclusive', 'dizem', 'cento', 'quarta', 'vai', 'uns', 'tentei', 'porém', 'ponto', 'ambas', 'veja', 'faz', 'fazes', 'é', 'dentro', 'pouco', 'me', 'cada', 'estivestes', 'atrás', 'nesta', 'dessa', 'quinze', 'comprido', 'quê', 'tenho', 'tanta', 'três', 'sem', 'ela', 'quinto', 'novos', 'tivestes', 'após', 'quer', 'falta', 'são', 'tiveram', 'fez', 'dos', 'posição', 'sétimo', 'fim', 'comprida', 'nas', 'fazem', 'meus', 'qualquer', 'cujo', 'meu', 'nossos', 'caminho', 'aquilo', 'números', 'for', 'apoia', 'tentaram', 'naquele', 'número', 'sois', 'isso', 'vão', 'minhas', 'daquele', 'estará', 'nem', 'momento', 'nós', 'ver', 'de', 'foram', 'catorze', 'seis', 'eu', 'boa', 'dezoito', 'irá', 'vossa', 'muito', 'desta', 'pegar', 'apoio', 'aqueles', 'na', 'maiorias', 'outros', 'pontos', 'sobre', 'vindo', 'estiveram', 'algumas', 'meio', 'fui', 'bom', 'estivemos', 'demais', 'ademais', 'desse', 'ele', 'debaixo', 'fazeis', 'que', 'aquele', 'vinda', 'quinta', 'talvez', 'lhe', 'nesse', 'duas', 'novas', 'nos', 'através', 'foi', 'povo', 'contra', 'maioria', 'dar', 'elas', 'tudo', 'breve', 'tive', 'essa', 'ligado', 'no', 'fazer', 'sexta', 'teu', 'fomos', 'neste', 'mas', 'sexto', 'iniciar', 'só', 'tanto', 'embora', 'ainda', 'lá', 'pouca', 'vais', 'aquela', 'esta', 'dão', 'ambos', 'sou', 'partir', 'diante', 'grupo', 'as', 'pode', 'conhecido', 'tentar', 'direita', 'não', 'posso', 'oitavo', 'além', 'toda', 'foste', 'segundo', 'vem', 'tua', 'até', 'menor', 'des', 'bem', 'dez', 'sistema', 'quais', 'zero', 'podem', 'deverá', 'devem', 'esteve', 'tipo', 'sétima', 'do', 'pelos', 'porque', 'aos', 'nível', 'grande', 'usa', 'próximo', 'vossas', 'ir', 'ao', 'com', 'doze', 'estava', 'ora', 'nove', 'vezes', 'vossos', 'aquelas', 'vosso', 'em', 'treze', 'enquanto', 'minha', 'também', 'pela', 'somente', 'quieta', 'muitos', 'você', 'estes', 'estas', 'dezassete', 'lado', 'maior', 'pois', 'eventual', 'certeza', 'todas', 'estou', 'põe', 'geral', 'dá', 'bastante', 'apenas', 'fará', 'tal', 'temos', 'coisa', 'quarto', 'obrigada', 'querem', 'próprio', 'cá', 'possivelmente', 'tens', 'próxima', 'tarde', 'isto', 'oitava', 'depois', 'vários', 'ali', 'tempo', 'exemplo', 'somos', 'vez', 'relação', 'saber', 'poder', 'algo', 'menos', 'uma', 'onde', 'porquanto', 'quanto', 'seria', 'era', 'estado', 'aí', 'como', 'este', 'então', 'vêm', 'nunca', 'vens', 'poderá', 'questão', 'portanto', 'ter', 'todos', 'outras', 'daquela', 'nosso', 'usar', 'seu', 'adeus', 'favor', 'tente', 'novo', 'deste', 'último', 'estiveste', 'teus', 'tiveste', 'fora', 'tuas', 'obrigado', 'máximo', 'por', 'certamente', 'mesmo', 'mais', 'antes', 'onze', 'num', 'pelas', 'tais', 'todo', 'sua', 'estão', 'naquela', 'estive', 'dois', 'um', 'dezasseis', 'inicio', 'vocês', 'acerca', 'outra', 'local', 'vós', 'faço', 'longe', 'cuja', 'final', 'pôde', 'numa', 'fazia', 'aqui', 'das', 'suas', 'vinte', 'quando', 'sete', 'está', 'eles', 'disso', 'lugar', 'quem', 'nada', 'grandes', 'porquê', 'seus', 'primeiro', 'podia', 'oito', 'mal', 'quieto', 'tendes', 'terceira', 'diz', 'para', 'quatro', 'põem', 'fostes', 'primeira', 'deve', 'área', 'qual', 'mil', 'desde', 'parece', 'és', 'logo', 'dizer', 'puderam', 'sim', 'tão', 'nenhuma', 'mês', 'nessa', 'possível', 'nova', 'nossa', 'meses', 'ontem', 'às', 'nuns', 'esses', 'perto', 'nossas', 'umas', 'estar', 'te', 'tivemos', 'baixo', 'contudo', 'segunda', 'apontar', 'cima', 'conselho', 'sempre', 'à', 'cedo', 'sabe', 'tu', 'entre', 'vos', 'parte', 'os', 'da', 'forma', 'corrente'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqa-7WXBAw8q"
      },
      "source": [
        "### Instalação do BERT da Hugging Face"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCdqJCtQN52l"
      },
      "source": [
        "Instala a interface pytorch para o BERT by Hugging Face. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RfUN_KolV-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "622862af-edb7-49df-d945-7bf11d06a3ad"
      },
      "source": [
        "# Instala a última versão da biblioteca\n",
        "#!pip install transformers\n",
        "\n",
        "# Instala uma versão específica da biblioteca\n",
        "!pip install -U transformers==4.5.1"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.5.1\n",
            "  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 52.9 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 44.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (3.4.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.1) (3.0.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (7.1.2)\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQj2wmKDpkrH"
      },
      "source": [
        "## 1 - Download do arquivo do PyTorch Checkpoint\n",
        "\n",
        "Lista de modelos da comunidade:\n",
        "* https://huggingface.co/models\n",
        "\n",
        "Português(https://github.com/neuralmind-ai/portuguese-bert):  \n",
        "* **\"neuralmind/bert-base-portuguese-cased\"**\n",
        "* **\"neuralmind/bert-large-portuguese-cased\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajrTjZzapkrK",
        "outputId": "db8d3ac4-dce6-4b60-a44a-5e711550e20f"
      },
      "source": [
        "# Importando as bibliotecas\n",
        "import os\n",
        "\n",
        "# Variável para setar o arquivo\n",
        "URL_MODELO = None\n",
        "\n",
        "# Comente uma das urls para carregar modelos de tamanhos diferentes(base/large)\n",
        "# URL_MODELO do arquivo do modelo tensorflow\n",
        "# arquivo menor(base) 1.1 Gbytes\n",
        "#URL_MODELO = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "# arquivo grande(large) 3.5 Gbytes\n",
        "URL_MODELO = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "# Se a variável foi setada\n",
        "if URL_MODELO:\n",
        "\n",
        "    # Diretório descompactação\n",
        "    DIRETORIO_MODELO = \"/content/modelo\"\n",
        "\n",
        "    # Recupera o nome do arquivo do modelo da URL_MODELO\n",
        "    arquivo = URL_MODELO.split(\"/\")[-1]\n",
        "\n",
        "    # Nome do arquivo do vocabulário\n",
        "    arquivo_vocab = \"vocab.txt\"\n",
        "\n",
        "    # Caminho do arquivo na URL_MODELO\n",
        "    caminho = URL_MODELO[0:len(URL_MODELO)-len(arquivo)]\n",
        "\n",
        "    # Verifica se a pasta de descompactação existe na pasta corrente\n",
        "    if os.path.exists(DIRETORIO_MODELO):\n",
        "      print(\"Apagando diretório existente do modelo!\")\n",
        "      # Apaga a pasta e os arquivos existentes\n",
        "      !rm -rf $DIRETORIO_MODELO      \n",
        "    \n",
        "    # Baixa o arquivo do modelo\n",
        "    !wget $URL_MODELO\n",
        "    # Descompacta o arquivo na pasta de descompactação\n",
        "    !unzip -o $arquivo -d $DIRETORIO_MODELO\n",
        "\n",
        "    # Baixa o arquivo do vocabulário\n",
        "    # O vocabulário não está no arquivo compactado acima, mesma url mas arquivo diferente\n",
        "    URL_MODELO_VOCAB = caminho + arquivo_vocab\n",
        "    !wget $URL_MODELO_VOCAB\n",
        "    \n",
        "    # Coloca o arquivo do vocabulário no diretório de descompactação\n",
        "    !mv $arquivo_vocab $DIRETORIO_MODELO\n",
        "            \n",
        "    # Move o arquivo para pasta de descompactação\n",
        "    !mv $arquivo $DIRETORIO_MODELO\n",
        "       \n",
        "    print(\"Pasta do \" + DIRETORIO_MODELO + \" pronta!\")\n",
        "    \n",
        "    # Lista a pasta corrente\n",
        "    !ls -la $DIRETORIO_MODELO\n",
        "else:\n",
        "    print(\"Variável URL_MODELO não setada!\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-29 13:35:53--  https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\n",
            "Resolving neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)... 52.219.97.186\n",
            "Connecting to neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)|52.219.97.186|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1244275810 (1.2G) [application/zip]\n",
            "Saving to: ‘bert-large-portuguese-cased_pytorch_checkpoint.zip’\n",
            "\n",
            "bert-large-portugue 100%[===================>]   1.16G  84.0MB/s    in 14s     \n",
            "\n",
            "2022-01-29 13:36:08 (82.2 MB/s) - ‘bert-large-portuguese-cased_pytorch_checkpoint.zip’ saved [1244275810/1244275810]\n",
            "\n",
            "Archive:  bert-large-portuguese-cased_pytorch_checkpoint.zip\n",
            "  inflating: /content/modelo/config.json  \n",
            "  inflating: /content/modelo/pytorch_model.bin  \n",
            "--2022-01-29 13:36:27--  https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/vocab.txt\n",
            "Resolving neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)... 52.219.106.146\n",
            "Connecting to neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)|52.219.106.146|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 209528 (205K) [text/plain]\n",
            "Saving to: ‘vocab.txt’\n",
            "\n",
            "vocab.txt           100%[===================>] 204.62K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2022-01-29 13:36:27 (2.29 MB/s) - ‘vocab.txt’ saved [209528/209528]\n",
            "\n",
            "Pasta do /content/modelo pronta!\n",
            "total 2525908\n",
            "drwxr-xr-x 2 root root       4096 Jan 29 13:36 .\n",
            "drwxr-xr-x 1 root root       4096 Jan 29 13:36 ..\n",
            "-rw-r--r-- 1 root root 1244275810 Jan 22  2020 bert-large-portuguese-cased_pytorch_checkpoint.zip\n",
            "-rw-rw-r-- 1 root root        874 Jan 12  2020 config.json\n",
            "-rw-rw-r-- 1 root root 1342014951 Jan 12  2020 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root     209528 Jan 21  2020 vocab.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcpd9t9PpkrX"
      },
      "source": [
        "## 2 - Carregando o Tokenizador BERT\n",
        "\n",
        "O tokenizador utiliza WordPiece, veja em [artigo original](https://arxiv.org/pdf/1609.08144.pdf).\n",
        "\n",
        "Carregando o tokenizador da pasta \"/content/modelo/\" do diretório padrão se variável `URL_MODELO` setada.\n",
        "\n",
        "**Caso contrário carrega da comunidade**\n",
        "\n",
        "Por default(`do_lower_case=True`) todas as letras são colocadas para minúsculas. Para ignorar a conversão para minúsculo use o parâmetro `do_lower_case=False`. Esta opção também considera as letras acentuadas(ãçéí...), que são necessárias a língua portuguesa.\n",
        "\n",
        "O parâmetro `do_lower_case` interfere na quantidade tokens a ser gerado a partir de um documento. Quando igual a `False` reduz a quantidade de tokens gerados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8cKVs4fpkrY",
        "outputId": "59b4069f-3b51-4a67-ca12-568259423148"
      },
      "source": [
        "# Importando as bibliotecas do tokenizador\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Se a variável URL_MODELO foi setada\n",
        "if DIRETORIO_MODELO:\n",
        "    # Carregando o Tokenizador\n",
        "    print(\"Carrgando o tokenizador BERT do diretório \" + DIRETORIO_MODELO + \"...\")\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(DIRETORIO_MODELO, \n",
        "                                              do_lower_case=False)    \n",
        "else:\n",
        "    # Carregando o Tokenizador da comunidade\n",
        "    print(\"Carregando o tokenizador da comunidade...\")\n",
        "    \n",
        "    #tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\", do_lower_case=False)\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-large-portuguese-cased\", do_lower_case=False)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carrgando o tokenizador BERT do diretório /content/modelo...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m__On2g1a--K"
      },
      "source": [
        "## 3 - Carregando o Modelo BERT(BertForMaskedLM)\n",
        "\n",
        "Se a variável `URL_MODELO` estiver setada carrega o modelo do diretório `content/modelo`.\n",
        "\n",
        "Caso contrário carrega da comunidade.\n",
        "\n",
        "Carregando o modelo da pasta \"/content/modelo/\" do diretório padrão.\n",
        "\n",
        "A implementação do huggingface pytorch inclui um conjunto de interfaces projetadas para uma variedade de tarefas de PNL. Embora essas interfaces sejam todas construídas sobre um modelo treinado de BERT, cada uma possui diferentes camadas superiores e tipos de saída projetados para acomodar suas tarefas específicas de PNL.\n",
        "\n",
        "A documentação para estas pode ser encontrada em [aqui](https://huggingface.co/transformers/model_doc/bert.html#bertformaskedlm).\n",
        "\n",
        "Por default o modelo está em modo avaliação ou seja `model.eval()`.\n",
        "\n",
        "-----------------------\n",
        "\n",
        "Durante a avaliação do modelo, este retorna um número de diferentes objetos com base em como é configurado na chamada do método `from_pretrained`. \n",
        "\n",
        "Quando definimos `output_hidden_states = True` na chamada do método `from_pretrained`, retorno do modelo possui no terceiro item os estados ocultos(**hidden_states**) de todas as camadas.  Veja a documentação para mais detalhes: https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "\n",
        "Quando **`output_hidden_states = True`** model retorna:\n",
        "- outputs[0] = last_hidden_state;\n",
        "- outputs[1] = pooler_output; \n",
        "- outputs[2] = hidden_states.\n",
        "\n",
        "Quando **`output_hidden_states = False`** ou não especificado model retorna:\n",
        "- outputs[0] = last_hidden_state;\n",
        "- outputs[1] = pooler_output.\n",
        "\n",
        "\n",
        "**ATENÇÃO**: O parâmetro ´**output_hidden_states = True**´ habilita gerar as camadas ocultas do modelo. Caso contrário somente a última camada é mantida. Este parâmetro otimiza a memória mas não os resultados.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRV6l_I-qg9s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9668d8f8-2984-48b5-eca3-bf4d98fab587"
      },
      "source": [
        "# Importando as bibliotecas do Modelo\n",
        "from transformers import BertForMaskedLM\n",
        "\n",
        "# Se a variável URL_MODELO1 foi setada\n",
        "if URL_MODELO:\n",
        "    # Carregando o modelo\n",
        "    print(\"Carregando o modelo BERT do diretório \" + DIRETORIO_MODELO + \"...\")\n",
        "\n",
        "    model = BertForMaskedLM.from_pretrained(DIRETORIO_MODELO, \n",
        "                                      output_attentions = False,\n",
        "                                      output_hidden_states = True)    \n",
        "else:\n",
        "    # Carregando o modelo da comunidade\n",
        "    print(\"Carregando o modelo BERT da comunidade ...\")\n",
        "\n",
        "    model = BertForMaskedLM.from_pretrained(\"neuralmind/bert-large-portuguese-cased\", \n",
        "                                      output_attentions = False,\n",
        "                                      output_hidden_states = True)## 5 - Funções auxiliares"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando o modelo BERT do diretório /content/modelo...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/modelo were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCQRC9fHAZQJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12a7fea3-c0f3-4d17-bd59-21d46c806501"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(29794, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=1024, out_features=29794, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CItBju3uAa8q"
      },
      "source": [
        "# model.to(\"cuda\")  # Se tiver gpu"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKicQ_TH_WxK"
      },
      "source": [
        "## 4 - Funções auxiliares\n",
        "\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### previsaoPalavraSentenca"
      ],
      "metadata": {
        "id": "0VKoJQW4ksbz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqYOs576NPQ"
      },
      "source": [
        "# Importando a biblioteca\n",
        "import torch\n",
        "\n",
        "def getPrevisaoPalavraSentenca(documento, top_k=5):\n",
        "    \"\"\" \n",
        "      Retorna uma lista com as k previsões para a palavra mascarada no documento.\n",
        "          \n",
        "      Parâmetros:\n",
        "        `documento` - Documento mascarado.\n",
        "        `top_k` - Quantidade de palavras a serem recuperadas.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Adiciona os tokens especiais ao documento\n",
        "    documento_marcado = \"[CLS] \" + documento + \"[SEP]\"\n",
        "    #print(\"documento_marcado:\", documento_marcado)\n",
        "\n",
        "    # Divide as palavras em tokens\n",
        "    documento_tokenizado = tokenizer.tokenize(documento_marcado)    \n",
        "    #print(\"documento_tokenizado:\", documento_tokenizado)\n",
        "\n",
        "    # Retorna o índice da mascara de atenção\n",
        "    mascara_atencao_indice = documento_tokenizado.index(\"[MASK]\")\n",
        "    #print(\"mascara_atencao_indice:\", mascara_atencao_indice)\n",
        "\n",
        "    # Mapeia os tokens em seus índices do vocabulário\n",
        "    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n",
        "    #print(\"tokens_indexados:\", tokens_indexados)\n",
        "    \n",
        "    # Converte as entradas de lista para tensores do torch\n",
        "    tokens_tensores = torch.tensor([tokens_indexados])\n",
        "    \n",
        "    # Realiza a predição dos tokens\n",
        "    with torch.no_grad():\n",
        "        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n",
        "        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "        outputs = model(tokens_tensores)\n",
        "\n",
        "    # Recupera a predição com os embeddings da última camada oculta    \n",
        "    predicao = outputs[0]\n",
        "    \n",
        "    # Normaliza os pesos das predições nos embeddings e calcula sua probabilidade\n",
        "    probabilidades = torch.nn.functional.softmax(predicao[0, mascara_atencao_indice], dim=-1)    \n",
        "    # Retorna os k maiores elementos de determinado tensor de entrada ao longo de uma determinada dimensão de forma ordenada descrescentemente.\n",
        "    top_k_pesos, top_k_indices = torch.topk(probabilidades, top_k, sorted=True)\n",
        "\n",
        "    # Mostra as predições\n",
        "    print(\"Frase:\", documento )\n",
        "    for i, indicePredicao in enumerate(top_k_indices):\n",
        "        # Mapeia os índices do vocabulário para os seus tokens\n",
        "        token_previsto = tokenizer.convert_ids_to_tokens([indicePredicao])[0]\n",
        "        token_peso = top_k_pesos[i]\n",
        "\n",
        "        print((i+1), \"[MASK]: \", token_previsto, \" | peso:\", float(token_peso))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### contaElemento"
      ],
      "metadata": {
        "id": "AbfqQZtfkuS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def contaElemento(lista, elemento):\n",
        "    \"\"\" \n",
        "      Conta o número do elemento na lista.\n",
        "          \n",
        "      Parâmetros:\n",
        "        `lista` - Lista com os elementos.\n",
        "        `elemento` - Elemento a ser contado a ocorrência na lista.\n",
        "\n",
        "      Retorno:    \n",
        "        `cont` - Quantidade de ocorrência de elmento na lista.\n",
        "    \"\"\"\n",
        "    cont = 0\n",
        "    # Percorre a lista\n",
        "    for i, linha in enumerate(lista):      \n",
        "      # Verifica se o elemento existe na lista\n",
        "      if linha in elemento:\n",
        "        # conta o elemento\n",
        "        cont = cont + 1\n",
        "    return cont"
      ],
      "metadata": {
        "id": "Dp9X6-3VN90o"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### getSentencaMascarada"
      ],
      "metadata": {
        "id": "BaNNRNftk2Wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as bibliotecas.\n",
        "from random import randint # Biblioteca para o sorteio\n",
        "\n",
        "def getSentencaMascarada(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\"], qtde=1):\n",
        "  \"\"\" \n",
        "      Gera a sentença mascarada com [MAKS] para usar com MLM do BERT.\n",
        "      Considera determinadas classes morfossintática das palavras e uma quantidade(qtde) de palavras a serem mascaradas.\n",
        "          \n",
        "      Parâmetros:\n",
        "        `sentenca` - Sentença a ser mascarada.\n",
        "        `sentenca_token` - Lista com os tokens da sentença.\n",
        "        `sentenca_pos` - Lista com as POS dos tokens da sentença.\n",
        "        `classe` - Lista com as classes morfossintática das palavras a serem mascarada com [MASK].\n",
        "        `qtde` - Quantidade de mascarada a serem realizadas nas palavras das sentenças.\n",
        "                 Seleciona aleatoriamente a(s) palavra(s) a ser(em) mascarada(s) se a qtde \n",
        "                 for menor que quantidade de palavras das classes na sentença.\n",
        "\n",
        "      Retorno:    \n",
        "        `sentencaMascarada` - Sentença mascarada.\n",
        "        `palavraMascarada` - Lista com as palavras substituidas pela máscara.\n",
        "\n",
        "  \"\"\"\n",
        "  sentencaMascarada = \"\"\n",
        "  palavraMascarada = \"\"\n",
        "\n",
        "  # Verifica a quantidade de trocas a ser realizada\n",
        "  if qtde != 0:\n",
        "\n",
        "    # Conta o número de palavras das classes especificadas\n",
        "    if len(classe) > 1:\n",
        "      # Se tem duas classes usa a primeira para contar se existe uma palavra\n",
        "      # Pega o primeiro para realizar a conta\n",
        "      classeConta = [classe[0]]\n",
        "      contaMascara = contaElemento(sentenca_pos, classeConta)\n",
        "      \n",
        "      # Senão encontrar pega a segunda classe\n",
        "      if contaMascara == 0:\n",
        "        #Pega a segunda classe\n",
        "        classeConta = [classe[1]]\n",
        "        contaMascara = contaElemento(sentenca_pos, classeConta)\n",
        "      \n",
        "      # Usa a classe para gerar a sentença mascarada\n",
        "      classe = classeConta\n",
        "    else:\n",
        "      contaMascara = contaElemento(sentenca_pos, classe)\n",
        "\n",
        "    \n",
        "    # Verifica se existe palavras das classes a serem mascaradas\n",
        "    if contaMascara != 0:    \n",
        "      # Verifica a quantidade de trocas é menor que a quantidade palavras a serem trocadas encontradas\n",
        "      if qtde < contaMascara:\n",
        "        # A quantidade de trocas é menor que a quantidade de palavras existentes\n",
        "        # Precisa sortear as posições que serão trocadas pela máscara dentro da quantidade\n",
        "               \n",
        "        roleta = []\n",
        "        # preenche a roleta com o indice das palavras as serem mscaradas\n",
        "        for i in range(contaMascara):\n",
        "            roleta.append(i)\n",
        "\n",
        "        # Sorteia as posições das trocas\n",
        "        posicao = []\n",
        "        for i in range(qtde):\n",
        "            sorteioPosicao = randint(0, len(roleta)-1)\n",
        "            # Guarda o número sorteado\n",
        "            posicao.append(roleta[sorteioPosicao])\n",
        "            # Remove o elemento sorteado da roleta\n",
        "            del roleta[sorteioPosicao]\n",
        "        \n",
        "        # Conta o número das trocas realizadas\n",
        "        troca = 0\n",
        "\n",
        "        # Substitui o elemento pela máscara\n",
        "        for i, token in enumerate(sentenca_token):            \n",
        "            # Se a classe da palavra é a desejada\n",
        "            if sentenca_pos[i] in classe:\n",
        "                # Verifica se a troca deve ser realizada para a posição\n",
        "                if troca in posicao:      \n",
        "                  # Trocar palavra da classe por [MASK]\n",
        "                  sentencaMascarada = sentencaMascarada + \"[MASK]\" + \" \"    \n",
        "                  # Guarda a palavra que foi mascarada\n",
        "                  palavraMascarada = token                                  \n",
        "                else:                  \n",
        "                  # Adiciona o token\n",
        "                  sentencaMascarada = sentencaMascarada + token + \" \"\n",
        "                # Avança para a próxima troca\n",
        "                troca = troca + 1\n",
        "            else:\n",
        "              # Adiciona o token\n",
        "                sentencaMascarada = sentencaMascarada + token + \" \"\n",
        "      else:        \n",
        "        # Trocar todas as palavras pela mascará, pois a quantidade\n",
        "        # de trocas é igual a quantidade de mascarás existentes na sentença\n",
        "\n",
        "        # Substitui o elemento da classe pela mascará\n",
        "        for i, token in enumerate(sentenca_token):\n",
        "            #print(token, sentenca_pos[i])        \n",
        "            # Se a classe da palavra é a desejada\n",
        "            if sentenca_pos[i] in classe:\n",
        "                # Trocar palavra da classe por [MASK]\n",
        "                sentencaMascarada = sentencaMascarada + \"[MASK]\" + \" \"    \n",
        "                # Guarda a palavra que foi mascarada\n",
        "                palavraMascarada = token \n",
        "            else:\n",
        "                sentencaMascarada = sentencaMascarada + token + \" \"\n",
        "    else:\n",
        "      # Não existe palavras da classe especificada      \n",
        "      print(\"Não existe palavras da classe especificada.\")\n",
        "      sentencaMascarada = sentenca    \n",
        "  else:\n",
        "    # Quantidade trocas igual a 0\n",
        "    print(\"Não foi especificado uma quantidade de trocas.\")\n",
        "    sentencaMascarada = sentenca\n",
        "\n",
        "  # Retira o espaço em branco do início e fim da sentença\n",
        "  sentencaMascarada = sentencaMascarada.strip(\" \")\n",
        "\n",
        "  return sentencaMascarada, palavraMascarada"
      ],
      "metadata": {
        "id": "NQBCxLcqBsU8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### getPerturbacaoPalavraSentenca"
      ],
      "metadata": {
        "id": "BSTMmNMvk-8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando a biblioteca\n",
        "import torch\n",
        "from random import randint # Biblioteca para o sorteio\n",
        "\n",
        "def getPerturbacaoPalavraSentenca(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\"], qtde=1):\n",
        "    \"\"\" \n",
        "        Gera a palavras da perturbação da sentença.\n",
        "        Considera determinadas classes morfossintática das palavras.\n",
        "            \n",
        "        Parâmetros:\n",
        "          `sentenca` - Sentença a ser mascarada.\n",
        "          `sentenca_token` - Lista com os tokens da sentença.\n",
        "          `sentenca_pos` - Lista com as POS dos tokens da sentença.\n",
        "          `classe` - Lista com as classes morfossintática das palavras a serem mascarada com [MASK].\n",
        "          `qtde` - Quantidade de mascarada a serem realizadas nas palavras das sentenças.\n",
        "                  Seleciona aleatoriamente a(s) palavra(s) a ser(em) mascarada(s) se a qtde \n",
        "                  for menor que quantidade de palavras das classes na sentença.\n",
        "\n",
        "        Retorno:    \n",
        "          `sentencaMascarada` - Sentença mascarada.\n",
        "          `palavraMascarada` - Palavra substituídas pela máscara.\n",
        "          `token_previsto` - Palavra prevista para a máscara.\n",
        "          `token_peso` - Peso da palavra prevista.\n",
        "          `sorteioPosicao` - Posição da palavra prevista na lista de previsões.\n",
        "    \"\"\"\n",
        "\n",
        "    #print(\"Sentença original:\", sentenca)\n",
        "    sentencaMascarada, palavraMascarada = getSentencaMascarada(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\"], qtde=1)\n",
        "    \n",
        "    # Adiciona os tokens especiais ao sentenca\n",
        "    sentenca_marcado = \"[CLS] \" + sentencaMascarada + \"[SEP]\"\n",
        "    #print(\"sentenca_marcado:\", sentenca_marcado)\n",
        "\n",
        "    # Divide as palavras em tokens\n",
        "    sentenca_tokenizado = tokenizer.tokenize(sentenca_marcado)    \n",
        "    #print(\"sentenca_tokenizado:\", sentenca_tokenizado)\n",
        "\n",
        "    # Retorna o índice da mascara de atenção\n",
        "    mascara_atencao_indice = sentenca_tokenizado.index(\"[MASK]\")\n",
        "    #print(\"mascara_atencao_indice:\", mascara_atencao_indice)\n",
        "\n",
        "    # Mapeia os tokens em seus índices do vocabulário\n",
        "    tokens_indexados = tokenizer.convert_tokens_to_ids(sentenca_tokenizado)\n",
        "    #print(\"tokens_indexados:\", tokens_indexados)\n",
        "    \n",
        "    # Converte as entradas de lista para tensores do torch\n",
        "    tokens_tensores = torch.tensor([tokens_indexados])\n",
        "    \n",
        "    # Realiza a predição dos tokens\n",
        "    with torch.no_grad():\n",
        "        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n",
        "        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "        outputs = model(tokens_tensores)\n",
        "\n",
        "    # Recupera a predição com os embeddings da última camada oculta    \n",
        "    predicao = outputs[0]\n",
        "    \n",
        "    # Normaliza os pesos das predições nos embeddings e calcula sua probabilidade\n",
        "    probabilidades = torch.nn.functional.softmax(predicao[0, mascara_atencao_indice], dim=-1)    \n",
        "    # Retorna os k maiores elementos de determinado tensor de entrada ao longo de uma determinada dimensão de forma ordenada descrescentemente.\n",
        "\n",
        "    # Quantidade de predições a ser recuperada\n",
        "    top_k = 500\n",
        "\n",
        "    # Recupera as top_k predições em ordem\n",
        "    top_k_pesos, top_k_indices = torch.topk(probabilidades, top_k, sorted=True)\n",
        "    \n",
        "    # Sorteia uma predição do intervalo\n",
        "    sorteioPosicao = randint(0, top_k-1)    \n",
        "    #print(\"sorteioPosicao:\",sorteioPosicao)\n",
        "\n",
        "    # Recupera as predições    \n",
        "    # Mapeia os índices do vocabulário para os seus tokens\n",
        "    token_previsto = tokenizer.convert_ids_to_tokens([top_k_indices[sorteioPosicao]])[0]\n",
        "    # Recupera os pesos da predição\n",
        "    token_peso = top_k_pesos[sorteioPosicao]\n",
        "    #print((sorteioPosicao+1), \"[MASK]: \", token_previsto, \" | peso:\", float(token_peso))        \n",
        "\n",
        "    if \"##\" in token_previsto:      \n",
        "      # Remove \"##\" do token\n",
        "      token_previsto = token_previsto[2:]\n",
        "      \n",
        "    return sentencaMascarada, palavraMascarada, token_previsto, token_peso, sorteioPosicao"
      ],
      "metadata": {
        "id": "avC4NB2kk_Fm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### getPerturbacaoSentenca"
      ],
      "metadata": {
        "id": "lxtXFpKBlEa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getPerturbacaoSentenca(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\"], qtde=1):\n",
        "\n",
        "  \"\"\" \n",
        "      Gera a sentença com a perturbação.\n",
        "      Considera determinadas classes morfossintática das palavras.\n",
        "          \n",
        "      Parâmetros:\n",
        "        `sentenca` - Sentença a ser mascarada.\n",
        "        `sentenca_token` - Lista com os tokens da sentença.\n",
        "        `sentenca_pos` - Lista com as POS dos tokens da sentença.\n",
        "        `classe` - Lista com as classes morfossintática das palavras a serem mascarada com [MASK].\n",
        "        `qtde` - Quantidade de mascarada a serem realizadas nas palavras das sentenças.\n",
        "                Seleciona aleatoriamente a(s) palavra(s) a ser(em) mascarada(s) se a qtde \n",
        "                for menor que quantidade de palavras das classes na sentença.\n",
        "\n",
        "      Retorno:    \n",
        "        `sentencaPerturbada` - Sentença com a perturbação.\n",
        "        `sentencaMascarada` - Sentença mascarada.\n",
        "        `palavraMascarada` - Palavra substituídas pela máscara.\n",
        "        `token_previsto` - Palavra prevista para a máscara.\n",
        "  \"\"\"\n",
        "\n",
        "  # Recupera a sentença mascarada e o token pervisto\n",
        "  sentencaMascarada, palavraMascarada, token_previsto, token_peso, sorteioPosicao = getPerturbacaoPalavraSentenca(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\"], qtde=1)\n",
        "\n",
        "  # Se existir o token especial [MASK]\n",
        "  if \"[MASK]\" in sentencaMascarada:\n",
        "    \n",
        "      # Substituir a mascará pelo token previsto\n",
        "      sentencaPerturbada = sentencaMascarada.replace(\"[MASK]\", token_previsto)\n",
        "  \n",
        "  return sentencaPerturbada, sentencaMascarada, palavraMascarada, token_previsto"
      ],
      "metadata": {
        "id": "iTnWU0dQlEke"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru02mC0Estsb"
      },
      "source": [
        "## 5 - Exemplo MLM previsão da próxima palavra utilizando BERT\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZkpDPZF6K0x"
      },
      "source": [
        "### Exemplo 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwWHiSy91cji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8ad81ab-b377-4612-f7cd-4f91ce6cda1f"
      },
      "source": [
        "sentenca = \"O carro bateu no [MASK].\"\n",
        "\n",
        "getPrevisaoPalavraSentenca(sentenca, top_k=10)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frase: O carro bateu no [MASK].\n",
            "1 [MASK]:  muro  | peso: 0.597743034362793\n",
            "2 [MASK]:  caminhão  | peso: 0.06205667182803154\n",
            "3 [MASK]:  chão  | peso: 0.0495670922100544\n",
            "4 [MASK]:  outro  | peso: 0.0391114167869091\n",
            "5 [MASK]:  solo  | peso: 0.034394290298223495\n",
            "6 [MASK]:  ônibus  | peso: 0.01980435661971569\n",
            "7 [MASK]:  portão  | peso: 0.013402305543422699\n",
            "8 [MASK]:  buraco  | peso: 0.010201003402471542\n",
            "9 [MASK]:  carro  | peso: 0.009121101349592209\n",
            "10 [MASK]:  rio  | peso: 0.00718745356425643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-dkydqHVBB4",
        "outputId": "bbc7444f-7bef-4503-b8f9-a71e0a376554"
      },
      "source": [
        "sentenca = \"O dia está [MASK].\"\n",
        "\n",
        "getPrevisaoPalavraSentenca(sentenca, top_k=10)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frase: O dia está [MASK].\n",
            "1 [MASK]:  claro  | peso: 0.18800124526023865\n",
            "2 [MASK]:  quente  | peso: 0.10005087405443192\n",
            "3 [MASK]:  chegando  | peso: 0.06581124663352966\n",
            "4 [MASK]:  escuro  | peso: 0.05243193358182907\n",
            "5 [MASK]:  terminando  | peso: 0.03215831145644188\n",
            "6 [MASK]:  bonito  | peso: 0.031797997653484344\n",
            "7 [MASK]:  frio  | peso: 0.029412493109703064\n",
            "8 [MASK]:  bom  | peso: 0.0276333000510931\n",
            "9 [MASK]:  longo  | peso: 0.022950707003474236\n",
            "10 [MASK]:  triste  | peso: 0.019353417679667473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IBIDVR9_iaB"
      },
      "source": [
        "### Exemplo 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kdo1kx3-C4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75796e4c-dc25-4ccc-a9b2-4a711a6ea21e"
      },
      "source": [
        "sentenca = \"O que é uma pilha e como [MASK] seu elemento?\"\n",
        "\n",
        "getPrevisaoPalavraSentenca(sentenca, top_k=10)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frase: O que é uma pilha e como [MASK] seu elemento?\n",
            "1 [MASK]:  identificar  | peso: 0.2645019590854645\n",
            "2 [MASK]:  funciona  | peso: 0.11154681444168091\n",
            "3 [MASK]:  localizar  | peso: 0.04558868333697319\n",
            "4 [MASK]:  é  | peso: 0.04059113189578056\n",
            "5 [MASK]:  encontrar  | peso: 0.034488629549741745\n",
            "6 [MASK]:  classificar  | peso: 0.02985268458724022\n",
            "7 [MASK]:  calcular  | peso: 0.029209716245532036\n",
            "8 [MASK]:  medir  | peso: 0.02668553777039051\n",
            "9 [MASK]:  utilizar  | peso: 0.025590619072318077\n",
            "10 [MASK]:  usar  | peso: 0.021644597873091698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPDz-9aT_k9Q"
      },
      "source": [
        "### Exemplo 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-5TNrWZ-6Gg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86ef2de4-e8a9-4a16-e136-e307fc9be266"
      },
      "source": [
        "sentenca = \"O que é uma [MASK] e como enfileirar seu elemento?\"\n",
        "\n",
        "getPrevisaoPalavraSentenca(sentenca, top_k=10)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frase: O que é uma [MASK] e como enfileirar seu elemento?\n",
            "1 [MASK]:  árvore  | peso: 0.1691964864730835\n",
            "2 [MASK]:  casa  | peso: 0.04466995969414711\n",
            "3 [MASK]:  pilha  | peso: 0.04050327092409134\n",
            "4 [MASK]:  planta  | peso: 0.038771532475948334\n",
            "5 [MASK]:  coleção  | peso: 0.03736716881394386\n",
            "6 [MASK]:  biblioteca  | peso: 0.0324641689658165\n",
            "7 [MASK]:  flor  | peso: 0.025039255619049072\n",
            "8 [MASK]:  mesa  | peso: 0.02046835422515869\n",
            "9 [MASK]:  fonte  | peso: 0.018971988931298256\n",
            "10 [MASK]:  caixa  | peso: 0.018774881958961487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GylSCDQIVO7m"
      },
      "source": [
        "### Exemplo 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXgHNxJvVKK-",
        "outputId": "62aea943-fbe6-4cfd-e8c0-f67b090a7030"
      },
      "source": [
        "sentenca = \"O que é uma [MASK] e como empilhar seu elemento?\"\n",
        "\n",
        "getPrevisaoPalavraSentenca(sentenca, top_k=10)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frase: O que é uma [MASK] e como empilhar seu elemento?\n",
            "1 [MASK]:  árvore  | peso: 0.13572701811790466\n",
            "2 [MASK]:  pilha  | peso: 0.10913962870836258\n",
            "3 [MASK]:  caixa  | peso: 0.035586193203926086\n",
            "4 [MASK]:  coleção  | peso: 0.03333856910467148\n",
            "5 [MASK]:  pirâmide  | peso: 0.02637934312224388\n",
            "6 [MASK]:  biblioteca  | peso: 0.0259123295545578\n",
            "7 [MASK]:  casa  | peso: 0.0231474582105875\n",
            "8 [MASK]:  estrutura  | peso: 0.022385787218809128\n",
            "9 [MASK]:  planta  | peso: 0.020019162446260452\n",
            "10 [MASK]:  mina  | peso: 0.017395537346601486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6 - Exemplo MLM gerando sentença perturbada utilizando BERT"
      ],
      "metadata": {
        "id": "_4wusjUqjuT1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 1\n",
        "\n",
        "Sentença 1 verbo"
      ],
      "metadata": {
        "id": "hStfTSjfj30j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentenca = \"Como enfileirar elementos em uma fila?\"\n",
        "sentenca_token = ['Como', 'enfileirar', 'elementos', 'em', 'uma', 'fila', '?']\n",
        "sentenca_pos = ['SCONJ', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', 'PUNCT']\n",
        "\n",
        "sentencaPerturbada, sentencaMascarada, palavraMascarada, token_previsto = getPerturbacaoSentenca(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\"])\n",
        "print(\"sentença Original  :\",sentenca)\n",
        "print(\"sentença Perturbada:\",sentencaPerturbada)\n",
        "print(\"sentença Mascarada :\",sentencaMascarada)\n",
        "print(\"palavra Mascarada  :\",palavraMascarada)\n",
        "print(\"token previsto     :\",token_previsto)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWKwqtOGkbyL",
        "outputId": "41b02339-89d3-47f2-d730-7111d0ceb7f0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentença Original  : Como enfileirar elementos em uma fila?\n",
            "sentença Perturbada: Como cantar elementos em uma fila ?\n",
            "sentença Mascarada : Como [MASK] elementos em uma fila ?\n",
            "palavra Mascarada  : enfileirar\n",
            "token previsto     : cantar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 2\n",
        "\n",
        "Sentença com dois verbos"
      ],
      "metadata": {
        "id": "HMWb-FrHltM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentenca = \"Como empilhar e desempilhar elementos em uma estrutura de dados pilha?\"\n",
        "sentenca_token = ['Como', 'empilhar', 'e', 'desempilhar', 'elementos', 'em', 'uma', 'estrutura', 'de', 'dados', 'pilha', '?']\n",
        "sentenca_pos = ['SCONJ', 'VERB', 'CCONJ', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', 'NOUN', 'PUNCT']\n",
        "\n",
        "sentencaPerturbada, sentencaMascarada, palavraMascarada, token_previsto = getPerturbacaoSentenca(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\"])\n",
        "print(\"sentença Original  :\",sentenca)\n",
        "print(\"sentença Perturbada:\",sentencaPerturbada)\n",
        "print(\"sentença Mascarada :\",sentencaMascarada)\n",
        "print(\"palavra Mascarada  :\",palavraMascarada)\n",
        "print(\"token previsto     :\",token_previsto)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6CnjaMlluX0",
        "outputId": "b1c0d300-df0b-4fef-b921-aa157a431d96"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentença Original  : Como empilhar e desempilhar elementos em uma estrutura de dados pilha?\n",
            "sentença Perturbada: Como cria e desempilhar elementos em uma estrutura de dados pilha ?\n",
            "sentença Mascarada : Como [MASK] e desempilhar elementos em uma estrutura de dados pilha ?\n",
            "palavra Mascarada  : empilhar\n",
            "token previsto     : cria\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 3\n",
        "\n",
        "Sentença com um substantivo e nenhum verbo"
      ],
      "metadata": {
        "id": "OcL7GudTl52L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentenca = \"Como desempilhar elementos em uma pilha?\"\n",
        "sentenca_token = ['Como', 'desempilhar', 'elementos', 'em', 'uma', 'pilha', '?']\n",
        "sentenca_pos = ['ADP', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN', 'PUNCT']\n",
        "\n",
        "sentencaPerturbada, sentencaMascarada, palavraMascarada, token_previsto = getPerturbacaoSentenca(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\"])\n",
        "print(\"sentença Original  :\",sentenca)\n",
        "print(\"sentença Perturbada:\",sentencaPerturbada)\n",
        "print(\"sentença Mascarada :\",sentencaMascarada)\n",
        "print(\"palavra Mascarada  :\",palavraMascarada)\n",
        "print(\"token previsto     :\",token_previsto)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eny_CAcZl52L",
        "outputId": "8970c29f-246b-46a5-ad51-ce1b4e9fab2e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentença Original  : Como desempilhar elementos em uma pilha?\n",
            "sentença Perturbada: Como desempilhar elementos em uma guitarra ?\n",
            "sentença Mascarada : Como desempilhar elementos em uma [MASK] ?\n",
            "palavra Mascarada  : pilha\n",
            "token previsto     : guitarra\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XJU5H24Sl3Z2"
      }
    }
  ]
}