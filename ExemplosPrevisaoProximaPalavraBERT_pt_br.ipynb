{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExemplosPrevisaoProximaPalavraBERT_pt_br.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9df197c1a5b148328de07ce75f9d2551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d55db668a4b64102919719085d8e26a1",
              "IPY_MODEL_98c38bc9cac847718018aee5acb3f3ef",
              "IPY_MODEL_cc1b4a9ab9b8434fab82d439d1323373"
            ],
            "layout": "IPY_MODEL_fa38a0714ddc44e1b533bdaf9896e567"
          }
        },
        "d55db668a4b64102919719085d8e26a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01f29b15097143db9e56d4657545f283",
            "placeholder": "​",
            "style": "IPY_MODEL_83ce180fc701491791598eaf34775782",
            "value": "Downloading: 100%"
          }
        },
        "98c38bc9cac847718018aee5acb3f3ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c3e5ccdc24d41c6875980eee9aa02e5",
            "max": 209528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_835f27d9b51f4f8fb65ff182f641e1a9",
            "value": 209528
          }
        },
        "cc1b4a9ab9b8434fab82d439d1323373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87e1937a7429494da8fbd5a33d3d2907",
            "placeholder": "​",
            "style": "IPY_MODEL_8ad7c7143fdb43bebf8de7f375a1e23b",
            "value": " 210k/210k [00:00&lt;00:00, 788kB/s]"
          }
        },
        "fa38a0714ddc44e1b533bdaf9896e567": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01f29b15097143db9e56d4657545f283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83ce180fc701491791598eaf34775782": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c3e5ccdc24d41c6875980eee9aa02e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "835f27d9b51f4f8fb65ff182f641e1a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87e1937a7429494da8fbd5a33d3d2907": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ad7c7143fdb43bebf8de7f375a1e23b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "836288481a0145f08ba0b86e7c88b209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d79c82965c914440bd6aab3b35889924",
              "IPY_MODEL_cb13c5426c6a4128b29897ddd57a2659",
              "IPY_MODEL_61e00284044745e7ae3b8c56fd7db8bb"
            ],
            "layout": "IPY_MODEL_571f4f427d994e7899fb3468626a8192"
          }
        },
        "d79c82965c914440bd6aab3b35889924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5f34ee07e514e5b84befe4f49c2c8a6",
            "placeholder": "​",
            "style": "IPY_MODEL_321a1b0c067e4db9969acc7f925b09ed",
            "value": "Downloading: 100%"
          }
        },
        "cb13c5426c6a4128b29897ddd57a2659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80053175f1394c22ba038687e5d1e3ce",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab1f8497e61b423583090d635a2008ae",
            "value": 2
          }
        },
        "61e00284044745e7ae3b8c56fd7db8bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c36a022f3a62478184178ab18218eb7e",
            "placeholder": "​",
            "style": "IPY_MODEL_bd3a7f6dd9184732b4fb2d793dc13d54",
            "value": " 2.00/2.00 [00:00&lt;00:00, 44.4B/s]"
          }
        },
        "571f4f427d994e7899fb3468626a8192": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5f34ee07e514e5b84befe4f49c2c8a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "321a1b0c067e4db9969acc7f925b09ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80053175f1394c22ba038687e5d1e3ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab1f8497e61b423583090d635a2008ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c36a022f3a62478184178ab18218eb7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd3a7f6dd9184732b4fb2d793dc13d54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce5870f4af7f46aa8b6ccdacbb40ab99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_300a04c7b06541fdb8f28e68e8fac945",
              "IPY_MODEL_d98695f08df24805b94d5ac8e3798d7d",
              "IPY_MODEL_30ceeedd27fe45008a9c0a7a46fa80bb"
            ],
            "layout": "IPY_MODEL_f868f81ae98d481593daee4a75a019d5"
          }
        },
        "300a04c7b06541fdb8f28e68e8fac945": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb65fe6e9dc54439ae1fadc37359f903",
            "placeholder": "​",
            "style": "IPY_MODEL_ca7e6a5e7a8e4e289dab4fed5b0563e2",
            "value": "Downloading: 100%"
          }
        },
        "d98695f08df24805b94d5ac8e3798d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbc7abab50ea43038b4c54bd4ff3d03a",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b37d5f037465446ba09e56241e213190",
            "value": 112
          }
        },
        "30ceeedd27fe45008a9c0a7a46fa80bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4a38134a8b144398722e7fd19ef4b90",
            "placeholder": "​",
            "style": "IPY_MODEL_de9c727f65b5425bbdce5769d0d74154",
            "value": " 112/112 [00:00&lt;00:00, 2.82kB/s]"
          }
        },
        "f868f81ae98d481593daee4a75a019d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb65fe6e9dc54439ae1fadc37359f903": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca7e6a5e7a8e4e289dab4fed5b0563e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbc7abab50ea43038b4c54bd4ff3d03a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b37d5f037465446ba09e56241e213190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4a38134a8b144398722e7fd19ef4b90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de9c727f65b5425bbdce5769d0d74154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be85449cf9c04dae94d8e1f92196455f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1cd5831793b8461989eb1385487fb539",
              "IPY_MODEL_05b43c624c59455d8899072ae342160e",
              "IPY_MODEL_74e4a789ce29487095b9683c99847e23"
            ],
            "layout": "IPY_MODEL_9b77df0998694fc0a8a777a9037f2f1c"
          }
        },
        "1cd5831793b8461989eb1385487fb539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2e9dd70cc01463e9514e1989c0a4018",
            "placeholder": "​",
            "style": "IPY_MODEL_fa0b41383ba440dca26771f6449f1b70",
            "value": "Downloading: 100%"
          }
        },
        "05b43c624c59455d8899072ae342160e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d548f3aeb6941a1bf877956d459ce89",
            "max": 155,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be9dd3c2978841cf86a5e9225505ad5b",
            "value": 155
          }
        },
        "74e4a789ce29487095b9683c99847e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ac3914963784333add2a970e9b48661",
            "placeholder": "​",
            "style": "IPY_MODEL_46687ef659664e8dbc4898a3f7f1ada4",
            "value": " 155/155 [00:00&lt;00:00, 3.94kB/s]"
          }
        },
        "9b77df0998694fc0a8a777a9037f2f1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2e9dd70cc01463e9514e1989c0a4018": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa0b41383ba440dca26771f6449f1b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d548f3aeb6941a1bf877956d459ce89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be9dd3c2978841cf86a5e9225505ad5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ac3914963784333add2a970e9b48661": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46687ef659664e8dbc4898a3f7f1ada4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19c3e6f63c2e4af199353664bd65c0f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a027623a696344e394d69db006dde71e",
              "IPY_MODEL_779883cae8e84f458b3ad0cc6652be26",
              "IPY_MODEL_b86717fb75e745aaa4c9ba1e92352e12"
            ],
            "layout": "IPY_MODEL_319a6f746c254df18fcea8adb7473dcb"
          }
        },
        "a027623a696344e394d69db006dde71e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8e2658a6ec543b596bef44d1adb24a2",
            "placeholder": "​",
            "style": "IPY_MODEL_c61b2ee0bffe4030bcfb7205a94ab7d0",
            "value": "Downloading: 100%"
          }
        },
        "779883cae8e84f458b3ad0cc6652be26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e35d8c0d40f8441da065ba5e02a5e53f",
            "max": 648,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_236e10c59ca741a1b1f45ab7b07f2823",
            "value": 648
          }
        },
        "b86717fb75e745aaa4c9ba1e92352e12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e2d3dcb610c49aba506715dc496556c",
            "placeholder": "​",
            "style": "IPY_MODEL_dda6ac973b15409f9fe82adce78c0fc9",
            "value": " 648/648 [00:00&lt;00:00, 10.7kB/s]"
          }
        },
        "319a6f746c254df18fcea8adb7473dcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8e2658a6ec543b596bef44d1adb24a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c61b2ee0bffe4030bcfb7205a94ab7d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e35d8c0d40f8441da065ba5e02a5e53f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "236e10c59ca741a1b1f45ab7b07f2823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e2d3dcb610c49aba506715dc496556c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dda6ac973b15409f9fe82adce78c0fc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01dc68c1feb842e9ba981b45af4b276f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c826a86ef8f543c0976aa6b8f6ec8092",
              "IPY_MODEL_42da8f08b1194084bf641daa13166eb9",
              "IPY_MODEL_138b6ea157954acfb1750f49a04f9273"
            ],
            "layout": "IPY_MODEL_01cca01327c5494eae391da83884dccb"
          }
        },
        "c826a86ef8f543c0976aa6b8f6ec8092": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e490bc1f15f54c8e87a656669d17af28",
            "placeholder": "​",
            "style": "IPY_MODEL_f72a4dbf991045fa82563e3c41fa403f",
            "value": "Downloading: 100%"
          }
        },
        "42da8f08b1194084bf641daa13166eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2da635452db40ebb26f3c70378e85d5",
            "max": 1342014951,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8baab4dfe9a74aaea8936328fa7f00e2",
            "value": 1342014951
          }
        },
        "138b6ea157954acfb1750f49a04f9273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f2d97924813453bae0e9830ec69a308",
            "placeholder": "​",
            "style": "IPY_MODEL_9415d86fc9b3405b977ece76dc6fcd05",
            "value": " 1.34G/1.34G [00:37&lt;00:00, 47.2MB/s]"
          }
        },
        "01cca01327c5494eae391da83884dccb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e490bc1f15f54c8e87a656669d17af28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f72a4dbf991045fa82563e3c41fa403f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2da635452db40ebb26f3c70378e85d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8baab4dfe9a74aaea8936328fa7f00e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f2d97924813453bae0e9830ec69a308": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9415d86fc9b3405b977ece76dc6fcd05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osmarbraz/exemplos_BERT/blob/main/ExemplosPrevisaoProximaPalavraBERT_pt_br.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78HE8FLsKN9Q"
      },
      "source": [
        "## Exemplo de Previsão da Próxima Palavra(pt-br) usando BERT Transformers by HuggingFace\n",
        "\n",
        "## **A execução pode ser feita através do menu Ambiente de Execução opção Executar tudo.**\n",
        "\n",
        "Exemplos de **Previsão da Próxima Palavra(pt-br)** usando **BERT** em uma sentença pelo mascaramento(\"[MASK]\") de palavras.\n",
        "\n",
        "**Link biblioteca Huggingface:**\n",
        "https://github.com/huggingface/transformers\n",
        "\n",
        "\n",
        "**Artigo original BERT Jacob Devlin:**\n",
        "https://arxiv.org/pdf/1506.06724.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyxb5Px3p1-e"
      },
      "source": [
        "# 0 - Preparação do ambiente\n",
        "Preparação do ambiente para execução do exemplo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAPVtRXQqDim"
      },
      "source": [
        "##Tratamento de logs\n",
        "\n",
        "Método para tratamento dos logs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcopxbGZqDip"
      },
      "source": [
        "# Biblioteca de logging\n",
        "import logging\n",
        "\n",
        "# Formatando a mensagem de logging\n",
        "logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GjYtXcMnSAe"
      },
      "source": [
        "## Identificando o ambiente Colab\n",
        "\n",
        "Cria uma variável para identificar que o notebook está sendo executado no Google Colaboratory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMiH0E3OnRa1"
      },
      "source": [
        "# Se estiver executando no Google Colaboratory\n",
        "import sys\n",
        "\n",
        "# Retorna true ou false se estiver no Google Colaboratory\n",
        "IN_COLAB = \"google.colab\" in sys.modules"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RufkKnojlwzu"
      },
      "source": [
        "## Instalação do spaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0LeiOTx0Dlk"
      },
      "source": [
        "https://spacy.io/\n",
        "\n",
        "Modelos do spaCy para português:\n",
        "https://spacy.io/models/pt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2Fvx0TVRQUw",
        "outputId": "9e942959-2811-4d9c-e225-2ee3890743cc"
      },
      "source": [
        "# Instala o spacy\n",
        "!pip install -U spacy==2.3.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spacy==2.3.5\n",
            "  Downloading spacy-2.3.5-cp37-cp37m-manylinux2014_x86_64.whl (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (1.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (3.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (0.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (1.21.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (0.7.8)\n",
            "Collecting srsly<1.1.0,>=1.0.2\n",
            "  Downloading srsly-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl (184 kB)\n",
            "\u001b[K     |████████████████████████████████| 184 kB 62.9 MB/s \n",
            "\u001b[?25hCollecting plac<1.2.0,>=0.9.6\n",
            "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Collecting catalogue<1.1.0,>=0.0.7\n",
            "  Downloading catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (2.0.6)\n",
            "Collecting thinc<7.5.0,>=7.4.1\n",
            "  Downloading thinc-7.4.5-cp37-cp37m-manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 64.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.3.5) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.5) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.5) (4.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (2.10)\n",
            "Installing collected packages: srsly, plac, catalogue, thinc, spacy\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 2.4.4\n",
            "    Uninstalling srsly-2.4.4:\n",
            "      Successfully uninstalled srsly-2.4.4\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 2.0.8\n",
            "    Uninstalling catalogue-2.0.8:\n",
            "      Successfully uninstalled catalogue-2.0.8\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.0\n",
            "    Uninstalling thinc-8.1.0:\n",
            "      Successfully uninstalled thinc-8.1.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.1\n",
            "    Uninstalling spacy-3.4.1:\n",
            "      Successfully uninstalled spacy-3.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.4.0 requires spacy<3.5.0,>=3.4.0, but you have spacy 2.3.5 which is incompatible.\u001b[0m\n",
            "Successfully installed catalogue-1.0.0 plac-1.1.3 spacy-2.3.5 srsly-1.0.5 thinc-7.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35GwcgkOlWi3"
      },
      "source": [
        "Realiza o download e carrega os modelos necessários a biblioteca\n",
        "\n",
        "https://spacy.io/models/pt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4LqE5kTwDYm"
      },
      "source": [
        "# Definição do nome do arquivo do modelo\n",
        "#ARQUIVOMODELO = \"pt_core_news_sm\"\n",
        "#ARQUIVOMODELO = \"pt_core_news_md\"\n",
        "ARQUIVOMODELO = \"pt_core_news_lg\"\n",
        "\n",
        "# Definição da versão da spaCy\n",
        "#VERSAOSPACY = \"-3.0.0a0\"\n",
        "VERSAOSPACY = \"-2.3.0\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ2KB3UCp-ws"
      },
      "source": [
        "#Baixa automaticamente o arquivo do modelo.\n",
        "#!python -m spacy download {ARQUIVOMODELO}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASk5iFeUp9LE",
        "outputId": "2e4c934a-adbc-44b9-b3e6-2f25739d8a73"
      },
      "source": [
        "# Realiza o download do arquivo do modelo para o diretório corrente\n",
        "!wget https://github.com/explosion/spacy-models/releases/download/{ARQUIVOMODELO}{VERSAOSPACY}/{ARQUIVOMODELO}{VERSAOSPACY}.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-08 23:51:12--  https://github.com/explosion/spacy-models/releases/download/pt_core_news_lg-2.3.0/pt_core_news_lg-2.3.0.tar.gz\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/84940268/a899e480-ab07-11ea-831b-b5aa9cc04510?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220808%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220808T235112Z&X-Amz-Expires=300&X-Amz-Signature=1ec391c82f0d44d9ba1c79ac1d2406474b4c206423de75a2fbb96f08557a201b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=84940268&response-content-disposition=attachment%3B%20filename%3Dpt_core_news_lg-2.3.0.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-08-08 23:51:12--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/84940268/a899e480-ab07-11ea-831b-b5aa9cc04510?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220808%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220808T235112Z&X-Amz-Expires=300&X-Amz-Signature=1ec391c82f0d44d9ba1c79ac1d2406474b4c206423de75a2fbb96f08557a201b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=84940268&response-content-disposition=attachment%3B%20filename%3Dpt_core_news_lg-2.3.0.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 576599832 (550M) [application/octet-stream]\n",
            "Saving to: ‘pt_core_news_lg-2.3.0.tar.gz’\n",
            "\n",
            "pt_core_news_lg-2.3 100%[===================>] 549.89M  27.3MB/s    in 20s     \n",
            "\n",
            "2022-08-08 23:51:32 (27.7 MB/s) - ‘pt_core_news_lg-2.3.0.tar.gz’ saved [576599832/576599832]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu_LkF7Nfm8_"
      },
      "source": [
        "Descompacta o arquivo do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9fCQQJGeVEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceb057c4-a3d5-4382-8ede-705c6313a161"
      },
      "source": [
        "# Descompacta o arquivo do modelo\n",
        "!tar -xvf  /content/{ARQUIVOMODELO}{VERSAOSPACY}.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pt_core_news_lg-2.3.0/\n",
            "pt_core_news_lg-2.3.0/PKG-INFO\n",
            "pt_core_news_lg-2.3.0/setup.py\n",
            "pt_core_news_lg-2.3.0/setup.cfg\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/dependency_links.txt\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/PKG-INFO\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/SOURCES.txt\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/requires.txt\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/top_level.txt\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/not-zip-safe\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/__init__.py\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/parser/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/parser/cfg\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/parser/moves\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/parser/model\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/ner/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/ner/cfg\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/ner/moves\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/ner/model\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tokenizer\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/lookups.bin\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/vectors\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/key2row\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/lookups_extra.bin\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/strings.json\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/accuracy.json\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tagger/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tagger/cfg\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tagger/tag_map\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tagger/model\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/meta.json\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/meta.json\n",
            "pt_core_news_lg-2.3.0/MANIFEST.in\n",
            "pt_core_news_lg-2.3.0/meta.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovOx-3Wb-JJW"
      },
      "source": [
        "# Coloca a pasta do modelo descompactado em uma pasta de nome mais simples\n",
        "!mv /content/{ARQUIVOMODELO}{VERSAOSPACY}/{ARQUIVOMODELO}/{ARQUIVOMODELO}{VERSAOSPACY} /content/{ARQUIVOMODELO}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STHT2c89qvwK"
      },
      "source": [
        "Carrega o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbELnrpgA4T1"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "import spacy\n",
        "\n",
        "CAMINHOMODELO = \"/content/\" + ARQUIVOMODELO\n",
        "\n",
        "#nlp = spacy.load(CAMINHOMODELO)\n",
        "# Necessário \"tagger\" para encontrar os substantivos\n",
        "nlp = spacy.load(CAMINHOMODELO, disable=[\"tokenizer\", \"lemmatizer\", \"ner\", \"parser\", \"textcat\", \"custom\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFTTdqxKQ1Ay"
      },
      "source": [
        "Recupera os stopwords do spaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBInu7ayQ31J"
      },
      "source": [
        "# Recupera as stop words\n",
        "spacy_stopwords = nlp.Defaults.stop_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_EYNu-_RX7k"
      },
      "source": [
        "Lista dos stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUSaUJEWRbnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e611560-fb05-419d-f058-20fc445b668c"
      },
      "source": [
        "print(\"Quantidade de stopwords:\", len(spacy_stopwords))\n",
        "\n",
        "print(spacy_stopwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade de stopwords: 413\n",
            "{'além', 'mês', 'naquela', 'deverá', 'debaixo', 'vos', 'depois', 'geral', 'porquê', 'tente', 'partir', 'faço', 'aí', 'terceiro', 'nas', 'tudo', 'estas', 'tuas', 'ao', 'pelas', 'porquanto', 'à', 'questão', 'conselho', 'ademais', 'ali', 'ele', 'por', 'dar', 'te', 'dezassete', 'próprio', 'agora', 'isto', 'tive', 'todo', 'favor', 'neste', 'vem', 'nessa', 'mil', 'esse', 'minha', 'sei', 'quando', 'dá', 'meus', 'portanto', 'cento', 'ou', 'nos', 'quero', 'fazem', 'todos', 'possivelmente', 'dessa', 'qual', 'pôde', 'pode', 'tão', 'grupo', 'quais', 'acerca', 'próximo', 'desse', 'novo', 'daquela', 'quem', 'disso', 'inclusive', 'tarde', 'iniciar', 'apontar', 'aquele', 'todas', 'nova', 'dezoito', 'contra', 'dos', 'dentro', 'relação', 'somente', 'alguns', 'obrigada', 'da', 'de', 'maior', 'segundo', 'bom', 'fui', 'nossas', 'pouco', 'falta', 'das', 'lhe', 'grande', 'ambos', 'último', 'tu', 'quinto', 'podem', 'meio', 'estivemos', 'no', 'vão', 'dois', 'estes', 'primeiro', 'vossas', 'estar', 'nível', 'mal', 'fazeis', 'vais', 'maioria', 'diante', 'quê', 'comprido', 'porém', 'baixo', 'umas', 'esteve', 'pouca', 'boa', 'nuns', 'poderá', 'aquela', 'mais', 'algo', 'naquele', 'tipo', 'aquilo', 'eventual', 'veja', 'é', 'quarto', 'sabe', 'quinze', 'uma', 'desde', 'do', 'algumas', 'vinte', 'dizem', 'quieta', 'tentar', 'apoia', 'dez', 'somos', 'dezasseis', 'estão', 'vosso', 'ambas', 'elas', 'parte', 'sexta', 'também', 'menor', 'cá', 'desta', 'era', 'parece', 'estou', 'só', 'longe', 'pois', 'nada', 'tivemos', 'aquelas', 'tal', 'és', 'fazer', 'nove', 'oitava', 'segunda', 'tentaram', 'vai', 'já', 'tenho', 'logo', 'teve', 'vezes', 'têm', 'seus', 'daquele', 'fomos', 'sois', 'isso', 'mas', 'pela', 'diz', 'usar', 'muito', 'seu', 'números', 'possível', 'se', 'você', 'sob', 'um', 'quanto', 'sétima', 'tendes', 'novas', 'não', 'eu', 'certamente', 'lá', 'conhecido', 'vêm', 'meu', 'onze', 'povo', 'forma', 'nesta', 'novos', 'até', 'coisa', 'quarta', 'qualquer', 'cuja', 'vindo', 'outra', 'maiorias', 'sempre', 'área', 'através', 'essa', 'dizer', 'cujo', 'toda', 'temos', 'zero', 'número', 'minhas', 'treze', 'querem', 'nunca', 'as', 'foram', 'assim', 'tais', 'posso', 'tiveste', 'ser', 'devem', 'essas', 'num', 'estava', 'vários', 'uns', 'então', 'fez', 'inicio', 'breve', 'onde', 'oito', 'em', 'lado', 'vinda', 'nossos', 'caminho', 'estiveste', 'às', 'terceira', 'vez', 'estiveram', 'atrás', 'seis', 'fazemos', 'ponto', 'ter', 'custa', 'eles', 'tivestes', 'tempo', 'sua', 'após', 'estás', 'demais', 'tanta', 'saber', 'catorze', 'aqueles', 'sexto', 'local', 'corrente', 'são', 'muitos', 'adeus', 'está', 'nós', 'tua', 'outras', 'máximo', 'puderam', 'apenas', 'estive', 'vós', 'valor', 'nem', 'primeira', 'foi', 'duas', 'cima', 'estará', 'os', 'exemplo', 'quer', 'irá', 'meses', 'esta', 'nesse', 'dão', 'poder', 'tentei', 'esses', 'ligado', 'tem', 'põem', 'vossos', 'tanto', 'porque', 'dezanove', 'usa', 'três', 'menos', 'sou', 'tiveram', 'ontem', 'fim', 'teu', 'quinta', 'ver', 'faz', 'pelo', 'fazes', 'podia', 'sete', 'estado', 'entre', 'quieto', 'ainda', 'sim', 'teus', 'para', 'embora', 'pegar', 'fora', 'lugar', 'pelos', 'talvez', 'como', 'tens', 'aqui', 'posição', 'nossa', 'comprida', 'doze', 'quatro', 'me', 'pontos', 'conhecida', 'oitavo', 'cada', 'estivestes', 'final', 'que', 'deste', 'fará', 'enquanto', 'certeza', 'na', 'outros', 'for', 'seria', 'grandes', 'direita', 'fazia', 'perto', 'cinco', 'cedo', 'ir', 'vens', 'foste', 'numa', 'deve', 'este', 'fostes', 'aos', 'momento', 'nenhuma', 'sobre', 'vossa', 'antes', 'com', 'apoio', 'ela', 'suas', 'obrigado', 'põe', 'nosso', 'ora', 'bastante', 'sem', 'contudo', 'sétimo', 'sistema', 'vocês', 'próxima', 'mesmo', 'bem', 'des'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqa-7WXBAw8q"
      },
      "source": [
        "## Instalação do BERT da Hugging Face"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCdqJCtQN52l"
      },
      "source": [
        "Instala a interface pytorch para o BERT by Hugging Face. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RfUN_KolV-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dff48e0-d837-4b00-8540-59fb98461e24"
      },
      "source": [
        "# Instala a última versão da biblioteca\n",
        "##!pip install transformers\n",
        "\n",
        "# Instala uma versão específica da biblioteca\n",
        "!pip install -U transformers==4.5.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.5.1\n",
            "  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 51.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (3.7.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2022.6.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 63.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.12.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.1) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=b84ddfa8bfcf9000e6920847582375c1aa9abed179c667c896f09960651149bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQj2wmKDpkrH"
      },
      "source": [
        "# 1 - Download do arquivo do PyTorch Checkpoint\n",
        "\n",
        "Lista de modelos da comunidade:\n",
        "* https://huggingface.co/models\n",
        "\n",
        "Português(https://github.com/neuralmind-ai/portuguese-bert):  \n",
        "* **\"neuralmind/bert-base-portuguese-cased\"**\n",
        "* **\"neuralmind/bert-large-portuguese-cased\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajrTjZzapkrK",
        "outputId": "07c95610-cc97-44d6-80cc-f52de930f226"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "import os\n",
        "\n",
        "# Variável para setar o arquivo\n",
        "URL_MODELO = None\n",
        "\n",
        "# Comente uma das urls para carregar modelos de tamanhos diferentes(base/large)\n",
        "# URL_MODELO do arquivo do modelo tensorflow\n",
        "# arquivo menor(base) 1.1 Gbytes\n",
        "#URL_MODELO = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "# arquivo grande(large) 3.5 Gbytes\n",
        "#URL_MODELO = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "# Se a variável foi setada\n",
        "if URL_MODELO:\n",
        "\n",
        "    # Diretório descompactação\n",
        "    DIRETORIO_MODELO = \"/content/modelo\"\n",
        "\n",
        "    # Recupera o nome do arquivo do modelo da URL_MODELO\n",
        "    arquivo = URL_MODELO.split(\"/\")[-1]\n",
        "\n",
        "    # Nome do arquivo do vocabulário\n",
        "    arquivo_vocab = \"vocab.txt\"\n",
        "\n",
        "    # Caminho do arquivo na URL_MODELO\n",
        "    caminho = URL_MODELO[0:len(URL_MODELO)-len(arquivo)]\n",
        "\n",
        "    # Verifica se a pasta de descompactação existe na pasta corrente\n",
        "    if os.path.exists(DIRETORIO_MODELO):\n",
        "      print(\"Apagando diretório existente do modelo!\")\n",
        "      # Apaga a pasta e os arquivos existentes\n",
        "      !rm -rf $DIRETORIO_MODELO      \n",
        "    \n",
        "    # Baixa o arquivo do modelo\n",
        "    !wget $URL_MODELO\n",
        "    # Descompacta o arquivo na pasta de descompactação\n",
        "    !unzip -o $arquivo -d $DIRETORIO_MODELO\n",
        "\n",
        "    # Baixa o arquivo do vocabulário\n",
        "    # O vocabulário não está no arquivo compactado acima, mesma url mas arquivo diferente\n",
        "    URL_MODELO_VOCAB = caminho + arquivo_vocab\n",
        "    !wget $URL_MODELO_VOCAB\n",
        "    \n",
        "    # Coloca o arquivo do vocabulário no diretório de descompactação\n",
        "    !mv $arquivo_vocab $DIRETORIO_MODELO\n",
        "            \n",
        "    # Move o arquivo para pasta de descompactação\n",
        "    !mv $arquivo $DIRETORIO_MODELO\n",
        "       \n",
        "    print(\"Pasta do \" + DIRETORIO_MODELO + \" pronta!\")\n",
        "    \n",
        "    # Lista a pasta corrente\n",
        "    !ls -la $DIRETORIO_MODELO\n",
        "else:\n",
        "    DIRETORIO_MODELO = None\n",
        "    print(\"Variável URL_MODELO não setada!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variável URL_MODELO não setada!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcpd9t9PpkrX"
      },
      "source": [
        "# 2 - Carregando o Tokenizador BERT\n",
        "\n",
        "O tokenizador utiliza WordPiece, veja em [artigo original](https://arxiv.org/pdf/1609.08144.pdf).\n",
        "\n",
        "Carregando o tokenizador da pasta \"/content/modelo/\" do diretório padrão se variável `URL_MODELO` setada.\n",
        "\n",
        "**Caso contrário carrega da comunidade**\n",
        "\n",
        "Por default(`do_lower_case=True`) todas as letras são colocadas para minúsculas. Para ignorar a conversão para minúsculo use o parâmetro `do_lower_case=False`. Esta opção também considera as letras acentuadas(ãçéí...), que são necessárias a língua portuguesa.\n",
        "\n",
        "O parâmetro `do_lower_case` interfere na quantidade tokens a ser gerado a partir de um documento. Quando igual a `False` reduz a quantidade de tokens gerados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "9df197c1a5b148328de07ce75f9d2551",
            "d55db668a4b64102919719085d8e26a1",
            "98c38bc9cac847718018aee5acb3f3ef",
            "cc1b4a9ab9b8434fab82d439d1323373",
            "fa38a0714ddc44e1b533bdaf9896e567",
            "01f29b15097143db9e56d4657545f283",
            "83ce180fc701491791598eaf34775782",
            "7c3e5ccdc24d41c6875980eee9aa02e5",
            "835f27d9b51f4f8fb65ff182f641e1a9",
            "87e1937a7429494da8fbd5a33d3d2907",
            "8ad7c7143fdb43bebf8de7f375a1e23b",
            "836288481a0145f08ba0b86e7c88b209",
            "d79c82965c914440bd6aab3b35889924",
            "cb13c5426c6a4128b29897ddd57a2659",
            "61e00284044745e7ae3b8c56fd7db8bb",
            "571f4f427d994e7899fb3468626a8192",
            "c5f34ee07e514e5b84befe4f49c2c8a6",
            "321a1b0c067e4db9969acc7f925b09ed",
            "80053175f1394c22ba038687e5d1e3ce",
            "ab1f8497e61b423583090d635a2008ae",
            "c36a022f3a62478184178ab18218eb7e",
            "bd3a7f6dd9184732b4fb2d793dc13d54",
            "ce5870f4af7f46aa8b6ccdacbb40ab99",
            "300a04c7b06541fdb8f28e68e8fac945",
            "d98695f08df24805b94d5ac8e3798d7d",
            "30ceeedd27fe45008a9c0a7a46fa80bb",
            "f868f81ae98d481593daee4a75a019d5",
            "fb65fe6e9dc54439ae1fadc37359f903",
            "ca7e6a5e7a8e4e289dab4fed5b0563e2",
            "cbc7abab50ea43038b4c54bd4ff3d03a",
            "b37d5f037465446ba09e56241e213190",
            "e4a38134a8b144398722e7fd19ef4b90",
            "de9c727f65b5425bbdce5769d0d74154",
            "be85449cf9c04dae94d8e1f92196455f",
            "1cd5831793b8461989eb1385487fb539",
            "05b43c624c59455d8899072ae342160e",
            "74e4a789ce29487095b9683c99847e23",
            "9b77df0998694fc0a8a777a9037f2f1c",
            "f2e9dd70cc01463e9514e1989c0a4018",
            "fa0b41383ba440dca26771f6449f1b70",
            "9d548f3aeb6941a1bf877956d459ce89",
            "be9dd3c2978841cf86a5e9225505ad5b",
            "7ac3914963784333add2a970e9b48661",
            "46687ef659664e8dbc4898a3f7f1ada4"
          ]
        },
        "id": "Z8cKVs4fpkrY",
        "outputId": "b474c3c4-d6a2-4931-c1ff-df49d539b09c"
      },
      "source": [
        "# Import das bibliotecas. do tokenizador\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Se a variável URL_MODELO foi setada\n",
        "if DIRETORIO_MODELO:\n",
        "    # Carregando o Tokenizador\n",
        "    print(\"Carrgando o tokenizador BERT do diretório \" + DIRETORIO_MODELO + \"...\")\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(DIRETORIO_MODELO, \n",
        "                                              do_lower_case=False)    \n",
        "else:\n",
        "    # Carregando o Tokenizador da comunidade\n",
        "    print(\"Carregando o tokenizador da comunidade...\")\n",
        "    \n",
        "    #tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\", do_lower_case=False)\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-large-portuguese-cased\", do_lower_case=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando o tokenizador da comunidade...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/210k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9df197c1a5b148328de07ce75f9d2551"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "836288481a0145f08ba0b86e7c88b209"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce5870f4af7f46aa8b6ccdacbb40ab99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/155 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be85449cf9c04dae94d8e1f92196455f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m__On2g1a--K"
      },
      "source": [
        "# 3 - Carregando o Modelo BERT(BertForMaskedLM)\n",
        "\n",
        "Se a variável `URL_MODELO` estiver setada carrega o modelo do diretório `content/modelo`.\n",
        "\n",
        "Caso contrário carrega da comunidade.\n",
        "\n",
        "Carregando o modelo da pasta \"/content/modelo/\" do diretório padrão.\n",
        "\n",
        "A implementação do huggingface pytorch inclui um conjunto de interfaces projetadas para uma variedade de tarefas de PNL. Embora essas interfaces sejam todas construídas sobre um modelo treinado de BERT, cada uma possui diferentes camadas superiores e tipos de saída projetados para acomodar suas tarefas específicas de PNL.\n",
        "\n",
        "A documentação para estas pode ser encontrada em [aqui](https://huggingface.co/transformers/model_doc/bert.html##bertformaskedlm).\n",
        "\n",
        "Por default o modelo está em modo avaliação ou seja `model.eval()`.\n",
        "\n",
        "-----------------------\n",
        "\n",
        "Durante a avaliação do modelo, este retorna um número de diferentes objetos com base em como é configurado na chamada do método `from_pretrained`. \n",
        "\n",
        "Quando definimos `output_hidden_states = True` na chamada do método `from_pretrained`, retorno do modelo possui no terceiro item os estados ocultos(**hidden_states**) de todas as camadas.  Veja a documentação para mais detalhes: https://huggingface.co/transformers/model_doc/bert.html##bertmodel\n",
        "\n",
        "Quando **`output_hidden_states = True`** model retorna:\n",
        "- outputs[0] = last_hidden_state;\n",
        "- outputs[1] = pooler_output; \n",
        "- outputs[2] = hidden_states.\n",
        "\n",
        "Quando **`output_hidden_states = False`** ou não especificado model retorna:\n",
        "- outputs[0] = last_hidden_state;\n",
        "- outputs[1] = pooler_output.\n",
        "\n",
        "\n",
        "**ATENÇÃO**: O parâmetro ´**output_hidden_states = True**´ habilita gerar as camadas ocultas do modelo. Caso contrário somente a última camada é mantida. Este parâmetro otimiza a memória mas não os resultados.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRV6l_I-qg9s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "19c3e6f63c2e4af199353664bd65c0f5",
            "a027623a696344e394d69db006dde71e",
            "779883cae8e84f458b3ad0cc6652be26",
            "b86717fb75e745aaa4c9ba1e92352e12",
            "319a6f746c254df18fcea8adb7473dcb",
            "f8e2658a6ec543b596bef44d1adb24a2",
            "c61b2ee0bffe4030bcfb7205a94ab7d0",
            "e35d8c0d40f8441da065ba5e02a5e53f",
            "236e10c59ca741a1b1f45ab7b07f2823",
            "1e2d3dcb610c49aba506715dc496556c",
            "dda6ac973b15409f9fe82adce78c0fc9",
            "01dc68c1feb842e9ba981b45af4b276f",
            "c826a86ef8f543c0976aa6b8f6ec8092",
            "42da8f08b1194084bf641daa13166eb9",
            "138b6ea157954acfb1750f49a04f9273",
            "01cca01327c5494eae391da83884dccb",
            "e490bc1f15f54c8e87a656669d17af28",
            "f72a4dbf991045fa82563e3c41fa403f",
            "a2da635452db40ebb26f3c70378e85d5",
            "8baab4dfe9a74aaea8936328fa7f00e2",
            "4f2d97924813453bae0e9830ec69a308",
            "9415d86fc9b3405b977ece76dc6fcd05"
          ]
        },
        "outputId": "695b042e-d76d-4959-9ee8-302f56ac05f9"
      },
      "source": [
        "# Import das bibliotecas. do Modelo\n",
        "from transformers import BertForMaskedLM\n",
        "\n",
        "# Se a variável URL_MODELO1 foi setada\n",
        "if URL_MODELO:\n",
        "    # Carregando o modelo\n",
        "    print(\"Carregando o modelo BERT do diretório \" + DIRETORIO_MODELO + \"...\")\n",
        "\n",
        "    model = BertForMaskedLM.from_pretrained(DIRETORIO_MODELO, \n",
        "                                      output_attentions = False,\n",
        "                                      output_hidden_states = True)    \n",
        "else:\n",
        "    # Carregando o modelo da comunidade\n",
        "    print(\"Carregando o modelo BERT da comunidade ...\")\n",
        "\n",
        "    model = BertForMaskedLM.from_pretrained(\"neuralmind/bert-large-portuguese-cased\", \n",
        "                                      output_attentions = False,\n",
        "                                      output_hidden_states = True)## 5 - Funções auxiliares"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando o modelo BERT da comunidade ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/648 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19c3e6f63c2e4af199353664bd65c0f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01dc68c1feb842e9ba981b45af4b276f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at neuralmind/bert-large-portuguese-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCQRC9fHAZQJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b551593d-5d9e-405f-cb5b-098630d9e506"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(29794, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=1024, out_features=29794, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CItBju3uAa8q"
      },
      "source": [
        "## model.to(\"cuda\")  ## Se tiver gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKicQ_TH_WxK"
      },
      "source": [
        "# 4 - Funções auxiliares\n",
        "\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## getPrevisaoPalavraSentenca"
      ],
      "metadata": {
        "id": "0VKoJQW4ksbz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqYOs576NPQ"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "import torch\n",
        "\n",
        "def getPrevisaoPalavraSentenca(documento, \n",
        "                               model, \n",
        "                               tokenizer, \n",
        "                               top_k_predicao=5):\n",
        "    \"\"\" \n",
        "      Retorna uma lista com as k previsões para a palavra mascarada no documento.\n",
        "          \n",
        "      Parâmetros:\n",
        "        `documento` - Documento mascarado.\n",
        "        `model`: um BertForMaskedLM\n",
        "        `tokenizer`: um tokenizador BERT\n",
        "        `top_k_predicao` - Quantidade de palavras a serem recuperadas mais próximas da máscara.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Adiciona os tokens especiais ao documento\n",
        "    documento_marcado = \"[CLS] \" + documento + \"[SEP]\"\n",
        "    ##print(\"documento_marcado:\", documento_marcado)\n",
        "\n",
        "    # Divide as palavras em tokens\n",
        "    documento_tokenizado = tokenizer.tokenize(documento_marcado)    \n",
        "    ##print(\"documento_tokenizado:\", documento_tokenizado)\n",
        "\n",
        "    # Retorna o índice da mascara de atenção\n",
        "    mascara_atencao_indice = documento_tokenizado.index(\"[MASK]\")\n",
        "    ##print(\"mascara_atencao_indice:\", mascara_atencao_indice)\n",
        "\n",
        "    # Mapeia os tokens em seus índices do vocabulário\n",
        "    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n",
        "    ##print(\"tokens_indexados:\", tokens_indexados)\n",
        "\n",
        "    # Define índices das sentenças A e B associados à 1ª e 2ª sentença \n",
        "    segmentos_ids = [0]*len(documento_tokenizado)\n",
        "    \n",
        "    # Converte as entradas de lista para tensores do torch\n",
        "    tokens_tensores = torch.tensor([tokens_indexados])\n",
        "    segmentos_tensores = torch.tensor([segmentos_ids])\n",
        "\n",
        "    # Se existe GPU disponível.\n",
        "    #if torch.cuda.is_available():  \n",
        "      # Se você tem uma GPU\n",
        "      #tokens_tensores = tokens_tensores.to('cuda')\n",
        "      #segmentos_tensores = segmentos_tensores.to('cuda')  \n",
        "    \n",
        "    # Realiza a predição dos tokens\n",
        "    with torch.no_grad():\n",
        "        ## Retorno de model quando ´output_hidden_states=True´ é setado:  \n",
        "        ##outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "        outputs = model(tokens_tensores, token_type_ids=segmentos_tensores)\n",
        "\n",
        "        ## A predição é recuperada dos embeddings da última camada oculta do modelo        \n",
        "        predicao = outputs[0]\n",
        "        \n",
        "    #print(\"shape:\", predicao.shape)\n",
        "    #print(\"mascara_atencao_indice:\", mascara_atencao_indice)\n",
        "\n",
        "    # Normaliza os pesos dos embeddings das predições e calcula sua probabilidade usando softmax.\n",
        "    probabilidades = torch.nn.functional.softmax(predicao[0, mascara_atencao_indice], dim=-1)    \n",
        "    # Probabilidade de cada uma das 29.794 palavras do vocabulário do BERT ser a palavra mascarada.\n",
        "    #print(\"Tamanho vocaculário:\", len(tokenizer.get_vocab())) #29.794\n",
        "    \n",
        "    # Retorna os k maiores elementos com as maiores probabilidades e sua posição(ordenada descrescentemente).\n",
        "    top_k_predicao_pesos, top_k_predicao_indices = torch.topk(probabilidades, top_k_predicao, sorted=True)\n",
        "    \n",
        "    # Converte os ids para os tokens do vocabulário\n",
        "    tokens_predicao = tokenizer.convert_ids_to_tokens([ind.item() for ind in top_k_predicao_indices])\n",
        "\n",
        "    # Retorna a predição e a probabilidade      \n",
        "    return list(zip(tokens_predicao, top_k_predicao_pesos))[:top_k_predicao]        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## getPredicaoTexto"
      ],
      "metadata": {
        "id": "_3thpDrr4EdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getPredicaoTexto(texto, model, tokenizer, topk=10):\n",
        "  \"\"\"\n",
        "    Encontra as melhores predições correspondentes para a palavra mascarada\n",
        "    \n",
        "    `model`: um BertForMaskedLM\n",
        "    `tokenizer`: um tokenizer Bert\n",
        "    `topK`: Número de predições para máscara\n",
        "\n",
        "    Retorna as predições e seus probabilidades\n",
        "  \"\"\"\n",
        "  # Prepara o texto\n",
        "  texto = '[CLS] '+ texto.lstrip('[CLS] ').rstrip(' [SEP]')+' [SEP]'\n",
        "  \n",
        "  # Tokeniza entrada\n",
        "  texto_tokenizado = tokenizer.tokenize(texto)\n",
        "\n",
        "  # Mascarara um token que tentaremos prever com `BertForMaskedLM`\n",
        "  masked_index = -1\n",
        "  for i, token in enumerate(texto_tokenizado):\n",
        "    if token=='[MASK]':\n",
        "      masked_index = i\n",
        "      break\n",
        "  assert i>=0\n",
        "\n",
        "  # Converte o token para um índice no vocabulário\n",
        "  indexed_tokens = tokenizer.convert_tokens_to_ids(texto_tokenizado)\n",
        "  # Definie índices das sentenças A e B associados à 1ª e 2ª sentença \n",
        "  segments_ids = [0]*len(texto_tokenizado)\n",
        "\n",
        "  # Converte as entradas em  tesores PyTorch\n",
        "  tokens_tensor = torch.tensor([indexed_tokens])\n",
        "  segments_tensors = torch.tensor([segments_ids])  \n",
        "\n",
        "  # Se você tem uma GPU\n",
        "  tokens_tensor = tokens_tensor.to('cuda')\n",
        "  segments_tensors = segments_tensors.to('cuda')  \n",
        "\n",
        "  # Predição dos tokens\n",
        "  with torch.no_grad():\n",
        "      outputs = model(tokens_tensor, token_type_ids=segments_tensors)\n",
        "      predictions = outputs[0]\n",
        "  \n",
        "  # print(\"Predictions shape: \" + str(predictions[0].shape))\n",
        "  predicted_inds = torch.argsort(-predictions[0, masked_index])\n",
        "  predicted_probs = [round(p.item(),4) for p in torch.softmax(predictions[0, masked_index], 0)[predicted_inds]]\n",
        "  predicted_tokens = tokenizer.convert_ids_to_tokens([ind.item() for ind in predicted_inds])\n",
        "  \n",
        "  return list(zip(predicted_tokens, predicted_probs))[:topk]"
      ],
      "metadata": {
        "id": "WOtEZ34t4Joi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## contaElemento"
      ],
      "metadata": {
        "id": "AbfqQZtfkuS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def contaElemento(lista, elemento):\n",
        "    \"\"\" \n",
        "      Conta o número de ocorrências do elemento na lista.\n",
        "          \n",
        "      Parâmetros:\n",
        "        `lista` - Lista com os elementos.\n",
        "        `elemento` - Elemento a ser contado a ocorrência na lista.\n",
        "\n",
        "      Retorno:    \n",
        "        `cont` - Quantidade de ocorrências de elmento na lista.\n",
        "    \"\"\"\n",
        "    cont = 0\n",
        "    # Percorre a lista\n",
        "    for i, linha in enumerate(lista):      \n",
        "      # Verifica se o elemento existe na lista\n",
        "      if linha in elemento:\n",
        "        # conta o elemento\n",
        "        cont = cont + 1\n",
        "    return cont"
      ],
      "metadata": {
        "id": "Dp9X6-3VN90o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## getSentencaMascarada"
      ],
      "metadata": {
        "id": "BaNNRNftk2Wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import das bibliotecas..\n",
        "from random import randint ## Biblioteca para o sorteio\n",
        "\n",
        "def getSentencaMascarada(sentenca, \n",
        "                         sentenca_token, \n",
        "                         sentenca_pos, \n",
        "                         classe=[\"VERB\",\"NOUN\",\"AUX\"], \n",
        "                         qtde=1):\n",
        "  \"\"\" \n",
        "      Gera a sentença mascarada com [MAKS] para usar com MLM do BERT.\n",
        "      Considera determinadas classes morfossintática das palavras e uma quantidade(qtde) de palavras a serem mascaradas.\n",
        "          \n",
        "      Parâmetros:\n",
        "        `sentenca` - Sentença a ser mascarada.\n",
        "        `sentenca_token` - Lista com os tokens da sentença.\n",
        "        `sentenca_pos` - Lista com as POS dos tokens da sentença.\n",
        "        `classe` - Lista com as classes morfossintática das palavras a serem mascarada com [MASK].\n",
        "        `qtde` - Quantidade de mascarada a serem realizadas nas palavras das sentenças.\n",
        "                 Seleciona aleatoriamente a(s) palavra(s) a ser(em) mascarada(s) se a qtde \n",
        "                 for menor que quantidade de palavras das classes na sentença.\n",
        "\n",
        "      Retorno:    \n",
        "        `sentenca_mascarada` - Sentença mascarada.\n",
        "        `palavra_mascarada` - Lista com as palavras substituidas pela máscara.\n",
        "\n",
        "  \"\"\"\n",
        "  sentenca_mascarada = \"\"\n",
        "  palavra_mascarada = \"\"\n",
        "\n",
        "  # Verifica a quantidade de trocas a ser realizada\n",
        "  if qtde != 0:\n",
        "\n",
        "    # Conta o número de palavras das classes especificadas\n",
        "    if len(classe) > 1:\n",
        "      # Se tem duas classes usa a primeira para contar se existe uma palavra\n",
        "      # Pega o primeiro para realizar a conta\n",
        "      classe_conta = [classe[0]]\n",
        "      conta_mascara = contaElemento(sentenca_pos, classe_conta)\n",
        "      \n",
        "      # Senão encontrar pega a segunda classe\n",
        "      if conta_mascara == 0:\n",
        "        # Pega a segunda classe\n",
        "        classe_conta = [classe[1]]\n",
        "        conta_mascara = contaElemento(sentenca_pos, classe_conta)\n",
        "\n",
        "        # Senão encontrar pega a terceira classe\n",
        "        if conta_mascara == 0:\n",
        "          ##Pega a terceira classe\n",
        "          classe_conta = [classe[2]]\n",
        "          conta_mascara = contaElemento(sentenca_pos, classe_conta) \n",
        "      \n",
        "      # Usa a classe para gerar a sentença mascarada\n",
        "      classe = classe_conta\n",
        "    else:\n",
        "      conta_mascara = contaElemento(sentenca_pos, classe)\n",
        "    \n",
        "    # Verifica se existe palavras das classes a serem mascaradas\n",
        "    if conta_mascara != 0:    \n",
        "      # Verifica a quantidade de trocas é menor que a quantidade palavras a serem trocadas encontradas\n",
        "      if qtde < conta_mascara:\n",
        "        # A quantidade de trocas é menor que a quantidade de palavras existentes\n",
        "        # Precisa sortear as posições que serão trocadas pela máscara dentro da quantidade\n",
        "               \n",
        "        roleta = []\n",
        "        # preenche a roleta com o indice das palavras as serem mscaradas\n",
        "        for i in range(conta_mascara):\n",
        "            roleta.append(i)\n",
        "\n",
        "        # Sorteia as posições das trocas\n",
        "        posicao = []\n",
        "        for i in range(qtde):\n",
        "            posicao_sorteio = randint(0, len(roleta)-1)\n",
        "            ## Guarda o número sorteado\n",
        "            posicao.append(roleta[posicao_sorteio])\n",
        "            ## Remove o elemento sorteado da roleta\n",
        "            del roleta[posicao_sorteio]\n",
        "        \n",
        "        # Conta o número das trocas realizadas\n",
        "        troca = 0\n",
        "\n",
        "        # Substitui o elemento pela máscara\n",
        "        for i, token in enumerate(sentenca_token):            \n",
        "            # Se a classe da palavra é a desejada\n",
        "            if sentenca_pos[i] in classe:\n",
        "                # Verifica se a troca deve ser realizada para a posição\n",
        "                if troca in posicao:      \n",
        "                  # Trocar palavra da classe por [MASK]\n",
        "                  sentenca_mascarada = sentenca_mascarada + \"[MASK]\" + \" \"    \n",
        "                  # Guarda a palavra que foi mascarada\n",
        "                  palavra_mascarada = token                                  \n",
        "                else:                  \n",
        "                  # Adiciona o token\n",
        "                  sentenca_mascarada = sentenca_mascarada + token + \" \"\n",
        "                # Avança para a próxima troca\n",
        "                troca = troca + 1\n",
        "            else:\n",
        "              # Adiciona o token\n",
        "                sentenca_mascarada = sentenca_mascarada + token + \" \"\n",
        "      else:        \n",
        "        # Trocar todas as palavras pela mascará, pois a quantidade\n",
        "        # de trocas é igual a quantidade de mascarás existentes na sentença\n",
        "\n",
        "        # Substitui o elemento da classe pela mascará\n",
        "        for i, token in enumerate(sentenca_token):\n",
        "            #print(token, sentenca_pos[i])        \n",
        "            # Se a classe da palavra é a desejada\n",
        "            if sentenca_pos[i] in classe:\n",
        "                # Trocar palavra da classe por [MASK]\n",
        "                sentenca_mascarada = sentenca_mascarada + \"[MASK]\" + \" \"    \n",
        "                # Guarda a palavra que foi mascarada\n",
        "                palavra_mascarada = token \n",
        "            else:\n",
        "                sentenca_mascarada = sentenca_mascarada + token + \" \"\n",
        "    else:\n",
        "      # Não existe palavras da classe especificada      \n",
        "      print(\"Não existe palavras da classe especificada.\")\n",
        "      sentenca_mascarada = sentenca    \n",
        "  else:\n",
        "    # Quantidade trocas igual a 0\n",
        "    print(\"Não foi especificado uma quantidade de trocas.\")\n",
        "    sentenca_mascarada = sentenca\n",
        "\n",
        "  # Retira o espaço em branco do início e fim da sentença\n",
        "  sentenca_mascarada = sentenca_mascarada.strip(\" \")\n",
        "\n",
        "  return sentenca_mascarada, palavra_mascarada"
      ],
      "metadata": {
        "id": "NQBCxLcqBsU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## getPerturbacaoPalavraSentencaAleatoria"
      ],
      "metadata": {
        "id": "BSTMmNMvk-8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import das bibliotecas\n",
        "import torch\n",
        "from random import randint ## Biblioteca para o sorteio\n",
        "\n",
        "def getPerturbacaoPalavraSentencaAleatoria(sentenca, \n",
        "                                           sentenca_token, \n",
        "                                           sentenca_pos, \n",
        "                                           classe=[\"VERB\",\"NOUN\",\"AUX\"], \n",
        "                                           qtde=1, \n",
        "                                           top_k_predicao = 500):\n",
        "    \"\"\" \n",
        "        Gera a palavras da perturbação da sentença com seleção aleatória entre as top_k predições.        \n",
        "        Considera determinadas classes morfossintática das palavras.\n",
        "            \n",
        "        Parâmetros:\n",
        "          `sentenca` - Sentença a ser mascarada.\n",
        "          `sentenca_token` - Lista com os tokens da sentença.\n",
        "          `sentenca_pos` - Lista com as POS dos tokens da sentença.\n",
        "          `classe` - Lista com as classes morfossintática das palavras a serem mascarada com [MASK].\n",
        "          `qtde` - Quantidade de mascarada a serem realizadas nas palavras das sentenças.\n",
        "                  Seleciona aleatoriamente a(s) palavra(s) a ser(em) mascarada(s) se a qtde \n",
        "                  for menor que quantidade de palavras das classes na sentença.          \n",
        "          `top_k_predicao` - Quantidade de palavras a serem recuperadas mais próximas da máscara.\n",
        "\n",
        "        Retorno:    \n",
        "          `sentenca_mascarada` - Sentença mascarada.\n",
        "          `palavra_mascarada` - Palavra substituídas pela máscara.\n",
        "          `token_predito` - Palavra prevista para a máscara.\n",
        "          `peso_predito` - Peso da palavra prevista.\n",
        "          `posicao_sorteio` - Posição da palavra prevista na lista de previsões.\n",
        "          `lista_previsoes` - Lista dos 'top_k_predicao' tokens preditos para a máscara.\n",
        "    \"\"\"\n",
        "\n",
        "    #print(\"Sentença original:\", sentenca)\n",
        "    sentenca_mascarada, palavra_mascarada = getSentencaMascarada(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde=1)\n",
        "    \n",
        "    # Adiciona os tokens especiais ao sentenca\n",
        "    sentenca_marcado = \"[CLS] \" + sentenca_mascarada + \"[SEP]\"\n",
        "    #print(\"sentenca_marcado:\", sentenca_marcado)\n",
        "\n",
        "    # Divide as palavras em tokens\n",
        "    sentenca_tokenizado = tokenizer.tokenize(sentenca_marcado)    \n",
        "    #print(\"sentenca_tokenizado:\", sentenca_tokenizado)\n",
        "\n",
        "    # Retorna o índice da mascara de atenção\n",
        "    mascara_atencao_indice = sentenca_tokenizado.index(\"[MASK]\")\n",
        "    #print(\"mascara_atencao_indice:\", mascara_atencao_indice)\n",
        "\n",
        "    # Mapeia os tokens em seus índices do vocabulário\n",
        "    tokens_indexados = tokenizer.convert_tokens_to_ids(sentenca_tokenizado)\n",
        "    #print(\"tokens_indexados:\", tokens_indexados)\n",
        "    \n",
        "    # Converte as entradas de lista para tensores do torch\n",
        "    tokens_tensores = torch.tensor([tokens_indexados])\n",
        "    \n",
        "    # Realiza a predição dos tokens\n",
        "    with torch.no_grad():\n",
        "        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n",
        "        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "        outputs = model(tokens_tensores)\n",
        "    \n",
        "    ## A predição é recuperada dos embeddings da última camada oculta do modelo        \n",
        "    predicao = outputs[0]\n",
        "\n",
        "    # Normaliza os pesos dos embeddings das predições e calcula sua probabilidade usando softmax.\n",
        "    probabilidades = torch.nn.functional.softmax(predicao[0, mascara_atencao_indice], dim=-1)  \n",
        "    # Probabilidade de cada uma das 29.794 palavras do vocabulário do BERT ser a palavra mascarada.  \n",
        "    #print(\"Tamanho vocaculário:\", len(tokenizer.get_vocab())) #29.794\n",
        "        \n",
        "    # Se existe mais de uma top_k_predição    \n",
        "    if top_k_predicao != 1:\n",
        "\n",
        "      # Retorna os k maiores elementos com as maiores probabilidades e sua posição(ordenada descrescentemente).\n",
        "      top_k_predicao_pesos, top_k_predicao_indices = torch.topk(probabilidades, top_k_predicao)\n",
        "      #print(\"top_k_predicao_pesos:\",top_k_predicao_pesos)\n",
        "      #print(\"top_k_predicao_indices:\",top_k_predicao_indices)\n",
        "      #print(\"len(top_k_predicao_indices):\",len(top_k_predicao_indices))\n",
        "\n",
        "      # Sorteia uma predição do intervalo\n",
        "      posicao_sorteio = randint(0, top_k_predicao-1)    \n",
        "      #print(\"posicao_sorteio:\",posicao_sorteio)\n",
        "\n",
        "      # Recupera as predições    \n",
        "      # Mapeia os índices do vocabulário para os seus tokens\n",
        "      token_predito = tokenizer.convert_ids_to_tokens([top_k_predicao_indices[posicao_sorteio]])[0]\n",
        "      # Recupera os pesos da predição\n",
        "      peso_predito = top_k_predicao_pesos[posicao_sorteio]\n",
        "      #print((posicao_sorteio+1), \"[MASK]: \", token_predito, \" | peso:\", float(peso_predito))\n",
        "           \n",
        "      # Se o token previsto for igual a palavra que foi substituída pela máscara ou desconhecida ([UNK]) sorteia outra palavra\n",
        "      while (palavra_mascarada.lower() == token_predito.lower()) or (token_predito == \"[UNK]\"):\n",
        "          # Sorteia uma predição do intervalo\n",
        "          posicao_sorteio = randint(0, top_k_predicao-1)    \n",
        "          #print(\"posicao_sorteio:\",posicao_sorteio)\n",
        "\n",
        "          # Recupera as predições    \n",
        "          # Mapeia os índices do vocabulário para os seus tokens\n",
        "          token_predito = tokenizer.convert_ids_to_tokens([top_k_predicao_indices[posicao_sorteio]])[0]\n",
        "          # Recupera os pesos da predição\n",
        "          peso_predito = top_k_predicao_pesos[posicao_sorteio]\n",
        "          #print((posicao_sorteio+1), \"[MASK]: \", token_predito, \" | peso:\", float(peso_predito))\n",
        "    \n",
        "    else:\n",
        "      # Se existe somente uma predição, esta não pode ser igual a palavra mascarada,\n",
        "      # portanto é necessário aumentar a quantidade de top_k predições para gerar uma predição diferente \n",
        "      # da palavra mascarada.\n",
        "              \n",
        "      # Recupera as top_k_predicao predições em ordem de orobabilidades\n",
        "      top_k_predicao_pesos, top_k_predicao_indices = torch.topk(probabilidades, top_k_predicao, sorted=True)\n",
        "      #print(\"top_k_predicao_pesos:\",top_k_predicao_pesos)\n",
        "      #print(\"top_k_predicao_indices:\",top_k_predicao_indices)\n",
        "      #print(\"len(top_k_predicao_indices):\",len(top_k_predicao_indices))\n",
        "\n",
        "      # Sorteia uma predição do intervalo\n",
        "      posicao_sorteio = randint(0, top_k_predicao-1)    \n",
        "      #print(\"posicao_sorteio:\",posicao_sorteio)\n",
        "\n",
        "      # Recupera as predições    \n",
        "      # Mapeia os índices do vocabulário para os seus tokens\n",
        "      token_predito = tokenizer.convert_ids_to_tokens([top_k_predicao_indices[posicao_sorteio]])[0]\n",
        "      # Recupera os pesos da predição\n",
        "      peso_predito = top_k_predicao_pesos[posicao_sorteio]\n",
        "      ##print((posicao_sorteio+1), \"[MASK]: \", token_predito, \" | probabilidade: {0:.2%}\".format(float(peso_predito)))\n",
        "      \n",
        "      # Se o token previsto for igual a palavra que foi substituída pela máscara ou desconhecida ([UNK]) sorteia outra palavra\n",
        "      while (palavra_mascarada.lower() == token_predito.lower()) or (token_predito == \"[UNK]\"):\n",
        "          \n",
        "          # Incrementa a quantidade de predições para pegar uma palavra diferente\n",
        "          top_k_predicao = top_k_predicao + 1\n",
        "\n",
        "          # Recupera as top_k_predicao + 1 predições em ordem de orobabilidades\n",
        "          top_k_predicao_pesos, top_k_predicao_indices = torch.topk(probabilidades, top_k_predicao, sorted=True)\n",
        "          #print(\"top_k_predicao_pesos:\",top_k_predicao_pesos)\n",
        "          #print(\"top_k_predicao_indices:\",top_k_predicao_indices)\n",
        "          #print(\"len(top_k_predicao_indices):\",len(top_k_predicao_indices))\n",
        "\n",
        "          # Sorteia uma predição do intervalo\n",
        "          posicao_sorteio = randint(0, top_k_predicao-1)    \n",
        "          #print(\"posicao_sorteio:\",posicao_sorteio)\n",
        "\n",
        "          # Recupera as predições    \n",
        "          # Mapeia os índices do vocabulário para os seus tokens\n",
        "          token_predito = tokenizer.convert_ids_to_tokens([top_k_predicao_indices[posicao_sorteio]])[0]\n",
        "          # Recupera os pesos da predição\n",
        "          peso_predito = top_k_predicao_pesos[posicao_sorteio]\n",
        "          #print((posicao_sorteio+1), \"[MASK]: \", token_predito, \" | peso:\", float(peso_predito))\n",
        "\n",
        "    if \"##\" in token_predito:      \n",
        "      # Remove \"##\" do token\n",
        "      token_predito = token_predito[2:]\n",
        "\n",
        "    # Lista das predições\n",
        "    lista_predicoes = []\n",
        "    for i, indicePredicao in enumerate(top_k_predicao_indices):\n",
        "        # Mapeia os índices do vocabulário para os seus tokens\n",
        "        token_predito1 = tokenizer.convert_ids_to_tokens([indicePredicao])[0]\n",
        "        peso_predito1 = top_k_predicao_pesos[i]\n",
        "        lista_predicoes.append([(i+1), token_predito1, float(peso_predito1)])        \n",
        "      \n",
        "    return sentenca_mascarada, palavra_mascarada, token_predito, peso_predito, posicao_sorteio, lista_predicoes"
      ],
      "metadata": {
        "id": "avC4NB2kk_Fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## getPerturbacaoSentencaAleatoria"
      ],
      "metadata": {
        "id": "lxtXFpKBlEa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getPerturbacaoSentencaAleatoria(sentenca, \n",
        "                                    sentenca_token, \n",
        "                                    sentenca_pos, \n",
        "                                    classe=[\"VERB\",\"NOUN\",\"AUX\"], \n",
        "                                    qtde=1, \n",
        "                                    top_k_predicao = 500):\n",
        "\n",
        "  \"\"\" \n",
        "      Gera a sentença com a perturbação com seleção aleatória da palavra perturbada.\n",
        "      Considera determinadas classes morfossintática das palavras.\n",
        "          \n",
        "      Parâmetros:\n",
        "        `sentenca` - Sentença a ser mascarada.\n",
        "        `sentenca_token` - Lista com os tokens da sentença.\n",
        "        `sentenca_pos` - Lista com as POS dos tokens da sentença.\n",
        "        `classe` - Lista com as classes morfossintática das palavras a serem mascarada com [MASK].\n",
        "        `qtde` - Quantidade de mascarada a serem realizadas nas palavras das sentenças.\n",
        "                Seleciona aleatoriamente a(s) palavra(s) a ser(em) mascarada(s) se a qtde \n",
        "                for menor que quantidade de palavras das classes na sentença.\n",
        "        `top_k_predicao` - Quantidade de palavras a serem recuperadas mais próximas da máscara.                \n",
        "\n",
        "      Retorno:    \n",
        "        `sentenca_perturbada` - Sentença com a perturbação.\n",
        "        `sentenca_mascarada` - Sentença mascarada.\n",
        "        `palavra_mascarada` - Palavra substituídas pela máscara.\n",
        "        `token_predito` - Palavra prevista para a máscara.\n",
        "        `lista_predicoes` - Lista dos tokens preditos para a máscara.\n",
        "        \n",
        "  \"\"\"\n",
        "\n",
        "  # Recupera a sentença mascarada e o token pervisto\n",
        "  sentenca_mascarada, palavra_mascarada, token_predito, peso_predito, posicao_sorteio, lista_predicoes = getPerturbacaoPalavraSentencaAleatoria(sentenca, sentenca_token, sentenca_pos, classe, qtde, top_k_predicao)\n",
        "  \n",
        "  # Se existir o token especial [MASK]\n",
        "  if \"[MASK]\" in sentenca_mascarada:\n",
        "    \n",
        "      # Substituir a mascará pelo token predito\n",
        "      sentenca_perturbada = sentenca_mascarada.replace(\"[MASK]\", token_predito)\n",
        "  \n",
        "  return sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, lista_predicoes"
      ],
      "metadata": {
        "id": "iTnWU0dQlEke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## getPerturbacaoPalavraSentencaSequencial"
      ],
      "metadata": {
        "id": "x25bKQWMSISt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import das bibliotecas\n",
        "import torch\n",
        "from random import randint ## Biblioteca para o sorteio\n",
        "\n",
        "def getPerturbacaoPalavraSentencaSequencial(sentenca, \n",
        "                                            sentenca_token, \n",
        "                                            sentenca_pos, \n",
        "                                            classe=[\"VERB\",\"NOUN\",\"AUX\"], \n",
        "                                            qtde=1, \n",
        "                                            top_k_predicao = 500):\n",
        "    \"\"\" \n",
        "        Gera a palavras da perturbação da sentença com seleção das top_k predições(em sequencia).        \n",
        "        Considera determinadas classes morfossintática das palavras.\n",
        "            \n",
        "        Parâmetros:\n",
        "          `sentenca` - Sentença a ser mascarada.\n",
        "          `sentenca_token` - Lista com os tokens da sentença.\n",
        "          `sentenca_pos` - Lista com as POS dos tokens da sentença.\n",
        "          `classe` - Lista com as classes morfossintática das palavras a serem mascarada com [MASK].\n",
        "          `qtde` - Quantidade de mascarada a serem realizadas nas palavras das sentenças.\n",
        "                  Seleciona aleatoriamente a(s) palavra(s) a ser(em) mascarada(s) se a qtde \n",
        "                  for menor que quantidade de palavras das classes na sentença.          \n",
        "          `top_k_predicao` - Quantidade de palavras a serem recuperadas mais próximas da máscara.\n",
        "\n",
        "        Retorno:    \n",
        "          `sentenca_mascarada` - Sentença mascarada.\n",
        "          `palavra_mascarada` - Palavra substituídas pela máscara.\n",
        "          `token_predito` - Palavra prevista para a máscara.\n",
        "          `peso_predito` - Peso da palavra prevista.\n",
        "          `lista_previsoes` - Lista dos 'top_k_predicao' tokens preditos para a máscara.\n",
        "    \"\"\"\n",
        "\n",
        "    #print(\"Sentença original:\", sentenca)\n",
        "    sentenca_mascarada, palavra_mascarada = getSentencaMascarada(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde=1)\n",
        "    \n",
        "    # Adiciona os tokens especiais ao sentenca\n",
        "    sentenca_marcado = \"[CLS] \" + sentenca_mascarada + \"[SEP]\"\n",
        "    #print(\"sentenca_marcado:\", sentenca_marcado)\n",
        "\n",
        "    # Divide as palavras em tokens\n",
        "    sentenca_tokenizado = tokenizer.tokenize(sentenca_marcado)    \n",
        "    #print(\"sentenca_tokenizado:\", sentenca_tokenizado)\n",
        "\n",
        "    # Retorna o índice da mascara de atenção\n",
        "    mascara_atencao_indice = sentenca_tokenizado.index(\"[MASK]\")\n",
        "    #print(\"mascara_atencao_indice:\", mascara_atencao_indice)\n",
        "\n",
        "    # Mapeia os tokens em seus índices do vocabulário\n",
        "    tokens_indexados = tokenizer.convert_tokens_to_ids(sentenca_tokenizado)\n",
        "    #print(\"tokens_indexados:\", tokens_indexados)\n",
        "    \n",
        "    # Converte as entradas de lista para tensores do torch\n",
        "    tokens_tensores = torch.tensor([tokens_indexados])\n",
        "    \n",
        "    # Realiza a predição dos tokens\n",
        "    with torch.no_grad():\n",
        "        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n",
        "        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "        outputs = model(tokens_tensores)\n",
        "    \n",
        "    ## A predição é recuperada dos embeddings da última camada oculta do modelo        \n",
        "    predicao = outputs[0]\n",
        "    \n",
        "    #print(\"shape:\", predicao.shape)\n",
        "    #print(\"mascara_atencao_indice:\", mascara_atencao_indice)\n",
        "\n",
        "    # Normaliza os pesos dos embeddings das predições e calcula sua probabilidade usando softmax.\n",
        "    probabilidades = torch.nn.functional.softmax(predicao[0, mascara_atencao_indice], dim=-1)    \n",
        "    # Probabilidade de cada uma das 29.794 palavras do vocabulário do BERT ser a palavra mascarada.\n",
        "    #print(\"Tamanho vocaculário:\", len(tokenizer.get_vocab())) #29.794\n",
        "    \n",
        "    # Retorna os k maiores elementos com as maiores probabilidades e sua posição(ordenada descrescentemente).\n",
        "    top_k_predicao_pesos, top_k_predicao_indices = torch.topk(probabilidades, top_k_predicao, sorted=True)\n",
        "        \n",
        "    # Recupera a 1a predição\n",
        "    posicao = 0\n",
        "    # Mapeia os índices do vocabulário para os seus tokens\n",
        "    token_predito = tokenizer.convert_ids_to_tokens([top_k_predicao_indices[posicao]])[0]\n",
        "    # Recupera os pesos da predição\n",
        "    peso_predito = top_k_predicao_pesos[posicao]\n",
        "    #print((posicao_sorteio+1), \"[MASK]: \", token_predito, \" | peso:\", float(peso_predito))\n",
        "\n",
        "    # Converte os ids para os tokens do vocabulário\n",
        "    tokens_predicao = tokenizer.convert_ids_to_tokens([ind.item() for ind in top_k_predicao_indices])\n",
        "\n",
        "    # Lista das predições\n",
        "    lista_predicoes = []\n",
        "    for i, indicePredicao in enumerate(top_k_predicao_indices):\n",
        "        # Mapeia os índices do vocabulário para os seus tokens\n",
        "        token_predito1 = tokenizer.convert_ids_to_tokens([indicePredicao])[0]\n",
        "        peso_predito1 = top_k_predicao_pesos[i]\n",
        "        lista_predicoes.append([(i+1), token_predito1, float(peso_predito1)])        \n",
        "      \n",
        "    return sentenca_mascarada, palavra_mascarada, token_predito, peso_predito, lista_predicoes"
      ],
      "metadata": {
        "id": "DLaRQqdUSISy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## getPerturbacaoSentencaSequencial"
      ],
      "metadata": {
        "id": "4NLImgKBRqIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getPerturbacaoSentencaSequencial(sentenca, \n",
        "                                     sentenca_token, \n",
        "                                     sentenca_pos, \n",
        "                                     classe=[\"VERB\",\"NOUN\",\"AUX\"], \n",
        "                                     qtde=1, \n",
        "                                     top_k_predicao = 500):\n",
        "\n",
        "  \"\"\" \n",
        "      Gera a sentença com a perturbação com seleção sequencial da palavra perturbada.\n",
        "      Considera determinadas classes morfossintática das palavras.\n",
        "          \n",
        "      Parâmetros:\n",
        "        `sentenca` - Sentença a ser mascarada.\n",
        "        `sentenca_token` - Lista com os tokens da sentença.\n",
        "        `sentenca_pos` - Lista com as POS dos tokens da sentença.\n",
        "        `classe` - Lista com as classes morfossintática das palavras a serem mascarada com [MASK].\n",
        "        `qtde` - Quantidade de mascarada a serem realizadas nas palavras das sentenças.\n",
        "                Seleciona aleatoriamente a(s) palavra(s) a ser(em) mascarada(s) se a qtde \n",
        "                for menor que quantidade de palavras das classes na sentença.\n",
        "        `top_k_predicao` - Quantidade de palavras a serem recuperadas mais próximas da máscara.                \n",
        "\n",
        "      Retorno:    \n",
        "        `sentenca_perturbada` - Sentença com a perturbação.\n",
        "        `sentenca_mascarada` - Sentença mascarada.\n",
        "        `palavra_mascarada` - Palavra substituídas pela máscara.\n",
        "        `token_predito` - Palavra prevista para a máscara.\n",
        "        `lista_predicoes` - Lista dos tokens preditos para a máscara.\n",
        "        \n",
        "  \"\"\"\n",
        "\n",
        "  # Recupera a sentença mascarada e o token pervisto\n",
        "  sentenca_mascarada, palavra_mascarada, token_predito, peso_predito, lista_predicoes = getPerturbacaoPalavraSentencaSequencial(sentenca, sentenca_token, sentenca_pos, classe, qtde, top_k_predicao)\n",
        "  \n",
        "  # Se existir o token especial [MASK]\n",
        "  if \"[MASK]\" in sentenca_mascarada:\n",
        "    \n",
        "      # Substituir a mascará pelo token predito\n",
        "      sentenca_perturbada = sentenca_mascarada.replace(\"[MASK]\", token_predito)\n",
        "  \n",
        "  return sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, lista_predicoes"
      ],
      "metadata": {
        "id": "6rlDRoxyRqIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru02mC0Estsb"
      },
      "source": [
        "# 5 - Exemplo MLM previsão da próxima palavra utilizando BERT\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZkpDPZF6K0x"
      },
      "source": [
        "## Exemplo 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentenca = \"O carro bateu no [MASK].\"\n",
        "\n",
        "predicao = getPrevisaoPalavraSentenca(sentenca, model, tokenizer, top_k_predicao=10)\n",
        "\n",
        "# Mostra as predições\n",
        "for i, pred in enumerate(predicao):  \n",
        "  print((i+1), \"[MASK]: \", pred[0], \" | probabilidade: {0:.2%}\".format(float(pred[1])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC7rhqw_PQl5",
        "outputId": "af60e2b1-328b-4730-c379-9f976c8b4e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 [MASK]:  muro  | probabilidade: 59.77%\n",
            "2 [MASK]:  caminhão  | probabilidade: 6.21%\n",
            "3 [MASK]:  chão  | probabilidade: 4.96%\n",
            "4 [MASK]:  outro  | probabilidade: 3.91%\n",
            "5 [MASK]:  solo  | probabilidade: 3.44%\n",
            "6 [MASK]:  ônibus  | probabilidade: 1.98%\n",
            "7 [MASK]:  portão  | probabilidade: 1.34%\n",
            "8 [MASK]:  buraco  | probabilidade: 1.02%\n",
            "9 [MASK]:  carro  | probabilidade: 0.91%\n",
            "10 [MASK]:  rio  | probabilidade: 0.72%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-dkydqHVBB4",
        "outputId": "913481bd-c067-4d3f-ca40-0f4e168bf938"
      },
      "source": [
        "sentenca = \"O dia está [MASK].\"\n",
        "\n",
        "predicao = getPrevisaoPalavraSentenca(sentenca, model, tokenizer, top_k_predicao=10)\n",
        "\n",
        "# Mostra as predições\n",
        "for i, pred in enumerate(predicao):  \n",
        "  print((i+1), \"[MASK]: \", pred[0], \" | probabilidade: {0:.2%}\".format(float(pred[1])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 [MASK]:  claro  | probabilidade: 18.80%\n",
            "2 [MASK]:  quente  | probabilidade: 10.01%\n",
            "3 [MASK]:  chegando  | probabilidade: 6.58%\n",
            "4 [MASK]:  escuro  | probabilidade: 5.24%\n",
            "5 [MASK]:  terminando  | probabilidade: 3.22%\n",
            "6 [MASK]:  bonito  | probabilidade: 3.18%\n",
            "7 [MASK]:  frio  | probabilidade: 2.94%\n",
            "8 [MASK]:  bom  | probabilidade: 2.76%\n",
            "9 [MASK]:  longo  | probabilidade: 2.30%\n",
            "10 [MASK]:  triste  | probabilidade: 1.94%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IBIDVR9_iaB"
      },
      "source": [
        "## Exemplo 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kdo1kx3-C4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f9b482-0ecc-496a-805c-ba00c59e485a"
      },
      "source": [
        "sentenca = \"O que é uma pilha e como [MASK] seu elemento?\"\n",
        "\n",
        "predicao = getPrevisaoPalavraSentenca(sentenca, model, tokenizer, top_k_predicao=10)\n",
        "\n",
        "# Mostra as predições\n",
        "for i, pred in enumerate(predicao):  \n",
        "  print((i+1), \"[MASK]: \", pred[0], \" | probabilidade: {0:.2%}\".format(float(pred[1])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 [MASK]:  identificar  | probabilidade: 26.45%\n",
            "2 [MASK]:  funciona  | probabilidade: 11.15%\n",
            "3 [MASK]:  localizar  | probabilidade: 4.56%\n",
            "4 [MASK]:  é  | probabilidade: 4.06%\n",
            "5 [MASK]:  encontrar  | probabilidade: 3.45%\n",
            "6 [MASK]:  classificar  | probabilidade: 2.99%\n",
            "7 [MASK]:  calcular  | probabilidade: 2.92%\n",
            "8 [MASK]:  medir  | probabilidade: 2.67%\n",
            "9 [MASK]:  utilizar  | probabilidade: 2.56%\n",
            "10 [MASK]:  usar  | probabilidade: 2.16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPDz-9aT_k9Q"
      },
      "source": [
        "## Exemplo 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-5TNrWZ-6Gg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90f6d818-2f33-461a-a4c6-7abee78b0a06"
      },
      "source": [
        "sentenca = \"O que é uma [MASK] e como enfileirar seu elemento?\"\n",
        "\n",
        "predicao = getPrevisaoPalavraSentenca(sentenca, model, tokenizer, top_k_predicao=10)\n",
        "\n",
        "# Mostra as predições\n",
        "for i, pred in enumerate(predicao):  \n",
        "  print((i+1), \"[MASK]: \", pred[0], \" | probabilidade: {0:.2%}\".format(float(pred[1])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 [MASK]:  árvore  | probabilidade: 16.92%\n",
            "2 [MASK]:  casa  | probabilidade: 4.47%\n",
            "3 [MASK]:  pilha  | probabilidade: 4.05%\n",
            "4 [MASK]:  planta  | probabilidade: 3.88%\n",
            "5 [MASK]:  coleção  | probabilidade: 3.74%\n",
            "6 [MASK]:  biblioteca  | probabilidade: 3.25%\n",
            "7 [MASK]:  flor  | probabilidade: 2.50%\n",
            "8 [MASK]:  mesa  | probabilidade: 2.05%\n",
            "9 [MASK]:  fonte  | probabilidade: 1.90%\n",
            "10 [MASK]:  caixa  | probabilidade: 1.88%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GylSCDQIVO7m"
      },
      "source": [
        "## Exemplo 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXgHNxJvVKK-",
        "outputId": "eb4193e6-c0bc-49ba-e2ef-7d92698484ad"
      },
      "source": [
        "sentenca = \"O que é uma [MASK] e como empilhar seu elemento?\"\n",
        "\n",
        "predicao = getPrevisaoPalavraSentenca(sentenca, model, tokenizer, top_k_predicao=10)\n",
        "\n",
        "# Mostra as predições\n",
        "for i, pred in enumerate(predicao):  \n",
        "  print((i+1), \"[MASK]: \", pred[0], \" | probabilidade: {0:.2%}\".format(float(pred[1])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 [MASK]:  árvore  | probabilidade: 13.57%\n",
            "2 [MASK]:  pilha  | probabilidade: 10.91%\n",
            "3 [MASK]:  caixa  | probabilidade: 3.56%\n",
            "4 [MASK]:  coleção  | probabilidade: 3.33%\n",
            "5 [MASK]:  pirâmide  | probabilidade: 2.64%\n",
            "6 [MASK]:  biblioteca  | probabilidade: 2.59%\n",
            "7 [MASK]:  casa  | probabilidade: 2.31%\n",
            "8 [MASK]:  estrutura  | probabilidade: 2.24%\n",
            "9 [MASK]:  planta  | probabilidade: 2.00%\n",
            "10 [MASK]:  mina  | probabilidade: 1.74%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 - Exemplo MLM gerando sentença perturbada com seleção aleatória entre top k predições utilizando BERT"
      ],
      "metadata": {
        "id": "_4wusjUqjuT1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top 1 predições"
      ],
      "metadata": {
        "id": "qiW3DZi_IjsS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 1\n",
        "\n",
        "Sentença 1 verbo(VERB)"
      ],
      "metadata": {
        "id": "8AKxPS2GIjsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentenca = \"Como enfileirar elementos em uma fila?\"\n",
        "sentenca_token = ['Como', 'enfileirar', 'elementos', 'em', 'uma', 'fila', '?']\n",
        "sentenca_pos = ['SCONJ', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', 'PUNCT']\n",
        "\n",
        "sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, lista_predicoes = getPerturbacaoSentencaAleatoria(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde=1, top_k_predicao = 1)\n",
        "print(\"sentença Original  :\",sentenca)\n",
        "print(\"sentença Perturbada:\",sentenca_perturbada)\n",
        "print(\"sentença Mascarada :\",sentenca_mascarada)\n",
        "print(\"palavra Mascarada  :\",palavra_mascarada, \" substituída por: \", token_predito)\n",
        "print(\"lista predições    :\", len(lista_predicoes))\n",
        "for i, linha in enumerate(lista_predicoes):\n",
        "    print(\"     \",linha[0], linha[1], \"{0:.2%}\".format(float(linha[2])))\n",
        "          "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9de20ddd-ea46-49ff-b7a6-cbab8c250c1d",
        "id": "JePgl1N4Ijsm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentença Original  : Como enfileirar elementos em uma fila?\n",
            "sentença Perturbada: Como colocar elementos em uma fila ?\n",
            "sentença Mascarada : Como [MASK] elementos em uma fila ?\n",
            "palavra Mascarada  : enfileirar  substituída por:  colocar\n",
            "lista predições    : 1\n",
            "      1 colocar 19.63%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentenca = \"Como desenfileirar elementos em uma fila?\"\n",
        "sentenca_token = ['Como', 'desenfileirar', 'elementos', 'em', 'uma', 'fila', '?']\n",
        "sentenca_pos = ['SCONJ', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', 'PUNCT']\n",
        "\n",
        "sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, lista_predicoes = getPerturbacaoSentencaAleatoria(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde=1, top_k_predicao = 1)\n",
        "print(\"sentença Original  :\",sentenca)\n",
        "print(\"sentença Perturbada:\",sentenca_perturbada)\n",
        "print(\"sentença Mascarada :\",sentenca_mascarada)\n",
        "print(\"palavra Mascarada  :\",palavra_mascarada, \" substituída por: \", token_predito)\n",
        "print(\"lista predições    :\", len(lista_predicoes))\n",
        "for i, linha in enumerate(lista_predicoes):\n",
        "    print(\"     \",linha[0], linha[1], \"{0:.2%}\".format(float(linha[2])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c393839f-25e9-428c-9dda-a1484279917c",
        "id": "zq7LhNHxIjsn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentença Original  : Como desenfileirar elementos em uma fila?\n",
            "sentença Perturbada: Como colocar elementos em uma fila ?\n",
            "sentença Mascarada : Como [MASK] elementos em uma fila ?\n",
            "palavra Mascarada  : desenfileirar  substituída por:  colocar\n",
            "lista predições    : 1\n",
            "      1 colocar 19.63%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 2\n",
        "\n",
        "Sentença com dois verbos (VERB)"
      ],
      "metadata": {
        "id": "mkc5dWn7Ijsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentenca = \"Como empilhar e desempilhar elementos em uma estrutura de dados pilha?\"\n",
        "sentenca_token = ['Como', 'empilhar', 'e', 'desempilhar', 'elementos', 'em', 'uma', 'estrutura', 'de', 'dados', 'pilha', '?']\n",
        "sentenca_pos = ['SCONJ', 'VERB', 'CCONJ', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', 'NOUN', 'PUNCT']\n",
        "\n",
        "sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, lista_predicoes = getPerturbacaoSentencaAleatoria(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde=1, top_k_predicao = 1)\n",
        "print(\"sentença Original  :\",sentenca)\n",
        "print(\"sentença Perturbada:\",sentenca_perturbada)\n",
        "print(\"sentença Mascarada :\",sentenca_mascarada)\n",
        "print(\"palavra Mascarada  :\",palavra_mascarada, \" substituída por: \", token_predito)\n",
        "print(\"lista predições    :\", len(lista_predicoes))\n",
        "for i, linha in enumerate(lista_predicoes):\n",
        "    print(\"     \",linha[0], linha[1], \"{0:.2%}\".format(float(linha[2])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60825bb6-0c6b-4ac0-fc58-1f3324ca47db",
        "id": "GCC3XXSgIjsn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentença Original  : Como empilhar e desempilhar elementos em uma estrutura de dados pilha?\n",
            "sentença Perturbada: Como introduzir e desempilhar elementos em uma estrutura de dados pilha ?\n",
            "sentença Mascarada : Como [MASK] e desempilhar elementos em uma estrutura de dados pilha ?\n",
            "palavra Mascarada  : empilhar  substituída por:  introduzir\n",
            "lista predições    : 1\n",
            "      1 introduzir 16.96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 3\n",
        "\n",
        "Sentença com um substantivo(NOUN) e nenhum verbo(VERB)"
      ],
      "metadata": {
        "id": "EImgU84MIjso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentenca = \"Como desempilhar elementos em uma pilha?\"\n",
        "sentenca_token = ['Como', 'desempilhar', 'elementos', 'em', 'uma', 'pilha', '?']\n",
        "sentenca_pos = ['ADP', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN', 'PUNCT']\n",
        "\n",
        "sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, lista_predicoes = getPerturbacaoSentencaAleatoria(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde=1, top_k_predicao = 1)\n",
        "print(\"sentença Original  :\",sentenca)\n",
        "print(\"sentença Perturbada:\",sentenca_perturbada)\n",
        "print(\"sentença Mascarada :\",sentenca_mascarada)\n",
        "print(\"palavra Mascarada  :\",palavra_mascarada, \" substituída por: \", token_predito)\n",
        "print(\"lista predições    :\", len(lista_predicoes))\n",
        "for i, linha in enumerate(lista_predicoes):\n",
        "    print(\"     \",linha[0], linha[1], \"{0:.2%}\".format(float(linha[2])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6debb385-f6d8-41f9-f515-3428bae94eca",
        "id": "tBLhsMsWIjso"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentença Original  : Como desempilhar elementos em uma pilha?\n",
            "sentença Perturbada: Como desempilhar água em uma pilha ?\n",
            "sentença Mascarada : Como desempilhar [MASK] em uma pilha ?\n",
            "palavra Mascarada  : elementos  substituída por:  água\n",
            "lista predições    : 1\n",
            "      1 água 5.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 4\n",
        "\n",
        "Sentença com um verbo(AUX) e nenhum substantivo(NOUN) e verbo(VERB)"
      ],
      "metadata": {
        "id": "LjlEsCbmIjso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Questão do FAQUAD\n",
        "sentenca = \"Em que a máquina de Hollerith foi pioneira?\"\n",
        "sentenca_token = ['Em', 'que', 'a', 'máquina', 'de', 'Hollerith', 'foi', 'pioneira', '?']\n",
        "sentenca_pos = ['ADP', 'PRON', 'DET', 'PROPN', 'ADP', 'PROPN', 'AUX', 'ADJ', 'PUNCT']\n",
        "\n",
        "sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, lista_predicoes = getPerturbacaoSentencaAleatoria(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde=1, top_k_predicao = 1)\n",
        "print(\"sentença Original  :\",sentenca)\n",
        "print(\"sentença Perturbada:\",sentenca_perturbada)\n",
        "print(\"sentença Mascarada :\",sentenca_mascarada)\n",
        "print(\"palavra Mascarada  :\",palavra_mascarada, \" substituída por: \", token_predito)\n",
        "print(\"lista predições    :\", len(lista_predicoes))\n",
        "for i, linha in enumerate(lista_predicoes):\n",
        "    print(\"     \",linha[0], linha[1], \"{0:.2%}\".format(float(linha[2])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ec8835-931d-44e4-95c4-e061ed67cea9",
        "id": "ze-1PL6AIjso"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentença Original  : Em que a máquina de Hollerith foi pioneira?\n",
            "sentença Perturbada: Em que a máquina de Hollerith é pioneira ?\n",
            "sentença Mascarada : Em que a máquina de Hollerith [MASK] pioneira ?\n",
            "palavra Mascarada  : foi  substituída por:  é\n",
            "lista predições    : 2\n",
            "      1 foi 75.35%\n",
            "      2 é 20.04%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top 10 predições"
      ],
      "metadata": {
        "id": "wq-AfUwlIXfX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 1\n",
        "\n",
        "Sentença 1 verbo(VERB)"
      ],
      "metadata": {
        "id": "uViR1is6IXfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentenca = \"Como enfileirar elementos em uma fila?\"\n",
        "sentenca_token = ['Como', 'enfileirar', 'elementos', 'em', 'uma', 'fila', '?']\n",
        "sentenca_pos = ['SCONJ', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', 'PUNCT']\n",
        "\n",
        "sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, lista_predicoes = getPerturbacaoSentencaAleatoria(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde=1, top_k_predicao = 10)\n",
        "print(\"sentença Original  :\",sentenca)\n",
        "print(\"sentença Perturbada:\",sentenca_perturbada)\n",
        "print(\"sentença Mascarada :\",sentenca_mascarada)\n",
        "print(\"palavra Mascarada  :\",palavra_mascarada, \" substituída por: \", token_predito)\n",
        "print(\"lista predições    :\", len(lista_predicoes))\n",
        "for i, linha in enumerate(lista_predicoes):\n",
        "    print(\"     \",linha[0], linha[1], \"{0:.2%}\".format(float(linha[2])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14f3ee6d-91ac-4ec2-aa34-878b24820ce2",
        "id": "np75hINUIXfp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentença Original  : Como enfileirar elementos em uma fila?\n",
            "sentença Perturbada: Como colocar elementos em uma fila ?\n",
            "sentença Mascarada : Como [MASK] elementos em uma fila ?\n",
            "palavra Mascarada  : enfileirar  substituída por:  colocar\n",
            "lista predições    : 10\n",
            "      1 colocar 19.63%\n",
            "      2 identificar 8.33%\n",
            "      3 encontrar 7.72%\n",
            "      4 adicionar 6.45%\n",
            "      5 organizar 4.34%\n",
            "      6 localizar 2.55%\n",
            "      7 classificar 2.26%\n",
            "      8 conseguir 1.62%\n",
            "      9 achar 1.48%\n",
            "      10 ver 1.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentenca = \"Como desenfileirar elementos em uma fila?\"\n",
        "sentenca_token = ['Como', 'desenfileirar', 'elementos', 'em', 'uma', 'fila', '?']\n",
        "sentenca_pos = ['SCONJ', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', 'PUNCT']\n",
        "\n",
        "sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, lista_predicoes = getPerturbacaoSentencaAleatoria(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde=1, top_k_predicao = 10)\n",
        "print(\"sentença Original  :\",sentenca)\n",
        "print(\"sentença Perturbada:\",sentenca_perturbada)\n",
        "print(\"sentença Mascarada :\",sentenca_mascarada)\n",
        "print(\"palavra Mascarada  :\",palavra_mascarada, \" substituída por: \", token_predito)\n",
        "print(\"lista predições    :\", len(lista_predicoes))\n",
        "for i, linha in enumerate(lista_predicoes):\n",
        "    print(\"     \",linha[0], linha[1], \"{0:.2%}\".format(float(linha[2])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54898665-a3ed-4a46-ddd8-f16b030649ba",
        "id": "RQ2qaUyXIXfq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentença Original  : Como desenfileirar elementos em uma fila?\n",
            "sentença Perturbada: Como conseguir elementos em uma fila ?\n",
            "sentença Mascarada : Como [MASK] elementos em uma fila ?\n",
            "palavra Mascarada  : desenfileirar  substituída por:  conseguir\n",
            "lista predições    : 10\n",
            "      1 colocar 19.63%\n",
            "      2 identificar 8.33%\n",
            "      3 encontrar 7.72%\n",
            "      4 adicionar 6.45%\n",
            "      5 organizar 4.34%\n",
            "      6 localizar 2.55%\n",
            "      7 classificar 2.26%\n",
            "      8 conseguir 1.62%\n",
            "      9 achar 1.48%\n",
            "      10 ver 1.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 2\n",
        "\n",
        "Sentença com dois verbos (VERB)"
      ],
      "metadata": {
        "id": "GUBt3NT_IXfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentenca = \"Como empilhar e desempilhar elementos em uma estrutura de dados pilha?\"\n",
        "sentenca_token = ['Como', 'empilhar', 'e', 'desempilhar', 'elementos', 'em', 'uma', 'estrutura', 'de', 'dados', 'pilha', '?']\n",
        "sentenca_pos = ['SCONJ', 'VERB', 'CCONJ', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', 'NOUN', 'PUNCT']\n",
        "\n",
        "sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, lista_predicoes = getPerturbacaoSentencaAleatoria(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde=1, top_k_predicao = 10)\n",
        "print(\"sentença Original  :\",sentenca)\n",
        "print(\"sentença Perturbada:\",sentenca_perturbada)\n",
        "print(\"sentença Mascarada :\",sentenca_mascarada)\n",
        "print(\"palavra Mascarada  :\",palavra_mascarada, \" substituída por: \", token_predito)\n",
        "print(\"lista predições    :\", len(lista_predicoes))\n",
        "for i, linha in enumerate(lista_predicoes):\n",
        "    print(\"     \",linha[0], linha[1], \"{0:.2%}\".format(float(linha[2])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a82db310-f215-47b9-f3af-08157614c4b8",
        "id": "of_yjakmIXfq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentença Original  : Como empilhar e desempilhar elementos em uma estrutura de dados pilha?\n",
            "sentença Perturbada: Como empilhar e mover elementos em uma estrutura de dados pilha ?\n",
            "sentença Mascarada : Como empilhar e [MASK] elementos em uma estrutura de dados pilha ?\n",
            "palavra Mascarada  : desempilhar  substituída por:  mover\n",
            "lista predições    : 10\n",
            "      1 organizar 37.04%\n",
            "      2 distribuir 5.52%\n",
            "      3 separar 4.06%\n",
            "      4 mover 3.52%\n",
            "      5 reunir 3.29%\n",
            "      6 classificar 3.16%\n",
            "      7 juntar 2.19%\n",
            "      8 localizar 1.98%\n",
            "      9 representar 1.76%\n",
            "      10 unir 1.57%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 3\n",
        "\n",
        "Sentença com um substantivo(NOUN) e nenhum verbo(VERB)"
      ],
      "metadata": {
        "id": "ka8hnA_EIXfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentenca = \"Como desempilhar elementos em uma pilha?\"\n",
        "sentenca_token = ['Como', 'desempilhar', 'elementos', 'em', 'uma', 'pilha', '?']\n",
        "sentenca_pos = ['ADP', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN', 'PUNCT']\n",
        "\n",
        "sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, lista_predicoes = getPerturbacaoSentencaAleatoria(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde=1, top_k_predicao = 10)\n",
        "print(\"sentença Original  :\",sentenca)\n",
        "print(\"sentença Perturbada:\",sentenca_perturbada)\n",
        "print(\"sentença Mascarada :\",sentenca_mascarada)\n",
        "print(\"palavra Mascarada  :\",palavra_mascarada, \" substituída por: \", token_predito)\n",
        "print(\"lista predições    :\", len(lista_predicoes))\n",
        "for i, linha in enumerate(lista_predicoes):\n",
        "    print(\"     \",linha[0], linha[1], \"{0:.2%}\".format(float(linha[2])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42c8ad55-9c1c-42cf-c604-b137b971b3ec",
        "id": "j5DV77CbIXfr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentença Original  : Como desempilhar elementos em uma pilha?\n",
            "sentença Perturbada: Como desempilhar elementos em uma construção ?\n",
            "sentença Mascarada : Como desempilhar elementos em uma [MASK] ?\n",
            "palavra Mascarada  : pilha  substituída por:  construção\n",
            "lista predições    : 10\n",
            "      1 imagem 6.41%\n",
            "      2 pintura 4.23%\n",
            "      3 construção 3.60%\n",
            "      4 composição 3.31%\n",
            "      5 peça 3.07%\n",
            "      6 fotografia 2.73%\n",
            "      7 cena 2.70%\n",
            "      8 caixa 2.57%\n",
            "      9 planta 2.26%\n",
            "      10 foto 2.04%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 4\n",
        "\n",
        "Sentença com um verbo(AUX) e nenhum substantivo(NOUN) e verbo(VERB)"
      ],
      "metadata": {
        "id": "y9KNZweQIXfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Questão do FAQUAD\n",
        "sentenca = \"Em que a máquina de Hollerith foi pioneira?\"\n",
        "sentenca_token = ['Em', 'que', 'a', 'máquina', 'de', 'Hollerith', 'foi', 'pioneira', '?']\n",
        "sentenca_pos = ['ADP', 'PRON', 'DET', 'PROPN', 'ADP', 'PROPN', 'AUX', 'ADJ', 'PUNCT']\n",
        "\n",
        "sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, lista_predicoes = getPerturbacaoSentencaAleatoria(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde=1, top_k_predicao = 10)\n",
        "print(\"sentença Original  :\",sentenca)\n",
        "print(\"sentença Perturbada:\",sentenca_perturbada)\n",
        "print(\"sentença Mascarada :\",sentenca_mascarada)\n",
        "print(\"palavra Mascarada  :\",palavra_mascarada, \" substituída por: \", token_predito)\n",
        "print(\"lista predições    :\", len(lista_predicoes))\n",
        "for i, linha in enumerate(lista_predicoes):\n",
        "    print(\"     \",linha[0], linha[1], \"{0:.2%}\".format(float(linha[2])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b628fa5-e61d-4807-e494-ec3d1a4bc45a",
        "id": "0kdaBJnqIXfs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentença Original  : Em que a máquina de Hollerith foi pioneira?\n",
            "sentença Perturbada: Em que a máquina de Hollerith será pioneira ?\n",
            "sentença Mascarada : Em que a máquina de Hollerith [MASK] pioneira ?\n",
            "palavra Mascarada  : foi  substituída por:  será\n",
            "lista predições    : 10\n",
            "      1 foi 75.35%\n",
            "      2 é 20.04%\n",
            "      3 era 2.49%\n",
            "      4 seria 1.39%\n",
            "      5 será 0.21%\n",
            "      6 fora 0.13%\n",
            "      7 parece 0.03%\n",
            "      8 ficou 0.02%\n",
            "      9 ser 0.02%\n",
            "      10 seja 0.02%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 - Exemplo MLM gerando sentença perturbada com seleção sequencial da predições utilizando BERT"
      ],
      "metadata": {
        "id": "zndrMK6FPLcc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top 1 predições"
      ],
      "metadata": {
        "id": "aMLVMfG4PLcc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 1\n",
        "\n",
        "Sentença 1 verbo(VERB)"
      ],
      "metadata": {
        "id": "9SUHJ8Z5PLcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentenca = \"Como enfileirar elementos em uma fila?\"\n",
        "sentenca_token = ['Como', 'enfileirar', 'elementos', 'em', 'uma', 'fila', '?']\n",
        "sentenca_pos = ['SCONJ', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', 'PUNCT']\n",
        "\n",
        "sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, lista_predicoes = getPerturbacaoSentencaSequencial(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde=1, top_k_predicao = 1)\n",
        "print(\"sentença Original  :\",sentenca)\n",
        "print(\"sentença Perturbada:\",sentenca_perturbada)\n",
        "print(\"sentença Mascarada :\",sentenca_mascarada)\n",
        "print(\"palavra Mascarada  :\",palavra_mascarada, \" substituída por: \", token_predito)\n",
        "print(\"lista predições    :\", len(lista_predicoes))\n",
        "for i, linha in enumerate(lista_predicoes):\n",
        "    print(\"     \",linha[0], linha[1], \"{0:.2%}\".format(float(linha[2])))\n",
        "          "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84527e53-718d-48f4-9641-a522da8b8edf",
        "id": "CuvufCVlPLcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentença Original  : Como enfileirar elementos em uma fila?\n",
            "sentença Perturbada: Como colocar elementos em uma fila ?\n",
            "sentença Mascarada : Como [MASK] elementos em uma fila ?\n",
            "palavra Mascarada  : enfileirar  substituída por:  colocar\n",
            "lista predições    : 1\n",
            "      1 colocar 19.63%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 2\n",
        "\n",
        "Sentença com dois verbos (VERB)"
      ],
      "metadata": {
        "id": "oI3FfgvkdxGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentenca = \"Como empilhar e desempilhar elementos em uma estrutura de dados pilha?\"\n",
        "sentenca_token = ['Como', 'empilhar', 'e', 'desempilhar', 'elementos', 'em', 'uma', 'estrutura', 'de', 'dados', 'pilha', '?']\n",
        "sentenca_pos = ['SCONJ', 'VERB', 'CCONJ', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', 'NOUN', 'PUNCT']\n",
        "\n",
        "sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, lista_predicoes = getPerturbacaoSentencaSequencial(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde=1, top_k_predicao = 1)\n",
        "print(\"sentença Original  :\",sentenca)\n",
        "print(\"sentença Perturbada:\",sentenca_perturbada)\n",
        "print(\"sentença Mascarada :\",sentenca_mascarada)\n",
        "print(\"palavra Mascarada  :\",palavra_mascarada, \" substituída por: \", token_predito)\n",
        "print(\"lista predições    :\", len(lista_predicoes))\n",
        "for i, linha in enumerate(lista_predicoes):\n",
        "    print(\"     \",linha[0], linha[1], \"{0:.2%}\".format(float(linha[2])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5a8a2c8-533e-471d-941c-0c91dc7ed661",
        "id": "C4tjTPuOdxGm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentença Original  : Como empilhar e desempilhar elementos em uma estrutura de dados pilha?\n",
            "sentença Perturbada: Como empilhar e organizar elementos em uma estrutura de dados pilha ?\n",
            "sentença Mascarada : Como empilhar e [MASK] elementos em uma estrutura de dados pilha ?\n",
            "palavra Mascarada  : desempilhar  substituída por:  organizar\n",
            "lista predições    : 1\n",
            "      1 organizar 37.04%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 3\n",
        "\n",
        "Sentença com um substantivo(NOUN) e nenhum verbo(VERB)"
      ],
      "metadata": {
        "id": "RMD-OLL9dxGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentenca = \"Como desempilhar elementos em uma pilha?\"\n",
        "sentenca_token = ['Como', 'desempilhar', 'elementos', 'em', 'uma', 'pilha', '?']\n",
        "sentenca_pos = ['ADP', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN', 'PUNCT']\n",
        "\n",
        "sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, lista_predicoes = getPerturbacaoSentencaSequencial(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde=1, top_k_predicao = 1)\n",
        "print(\"sentença Original  :\",sentenca)\n",
        "print(\"sentença Perturbada:\",sentenca_perturbada)\n",
        "print(\"sentença Mascarada :\",sentenca_mascarada)\n",
        "print(\"palavra Mascarada  :\",palavra_mascarada, \" substituída por: \", token_predito)\n",
        "print(\"lista predições    :\", len(lista_predicoes))\n",
        "for i, linha in enumerate(lista_predicoes):\n",
        "    print(\"     \",linha[0], linha[1], \"{0:.2%}\".format(float(linha[2])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3bcd7f1-fe11-4c22-a8ca-99c190a7196b",
        "id": "a8UBppzQdxGm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentença Original  : Como desempilhar elementos em uma pilha?\n",
            "sentença Perturbada: Como colocar elementos em uma pilha ?\n",
            "sentença Mascarada : Como [MASK] elementos em uma pilha ?\n",
            "palavra Mascarada  : desempilhar  substituída por:  colocar\n",
            "lista predições    : 1\n",
            "      1 colocar 17.93%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 4\n",
        "\n",
        "Sentença com um verbo(AUX) e nenhum substantivo(NOUN) e verbo(VERB)"
      ],
      "metadata": {
        "id": "B623ZdhsdxGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Questão do FAQUAD\n",
        "sentenca = \"Em que a máquina de Hollerith foi pioneira?\"\n",
        "sentenca_token = ['Em', 'que', 'a', 'máquina', 'de', 'Hollerith', 'foi', 'pioneira', '?']\n",
        "sentenca_pos = ['ADP', 'PRON', 'DET', 'PROPN', 'ADP', 'PROPN', 'AUX', 'ADJ', 'PUNCT']\n",
        "\n",
        "sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, lista_predicoes = getPerturbacaoSentencaSequencial(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde=1, top_k_predicao = 1)\n",
        "print(\"sentença Original  :\",sentenca)\n",
        "print(\"sentença Perturbada:\",sentenca_perturbada)\n",
        "print(\"sentença Mascarada :\",sentenca_mascarada)\n",
        "print(\"palavra Mascarada  :\",palavra_mascarada, \" substituída por: \", token_predito)\n",
        "print(\"lista predições    :\", len(lista_predicoes))\n",
        "for i, linha in enumerate(lista_predicoes):\n",
        "    print(\"     \",linha[0], linha[1], \"{0:.2%}\".format(float(linha[2])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73d223e6-d0c7-4b55-8c39-557ec07420d2",
        "id": "PN4nArUbdxGn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentença Original  : Em que a máquina de Hollerith foi pioneira?\n",
            "sentença Perturbada: Em que a máquina de Hollerith foi pioneira ?\n",
            "sentença Mascarada : Em que a máquina de Hollerith [MASK] pioneira ?\n",
            "palavra Mascarada  : foi  substituída por:  foi\n",
            "lista predições    : 1\n",
            "      1 foi 75.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top 10 predições"
      ],
      "metadata": {
        "id": "0hs_WOOad5f1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 1\n",
        "\n",
        "Sentença 1 verbo(VERB)"
      ],
      "metadata": {
        "id": "Uu5IP9ggd5f1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentenca = \"Como enfileirar elementos em uma fila?\"\n",
        "sentenca_token = ['Como', 'enfileirar', 'elementos', 'em', 'uma', 'fila', '?']\n",
        "sentenca_pos = ['SCONJ', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', 'PUNCT']\n",
        "\n",
        "sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, lista_predicoes = getPerturbacaoSentencaSequencial(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde=1, top_k_predicao = 10)\n",
        "print(\"sentença Original  :\",sentenca)\n",
        "print(\"sentença Perturbada:\",sentenca_perturbada)\n",
        "print(\"sentença Mascarada :\",sentenca_mascarada)\n",
        "print(\"palavra Mascarada  :\",palavra_mascarada, \" substituída por: \", token_predito)\n",
        "print(\"lista predições    :\", len(lista_predicoes))\n",
        "for i, linha in enumerate(lista_predicoes):\n",
        "    print(\"     \",linha[0], linha[1], \"{0:.2%}\".format(float(linha[2])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d08e78b8-0df2-4a98-b608-333f95a4b6b7",
        "id": "zUX0WHp9d5f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentença Original  : Como enfileirar elementos em uma fila?\n",
            "sentença Perturbada: Como colocar elementos em uma fila ?\n",
            "sentença Mascarada : Como [MASK] elementos em uma fila ?\n",
            "palavra Mascarada  : enfileirar  substituída por:  colocar\n",
            "lista predições    : 10\n",
            "      1 colocar 19.63%\n",
            "      2 identificar 8.33%\n",
            "      3 encontrar 7.72%\n",
            "      4 adicionar 6.45%\n",
            "      5 organizar 4.34%\n",
            "      6 localizar 2.55%\n",
            "      7 classificar 2.26%\n",
            "      8 conseguir 1.62%\n",
            "      9 achar 1.48%\n",
            "      10 ver 1.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentenca = \"Como desenfileirar elementos em uma fila?\"\n",
        "sentenca_token = ['Como', 'desenfileirar', 'elementos', 'em', 'uma', 'fila', '?']\n",
        "sentenca_pos = ['SCONJ', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', 'PUNCT']\n",
        "\n",
        "sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, lista_predicoes = getPerturbacaoSentencaSequencial(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde=1, top_k_predicao = 10)\n",
        "print(\"sentença Original  :\",sentenca)\n",
        "print(\"sentença Perturbada:\",sentenca_perturbada)\n",
        "print(\"sentença Mascarada :\",sentenca_mascarada)\n",
        "print(\"palavra Mascarada  :\",palavra_mascarada, \" substituída por: \", token_predito)\n",
        "print(\"lista predições    :\", len(lista_predicoes))\n",
        "for i, linha in enumerate(lista_predicoes):\n",
        "    print(\"     \",linha[0], linha[1], \"{0:.2%}\".format(float(linha[2])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ea4133-8448-4a3c-bc50-7a41d0212bb7",
        "id": "3V2nvS7Fd5f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentença Original  : Como desenfileirar elementos em uma fila?\n",
            "sentença Perturbada: Como colocar elementos em uma fila ?\n",
            "sentença Mascarada : Como [MASK] elementos em uma fila ?\n",
            "palavra Mascarada  : desenfileirar  substituída por:  colocar\n",
            "lista predições    : 10\n",
            "      1 colocar 19.63%\n",
            "      2 identificar 8.33%\n",
            "      3 encontrar 7.72%\n",
            "      4 adicionar 6.45%\n",
            "      5 organizar 4.34%\n",
            "      6 localizar 2.55%\n",
            "      7 classificar 2.26%\n",
            "      8 conseguir 1.62%\n",
            "      9 achar 1.48%\n",
            "      10 ver 1.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 2\n",
        "\n",
        "Sentença com dois verbos (VERB)"
      ],
      "metadata": {
        "id": "Of-fr6eOd5f2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentenca = \"Como empilhar e desempilhar elementos em uma estrutura de dados pilha?\"\n",
        "sentenca_token = ['Como', 'empilhar', 'e', 'desempilhar', 'elementos', 'em', 'uma', 'estrutura', 'de', 'dados', 'pilha', '?']\n",
        "sentenca_pos = ['SCONJ', 'VERB', 'CCONJ', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', 'NOUN', 'PUNCT']\n",
        "\n",
        "sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, lista_predicoes = getPerturbacaoSentencaSequencial(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde=1, top_k_predicao = 10)\n",
        "print(\"sentença Original  :\",sentenca)\n",
        "print(\"sentença Perturbada:\",sentenca_perturbada)\n",
        "print(\"sentença Mascarada :\",sentenca_mascarada)\n",
        "print(\"palavra Mascarada  :\",palavra_mascarada, \" substituída por: \", token_predito)\n",
        "print(\"lista predições    :\", len(lista_predicoes))\n",
        "for i, linha in enumerate(lista_predicoes):\n",
        "    print(\"     \",linha[0], linha[1], \"{0:.2%}\".format(float(linha[2])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79b54672-177b-49ad-fa2f-f556e51f08f3",
        "id": "9T7OKiW7d5f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentença Original  : Como empilhar e desempilhar elementos em uma estrutura de dados pilha?\n",
            "sentença Perturbada: Como empilhar e organizar elementos em uma estrutura de dados pilha ?\n",
            "sentença Mascarada : Como empilhar e [MASK] elementos em uma estrutura de dados pilha ?\n",
            "palavra Mascarada  : desempilhar  substituída por:  organizar\n",
            "lista predições    : 10\n",
            "      1 organizar 37.04%\n",
            "      2 distribuir 5.52%\n",
            "      3 separar 4.06%\n",
            "      4 mover 3.52%\n",
            "      5 reunir 3.29%\n",
            "      6 classificar 3.16%\n",
            "      7 juntar 2.19%\n",
            "      8 localizar 1.98%\n",
            "      9 representar 1.76%\n",
            "      10 unir 1.57%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 3\n",
        "\n",
        "Sentença com um substantivo(NOUN) e nenhum verbo(VERB)"
      ],
      "metadata": {
        "id": "VbfBQVCAd5f3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentenca = \"Como desempilhar elementos em uma pilha?\"\n",
        "sentenca_token = ['Como', 'desempilhar', 'elementos', 'em', 'uma', 'pilha', '?']\n",
        "sentenca_pos = ['ADP', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN', 'PUNCT']\n",
        "\n",
        "sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, lista_predicoes = getPerturbacaoSentencaSequencial(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde=1, top_k_predicao = 10)\n",
        "print(\"sentença Original  :\",sentenca)\n",
        "print(\"sentença Perturbada:\",sentenca_perturbada)\n",
        "print(\"sentença Mascarada :\",sentenca_mascarada)\n",
        "print(\"palavra Mascarada  :\",palavra_mascarada, \" substituída por: \", token_predito)\n",
        "print(\"lista predições    :\", len(lista_predicoes))\n",
        "for i, linha in enumerate(lista_predicoes):\n",
        "    print(\"     \",linha[0], linha[1], \"{0:.2%}\".format(float(linha[2])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65f4b1db-5c43-4ccd-c5c3-9b8600e42081",
        "id": "HFhBU7j5d5f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentença Original  : Como desempilhar elementos em uma pilha?\n",
            "sentença Perturbada: Como desempilhar elementos em uma imagem ?\n",
            "sentença Mascarada : Como desempilhar elementos em uma [MASK] ?\n",
            "palavra Mascarada  : pilha  substituída por:  imagem\n",
            "lista predições    : 10\n",
            "      1 imagem 6.41%\n",
            "      2 pintura 4.23%\n",
            "      3 construção 3.60%\n",
            "      4 composição 3.31%\n",
            "      5 peça 3.07%\n",
            "      6 fotografia 2.73%\n",
            "      7 cena 2.70%\n",
            "      8 caixa 2.57%\n",
            "      9 planta 2.26%\n",
            "      10 foto 2.04%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 4\n",
        "\n",
        "Sentença com um verbo(AUX) e nenhum substantivo(NOUN) e verbo(VERB)"
      ],
      "metadata": {
        "id": "vEqESGk_d5f5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Questão do FAQUAD\n",
        "sentenca = \"Em que a máquina de Hollerith foi pioneira?\"\n",
        "sentenca_token = ['Em', 'que', 'a', 'máquina', 'de', 'Hollerith', 'foi', 'pioneira', '?']\n",
        "sentenca_pos = ['ADP', 'PRON', 'DET', 'PROPN', 'ADP', 'PROPN', 'AUX', 'ADJ', 'PUNCT']\n",
        "\n",
        "sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, lista_predicoes = getPerturbacaoSentencaSequencial(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde=1, top_k_predicao = 10)\n",
        "print(\"sentença Original  :\",sentenca)\n",
        "print(\"sentença Perturbada:\",sentenca_perturbada)\n",
        "print(\"sentença Mascarada :\",sentenca_mascarada)\n",
        "print(\"palavra Mascarada  :\",palavra_mascarada, \" substituída por: \", token_predito)\n",
        "print(\"lista predições    :\", len(lista_predicoes))\n",
        "for i, linha in enumerate(lista_predicoes):\n",
        "    print(\"     \",linha[0], linha[1], \"{0:.2%}\".format(float(linha[2])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57954288-72c4-49e2-d8a1-bf1af9571de5",
        "id": "Sim32LL9d5f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentença Original  : Em que a máquina de Hollerith foi pioneira?\n",
            "sentença Perturbada: Em que a máquina de Hollerith foi pioneira ?\n",
            "sentença Mascarada : Em que a máquina de Hollerith [MASK] pioneira ?\n",
            "palavra Mascarada  : foi  substituída por:  foi\n",
            "lista predições    : 10\n",
            "      1 foi 75.35%\n",
            "      2 é 20.04%\n",
            "      3 era 2.49%\n",
            "      4 seria 1.39%\n",
            "      5 será 0.21%\n",
            "      6 fora 0.13%\n",
            "      7 parece 0.03%\n",
            "      8 ficou 0.02%\n",
            "      9 ser 0.02%\n",
            "      10 seja 0.02%\n"
          ]
        }
      ]
    }
  ]
}