{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExemplosVisualizacaoEmbeddingBERT_pt_br.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6f7787a6708245ef84a7e1162b9b9da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9be35067c781458889b1203af0bd0f13",
              "IPY_MODEL_89fa08586d7046c59b25a89754744078",
              "IPY_MODEL_747c92921c344f41a340752ce0ffc181"
            ],
            "layout": "IPY_MODEL_efd1f0d5744f436cb6a4cc594a38077e"
          }
        },
        "9be35067c781458889b1203af0bd0f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f369ea103e44a59b6ba16eb05314ed8",
            "placeholder": "​",
            "style": "IPY_MODEL_336d878fcfd8494888b3974a25b8b141",
            "value": "Downloading: 100%"
          }
        },
        "89fa08586d7046c59b25a89754744078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_334279c9b483492fae9cf6cbb2455b43",
            "max": 209528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_beed785495b448bb89b604e4d6eca036",
            "value": 209528
          }
        },
        "747c92921c344f41a340752ce0ffc181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d7568bed66a433a9622ada4d7599ea2",
            "placeholder": "​",
            "style": "IPY_MODEL_fc6931dc81c04546821c608cbb64ddfd",
            "value": " 210k/210k [00:00&lt;00:00, 1.42MB/s]"
          }
        },
        "efd1f0d5744f436cb6a4cc594a38077e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f369ea103e44a59b6ba16eb05314ed8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "336d878fcfd8494888b3974a25b8b141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "334279c9b483492fae9cf6cbb2455b43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beed785495b448bb89b604e4d6eca036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d7568bed66a433a9622ada4d7599ea2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc6931dc81c04546821c608cbb64ddfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b03c0654a587461ba3cceb0a699629ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5f5b653ee9a4372b6aa046ae367cef4",
              "IPY_MODEL_bb045b6d43d84a749c5ad3d91c386930",
              "IPY_MODEL_9ba528854ed948b8adf363376d049316"
            ],
            "layout": "IPY_MODEL_4fedfeef7ef94789a080be9dd23d9080"
          }
        },
        "e5f5b653ee9a4372b6aa046ae367cef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2d8e93c0e344ebaa6d4bd7c5de4c709",
            "placeholder": "​",
            "style": "IPY_MODEL_d02f3570b13444948fc0f2759c76236e",
            "value": "Downloading: 100%"
          }
        },
        "bb045b6d43d84a749c5ad3d91c386930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c23415d5d32462eb45308e3e394dd35",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6101ed8361e4ea69432afac1d057ff2",
            "value": 2
          }
        },
        "9ba528854ed948b8adf363376d049316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d7aeaede18445beaaa224d88de0eddb",
            "placeholder": "​",
            "style": "IPY_MODEL_6107faa838c34b0290d64497c47f68c2",
            "value": " 2.00/2.00 [00:00&lt;00:00, 35.0B/s]"
          }
        },
        "4fedfeef7ef94789a080be9dd23d9080": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2d8e93c0e344ebaa6d4bd7c5de4c709": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d02f3570b13444948fc0f2759c76236e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c23415d5d32462eb45308e3e394dd35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6101ed8361e4ea69432afac1d057ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d7aeaede18445beaaa224d88de0eddb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6107faa838c34b0290d64497c47f68c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a1974cc16234c95a19d2b2dace6cce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_795125a5d6074e8e97edd90a8b958fc2",
              "IPY_MODEL_b0a8a4b5b8e8448694d327b103cb3802",
              "IPY_MODEL_26ad841ce82f42c0a604072c11aa9571"
            ],
            "layout": "IPY_MODEL_2aada03893cb4b8ab0f15663b75c669d"
          }
        },
        "795125a5d6074e8e97edd90a8b958fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d4de51bf8124caca95b19ff0d9dbf8b",
            "placeholder": "​",
            "style": "IPY_MODEL_af68429748b74c8db2e8e233d62109cc",
            "value": "Downloading: 100%"
          }
        },
        "b0a8a4b5b8e8448694d327b103cb3802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_736c3042d95f428abcbbabc1410aa4a2",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc5f2778aa794574884c9ffc4bedf4dd",
            "value": 112
          }
        },
        "26ad841ce82f42c0a604072c11aa9571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_873d7281610c42818e451e8315aba768",
            "placeholder": "​",
            "style": "IPY_MODEL_966769d55aee4e6cb4eb7c7cbf06a844",
            "value": " 112/112 [00:00&lt;00:00, 2.58kB/s]"
          }
        },
        "2aada03893cb4b8ab0f15663b75c669d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d4de51bf8124caca95b19ff0d9dbf8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af68429748b74c8db2e8e233d62109cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "736c3042d95f428abcbbabc1410aa4a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc5f2778aa794574884c9ffc4bedf4dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "873d7281610c42818e451e8315aba768": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "966769d55aee4e6cb4eb7c7cbf06a844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf6bc5cf4725471eb937139f0c5597a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb6d07d6c28a44c88e31a3ca599500e8",
              "IPY_MODEL_61f1265857214fcc93833bbda557f802",
              "IPY_MODEL_e6296f193f60481082ed4f654ba27197"
            ],
            "layout": "IPY_MODEL_9d2dadd602744d0cbaa7df01956877e8"
          }
        },
        "bb6d07d6c28a44c88e31a3ca599500e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a20ac1f8755433ba2b5f3d958b09d79",
            "placeholder": "​",
            "style": "IPY_MODEL_4d50040b8573434e9a6e341aab96766c",
            "value": "Downloading: 100%"
          }
        },
        "61f1265857214fcc93833bbda557f802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3195e303e5424c8e8307803bf11aaec6",
            "max": 43,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_680ba6ad5baa4380a8689ffa1c77b616",
            "value": 43
          }
        },
        "e6296f193f60481082ed4f654ba27197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89625b11ccda4574ba966b26b8073cfa",
            "placeholder": "​",
            "style": "IPY_MODEL_dc90281b15f84a81b31b3453e0054d9a",
            "value": " 43.0/43.0 [00:00&lt;00:00, 1.14kB/s]"
          }
        },
        "9d2dadd602744d0cbaa7df01956877e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a20ac1f8755433ba2b5f3d958b09d79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d50040b8573434e9a6e341aab96766c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3195e303e5424c8e8307803bf11aaec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "680ba6ad5baa4380a8689ffa1c77b616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89625b11ccda4574ba966b26b8073cfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc90281b15f84a81b31b3453e0054d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc7190a078ba4830a3eefaba64ec5e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee460832ee9046e6928d47a41a82e80e",
              "IPY_MODEL_548c33dd28a94267a965e3a60f710c7b",
              "IPY_MODEL_b7cee2d7303f44b493566f1d97e6919b"
            ],
            "layout": "IPY_MODEL_738e20ca927c432f82c92e8102826b2d"
          }
        },
        "ee460832ee9046e6928d47a41a82e80e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e0a45474d9942558ba0852e02396aab",
            "placeholder": "​",
            "style": "IPY_MODEL_12d9047add6a4948a7c5608d0ed7a1e8",
            "value": "Downloading: 100%"
          }
        },
        "548c33dd28a94267a965e3a60f710c7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5adf4363405c43f793dff3c8e1b072e5",
            "max": 647,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_758869cbfc3d499788272731cb228ba7",
            "value": 647
          }
        },
        "b7cee2d7303f44b493566f1d97e6919b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbddf65003724258baeef431f77d3453",
            "placeholder": "​",
            "style": "IPY_MODEL_1c04189713544c5e8aca4eba1edec4df",
            "value": " 647/647 [00:00&lt;00:00, 11.4kB/s]"
          }
        },
        "738e20ca927c432f82c92e8102826b2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e0a45474d9942558ba0852e02396aab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12d9047add6a4948a7c5608d0ed7a1e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5adf4363405c43f793dff3c8e1b072e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "758869cbfc3d499788272731cb228ba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbddf65003724258baeef431f77d3453": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c04189713544c5e8aca4eba1edec4df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33b6d86cbe4143d1b275b3eb4f1e7ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be6364355d9d4743b431d1fee1bd4532",
              "IPY_MODEL_f1a6c478db9d4808b8670d9a565f8aa3",
              "IPY_MODEL_fb926d61fd5d4ec8a1aa3f8726c9b64d"
            ],
            "layout": "IPY_MODEL_7919ede5c0d342dc9353b820211ab0a3"
          }
        },
        "be6364355d9d4743b431d1fee1bd4532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48d3202edfb244bb92f4cd7bf6338c91",
            "placeholder": "​",
            "style": "IPY_MODEL_886b4534d02c49a2bf83257ef389dc40",
            "value": "Downloading: 100%"
          }
        },
        "f1a6c478db9d4808b8670d9a565f8aa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b061fd8215e945a89acd2da15e45cc47",
            "max": 438235074,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc78de5395e746a784608156c458cb1d",
            "value": 438235074
          }
        },
        "fb926d61fd5d4ec8a1aa3f8726c9b64d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23107f548f884b3ba726aba2cd166ac2",
            "placeholder": "​",
            "style": "IPY_MODEL_b010042403ae4e54bf02c90eba11c219",
            "value": " 438M/438M [00:10&lt;00:00, 45.3MB/s]"
          }
        },
        "7919ede5c0d342dc9353b820211ab0a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48d3202edfb244bb92f4cd7bf6338c91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "886b4534d02c49a2bf83257ef389dc40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b061fd8215e945a89acd2da15e45cc47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc78de5395e746a784608156c458cb1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23107f548f884b3ba726aba2cd166ac2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b010042403ae4e54bf02c90eba11c219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osmarbraz/exemplos_BERT/blob/main/ExemplosVisualizacaoEmbeddingBERT_pt_br.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78HE8FLsKN9Q"
      },
      "source": [
        "#Exemplo de Visualização de Embeddings usando BERT Transformers by HuggingFace e Embedding Projector.\n",
        "\n",
        "Exemplo de visualização: \n",
        "https://projector.tensorflow.org/?config=https://raw.githubusercontent.com/osmarbraz/cohebertv1visualizacao/main/config.json\n",
        "\n",
        "\n",
        "Repositório no github.\n",
        "https://github.com/osmarbraz/cohebertv1visualizacao\n",
        "\n",
        "\n",
        "---------------------------\n",
        "\n",
        "**Utiliza o *projeto embeddings* projector para exibir os dados:**\n",
        "https://projector.tensorflow.org/\n",
        "\n",
        "\n",
        "**Link biblioteca Huggingface:**\n",
        "https://github.com/huggingface/transformers\n",
        "\n",
        "\n",
        "**Artigo original BERT Jacob Devlin:**\n",
        "https://arxiv.org/pdf/1506.06724.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyxb5Px3p1-e"
      },
      "source": [
        "# 0 - Preparação do ambiente\n",
        "Preparação do ambiente para execução do exemplo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAPVtRXQqDim"
      },
      "source": [
        "## Tratamento de logs\n",
        "\n",
        "Método para tratamento dos logs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcopxbGZqDip"
      },
      "source": [
        "# Biblioteca de logging\n",
        "import logging\n",
        "\n",
        "# Formatando a mensagem de logging\n",
        "logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GjYtXcMnSAe"
      },
      "source": [
        "## Identificando o ambiente Colab\n",
        "\n",
        "Cria uma variável para identificar que o notebook está sendo executado no Google Colaboratory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMiH0E3OnRa1"
      },
      "source": [
        "# Se estiver executando no Google Colaboratory\n",
        "import sys\n",
        "\n",
        "# Retorna true ou false se estiver no Google Colaboratory\n",
        "IN_COLAB = \"google.colab\" in sys.modules"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RufkKnojlwzu"
      },
      "source": [
        "# 1 - Instalação do spaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0LeiOTx0Dlk"
      },
      "source": [
        "https://spacy.io/\n",
        "\n",
        "Modelos do spaCy para português:\n",
        "https://spacy.io/models/pt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2Fvx0TVRQUw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ff2c53b-52a3-402a-a6c1-29e3044c3dc0"
      },
      "source": [
        "# Instala o spacy\n",
        "!pip install -U spacy==2.3.5"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spacy==2.3.5\n",
            "  Downloading spacy-2.3.5-cp37-cp37m-manylinux2014_x86_64.whl (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (0.9.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (1.0.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (2.23.0)\n",
            "Collecting thinc<7.5.0,>=7.4.1\n",
            "  Downloading thinc-7.4.5-cp37-cp37m-manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 64.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (3.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (1.21.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (2.0.6)\n",
            "Collecting catalogue<1.1.0,>=0.0.7\n",
            "  Downloading catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
            "Collecting plac<1.2.0,>=0.9.6\n",
            "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (0.7.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (57.4.0)\n",
            "Collecting srsly<1.1.0,>=1.0.2\n",
            "  Downloading srsly-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl (184 kB)\n",
            "\u001b[K     |████████████████████████████████| 184 kB 37.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.3.5) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.5) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.5) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5) (1.24.3)\n",
            "Installing collected packages: srsly, plac, catalogue, thinc, spacy\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 2.4.4\n",
            "    Uninstalling srsly-2.4.4:\n",
            "      Successfully uninstalled srsly-2.4.4\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 2.0.8\n",
            "    Uninstalling catalogue-2.0.8:\n",
            "      Successfully uninstalled catalogue-2.0.8\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.0\n",
            "    Uninstalling thinc-8.1.0:\n",
            "      Successfully uninstalled thinc-8.1.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.1\n",
            "    Uninstalling spacy-3.4.1:\n",
            "      Successfully uninstalled spacy-3.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.4.0 requires spacy<3.5.0,>=3.4.0, but you have spacy 2.3.5 which is incompatible.\u001b[0m\n",
            "Successfully installed catalogue-1.0.0 plac-1.1.3 spacy-2.3.5 srsly-1.0.5 thinc-7.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35GwcgkOlWi3"
      },
      "source": [
        "Realiza o download e carrega os modelos necessários a biblioteca\n",
        "\n",
        "https://spacy.io/models/pt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4LqE5kTwDYm"
      },
      "source": [
        "# Definição do nome do arquivo do modelo\n",
        "#ARQUIVOMODELO = \"pt_core_news_sm\"\n",
        "#ARQUIVOMODELO = \"pt_core_news_md\"\n",
        "ARQUIVOMODELO = \"pt_core_news_lg\"\n",
        "\n",
        "# Definição da versão da spaCy\n",
        "#VERSAOSPACY = \"-3.0.0a0\"\n",
        "VERSAOSPACY = \"-2.3.0\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ2KB3UCp-ws"
      },
      "source": [
        "#Baixa automaticamente o arquivo do modelo.\n",
        "#!python -m spacy download {ARQUIVOMODELO}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASk5iFeUp9LE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29f0bd24-d265-473a-e74e-92c0f4b14d12"
      },
      "source": [
        "# Realiza o download do arquivo do modelo para o diretório corrente\n",
        "!wget https://github.com/explosion/spacy-models/releases/download/{ARQUIVOMODELO}{VERSAOSPACY}/{ARQUIVOMODELO}{VERSAOSPACY}.tar.gz"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-29 22:17:00--  https://github.com/explosion/spacy-models/releases/download/pt_core_news_lg-2.3.0/pt_core_news_lg-2.3.0.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/84940268/a899e480-ab07-11ea-831b-b5aa9cc04510?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220729%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220729T221700Z&X-Amz-Expires=300&X-Amz-Signature=ce4f8c39b672213a0dda812ac0a477f762a1c9593cc31d41ec9a547151f65d2c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=84940268&response-content-disposition=attachment%3B%20filename%3Dpt_core_news_lg-2.3.0.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-07-29 22:17:00--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/84940268/a899e480-ab07-11ea-831b-b5aa9cc04510?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220729%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220729T221700Z&X-Amz-Expires=300&X-Amz-Signature=ce4f8c39b672213a0dda812ac0a477f762a1c9593cc31d41ec9a547151f65d2c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=84940268&response-content-disposition=attachment%3B%20filename%3Dpt_core_news_lg-2.3.0.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 576599832 (550M) [application/octet-stream]\n",
            "Saving to: ‘pt_core_news_lg-2.3.0.tar.gz’\n",
            "\n",
            "pt_core_news_lg-2.3 100%[===================>] 549.89M  89.8MB/s    in 5.8s    \n",
            "\n",
            "2022-07-29 22:17:06 (95.5 MB/s) - ‘pt_core_news_lg-2.3.0.tar.gz’ saved [576599832/576599832]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu_LkF7Nfm8_"
      },
      "source": [
        "Descompacta o arquivo do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9fCQQJGeVEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09ee5e10-01b4-4f82-c656-d1a54de5ab41"
      },
      "source": [
        "# Descompacta o arquivo do modelo\n",
        "!tar -xvf  /content/{ARQUIVOMODELO}{VERSAOSPACY}.tar.gz"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pt_core_news_lg-2.3.0/\n",
            "pt_core_news_lg-2.3.0/PKG-INFO\n",
            "pt_core_news_lg-2.3.0/setup.py\n",
            "pt_core_news_lg-2.3.0/setup.cfg\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/dependency_links.txt\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/PKG-INFO\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/SOURCES.txt\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/requires.txt\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/top_level.txt\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg.egg-info/not-zip-safe\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/__init__.py\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/parser/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/parser/cfg\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/parser/moves\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/parser/model\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/ner/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/ner/cfg\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/ner/moves\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/ner/model\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tokenizer\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/lookups.bin\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/vectors\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/key2row\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/lookups_extra.bin\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/vocab/strings.json\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/accuracy.json\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tagger/\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tagger/cfg\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tagger/tag_map\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/tagger/model\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/pt_core_news_lg-2.3.0/meta.json\n",
            "pt_core_news_lg-2.3.0/pt_core_news_lg/meta.json\n",
            "pt_core_news_lg-2.3.0/MANIFEST.in\n",
            "pt_core_news_lg-2.3.0/meta.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovOx-3Wb-JJW"
      },
      "source": [
        "# Coloca a pasta do modelo descompactado em uma pasta de nome mais simples\n",
        "!mv /content/{ARQUIVOMODELO}{VERSAOSPACY}/{ARQUIVOMODELO}/{ARQUIVOMODELO}{VERSAOSPACY} /content/{ARQUIVOMODELO}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STHT2c89qvwK"
      },
      "source": [
        "Carrega o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbELnrpgA4T1"
      },
      "source": [
        "import spacy\n",
        "\n",
        "CAMINHOMODELO = \"/content/\" + ARQUIVOMODELO\n",
        "\n",
        "#nlp = spacy.load(CAMINHOMODELO)\n",
        "# Necessário \"tagger\" para encontrar os substantivos\n",
        "nlp = spacy.load(CAMINHOMODELO, disable=[\"tokenizer\", \"lemmatizer\", \"ner\", \"parser\", \"textcat\", \"custom\"])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqa-7WXBAw8q"
      },
      "source": [
        "# 2 - Instalação BERT da Hugging Face"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCdqJCtQN52l"
      },
      "source": [
        "Instala a interface pytorch para o BERT by Hugging Face. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RfUN_KolV-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "284ffabf-fc26-4378-b443-56a1c988dfc7"
      },
      "source": [
        "# Instala a última versão da biblioteca\n",
        "#!pip install transformers\n",
        "\n",
        "# Instala uma versão específica da biblioteca\n",
        "!pip install -U transformers==4.5.1"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.5.1\n",
            "  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (3.7.1)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 59.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 23.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.64.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.1) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=0408dcfcfde3fa64063dfe9753c32cc668dc2334f3c32cf2029dd946aa7b198a\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQj2wmKDpkrH"
      },
      "source": [
        "# 3 - Configuração do BERT\n",
        "\n",
        "Lista de modelos da comunidade:\n",
        "* https://huggingface.co/models\n",
        "\n",
        "Português(https://github.com/neuralmind-ai/portuguese-bert):  \n",
        "* **\"neuralmind/bert-base-portuguese-cased\"**\n",
        "* **\"neuralmind/bert-large-portuguese-cased\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajrTjZzapkrK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "def4495d-1b6b-432e-d954-3a7b1b3f5aeb"
      },
      "source": [
        "MODELO_BERT = \"neuralmind/bert-large-portuguese-cased\"\n",
        "# MODELO_BERT = \"neuralmind/bert-base-portuguese-cased\"\n",
        "\n",
        "print(\"BERT:\",MODELO_BERT)\n",
        "\n",
        "TAMANHO_BERT = 'large'\n",
        "if 'base' in MODELO_BERT:\n",
        "  TAMANHO_BERT = 'base'"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT: neuralmind/bert-base-portuguese-cased\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcpd9t9PpkrX"
      },
      "source": [
        "# 4 - Carregando o Tokenizador BERT\n",
        "\n",
        "O tokenizador utiliza WordPiece, veja em [artigo original](https://arxiv.org/pdf/1609.08144.pdf).\n",
        "\n",
        "Carregando o tokenizador da pasta \"/content/modelo/\" do diretório padrão se variável `URL_MODELO` setada.\n",
        "\n",
        "**Caso contrário carrega da comunidade**\n",
        "\n",
        "Por default(`do_lower_case=True`) todas as letras são colocadas para minúsculas. Para ignorar a conversão para minúsculo use o parâmetro `do_lower_case=False`. Esta opção também considera as letras acentuadas(ãçéí...), que são necessárias a língua portuguesa.\n",
        "\n",
        "O parâmetro `do_lower_case` interfere na quantidade tokens a ser gerado apartir de um documento. Quando igual a `False` reduz a quantidade de tokens gerados."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as bibliotecas\n",
        "import os\n",
        "\n",
        "# Variável para setar o arquivo\n",
        "URL_MODELO = None\n",
        "\n",
        "# Comente uma das urls para carregar modelos de tamanhos diferentes(base/large)\n",
        "# URL_MODELO do arquivo do modelo tensorflow\n",
        "# arquivo menor(base) 1.1 Gbytes\n",
        "#URL_MODELO = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "# arquivo grande(large) 3.5 Gbytes\n",
        "#URL_MODELO = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\"\n",
        "\n",
        "# Se a variável foi setada\n",
        "if URL_MODELO:\n",
        "\n",
        "    # Diretório descompactação\n",
        "    DIRETORIO_MODELO = \"/content/modelo\"\n",
        "\n",
        "    # Recupera o nome do arquivo do modelo da URL_MODELO\n",
        "    arquivo = URL_MODELO.split(\"/\")[-1]\n",
        "\n",
        "    # Nome do arquivo do vocabulário\n",
        "    arquivo_vocab = \"vocab.txt\"\n",
        "\n",
        "    # Caminho do arquivo na URL_MODELO\n",
        "    caminho = URL_MODELO[0:len(URL_MODELO)-len(arquivo)]\n",
        "\n",
        "    # Verifica se a pasta de descompactação existe na pasta corrente\n",
        "    if os.path.exists(DIRETORIO_MODELO):\n",
        "      print(\"Apagando diretório existente do modelo!\")\n",
        "      # Apaga a pasta e os arquivos existentes\n",
        "      !rm -rf $DIRETORIO_MODELO    \n",
        "\n",
        "    # Baixa o arquivo do modelo\n",
        "    !wget $URL_MODELO\n",
        "    \n",
        "    # Descompacta o arquivo na pasta de descompactação\n",
        "    !unzip -o $arquivo -d $DIRETORIO_MODELO\n",
        "\n",
        "    # Baixa o arquivo do vocabulário\n",
        "    # O vocabulário não está no arquivo compactado acima, mesma url mas arquivo diferente\n",
        "    URL_MODELO_VOCAB = caminho + arquivo_vocab\n",
        "    !wget $URL_MODELO_VOCAB\n",
        "    \n",
        "    # Coloca o arquivo do vocabulário no diretório de descompactação\n",
        "    !mv $arquivo_vocab $DIRETORIO_MODELO\n",
        "            \n",
        "    # Move o arquivo para pasta de descompactação\n",
        "    !mv $arquivo $DIRETORIO_MODELO\n",
        "       \n",
        "    print(\"Pasta do \" + DIRETORIO_MODELO + \" pronta!\")\n",
        "    \n",
        "    # Lista a pasta corrente\n",
        "    !ls -la $DIRETORIO_MODELO\n",
        "else:\n",
        "    DIRETORIO_MODELO = None\n",
        "    print(\"Variável URL_MODELO não setada!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Cj6GiQN_i4f",
        "outputId": "03b1f375-d699-408b-9e66-5321b9202836"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variável URL_MODELO não setada!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8cKVs4fpkrY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "6f7787a6708245ef84a7e1162b9b9da5",
            "9be35067c781458889b1203af0bd0f13",
            "89fa08586d7046c59b25a89754744078",
            "747c92921c344f41a340752ce0ffc181",
            "efd1f0d5744f436cb6a4cc594a38077e",
            "2f369ea103e44a59b6ba16eb05314ed8",
            "336d878fcfd8494888b3974a25b8b141",
            "334279c9b483492fae9cf6cbb2455b43",
            "beed785495b448bb89b604e4d6eca036",
            "9d7568bed66a433a9622ada4d7599ea2",
            "fc6931dc81c04546821c608cbb64ddfd",
            "b03c0654a587461ba3cceb0a699629ec",
            "e5f5b653ee9a4372b6aa046ae367cef4",
            "bb045b6d43d84a749c5ad3d91c386930",
            "9ba528854ed948b8adf363376d049316",
            "4fedfeef7ef94789a080be9dd23d9080",
            "f2d8e93c0e344ebaa6d4bd7c5de4c709",
            "d02f3570b13444948fc0f2759c76236e",
            "1c23415d5d32462eb45308e3e394dd35",
            "e6101ed8361e4ea69432afac1d057ff2",
            "5d7aeaede18445beaaa224d88de0eddb",
            "6107faa838c34b0290d64497c47f68c2",
            "9a1974cc16234c95a19d2b2dace6cce1",
            "795125a5d6074e8e97edd90a8b958fc2",
            "b0a8a4b5b8e8448694d327b103cb3802",
            "26ad841ce82f42c0a604072c11aa9571",
            "2aada03893cb4b8ab0f15663b75c669d",
            "7d4de51bf8124caca95b19ff0d9dbf8b",
            "af68429748b74c8db2e8e233d62109cc",
            "736c3042d95f428abcbbabc1410aa4a2",
            "cc5f2778aa794574884c9ffc4bedf4dd",
            "873d7281610c42818e451e8315aba768",
            "966769d55aee4e6cb4eb7c7cbf06a844",
            "bf6bc5cf4725471eb937139f0c5597a9",
            "bb6d07d6c28a44c88e31a3ca599500e8",
            "61f1265857214fcc93833bbda557f802",
            "e6296f193f60481082ed4f654ba27197",
            "9d2dadd602744d0cbaa7df01956877e8",
            "3a20ac1f8755433ba2b5f3d958b09d79",
            "4d50040b8573434e9a6e341aab96766c",
            "3195e303e5424c8e8307803bf11aaec6",
            "680ba6ad5baa4380a8689ffa1c77b616",
            "89625b11ccda4574ba966b26b8073cfa",
            "dc90281b15f84a81b31b3453e0054d9a"
          ]
        },
        "outputId": "7011b2ee-6496-4288-e2d3-63f39f37d3cf"
      },
      "source": [
        "# Importando as bibliotecas do tokenizador\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Se a variável URL_MODELO foi setada\n",
        "if URL_MODELO:\n",
        "    # Carregando o Tokenizador\n",
        "    print(\"Carrgando o tokenizador BERT do diretório \" + DIRETORIO_MODELO + \"...\")\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(DIRETORIO_MODELO, \n",
        "                                              do_lower_case=False)    \n",
        "else:\n",
        "    # Carregando o Tokenizador da comunidade\n",
        "    print(\"Carregando o tokenizador da comunidade...\")\n",
        "    \n",
        "    tokenizer = BertTokenizer.from_pretrained(MODELO_BERT, do_lower_case=False)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando o tokenizador da comunidade...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/210k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f7787a6708245ef84a7e1162b9b9da5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b03c0654a587461ba3cceb0a699629ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a1974cc16234c95a19d2b2dace6cce1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf6bc5cf4725471eb937139f0c5597a9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m__On2g1a--K"
      },
      "source": [
        "# 5 - Carregando o Modelo BERT(BertModel)\n",
        "\n",
        "Se a variável `URL_MODELO` estiver setada carrega o modelo do diretório `content/modelo`.\n",
        "\n",
        "Caso contrário carrega da comunidade.\n",
        "\n",
        "Carregando o modelo da pasta \"/content/modelo/\" do diretório padrão.\n",
        "\n",
        "A implementação do huggingface pytorch inclui um conjunto de interfaces projetadas para uma variedade de tarefas de PNL. Embora essas interfaces sejam todas construídas sobre um modelo treinado de BERT, cada uma possui diferentes camadas superiores e tipos de saída projetados para acomodar suas tarefas específicas de PNL.\n",
        "\n",
        "A documentação para estas pode ser encontrada em [aqui](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html).\n",
        "\n",
        "Por default o modelo está em modo avaliação ou seja `model.eval()`.\n",
        "\n",
        "-----------------------\n",
        "\n",
        "Durante a avaliação do modelo, este retorna um número de diferentes objetos com base em como é configurado na chamada do método `from_pretrained`. \n",
        "\n",
        "Quando definimos `output_hidden_states = True` na chamada do método `from_pretrained`, retorno do modelo possui no terceiro item os estados ocultos(**hidden_states**) de todas as camadas.  Veja a documentação para mais detalhes: https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "\n",
        "Quando **`output_hidden_states = True`** model retorna:\n",
        "- outputs[0] = last_hidden_state;\n",
        "- outputs[1] = pooler_output; \n",
        "- outputs[2] = hidden_states.\n",
        "\n",
        "Quando **`output_hidden_states = False`** ou não especificado model retorna:\n",
        "- outputs[0] = last_hidden_state;\n",
        "- outputs[1] = pooler_output.\n",
        "\n",
        "\n",
        "**ATENÇÃO**: O parâmetro ´**output_hidden_states = True**´ habilita gerar as camadas ocultas do modelo. Caso contrário somente a última camada é mantida. Este parâmetro otimiza a memória mas não os resultados.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRV6l_I-qg9s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "dc7190a078ba4830a3eefaba64ec5e0a",
            "ee460832ee9046e6928d47a41a82e80e",
            "548c33dd28a94267a965e3a60f710c7b",
            "b7cee2d7303f44b493566f1d97e6919b",
            "738e20ca927c432f82c92e8102826b2d",
            "1e0a45474d9942558ba0852e02396aab",
            "12d9047add6a4948a7c5608d0ed7a1e8",
            "5adf4363405c43f793dff3c8e1b072e5",
            "758869cbfc3d499788272731cb228ba7",
            "dbddf65003724258baeef431f77d3453",
            "1c04189713544c5e8aca4eba1edec4df",
            "33b6d86cbe4143d1b275b3eb4f1e7ca7",
            "be6364355d9d4743b431d1fee1bd4532",
            "f1a6c478db9d4808b8670d9a565f8aa3",
            "fb926d61fd5d4ec8a1aa3f8726c9b64d",
            "7919ede5c0d342dc9353b820211ab0a3",
            "48d3202edfb244bb92f4cd7bf6338c91",
            "886b4534d02c49a2bf83257ef389dc40",
            "b061fd8215e945a89acd2da15e45cc47",
            "fc78de5395e746a784608156c458cb1d",
            "23107f548f884b3ba726aba2cd166ac2",
            "b010042403ae4e54bf02c90eba11c219"
          ]
        },
        "outputId": "12e6eef4-2fd4-4abb-ac9c-65eb73e9e3f8"
      },
      "source": [
        "# Importando as bibliotecas do Modelo\n",
        "from transformers import BertModel\n",
        "\n",
        "# Se a variável URL_MODELO1 foi setada\n",
        "if URL_MODELO:\n",
        "    # Carregando o Tokenizador\n",
        "    print(\"Carregando o modelo BERT do diretório \" + DIRETORIO_MODELO + \"...\")\n",
        "\n",
        "    model = BertModel.from_pretrained(DIRETORIO_MODELO, \n",
        "                                      output_hidden_states = True)    \n",
        "else:\n",
        "    # Carregando o Tokenizador da comunidade\n",
        "    print(\"Carregando o modelo BERT da comunidade ...\")\n",
        "\n",
        "    model = BertModel.from_pretrained(MODELO_BERT, \n",
        "                                       output_hidden_states = True)    "
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando o modelo BERT da comunidade ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/647 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc7190a078ba4830a3eefaba64ec5e0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33b6d86cbe4143d1b275b3eb4f1e7ca7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU3wHzNUmmBP"
      },
      "source": [
        "# 6 - Funções auxiliares BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s42mgtmSZ8MR"
      },
      "source": [
        "#### getEmbeddingsCamadas\n",
        "\n",
        "Funções que recuperam os embeddings das camadas:\n",
        "- Primeira camada;\n",
        "- Penúltima camada;\n",
        "- Ùltima camada;\n",
        "- Soma das 4 últimas camadas;\n",
        "- Concatenação das 4 últimas camadas;\n",
        "- Soma de todas as camadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgo3EBTRZ9-3"
      },
      "source": [
        "def getEmbeddingPrimeiraCamada(output):\n",
        "  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n",
        "      \n",
        "  # Retorna todas a primeira(-1) camada\n",
        "  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  resultado = output[2][0]\n",
        "  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  \n",
        "  return resultado\n",
        "\n",
        "def getEmbeddingPenultimaCamada(output):\n",
        "  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n",
        "      \n",
        "  # Retorna todas a primeira(-1) camada\n",
        "  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  resultado = output[2][-2]\n",
        "  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  \n",
        "  return resultado\n",
        "\n",
        "def getEmbeddingUltimaCamada(output):\n",
        "  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n",
        "     \n",
        "  # Retorna todas a primeira(-1) camada\n",
        "  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  resultado = output[2][-1]\n",
        "  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  \n",
        "  return resultado    \n",
        "\n",
        "def getEmbeddingSoma4UltimasCamadas(output):\n",
        "  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n",
        "      \n",
        "  # Retorna todas a primeira(-1) camada\n",
        "  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  embeddingCamadas = output[2][-4:]\n",
        "  # Saída: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "\n",
        "  # Usa o método `stack` para criar uma nova dimensão no tensor \n",
        "  # com a concateção dos tensores dos embeddings.        \n",
        "  #Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  resultadoStack = torch.stack(embeddingCamadas, dim=0)\n",
        "  # Saída: <4> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n",
        "  \n",
        "  # Realiza a soma dos embeddings de todos os tokens para as camadas\n",
        "  # Entrada: <4> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n",
        "  resultado = torch.sum(resultadoStack, dim=0)\n",
        "  # Saida: <1(lote)> x <qtde_tokens> x <768 ou 1024>\n",
        "  \n",
        "  return resultado\n",
        "\n",
        "def getEmbeddingConcat4UltimasCamadas(output):  \n",
        "  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n",
        "      \n",
        "  # Cria uma lista com os tensores a serem concatenados\n",
        "  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  # Lista com os tensores a serem concatenados\n",
        "  listaConcat = []\n",
        "  # Percorre os 4 últimos\n",
        "  for i in [-1,-2,-3,-4]:\n",
        "      # Concatena da lista\n",
        "      listaConcat.append(output[2][i])\n",
        "  # Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  \n",
        "  # Realiza a concatenação dos embeddings de todos as camadas\n",
        "  # Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  resultado = torch.cat(listaConcat, dim=-1)\n",
        "  # Saída: Entrada: (<1(lote)> x <qtde_tokens> <3072 ou 4096>)  \n",
        "    \n",
        "  return resultado   \n",
        "\n",
        "def getEmbeddingSomaTodasAsCamada(output):\n",
        "  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n",
        "   \n",
        "  # Retorna todas as camadas descontando a primeira(0)\n",
        "  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  embeddingCamadas = output[2][1:]\n",
        "  # Saída: List das camadas(12 ou 24) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  \n",
        "  # Usa o método `stack` para criar uma nova dimensão no tensor \n",
        "  # com a concateção dos tensores dos embeddings.        \n",
        "  #Entrada: List das camadas(12 ou 24) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n",
        "  resultadoStack = torch.stack(embeddingCamadas, dim=0)\n",
        "  # Saída: <12 ou 24> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n",
        "    \n",
        "  # Realiza a soma dos embeddings de todos os tokens para as camadas\n",
        "  # Entrada: <12 ou 24> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n",
        "  resultado = torch.sum(resultadoStack, dim=0)\n",
        "  # Saida: <1(lote)> x <qtde_tokens> x <768 ou 1024>\n",
        "    \n",
        "  return resultado"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWqMsrb-ew5T"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm98RoojJcqP"
      },
      "source": [
        "# Import das bibliotecas\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7nx_eZ8hSlr"
      },
      "source": [
        "#### getEmbeddingsVisual\n",
        "\n",
        "Função para gerar as coordenadas de plotagem a partir das sentenças de embeddings.\n",
        "\n",
        "Existe uma função para os tipos de camadas utilizadas:\n",
        "- Ùltima camada;\n",
        "- Soma das 4 últimas camadas;\n",
        "- Concatenação das 4 últimas camadas;\n",
        "- Soma de todas as camadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO_fSqnNz2Cl"
      },
      "source": [
        "def getEmbeddingsVisualUltimaCamada(documento, modelo, tokenizador):\n",
        "    \n",
        "    # Adiciona os tokens especiais\n",
        "    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n",
        "\n",
        "    # Divide a sentença em tokens\n",
        "    documento_tokenizado = tokenizador.tokenize(documento_marcado)\n",
        "\n",
        "    # Mapeia as strings dos tokens em seus índices do vocabuário    \n",
        "    tokens_indexados = tokenizador.convert_tokens_to_ids(documento_tokenizado)\n",
        "    \n",
        "    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n",
        "    mascara_atencao = [1] * len(documento_tokenizado)\n",
        "\n",
        "    # Converte a entrada em tensores\n",
        "    tokens_tensores = torch.as_tensor([tokens_indexados])\n",
        "    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n",
        "    \n",
        "    # Prediz os atributos dos estados ocultos para cada camada\n",
        "    with torch.no_grad():        \n",
        "        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n",
        "        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n",
        "\n",
        "    # Camada embedding    \n",
        "    camada = getEmbeddingUltimaCamada(outputs)\n",
        "\n",
        "    # Remove a dimensão 1, o lote \"batches\".\n",
        "    token_embeddings = torch.squeeze(camada, dim=0)\n",
        "\n",
        "    # Recupera os embeddings dos tokens como um vetor\n",
        "    embeddings = token_embeddings.numpy()\n",
        "\n",
        "    # Converte para um array\n",
        "    W = np.array(embeddings)\n",
        "    # Transforma em um array\n",
        "    B = np.array([embeddings[0], embeddings[-1]])\n",
        "    # Invertee B.T\n",
        "    Bi = np.linalg.pinv(B.T)\n",
        "\n",
        "    #Projeta a palavra no espaço\n",
        "    Wp = np.matmul(Bi,W.T)\n",
        "\n",
        "    return Wp, documento_tokenizado"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTd1Zaoez2Cl"
      },
      "source": [
        "def getEmbeddingsVisualSoma4UltimasCamadas(documento, modelo, tokenizador):\n",
        "    \n",
        "    # Adiciona os tokens especiais\n",
        "    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n",
        "\n",
        "    # Divide a sentença em tokens\n",
        "    documento_tokenizado = tokenizador.tokenize(documento_marcado)\n",
        "\n",
        "    # Mapeia as strings dos tokens em seus índices do vocabuário    \n",
        "    tokens_indexados = tokenizador.convert_tokens_to_ids(documento_tokenizado)\n",
        "    \n",
        "    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n",
        "    mascara_atencao = [1] * len(documento_tokenizado)\n",
        "\n",
        "    # Converte a entrada em tensores\n",
        "    tokens_tensores = torch.as_tensor([tokens_indexados])\n",
        "    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n",
        "    \n",
        "    # Prediz os atributos dos estados ocultos para cada camada\n",
        "    with torch.no_grad():        \n",
        "        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n",
        "        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n",
        "\n",
        "    # Camada embedding    \n",
        "    camada = getEmbeddingSoma4UltimasCamadas(outputs)\n",
        "\n",
        "    # Remove a dimensão 1, o lote \"batches\".\n",
        "    token_embeddings = torch.squeeze(camada, dim=0)\n",
        "\n",
        "    # Recupera os embeddings dos tokens como um vetor\n",
        "    embeddings = token_embeddings.numpy()\n",
        "\n",
        "    # Converte para um array\n",
        "    W = np.array(embeddings)\n",
        "    # Transforma em um array\n",
        "    B = np.array([embeddings[0], embeddings[-1]])\n",
        "    # Invertee B.T\n",
        "    Bi = np.linalg.pinv(B.T)\n",
        "\n",
        "    #Projeta a palavra no espaço\n",
        "    Wp = np.matmul(Bi,W.T)\n",
        "\n",
        "    return Wp, documento_tokenizado"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GpcoBpyz2Cl"
      },
      "source": [
        "def getEmbeddingsVisualConcat4UltimasCamadas(documento, modelo, tokenizador):\n",
        "    \n",
        "    # Adiciona os tokens especiais\n",
        "    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n",
        "\n",
        "    # Divide a sentença em tokens\n",
        "    documento_tokenizado = tokenizador.tokenize(documento_marcado)\n",
        "\n",
        "    # Mapeia as strings dos tokens em seus índices do vocabuário    \n",
        "    tokens_indexados = tokenizador.convert_tokens_to_ids(documento_tokenizado)\n",
        "    \n",
        "    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n",
        "    mascara_atencao = [1] * len(documento_tokenizado)\n",
        "\n",
        "    # Converte a entrada em tensores\n",
        "    tokens_tensores = torch.as_tensor([tokens_indexados])\n",
        "    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n",
        "    \n",
        "    # Prediz os atributos dos estados ocultos para cada camada\n",
        "    with torch.no_grad():        \n",
        "        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n",
        "        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n",
        "\n",
        "    # Camada embedding    \n",
        "    camada = getEmbeddingConcat4UltimasCamadas(outputs)\n",
        "\n",
        "    # Remove a dimensão 1, o lote \"batches\".\n",
        "    token_embeddings = torch.squeeze(camada, dim=0)\n",
        "\n",
        "    # Recupera os embeddings dos tokens como um vetor\n",
        "    embeddings = token_embeddings.numpy()\n",
        "\n",
        "    # Converte para um array\n",
        "    W = np.array(embeddings)\n",
        "    # Transforma em um array\n",
        "    B = np.array([embeddings[0], embeddings[-1]])\n",
        "    # Invertee B.T\n",
        "    Bi = np.linalg.pinv(B.T)\n",
        "\n",
        "    #Projeta a palavra no espaço\n",
        "    Wp = np.matmul(Bi,W.T)\n",
        "\n",
        "    return Wp, documento_tokenizado"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn7WjxPHz2Cl"
      },
      "source": [
        "def getEmbeddingsVisualSomaTodasAsCamadas(documento, modelo, tokenizador):\n",
        "    \n",
        "    # Adiciona os tokens especiais\n",
        "    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n",
        "\n",
        "    # Divide a sentença em tokens\n",
        "    documento_tokenizado = tokenizador.tokenize(documento_marcado)\n",
        "\n",
        "    # Mapeia as strings dos tokens em seus índices do vocabuário    \n",
        "    tokens_indexados = tokenizador.convert_tokens_to_ids(documento_tokenizado)\n",
        "    \n",
        "    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n",
        "    mascara_atencao = [1] * len(documento_tokenizado)\n",
        "\n",
        "    # Converte a entrada em tensores\n",
        "    tokens_tensores = torch.as_tensor([tokens_indexados])\n",
        "    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n",
        "    \n",
        "    # Prediz os atributos dos estados ocultos para cada camada\n",
        "    with torch.no_grad():        \n",
        "        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n",
        "        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n",
        "\n",
        "    # Camada embedding    \n",
        "    camada = getEmbeddingSomaTodasAsCamada(outputs)\n",
        "\n",
        "    # Remove a dimensão 1, o lote \"batches\".\n",
        "    token_embeddings = torch.squeeze(camada, dim=0)\n",
        "\n",
        "    # Recupera os embeddings dos tokens como um vetor\n",
        "    embeddings = token_embeddings.numpy()\n",
        "\n",
        "    # Converte para um array\n",
        "    W = np.array(embeddings)\n",
        "    # Transforma em um array\n",
        "    B = np.array([embeddings[0], embeddings[-1]])\n",
        "    # Invertee B.T\n",
        "    Bi = np.linalg.pinv(B.T)\n",
        "\n",
        "    #Projeta a palavra no espaço\n",
        "    Wp = np.matmul(Bi,W.T)\n",
        "\n",
        "    return Wp, documento_tokenizado"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8MjE0utzlZT"
      },
      "source": [
        "#### getEmbeddings\n",
        "\n",
        "Função para gerar os embeddings das sentenças.\n",
        "\n",
        "Existe uma função para os tipos de camadas utilizadas:\n",
        "- Ùltima camada;\n",
        "- Soma das 4 últimas camadas;\n",
        "- Concatenação das 4 últimas camadas;\n",
        "- Soma de todas as camadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QcqOuwS067Q"
      },
      "source": [
        "def getEmbeddingsUltimaCamada(documento, modelo, tokenizador):\n",
        "    \n",
        "    # Adiciona os tokens especiais\n",
        "    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n",
        "\n",
        "    # Divide a sentença em tokens\n",
        "    documento_tokenizado = tokenizador.tokenize(documento_marcado)\n",
        "\n",
        "    # Mapeia as strings dos tokens em seus índices do vocabuário    \n",
        "    tokens_indexados = tokenizador.convert_tokens_to_ids(documento_tokenizado)\n",
        "    \n",
        "    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n",
        "    mascara_atencao = [1] * len(documento_tokenizado)\n",
        "\n",
        "    # Converte a entrada em tensores\n",
        "    tokens_tensores = torch.as_tensor([tokens_indexados])\n",
        "    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n",
        "    \n",
        "    # Prediz os atributos dos estados ocultos para cada camada\n",
        "    with torch.no_grad():        \n",
        "        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n",
        "        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n",
        "\n",
        "    # Camada embedding    \n",
        "    camada = getEmbeddingUltimaCamada(outputs)\n",
        "\n",
        "    # Remove a dimensão 1, o lote \"batches\".\n",
        "    token_embeddings = torch.squeeze(camada, dim=0)\n",
        " \n",
        "    return token_embeddings, documento_tokenizado"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK1wDGBl067Y"
      },
      "source": [
        "def getEmbeddingsSoma4UltimasCamadas(documento, modelo, tokenizador):\n",
        "    \n",
        "    # Adiciona os tokens especiais\n",
        "    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n",
        "\n",
        "    # Divide a sentença em tokens\n",
        "    documento_tokenizado = tokenizador.tokenize(documento_marcado)\n",
        "\n",
        "    # Mapeia as strings dos tokens em seus índices do vocabuário    \n",
        "    tokens_indexados = tokenizador.convert_tokens_to_ids(documento_tokenizado)\n",
        "    \n",
        "    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n",
        "    mascara_atencao = [1] * len(documento_tokenizado)\n",
        "\n",
        "    # Converte a entrada em tensores\n",
        "    tokens_tensores = torch.as_tensor([tokens_indexados])\n",
        "    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n",
        "    \n",
        "    # Prediz os atributos dos estados ocultos para cada camada\n",
        "    with torch.no_grad():        \n",
        "        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n",
        "        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n",
        "\n",
        "    # Camada embedding    \n",
        "    camada = getEmbeddingSoma4UltimasCamadas(outputs)\n",
        "\n",
        "    # Remove a dimensão 1, o lote \"batches\".\n",
        "    token_embeddings = torch.squeeze(camada, dim=0)\n",
        "   \n",
        "    return token_embeddings, documento_tokenizado"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hym19Hxr067Y"
      },
      "source": [
        "def getEmbeddingsConcat4UltimasCamadas(documento, modelo, tokenizador):\n",
        "    \n",
        "    # Adiciona os tokens especiais\n",
        "    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n",
        "\n",
        "    # Divide a sentença em tokens\n",
        "    documento_tokenizado = tokenizador.tokenize(documento_marcado)\n",
        "\n",
        "    # Mapeia as strings dos tokens em seus índices do vocabuário    \n",
        "    tokens_indexados = tokenizador.convert_tokens_to_ids(documento_tokenizado)\n",
        "    \n",
        "    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n",
        "    mascara_atencao = [1] * len(documento_tokenizado)\n",
        "\n",
        "    # Converte a entrada em tensores\n",
        "    tokens_tensores = torch.as_tensor([tokens_indexados])\n",
        "    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n",
        "    \n",
        "    # Prediz os atributos dos estados ocultos para cada camada\n",
        "    with torch.no_grad():        \n",
        "        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n",
        "        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n",
        "\n",
        "    # Camada embedding    \n",
        "    camada = getEmbeddingConcat4UltimasCamadas(outputs)\n",
        "\n",
        "    # Remove a dimensão 1, o lote \"batches\".\n",
        "    token_embeddings = torch.squeeze(camada, dim=0)\n",
        "\n",
        "    return token_embeddings, documento_tokenizado"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-PLZiUR067Z"
      },
      "source": [
        "def getEmbeddingsSomaTodasAsCamadas(documento, modelo, tokenizador):\n",
        "    \n",
        "    # Adiciona os tokens especiais\n",
        "    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n",
        "\n",
        "    # Divide a sentença em tokens\n",
        "    documento_tokenizado = tokenizador.tokenize(documento_marcado)\n",
        "\n",
        "    # Mapeia as strings dos tokens em seus índices do vocabuário    \n",
        "    tokens_indexados = tokenizador.convert_tokens_to_ids(documento_tokenizado)\n",
        "    \n",
        "    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n",
        "    mascara_atencao = [1] * len(documento_tokenizado)\n",
        "\n",
        "    # Converte a entrada em tensores\n",
        "    tokens_tensores = torch.as_tensor([tokens_indexados])\n",
        "    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n",
        "    \n",
        "    # Prediz os atributos dos estados ocultos para cada camada\n",
        "    with torch.no_grad():        \n",
        "        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n",
        "        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n",
        "        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n",
        "\n",
        "    # Camada embedding    \n",
        "    camada = getEmbeddingSomaTodasAsCamada(outputs)\n",
        "\n",
        "    # Remove a dimensão 1, o lote \"batches\".\n",
        "    token_embeddings = torch.squeeze(camada, dim=0)\n",
        "\n",
        "    return token_embeddings, documento_tokenizado"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt06PTN5idrg"
      },
      "source": [
        "## Similaridade do cosseno entre os embeddings.\n",
        "\n",
        "https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html#scipy.spatial.distance.cosine\n",
        "\n",
        "A função spatial.distance.cosine do módulo scipy calcula a distância em vez da similaridade do cosseno, mas para conseguir isso, podemos subtrair o valor da distância de 1.\n",
        "\n",
        "Intervalo de [-1,1] \n",
        "\n",
        "Vetores iguais a distância é igual 1.\n",
        "\n",
        "Vetores diferentes medida próxima de -1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vbXj-brOlMF"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "def similaridadeCosseno(embeddings1, embeddings2):\n",
        "    \"\"\"\n",
        "      Similaridade do cosseno dos embeddings dos textos.\n",
        "      \n",
        "      Parâmetros:\n",
        "      `embeddings1` - Um embedding a ser medido.\n",
        "      `embeddings2` - Um embedding a ser medido.\n",
        "    \"\"\"\n",
        "    \n",
        "    similaridade = 1 - cosine(embeddings1, embeddings2)\n",
        "    \n",
        "    return similaridade"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IcrjAbhwake"
      },
      "source": [
        "## Distância Euclidiana entre os embeddings.\n",
        "\n",
        "Possui outros nomes como distância L2 ou norma L2.\n",
        "\n",
        "https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.euclidean.html#scipy.spatial.distance.euclidean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIrTId9jwakh"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "def distanciaEuclidiana(embeddings1, embeddings2):\n",
        "    \"\"\"\n",
        "      Distância euclidiana entre os embeddings dos textos.\n",
        "      Possui outros nomes como distância L2 ou norma L2.\n",
        "      \n",
        "      Parâmetros:\n",
        "      `embeddings1` - Um embedding a ser medido.\n",
        "      `embeddings2` - Um embedding a ser medido.\n",
        "    \"\"\"\n",
        "    \n",
        "    distancia = euclidean(embeddings1, embeddings2)\n",
        "    \n",
        "    return distancia"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uJlqYCSXdVk"
      },
      "source": [
        "## Distância Manhattan entre os embeddings.\n",
        "\n",
        "Possui outros nomes como distância Cityblock, distância L1, norma L1 e métrica do táxi.\n",
        "\n",
        "https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cityblock.html#scipy.spatial.distance.cityblock"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFG5UT_SXdVn"
      },
      "source": [
        "# Import das bibliotecas.\n",
        "from scipy.spatial.distance import cityblock\n",
        "\n",
        "def distanciaManhattan(embeddings1, embeddings2):\n",
        "    \"\"\"\n",
        "      Distância Manhattan entre os embeddings dos textos \n",
        "      Possui outros nomes como distância Cityblock, distância L1, norma L1 e métrica do táxi.\n",
        "      \n",
        "      Parâmetros:\n",
        "      `embeddings1` - Um embedding a ser medido.\n",
        "      `embeddings2` - Um embedding a ser medido.\n",
        "    \"\"\"\n",
        "    \n",
        "    distancia = cityblock(embeddings1, embeddings2)\n",
        "\n",
        "    return distancia"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFd1rse11DpZ"
      },
      "source": [
        "## getDocumentoTokenizado \n",
        "\n",
        "Retorna o documento tokenizado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvWIBFTLJ7z9"
      },
      "source": [
        "def getDocumentoTokenizado(documento, tokenizer):\n",
        "    \"\"\"\n",
        "      Retorna o documento tokenizado pelo BERT.\n",
        "    \n",
        "      Parâmetros:\n",
        "      `documento` - Documento a ser tokenizado.\n",
        "      `tokenizer` - Tokenizador do BERT.\n",
        "    \"\"\"    \n",
        "\n",
        "    # Adiciona os tokens especiais.\n",
        "    documentoMarcado = \"[CLS] \" + documento + \" [SEP]\"\n",
        "\n",
        "    # Documento tokenizado\n",
        "    documentoTokenizado = tokenizer.tokenize(documentoMarcado)\n",
        "\n",
        "    del tokenizer\n",
        "\n",
        "    return documentoTokenizado    "
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wvgXwN81RCz"
      },
      "source": [
        "## encontrarIndiceSubLista \n",
        "\n",
        "Retorna os índices de início e fim da sublista na lista"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abS44M4yvFxf"
      },
      "source": [
        "# Localiza os índices de início e fim de uma sublista em uma lista\n",
        "def encontrarIndiceSubLista(lista, sublista):\n",
        "\n",
        "    \"\"\"\n",
        "      Localiza os índices de início e fim de uma sublista em uma lista.\n",
        "    \n",
        "      Parâmetros:\n",
        "      `lista` - Uma lista.\n",
        "      `sublista` - Uma sublista a ser localizada na lista.\n",
        "    \"\"\"    \n",
        "    # https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore%E2%80%93Horspool_algorithm\n",
        "\n",
        "    # Recupera o tamanho da lista \n",
        "    h = len(lista)\n",
        "    # Recupera o tamanho da sublista\n",
        "    n = len(sublista)    \n",
        "    skip = {sublista[i]: n - i - 1 for i in range(n - 1)}\n",
        "    i = n - 1\n",
        "    while i < h:\n",
        "        for j in range(n):\n",
        "            if lista[i - j] != sublista[-j - 1]:\n",
        "                i += skip.get(lista[i], n)\n",
        "                break\n",
        "        else:\n",
        "            indiceInicio = i - n + 1\n",
        "            indiceFim = indiceInicio + len(sublista)-1\n",
        "            return indiceInicio, indiceFim\n",
        "    return -1, -1"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGL37G6XFcwp"
      },
      "source": [
        "## getEmbeddingSentencaEmbeddingDocumentoComTodasPalavras\n",
        "\n",
        "A partir dos embeddings do documento, localiza o indíce de início e fim de uma sentença no documento e retorna os embeddings da sentença."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI07Y_M8__HG"
      },
      "source": [
        "def getEmbeddingSentencaEmbeddingDocumentoComTodasPalavras(embeddingDocumento, \n",
        "                                                           tokenBERTDocumento, \n",
        "                                                           sentenca, \n",
        "                                                           tokenizer):\n",
        "\n",
        "  # Tokeniza a sentença\n",
        "  sentencaTokenizadaBert = getDocumentoTokenizado(sentenca, tokenizer)\n",
        "  #print(sentencaTokenizadaBert)\n",
        "\n",
        "  # Remove os tokens de início e fim da sentença\n",
        "  sentencaTokenizadaBert.remove(\"[CLS]\")\n",
        "  sentencaTokenizadaBert.remove(\"[SEP]\")    \n",
        "  #print(len(sentencaTokenizadaBert))\n",
        "  \n",
        "  # Localiza os índices dos tokens da sentença no documento\n",
        "  inicio, fim = encontrarIndiceSubLista(tokenBERTDocumento, sentencaTokenizadaBert)\n",
        "  #print(inicio,fim) \n",
        " \n",
        "  # Recupera os embeddings dos tokens da sentença a partir dos embeddings do documento\n",
        "  embeddingSentenca = embeddingDocumento[inicio:fim+1]\n",
        "  #print(\"embeddingSentenca=\", embeddingSentenca.shape)\n",
        "\n",
        "  del tokenizer\n",
        "  del tokenBERTDocumento\n",
        "  del embeddingDocumento\n",
        "  \n",
        "  # Retorna o embedding da sentença no documento\n",
        "  return embeddingSentenca, sentencaTokenizadaBert"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## criarLotesInteligentes"
      ],
      "metadata": {
        "id": "_Hn-fDoMKiqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import das bibliotecas.\n",
        "from tqdm.notebook import tqdm as tqdm_notebook\n",
        "import random\n",
        "\n",
        "def criarLotesInteligentes(tokenizer, \n",
        "                           documentos,     \n",
        "                           batch_size):\n",
        "    '''\n",
        "    Esta função combina todos os passos para preparar os lotes.\n",
        "    '''\n",
        "    logging.info(\"Criando Lotes Inteligentes de {:,} amostras com tamanho de lote {:,}...\".format(len(documentos), batch_size))\n",
        "\n",
        "    # ============================\n",
        "    #   Tokenização & Truncamento\n",
        "    # ============================\n",
        "\n",
        "    input_ids_completos = []\n",
        "    \n",
        "    # Tokeniza todas as amostras de treinamento\n",
        "    #logging.info(\"Tokenizando {:,} amostra...\".format(len(classes)))\n",
        "    \n",
        "    # Barra de progresso dos documentos\n",
        "    documentos_bar = tqdm_notebook(documentos, desc=f'Documentos ', unit=f'documento', total=len(documentos))\n",
        "\n",
        "    # Para cada amostra de treinamento...\n",
        "    for documento in documentos_bar:\n",
        "    \n",
        "        # Relatório de progresso\n",
        "        #if ((len(input_ids_completos) % intervalo_atualizacao) == 0):\n",
        "        #    logging.info(\"  Tokenizado {:,} amostras.\".format(len(input_ids_completos)))\n",
        "\n",
        "        # Tokeniza a amostra.\n",
        "        input_ids = tokenizer.encode(text=documento,                    # Documento a ser codificado.\n",
        "                                    add_special_tokens=True,            # Adiciona os ttokens especiais.\n",
        "                                    max_length=128,                     # Tamanho do truncamento!\n",
        "                                    truncation=True,                    # Faz o truncamento!\n",
        "                                    padding=False)                      # Não preenche.\n",
        "                \n",
        "        # Adicione o resultado tokenizado à nossa lista.\n",
        "        input_ids_completos.append(input_ids)\n",
        "\n",
        "        del input_ids\n",
        "    \n",
        "    del documentos    \n",
        "    \n",
        "    #logging.info(\"{:>10,} amostras tokenizadas.\".format(len(input_ids_completos)))\n",
        "\n",
        "    # =========================\n",
        "    #      Seleciona os Lotes\n",
        "    # =========================    \n",
        "    \n",
        "    # Classifique as duas listas pelo comprimento da sequência de entrada.\n",
        "    amostras = sorted(zip(input_ids_completos), key=lambda x: len(x[0]))\n",
        "\n",
        "    del input_ids_completos\n",
        "    \n",
        "    #logging.info(\"{:>10,} amostras após classificação.\".format(len(amostras)))\n",
        "\n",
        "    # Lista de lotes que iremos construir.\n",
        "    batch_ordered_documentos = []\n",
        "    batch_ordered_classes = []\n",
        "\n",
        "    logging.info(\"Criando lotes de tamanho {:}...\".format(batch_size))\n",
        "\n",
        "    # Faça um loop em todas as amostras de entrada ... \n",
        "    while len(amostras) > 0:\n",
        "        \n",
        "        # Mostra o progresso.\n",
        "        # if ((len(batch_ordered_documentos) % intervalo_atualizacao) == 0 \\          \n",
        "          #  and not len(batch_ordered_documentos) == 0):\n",
        "           #logging.info(\"  Selecionado {:,} lotes.\".format(len(batch_ordered_documentos)))\n",
        "        \n",
        "        # `to_take` é o tamanho real do nosso lote. Será `batch_size` até\n",
        "        # chegamos ao último lote, que pode ser menor.\n",
        "        to_take = min(batch_size, len(amostras))\n",
        "        \n",
        "        # Escolha um índice aleatório na lista de amostras restantes para começar o nosso lote.\n",
        "        select = random.randint(0, len(amostras) - to_take)\n",
        "\n",
        "        # Selecione um lote contíguo de amostras começando em `select`.\n",
        "        #print (\"Selecionando lote de {:} a {:}\".format(select, select+to_take))\n",
        "        batch = amostras[select:(select + to_take)]\n",
        "\n",
        "        #print(\"Tamanho do lote:\", len(batch))\n",
        "        \n",
        "        # Cada amostra é uma tupla --divida para criar uma lista separada de\n",
        "        # sequências e uma lista de rótulos para este lote.\n",
        "        batch_ordered_documentos.append([s[0] for s in batch])\n",
        "                \n",
        "        # Remova a amostra da lista\n",
        "        del amostras[select:select + to_take]\n",
        "\n",
        "    logging.info(\"  FEITO - Selecionado {:,} lotes.\".format(len(batch_ordered_documentos)))\n",
        "\n",
        "    # =========================\n",
        "    #        Adicionando o preenchimento\n",
        "    # =========================    \n",
        "\n",
        "    # logging.info(\"Preenchendo sequências dentro de cada lote...\")\n",
        "\n",
        "    py_input_ids = []\n",
        "    py_attention_masks = []\n",
        "\n",
        "    # Para cada lote...\n",
        "    for batch_input_ids in batch_ordered_documentos:\n",
        "\n",
        "        # Nova versão do lote, desta vez com sequências preenchidas e agora com\n",
        "        # as máscaras de atenção definidas.\n",
        "        batch_padded_input_ids = []\n",
        "        batch_attention_masks = []\n",
        "                \n",
        "        # Primeiro, encontre a amostra mais longa do lote.\n",
        "        # Observe que as sequências atualmente incluem os tokens especiais!\n",
        "        max_size = max([len(input) for input in batch_input_ids])\n",
        "                \n",
        "        # Para cada entrada neste lote...\n",
        "        for input in batch_input_ids:\n",
        "                        \n",
        "            # Quantos tokens pad precisam ser adicionados\n",
        "            num_pads = max_size - len(input)\n",
        "\n",
        "            # Adiciona `num_pads` do pad token(tokenizer.pad_token_id) até o final da sequência.\n",
        "            padded_input = input + [tokenizer.pad_token_id] * num_pads\n",
        "\n",
        "            # Define a máscara de atenção --é apenas um `1` para cada token real\n",
        "            # e um `0` para cada token de preenchimento(pad).\n",
        "            attention_mask = [1] * len(input) + [0] * num_pads\n",
        "                        \n",
        "            # Adiciona o resultado preenchido ao lote.\n",
        "            batch_padded_input_ids.append(padded_input)\n",
        "            batch_attention_masks.append(attention_mask)\n",
        "\n",
        "            del padded_input\n",
        "            del attention_mask\n",
        "        \n",
        "        # Nosso lote foi preenchido, portanto, precisamos salvar este lote atualizado.\n",
        "        # Também precisamos que as entradas sejam tensores PyTorch, então faremos isso aqui.\n",
        "        py_input_ids.append(torch.tensor(batch_padded_input_ids))\n",
        "        py_attention_masks.append(torch.tensor(batch_attention_masks))\n",
        "\n",
        "        del batch_padded_input_ids\n",
        "        del batch_attention_masks\n",
        "\n",
        "    del batch_ordered_documentos\n",
        "    del batch_ordered_classes\n",
        "    \n",
        "    del tokenizer    \n",
        "\n",
        "    # Retorna o conjunto de dados em lotes inteligentes!\n",
        "    return (py_input_ids, py_attention_masks)"
      ],
      "metadata": {
        "id": "6u8rFCPdKi2o"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzk8VOp7oy8n"
      },
      "source": [
        "# 7 - Funções auxiliares spaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### getStopwords\n",
        "\n",
        "Recupera as stopwords do spaCy"
      ],
      "metadata": {
        "id": "AEzytjZi5Iw2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKg-_XyWoy8o"
      },
      "source": [
        "def getStopwords(nlp):\n",
        "    \"\"\"\n",
        "      Recupera as stop words do nlp(Spacy).\n",
        "    \n",
        "      Parâmetros:\n",
        "        `nlp` - Um modelo spaCy carregado.           \n",
        "    \"\"\"\n",
        "    \n",
        "    spacy_stopwords = nlp.Defaults.stop_words\n",
        "\n",
        "    return spacy_stopwords "
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZdNFrC3oy8p"
      },
      "source": [
        "Lista dos stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1o8jevtoy8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fba46dee-74db-4e61-bcdb-426d21b5111b"
      },
      "source": [
        "logging.info(\"Quantidade de stopwords: {}.\".format(len(getStopwords(nlp))))\n",
        "\n",
        "print(getStopwords(nlp))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-29 22:20:39,019 : INFO : Quantidade de stopwords: 413.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tendes', 'bastante', 'portanto', 'põem', 'ela', 'grupo', 'vinte', 'contudo', 'pois', 'dezasseis', 'adeus', 'sois', 'três', 'tenho', 'assim', 'desta', 'foram', 'para', 'tive', 'favor', 'onze', 'seus', 'tudo', 'ter', 'menor', 'nove', 'povo', 'estava', 'estado', 'também', 'baixo', 'já', 'como', 'vai', 'vem', 'nada', 'valor', 'parece', 'enquanto', 'fazia', 'na', 'tiveste', 'partir', 'longe', 'vos', 'quarto', 'vossos', 'algo', 'oito', 'essa', 'tivemos', 'umas', 'teu', 'área', 'tal', 'conselho', 'com', 'fora', 'vais', 'numa', 'pela', 'fazeis', 'embora', 'obrigado', 'terceira', 'cujo', 'veja', 'cá', 'nessa', 'nosso', 'vocês', 'cuja', 'do', 'ainda', 'sem', 'posição', 'eventual', 'certamente', 'inicio', 'faz', 'lhe', 'fez', 'lugar', 'tem', 'tentaram', 'geral', 'menos', 'onde', 'estar', 'desse', 'temos', 'poderá', 'outras', 'vós', 'dar', 'conhecido', 'sexta', 'tentei', 'boa', 'breve', 'devem', 'somente', 'apoia', 'quanto', 'duas', 'obrigada', 'então', 'aí', 'só', 'tente', 'aquilo', 'possível', 'momento', 'um', 'quem', 'nossos', 'direita', 'elas', 'sua', 'cima', 'grandes', 'cada', 'agora', 'estiveste', 'qual', 'seria', 'aqueles', 'quer', 'mal', 'num', 'outra', 'aqui', 'caminho', 'alguns', 'tanta', 'primeiro', 'fazer', 'novos', 'sexto', 'foste', 'ligado', 'sabe', 'outros', 'daquela', 'seis', 'após', 'estará', 'coisa', 'se', 'todos', 'ontem', 'nossa', 'irá', 'porque', 'sobre', 'bem', 'próprio', 'fazes', 'depois', 'tempo', 'eles', 'está', 'tu', 'quinto', 'das', 'através', 'local', 'vossa', 'põe', 'novo', 'toda', 'estes', 'novas', 'és', 'meus', 'vinda', 'estivemos', 'uma', 'aquelas', 'corrente', 'custa', 'for', 'perto', 'apoio', 'ver', 'sob', 'por', 'sétima', 'dizem', 'dois', 'quinze', 'estas', 'tiveram', 'logo', 'mês', 'tentar', 'no', 'este', 'usar', 'esteve', 'isso', 'você', 'estiveram', 'faço', 'dá', 'deste', 'fazemos', 'fui', 'estão', 'minha', 'porquanto', 'poder', 'pegar', 'mas', 'muito', 'nova', 'quieta', 'quando', 'bom', 'próximo', 'segundo', 'nem', 'é', 'qualquer', 'que', 'sétimo', 'porém', 'dizer', 'pelos', 'quarta', 'quero', 'eu', 'apontar', 'dessa', 'dos', 'maioria', 'vão', 'ora', 'máximo', 'relação', 'nesse', 'dão', 'meu', 'muitos', 'possivelmente', 'sete', 'são', 'isto', 'uns', 'aquele', 'vez', 'sou', 'puderam', 'lá', 'mil', 'pouco', 'tais', 'estive', 'nas', 'dez', 'nunca', 'teve', 'quais', 'daquele', 'esta', 'ou', 'vens', 'estivestes', 'pelo', 'tarde', 'estás', 'ele', 'foi', 'dezanove', 'número', 'sim', 'treze', 'esses', 'ir', 'próxima', 'mais', 'des', 'quatro', 'ser', 'debaixo', 'nenhuma', 'usa', 'pôde', 'vindo', 'sei', 'tua', 'pontos', 'doze', 'fostes', 'tanto', 'vezes', 'forma', 'tão', 'até', 'quinta', 'contra', 'demais', 'às', 'apenas', 'essas', 'disso', 'nesta', 'vários', 'vosso', 'era', 'aos', 'deverá', 'meio', 'nossas', 'podem', 'terceiro', 'ambas', 'grande', 'lado', 'fará', 'atrás', 'iniciar', 'questão', 'comprida', 'suas', 'vossas', 'antes', 'te', 'último', 'querem', 'fazem', 'fomos', 'ambos', 'deve', 'tens', 'segunda', 'dezassete', 'certeza', 'em', 'acerca', 'esse', 'falta', 'fim', 'meses', 'oitava', 'todo', 'pouca', 'ali', 'cinco', 'desde', 'naquela', 'tipo', 'posso', 'pelas', 'seu', 'de', 'zero', 'conhecida', 'números', 'teus', 'da', 'dezoito', 'pode', 'sempre', 'porquê', 'diz', 'minhas', 'saber', 'não', 'primeira', 'oitavo', 'nuns', 'quieto', 'podia', 'somos', 'parte', 'aquela', 'tuas', 'nível', 'nós', 'sistema', 'final', 'têm', 'as', 'talvez', 'ademais', 'algumas', 'cento', 'dentro', 'ao', 'entre', 'cedo', 'estou', 'nos', 'quê', 'mesmo', 'maiorias', 'à', 'além', 'diante', 'maior', 'naquele', 'catorze', 'exemplo', 'ponto', 'os', 'me', 'todas', 'tivestes', 'comprido', 'vêm', 'inclusive', 'neste'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4Soqt3fp3Lu"
      },
      "source": [
        "### getListaTokensPOSSentenca\n",
        "\n",
        "Retorna duas listas uma com os tokens e a outra com a POS-Tagging dos tokens da sentenca."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvd99wd_pwmt"
      },
      "source": [
        "def getListaTokensPOSSentenca(sentenca):\n",
        "  # Verifica se o sentenca não foi processado pelo spaCy  \n",
        "  if type(sentenca) is not spacy.tokens.doc.Doc:\n",
        "      # Realiza o parsing no spacy\n",
        "      doc = nlp(sentenca)\n",
        "  else:\n",
        "      doc = sentenca\n",
        "\n",
        "  # Lista dos tokens\n",
        "  listatokens = []\n",
        "  listapos = []\n",
        "\n",
        "  # Percorre a sentença adicionando os tokens e as POS\n",
        "  for token in doc:    \n",
        "    listatokens.append(token.text)\n",
        "    listapos.append(token.pos_)\n",
        "    \n",
        "  return listatokens, listapos"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8 - Exemplo de visualização\n",
        "\n",
        "Artigo https://arxiv.org/pdf/1611.05469v1.pdf\n",
        "\n",
        "https://towardsdatascience.com/bert-visualization-in-embedding-projector-dfe4c9e18ca9\n",
        "\n",
        "https://krishansubudhi.github.io/deeplearning/2020/08/27/bert-embeddings-visualization.html\n",
        "\n",
        "https://amitness.com/interactive-sentence-embeddings/"
      ],
      "metadata": {
        "id": "1qezcBkxnEdR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Documentos a serem visualizados\n",
        "\n",
        "Crie uma lista com os documentos a serem visualizados."
      ],
      "metadata": {
        "id": "AulP5iWUK7Uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentos = [\"Como enfileirar elementos em uma fila?\",      \n",
        "\"Como desenfileirar elementos em uma fila?\",\n",
        "\"Como empilhar elementos em uma pilha?\",\n",
        "\"Como empilhar e desempilhar elementos em uma pilha?\",\n",
        "\"Como empilhar elementos em uma estrutura de dados pilha?\",\n",
        "\"Como empilhar e desempilhar elementos em uma estrutura de dados pilha?\",\n",
        "\"Como desempilhar elementos em uma pilha?\",\n",
        "\"Como desempilhar elementos em uma estrutura de dados pilha?\",\n",
        "\"O que é uma pilha e como empilhar seu elemento?\",\n",
        "\"O que é uma fila e como enfileirar seu elemento?\",\n",
        "\"O que é uma fila e como desenfileirar um elemento nela?\",\n",
        "\"O que é uma pilha e como desempilhar um elemento nela?\",\n",
        "\"O que é uma fila e como enfileirar um elemento nela?\",\n",
        "\"O que é uma pilha e como empilhar um elemento nela?\",\n",
        "\"O que é uma pilha e como empilhar e desempilhar seus elementos?\",\n",
        "\"O que é uma fila e como enfileirar e desenfileirar seus elementos?\",\n",
        "\"Como são implementadas as operações de empilhar e desempilhar elementos em uma pilha?\",\n",
        "\"Como são implementadas as operações de enfileirar e desenfileirar elementos em uma fila?\",\n",
        "\"Em uma pilha a operação de empilhar ocorre em qual extremidade?\",\n",
        "\"Em uma fila a operação de enfileirar ocorre em qual extremidade?\"]\n",
        "\n",
        "print(\"Quantidade de docucmentos:\", len(documentos))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeKykKHDxKaM",
        "outputId": "4bca6096-19a1-41ac-e09c-34ea115a7e51"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade de docucmentos: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gera os embeddings dos documentos"
      ],
      "metadata": {
        "id": "XH14_8Ex-j4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lista_embeddings = []\n",
        "lista_documentos_tokenizado = []\n",
        "\n",
        "maior_sequencia = 0\n",
        "\n",
        "total_tokens = 0\n",
        "\n",
        "# Percorre os documentos\n",
        "for i, documento in enumerate(documentos):\n",
        "  \n",
        "    # Gera embeddings utilizando as 4 últimas camadas do BERT\n",
        "    # token_embeddings, documento_tokenizado =  getEmbeddingsUltimaCamada(documento, model, tokenizer)\n",
        "\n",
        "    # Gera embeddings concatenando as 4 últimas camadas do BERT\n",
        "    token_embeddings, documento_tokenizado = getEmbeddingsConcat4UltimasCamadas(documento, model, tokenizer)\n",
        "    \n",
        "    # Guarda o maior tamanho de documento\n",
        "    if len(documento_tokenizado) > maior_sequencia:\n",
        "        maior_sequencia =  len(documento_tokenizado)\n",
        "\n",
        "    # Guarda o total de tokens dos documentos\n",
        "    total_tokens = total_tokens + len(documento_tokenizado)\n",
        "\n",
        "    # Guarda os embeddings e o documento tokenizado\n",
        "    lista_embeddings.append(token_embeddings)\n",
        "    lista_documentos_tokenizado.append(documento_tokenizado)    "
      ],
      "metadata": {
        "id": "ci-w8ZFF97I7"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostra um documento processado."
      ],
      "metadata": {
        "id": "HiZ5QDuwjLXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(lista_embeddings[0]))\n",
        "print(lista_documentos_tokenizado[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJT4pMDVjG5e",
        "outputId": "dfbe11f7-3a05-4dca-9bbf-de72bf95fb2e"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n",
            "['[CLS]', 'Como', 'enf', '##ile', '##ira', '##r', 'elementos', 'em', 'uma', 'fil', '##a', '?', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantidade de tokens nos documentos"
      ],
      "metadata": {
        "id": "dkk2P44kMwql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Quantidade de tokens:\", total_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CJEdUc-Mz1Q",
        "outputId": "d91039e6-59b4-4d9e-a59a-204fff2143d1"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade de tokens: 336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maior tamanho  de documento"
      ],
      "metadata": {
        "id": "2kDAImEyK1JE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"max_seq_length:\", maior_sequencia)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cswsAdWd_Bta",
        "outputId": "f9993e2e-39b2-4133-b8c6-5b292cfcca24"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_seq_length: 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gera os arquivos para o Embedding Projector"
      ],
      "metadata": {
        "id": "7VPZ70UJKxjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arquivos com os valores dos embeddings"
      ],
      "metadata": {
        "id": "GCQZLYgPKxjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Sufixo do arquivo\n",
        "sufixo_arquivo = \"_\" + str(lista_embeddings[0].size()[1]) + \"_\" + TAMANHO_BERT\n",
        "\n",
        "# Abre o arquivo\n",
        "with open(\"records\" + sufixo_arquivo + \".tsv\", 'w') as tsvfile:\n",
        "  # Cria um arquivo separado por tab\n",
        "    writer = csv.writer(tsvfile, delimiter='\\t')\n",
        "    \n",
        "    # Percorre os embeddings\n",
        "    for i, documento_embedding in enumerate(lista_embeddings):\n",
        "\n",
        "        # Converte os tensores em numpy array\n",
        "        documento_embedding_np =  documento_embedding.numpy()        \n",
        "        # Qtde de tokens do documento\n",
        "        length = len(lista_documentos_tokenizado[i]) \n",
        "        \n",
        "        # Escreve no arquivo os embeddings do documento       \n",
        "        writer.writerows(documento_embedding_np[:length])     \n",
        "        "
      ],
      "metadata": {
        "id": "XcsQK9ykDY-d"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arquivo com os metadados dos embeddings"
      ],
      "metadata": {
        "id": "LALRlVGbU1AF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Sufixo do arquivo\n",
        "sufixo_arquivo = \"_\" + str(lista_embeddings[0].size()[1]) + \"_\" + TAMANHO_BERT\n",
        "\n",
        "# Abre o arquivo\n",
        "with open(\"meta\" + sufixo_arquivo + \".tsv\", 'w') as tsvfile:\n",
        "    # Define o escritor do arquivo\n",
        "    writer = csv.writer(tsvfile, delimiter='\\t')\n",
        "    \n",
        "    # Cabeçalho do arquivo\n",
        "    writer.writerow([\"Token\", \"Sentença\"])    \n",
        "\n",
        "    # Percorre os embeddings\n",
        "    for i, documento_embedding in enumerate(lista_embeddings):\n",
        "        length = len(lista_documentos_tokenizado[i])        \n",
        "        \n",
        "        # Escreve a palavra e sua sentença\n",
        "        for j in range(length):            \n",
        "            s = [lista_documentos_tokenizado[i][j], documentos[i]]\n",
        "            writer.writerow(s)"
      ],
      "metadata": {
        "id": "2JYRqx67HeKS"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Faça o download dos arquivos **records_4096.tsv** e **meta_4096.tsv** e carregue em https://projector.tensorflow.org/ na opção load.\n",
        "\n",
        "Carrega os arquivos na ferramenta através do link \"Load\". Na opção existe um link botão para carregar o arquivo dos embeddings e um outro botão para carregar os metadados.\n",
        "\n",
        "\n",
        "\n",
        "Você também pode utilizar um link a um arquivo de configuração config.json com a referência aos arquivos em algum repositório publico na internet, por exemplo github ou gist\n",
        "\n",
        "\n",
        "Aqui um exemplo.\n",
        "\n",
        "https://projector.tensorflow.org/?config=https://raw.githubusercontent.com/osmarbraz/cohebertv1visualizacao/main/config.json\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BY8zaGdnNMx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9 - Exemplo de visualização com pooling de embeddings\n",
        "\n",
        "Combina os embeddings de tokens de palavras fora do vocabulário do BERT realizando a média."
      ],
      "metadata": {
        "id": "cEW9IB_8hQSy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEtmDaKqAL-9"
      },
      "source": [
        "### getTokensEmbeddingsPOSSentenca\n",
        "Gera os tokens, POS e embeddings de cada sentença."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "MXPWq5JyIoQf"
      },
      "outputs": [],
      "source": [
        "# Dicionário de tokens de exceções e seus deslocamentos para considerar mais tokens do BERT em relação ao spaCy\n",
        "# A tokenização do BERT gera mais tokens que a tokenização das palavras do spaCy\n",
        "dic_excecao_maior = {\"\":-1,\n",
        "                    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "89oBywgbIxzV"
      },
      "outputs": [],
      "source": [
        "def getExcecaoDicMaior(token, dic_excecao_maior):   \n",
        "    \n",
        "  valor = dic_excecao_maior.get(token)\n",
        "  if valor != None:\n",
        "      return valor\n",
        "  else:\n",
        "      return -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "MPODj-AWfhxW"
      },
      "outputs": [],
      "source": [
        "# Dicionário de tokens de exceções e seus deslocamentos para considerar menos tokens do BERT em relação ao spaCy\n",
        "# A tokenização do BERT gera menos tokens que a tokenização das palavras do spaCy\n",
        "dic_excecao_menor = {\"1°\":1,\n",
        "                    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "xy2bzLBWfeqi"
      },
      "outputs": [],
      "source": [
        "def getExcecaoDicMenor(token, dic_excecao_menor):   \n",
        "    \n",
        "  valor = dic_excecao_menor.get(token)\n",
        "  if valor != None:\n",
        "      return valor\n",
        "  else:\n",
        "      return -1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Função que retorna os embeddings, tokens e POS da sentença com um mesmo tamanho."
      ],
      "metadata": {
        "id": "LLRdNsbo0qxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa a biblioteca\n",
        "import torch\n",
        "\n",
        "def getTokensEmbeddingsPOSSentenca(embeddingDocumento, \n",
        "                                   tokenBERTDocumento, \n",
        "                                   sentenca):\n",
        "    \"\"\"    \n",
        "      Retorna os tokens, as postagging e os embeddings dos tokens igualando a quantidade de tokens do spaCy com a tokenização do BERT de acordo com a estratégia. \n",
        "      Usa a estratégia MEAN para calcular a média dos embeddings dos tokens que formam uma palavra.\n",
        "      Usa a estratégia MAX para calcular o valor máximo dos embeddings dos tokens que formam uma palavra.\n",
        "    \"\"\"\n",
        "   \n",
        "    #Guarda os tokens e embeddings\n",
        "    listaTokens = []\n",
        "    listaEmbeddingsMEAN = []\n",
        "    listaEmbeddingsMAX = []\n",
        "    \n",
        "    # Gera a tokenização e POS-Tagging da sentença    \n",
        "    sentenca_token, sentenca_pos = getListaTokensPOSSentenca(sentenca)\n",
        "\n",
        "    # print(\"\\nsentenca          :\",sentenca)    \n",
        "    # print(\"sentenca_token      :\",sentenca_token)\n",
        "    # print(\"len(sentenca_token) :\",len(sentenca_token))    \n",
        "    # print(\"sentenca_pos        :\",sentenca_pos)\n",
        "    # print(\"len(sentenca_pos)   :\",len(sentenca_pos))\n",
        "    \n",
        "    # Recupera os embeddings da sentença dos embeddings do documento    \n",
        "    embeddingSentenca = embeddingDocumento    \n",
        "    sentencaTokenizadaBert = tokenBERTDocumento\n",
        "    \n",
        "    # embedding <qtde_tokens x 4096>        \n",
        "    # print(\"embeddingSentenca          :\",embeddingSentenca.shape)\n",
        "    # print(\"sentencaTokenizadaBert     :\",sentencaTokenizadaBert)\n",
        "    # print(\"len(sentencaTokenizadaBert):\",len(sentencaTokenizadaBert))\n",
        "\n",
        "    # Seleciona os pares de palavra a serem avaliadas\n",
        "    posWi = 0 # Posição do token da palavra gerado pelo spaCy\n",
        "    posWj = posWi # Posição do token da palavra gerado pelo BERT\n",
        "    pos2 = -1\n",
        "\n",
        "    # Enquanto o indíce da palavra posWj(2a palavra) não chegou ao final da quantidade de tokens do BERT\n",
        "    while posWj < len(sentencaTokenizadaBert):  \n",
        "\n",
        "      # Seleciona os tokens da sentença\n",
        "      Wi = sentenca_token[posWi] # Recupera o token da palavra gerado pelo spaCy\n",
        "      Wi1 = \"\"\n",
        "      pos2 = -1\n",
        "      if posWi+1 < len(sentenca_token):\n",
        "        Wi1 = sentenca_token[posWi+1] # Recupera o próximo token da palavra gerado pelo spaCy\n",
        "  \n",
        "        # Localiza o deslocamento da exceção        \n",
        "        pos2 = getExcecaoDicMenor(Wi+Wi1, dic_excecao_menor)  \n",
        "        #print(\"Exceção pos2:\", pos2)\n",
        "\n",
        "      Wj = sentencaTokenizadaBert[posWj] # Recupera o token da palavra gerado pelo BERT\n",
        "      # print(\"Wi[\",posWi,\"]=\", Wi)\n",
        "      # print(\"Wj[\",posWj,\"]=\", Wj)\n",
        "\n",
        "      # Tratando exceções\n",
        "      # Localiza o deslocamento da exceção\n",
        "      pos = getExcecaoDicMaior(Wi, dic_excecao_maior)  \n",
        "      #print(\"Exceção pos:\", pos)\n",
        "            \n",
        "      if pos != -1 or pos2 != -1:      \n",
        "        if pos != -1:\n",
        "          #print(\"Adiciona 1 Exceção palavra == Wi or palavra = [UNK]:\",Wi)\n",
        "          listaTokens.append(Wi)          \n",
        "          # Verifica se tem mais de um token\n",
        "          if pos != 1:\n",
        "            indiceToken = posWj + pos\n",
        "            #print(\"Calcula a média de :\", posWj , \"até\", indiceToken)\n",
        "            embeddingsTokensPalavra = embeddingSentenca[posWj:indiceToken]\n",
        "            #print(\"embeddingsTokensPalavra:\",embeddingsTokensPalavra.shape)\n",
        "            # calcular a média dos embeddings dos tokens do BERT da palavra\n",
        "            embeddingEstrategiaMEAN = torch.mean(embeddingsTokensPalavra, dim=0)\n",
        "            #print(\"embeddingEstrategiaMEAN:\",embeddingEstrategiaMEAN.shape)\n",
        "            listaEmbeddingsMEAN.append(embeddingEstrategiaMEAN)\n",
        "\n",
        "            # calcular o máximo dos embeddings dos tokens do BERT da palavra\n",
        "            embeddingEstrategiaMAX, linha = torch.max(embeddingsTokensPalavra, dim=0)\n",
        "            #print(\"embeddingEstrategiaMAX:\",embeddingEstrategiaMAX.shape)\n",
        "            listaEmbeddingsMAX.append(embeddingEstrategiaMAX)\n",
        "          else:\n",
        "            # Adiciona o embedding do token a lista de embeddings\n",
        "            listaEmbeddingsMEAN.append(embeddingSentenca[posWj])            \n",
        "            listaEmbeddingsMAX.append(embeddingSentenca[posWj])\n",
        "         \n",
        "          # Avança para a próxima palavra e token do BERT\n",
        "          posWi = posWi + 1\n",
        "          posWj = posWj + pos\n",
        "          #print(\"Proxima:\")            \n",
        "          #print(\"Wi[\",posWi,\"]=\", sentenca_token[posWi])\n",
        "          #print(\"Wj[\",posWj,\"]=\", sentencaTokenizadaBert[posWj])\n",
        "        else:\n",
        "          if pos2 != -1:\n",
        "            #print(\"Adiciona 1 Exceção palavra == Wi or palavra = [UNK]:\",Wi)\n",
        "            listaTokens.append(Wi+Wi1)          \n",
        "            # Verifica se tem mais de um token\n",
        "            if pos2 == 1: \n",
        "              # Adiciona o embedding do token a lista de embeddings\n",
        "              listaEmbeddingsMEAN.append(embeddingSentenca[posWj])\n",
        "              listaEmbeddingsMAX.append(embeddingSentenca[posWj])\n",
        "          \n",
        "            # Avança para a próxima palavra e token do BERT\n",
        "            posWi = posWi + 2\n",
        "            posWj = posWj + pos2\n",
        "            #print(\"Proxima:\")            \n",
        "            #print(\"Wi[\",posWi,\"]=\", sentenca_token[posWi])\n",
        "            #print(\"Wj[\",posWj,\"]=\", sentencaTokenizadaBert[posWj])\n",
        "      else:  \n",
        "        # Tokens iguais adiciona a lista, o token não possui subtoken\n",
        "        if (Wi == Wj or Wj==\"[UNK]\"):\n",
        "          # Adiciona o token a lista de tokens\n",
        "          #print(\"Adiciona 2 Wi==Wj or Wj==[UNK]:\", Wi )\n",
        "          listaTokens.append(Wi)          \n",
        "          # Adiciona o embedding do token a lista de embeddings\n",
        "          listaEmbeddingsMEAN.append(embeddingSentenca[posWj])\n",
        "          listaEmbeddingsMAX.append(embeddingSentenca[posWj])\n",
        "          #print(\"embedding1[posWj]:\", embeddingSentenca[posWj].shape)\n",
        "          # Avança para a próxima palavra e token do BERT\n",
        "          posWi = posWi + 1\n",
        "          posWj = posWj + 1   \n",
        "              \n",
        "        else:          \n",
        "          # A palavra foi tokenizada pelo Wordpice com ## ou diferente do spaCy ou desconhecida\n",
        "          # Inicializa a palavra a ser montada          \n",
        "          palavraPOS = Wj\n",
        "          indiceToken = posWj + 1                 \n",
        "          while  ((palavraPOS != Wi) and indiceToken < len(sentencaTokenizadaBert)):\n",
        "              if \"##\" in sentencaTokenizadaBert[indiceToken]:\n",
        "                # Remove os caracteres \"##\" do token\n",
        "                parte = sentencaTokenizadaBert[indiceToken][2:]\n",
        "              else:                \n",
        "                parte = sentencaTokenizadaBert[indiceToken]\n",
        "              \n",
        "              palavraPOS = palavraPOS + parte\n",
        "              #print(\"palavraPOS:\",palavraPOS)\n",
        "              # Avança para o próximo token do BERT\n",
        "              indiceToken = indiceToken + 1\n",
        "\n",
        "          #print(\"\\nMontei palavra:\",palavraPOS)\n",
        "          if (palavraPOS == Wi or palavraPOS == \"[UNK]\"):\n",
        "              # Adiciona o token a lista\n",
        "              #print(\"Adiciona 3 palavra == Wi or palavraPOS = [UNK]:\",Wi)\n",
        "              listaTokens.append(Wi)\n",
        "              # Calcula a média dos tokens da palavra\n",
        "              #print(\"Calcula o máximo :\", posWj , \"até\", indiceToken)\n",
        "              embeddingsTokensPalavra = embeddingSentenca[posWj:indiceToken]\n",
        "              #print(\"embeddingsTokensPalavra2:\",embeddingsTokensPalavra)\n",
        "              #print(\"embeddingsTokensPalavra2:\",embeddingsTokensPalavra.shape)\n",
        "              \n",
        "              # calcular a média dos embeddings dos tokens do BERT da palavra\n",
        "              embeddingEstrategiaMEAN = torch.mean(embeddingsTokensPalavra, dim=0)        \n",
        "              #print(\"embeddingEstrategiaMEAN:\",embeddingEstrategiaMEAN)\n",
        "              #print(\"embeddingEstrategiaMEAN.shape:\",embeddingEstrategiaMEAN.shape)      \n",
        "              listaEmbeddingsMEAN.append(embeddingEstrategiaMEAN)\n",
        "             \n",
        "              # calcular o valor máximo dos embeddings dos tokens do BERT da palavra\n",
        "              embeddingEstrategiaMAX, linha = torch.max(embeddingsTokensPalavra, dim=0)\n",
        "              #print(\"embeddingEstrategiaMAX:\",embeddingEstrategiaMAX)\n",
        "              #print(\"embeddingEstrategiaMAX.shape:\",embeddingEstrategiaMAX.shape)     \n",
        "              listaEmbeddingsMAX.append(embeddingEstrategiaMAX)\n",
        "\n",
        "          # Avança para o próximo token do spaCy\n",
        "          posWi = posWi + 1\n",
        "          # Pula para o próximo token do BERT\n",
        "          posWj = indiceToken\n",
        "    \n",
        "    # Verificação se as listas estão com o mesmo tamanho\n",
        "    #if (len(listaTokens) != len(sentenca_token)) or (len(listaEmbeddingsMEAN) != len(sentenca_token)):\n",
        "    if (len(listaTokens) !=  len(listaEmbeddingsMEAN)):\n",
        "       print(\"\\nsentenca                :\",sentenca)         \n",
        "       print(\"sentenca_pos            :\",sentenca_pos)\n",
        "       print(\"sentenca_token          :\",sentenca_token)\n",
        "       print(\"sentencaTokenizadaBert  :\",sentencaTokenizadaBert)\n",
        "       print(\"listaTokens             :\",listaTokens)        \n",
        "       print(\"len(listaTokens)        :\",len(listaTokens))       \n",
        "       print(\"listaEmbeddingsMEAN     :\",listaEmbeddingsMEAN)\n",
        "       print(\"len(listaEmbeddingsMEAN):\",len(listaEmbeddingsMEAN))\n",
        "       print(\"listaEmbeddingsMAX      :\",listaEmbeddingsMAX)\n",
        "       print(\"len(listaEmbeddingsMAX) :\",len(listaEmbeddingsMAX))\n",
        "\n",
        "    del embeddingSentenca\n",
        "    del tokenBERTDocumento\n",
        "    del sentencaTokenizadaBert\n",
        "    del sentenca_token\n",
        "\n",
        "    return listaTokens, sentenca_pos, listaEmbeddingsMEAN, listaEmbeddingsMAX"
      ],
      "metadata": {
        "id": "rhqh2qFd4pIv"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Documentos a serem visualizados\n",
        "\n",
        "Crie uma lista com os documentos a serem visualizados."
      ],
      "metadata": {
        "id": "uyYriYT4hQS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentos = [\"Como enfileirar elementos em uma fila?\",      \n",
        "\"Como desenfileirar elementos em uma fila?\",\n",
        "\"Como empilhar elementos em uma pilha?\",\n",
        "\"Como empilhar e desempilhar elementos em uma pilha?\",\n",
        "\"Como empilhar elementos em uma estrutura de dados pilha?\",\n",
        "\"Como empilhar e desempilhar elementos em uma estrutura de dados pilha?\",\n",
        "\"Como desempilhar elementos em uma pilha?\",\n",
        "\"Como desempilhar elementos em uma estrutura de dados pilha?\",\n",
        "\"O que é uma pilha e como empilhar seu elemento?\",\n",
        "\"O que é uma fila e como enfileirar seu elemento?\",\n",
        "\"O que é uma fila e como desenfileirar um elemento nela?\",\n",
        "\"O que é uma pilha e como desempilhar um elemento nela?\",\n",
        "\"O que é uma fila e como enfileirar um elemento nela?\",\n",
        "\"O que é uma pilha e como empilhar um elemento nela?\",\n",
        "\"O que é uma pilha e como empilhar e desempilhar seus elementos?\",\n",
        "\"O que é uma fila e como enfileirar e desenfileirar seus elementos?\",\n",
        "\"Como são implementadas as operações de empilhar e desempilhar elementos em uma pilha?\",\n",
        "\"Como são implementadas as operações de enfileirar e desenfileirar elementos em uma fila?\",\n",
        "\"Em uma pilha a operação de empilhar ocorre em qual extremidade?\",\n",
        "\"Em uma fila a operação de enfileirar ocorre em qual extremidade?\"]\n",
        "\n",
        "print(\"Quantidade de docucmentos:\", len(documentos))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aa992ed-4cb2-49de-8433-3367721d4c2c",
        "id": "vqOUcGcfhQS-"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade de docucmentos: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gera os embeddings dos documentos"
      ],
      "metadata": {
        "id": "YWrqyq31hQS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lista_embeddings = []\n",
        "lista_documentos_tokenizado = []\n",
        "\n",
        "maior_sequencia = 0\n",
        "\n",
        "total_tokens = 0\n",
        "\n",
        "# Percorre os documentos\n",
        "for i, documento in enumerate(documentos):\n",
        "  \n",
        "    # Gera embeddings utilizando as 4 últimas camadas do BERT\n",
        "    # token_embeddings, documento_tokenizado =  getEmbeddingsUltimaCamada(documento, model, tokenizer)\n",
        "\n",
        "    # Gera embeddings concatenando as 4 últimas camadas do BERT\n",
        "    token_embeddings, documento_tokenizado = getEmbeddingsConcat4UltimasCamadas(documento, model, tokenizer)\n",
        "\n",
        "    # Combina os embeddings de palavras fora do vocabulário do BERT\n",
        "    listaTokens1, listaPOS1, listaEmbeddingsMEAN1, listaEmbeddingsMAX1 =  getTokensEmbeddingsPOSSentenca(token_embeddings[1:-1],\n",
        "                                                                                                         documento_tokenizado[1:-1], \n",
        "                                                                                                         documento)\n",
        "  \n",
        "    # Guarda o maior tamanho de documento\n",
        "    if len(listaTokens1) > maior_sequencia:\n",
        "        maior_sequencia =  len(listaTokens1)\n",
        "\n",
        "    # Guarda o total de tokens dos documentos\n",
        "    total_tokens = total_tokens + len(listaTokens1)\n",
        "\n",
        "    # Guarda os embeddings e o documento tokenizado\n",
        "    lista_embeddings.append(listaEmbeddingsMEAN1)\n",
        "    lista_documentos_tokenizado.append(listaTokens1)    "
      ],
      "metadata": {
        "id": "N128_6q1hQS_"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostra um documento processado."
      ],
      "metadata": {
        "id": "JezKt4vhjPUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(lista_embeddings[0]))\n",
        "print(lista_documentos_tokenizado[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxA12sVaiYY0",
        "outputId": "a4282b45-38cf-489d-8f5b-67a86b143bbb"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "['Como', 'enfileirar', 'elementos', 'em', 'uma', 'fila', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantidade de tokens nos documentos"
      ],
      "metadata": {
        "id": "udGj7mfVhQS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Quantidade de tokens:\", total_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a26c269-2e50-4faa-fb41-71e5899f796d",
        "id": "Lrkl6jQuhQS_"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade de tokens: 217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maior tamanho  de documento"
      ],
      "metadata": {
        "id": "0G9kohhGhQS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"max_seq_length:\", maior_sequencia)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "633e05e8-7632-414e-a557-ffc78b252b1e",
        "id": "WyPhoXxyhQTA"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_seq_length: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gera os arquivos para o Embedding Projector"
      ],
      "metadata": {
        "id": "-zSJ9uMLhQTA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arquivos com os valores dos embeddings"
      ],
      "metadata": {
        "id": "vDKe0yt_hQTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Sufixo do arquivo\n",
        "sufixo_arquivo = \"_\" + str(lista_embeddings[0][0].size()[0]) + \"_\" + TAMANHO_BERT + \"_pool\"\n",
        "\n",
        "# Abre o arquivo\n",
        "with open(\"records\" + sufixo_arquivo + \".tsv\", 'w') as tsvfile:\n",
        "  # Cria um arquivo separado por tab\n",
        "    writer = csv.writer(tsvfile, delimiter='\\t')    \n",
        "\n",
        "    # Percorre os embeddings\n",
        "    for i, documento_embedding in enumerate(lista_embeddings):\n",
        "      \n",
        "        # Converte os tensores em numpy array\n",
        "        documento_embedding_np = []\n",
        "        for linha in documento_embedding:\n",
        "            novo = linha.numpy()\n",
        "            # print(len(novo))\n",
        "            # print(novo)\n",
        "            documento_embedding_np.append(novo)\n",
        "\n",
        "\n",
        "        # Qtde de tokens do documento\n",
        "        length = len(lista_documentos_tokenizado[i]) \n",
        "        # print(\"length:\", length)\n",
        "        # Escreve no arquivo os embeddings do documento       \n",
        "        writer.writerows(documento_embedding_np[:length])                "
      ],
      "metadata": {
        "id": "daCAHj1thQTA"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arquivo com os metadados dos embeddings"
      ],
      "metadata": {
        "id": "DkcJoKwwhQTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Sufixo do arquivo\n",
        "sufixo_arquivo = \"_\" + str(lista_embeddings[0][0].size()[0]) + \"_\" + TAMANHO_BERT + \"_pool\"\n",
        "\n",
        "# Abre o arquivo\n",
        "with open(\"meta\" + sufixo_arquivo + \".tsv\", 'w') as tsvfile:\n",
        "    # Define o escritor do arquivo\n",
        "    writer = csv.writer(tsvfile, delimiter='\\t')\n",
        "    \n",
        "    # Cabeçalho do arquivo\n",
        "    writer.writerow([\"Token\", \"Sentence\"])    \n",
        "\n",
        "    # Percorre os embeddings\n",
        "    for i, documento_embedding in enumerate(lista_embeddings):\n",
        "        length = len(lista_documentos_tokenizado[i])        \n",
        "        \n",
        "        # Escreve a palavra e sua sentença\n",
        "        for j in range(length):            \n",
        "            s = [lista_documentos_tokenizado[i][j], documentos[i]]\n",
        "            writer.writerow(s)"
      ],
      "metadata": {
        "id": "4robQVjFhQTA"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Faça o download dos arquivos **records_4096.tsv** e **meta_4096.tsv** e carregue em https://projector.tensorflow.org/ na opção load.\n",
        "\n",
        "Carrega os arquivos na ferramenta através do link \"Load\". Na opção existe um link botão para carregar o arquivo dos embeddings e um outro botão para carregar os metadados.\n",
        "\n",
        "\n",
        "\n",
        "Você também pode utilizar um link a um arquivo de configuração config.json com a referência aos arquivos em algum repositório publico na internet, por exemplo github ou gist\n",
        "\n",
        "\n",
        "Aqui um exemplo.\n",
        "\n",
        "https://projector.tensorflow.org/?config=https://raw.githubusercontent.com/osmarbraz/cohebertv1visualizacao/main/config.json\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5RgIexUdhQTB"
      }
    }
  ]
}